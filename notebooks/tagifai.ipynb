{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false,
    "colab": {
      "name": "tagifai.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42da19ab1c944b76a2f0ef935839550e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_644721e1a14c418e9e0fcada51fbffe2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8fc242b3d87742a39ac1cd99e7607eb8",
              "IPY_MODEL_5460c265079245548bed7ec01c0a95f8"
            ]
          }
        },
        "644721e1a14c418e9e0fcada51fbffe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fc242b3d87742a39ac1cd99e7607eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "3d",
              "action-localization",
              "action-recognition",
              "active-learning",
              "activity-recognition",
              "adversarial-attacks",
              "adversarial-defense",
              "adversarial-image-detection",
              "adversarial-learning",
              "adversarial-text",
              "angular",
              "animations",
              "annotation",
              "anomaly-detection",
              "arima",
              "artificial-general-intelligence",
              "attention",
              "audio-classification",
              "audio-generation",
              "audio-tagging",
              "autoencoders",
              "automl",
              "autonomous-vehicles",
              "aws",
              "azure",
              "backend",
              "bayesian-deep-learning",
              "bayesian-inference",
              "bidaf",
              "boundary-detection",
              "c",
              "c#",
              "c++",
              "caffe",
              "calibration",
              "camera-localization",
              "captioning",
              "causal-inference",
              "chainer",
              "character-embeddings",
              "chunking",
              "ci-cd",
              "classification",
              "clustering",
              "code-generation",
              "code-summarization",
              "collaborative-filtering",
              "collaborative-ranking",
              "colorization",
              "common-sense-reasoning",
              "computer-vision",
              "conditional-random-fields",
              "conditional-variational-autoencoders",
              "constituency-parsing",
              "contextualized-embeddings",
              "contour-detection",
              "contrastive-loss",
              "conversational-ai",
              "convolutional-neural-networks",
              "coreference-resolution",
              "coreml",
              "counterfactuals",
              "cropping",
              "cross-lingual",
              "crowd-counting",
              "css",
              "d3",
              "data-augmentation",
              "data-mining",
              "data-science",
              "data-summarization",
              "databases",
              "deblurring",
              "decision-making",
              "decision-trees",
              "deconvolution",
              "deep-learning",
              "deep-q-networks",
              "denoising",
              "density-estimation",
              "dependency-parsing",
              "depth-completion",
              "depth-estimation",
              "devops",
              "dialogue",
              "dictionary-learning",
              "dimensionality-reduction",
              "disease-prediction",
              "disparity-estimation",
              "distributed-training",
              "django",
              "dl4j",
              "dlib",
              "docker",
              "document-classification",
              "document-embeddings",
              "document-ranking",
              "domain-adaptation",
              "drug-discovery",
              "dynet",
              "edge-detection",
              "embeddings",
              "emotion-recognition",
              "enhancement",
              "entity-alignment",
              "entity-disambiguation",
              "entity-extraction",
              "entity-linking",
              "entity-resolution",
              "entity-typing",
              "expectation-maximization",
              "experiment-tracking",
              "exploratory-data-analysis",
              "face-detection",
              "face-generation",
              "face-reconstruction",
              "fake-news-detection",
              "fastai",
              "fastapi",
              "fasttext",
              "feature-engineering",
              "feature-importance",
              "feature-selection",
              "few-shot-learning",
              "fine-tuning",
              "flask",
              "forecasting",
              "fraud-detection",
              "frontend",
              "gated-recurrent-units",
              "gaussian-processes",
              "gaze-estimation",
              "generation",
              "generative-adversarial-networks",
              "geometric-deep-learning",
              "gesture-recognition",
              "git",
              "gluon",
              "go",
              "gpt",
              "gradient-boosting",
              "graph-classification",
              "graph-clustering",
              "graph-construction",
              "graph-convolutional-networks",
              "graph-embedding",
              "graph-neural-networks",
              "graph-representation-learning",
              "graph-similarity",
              "graphql",
              "graphs",
              "grasping",
              "h2o",
              "hand-pose-estimation",
              "haskell",
              "hidden-markov-models",
              "hierarchical-reinforcement-learning",
              "highway-networks",
              "html",
              "huggingface",
              "human-detection",
              "hyperparameter-optimization",
              "image-captioning",
              "image-categorization",
              "image-classification",
              "image-clustering",
              "image-compression",
              "image-enhancement",
              "image-generation",
              "image-imputation",
              "image-recognition",
              "image-reconstruction",
              "image-restoration",
              "image-similarity-search",
              "image-to-image-translation",
              "imitation-learning",
              "imputation",
              "inference",
              "information-extraction",
              "information-retrieval",
              "instance-segmentation",
              "integration-tests",
              "intent-classification",
              "intent-detection",
              "interpretability",
              "java",
              "javascript",
              "jax",
              "julia",
              "k-nearest-neighbors",
              "keras",
              "keyword-extraction",
              "keyword-spotting",
              "knowledge-base",
              "knowledge-base-question-answering",
              "knowledge-distillation",
              "knowledge-graphs",
              "kuberflow",
              "kubernetes",
              "language-identification",
              "language-modeling",
              "latent-dirichlet-allocation",
              "learning-rates",
              "lemmatization",
              "lexical-simplification",
              "linear-discriminant-analysis",
              "linear-regression",
              "linguistic-acceptability",
              "logistic-regression",
              "lstm",
              "machine-learning",
              "machine-translation",
              "matplotlib",
              "medical-imaging",
              "meta-learning",
              "metrics",
              "mlops",
              "model-compression",
              "model-management",
              "model-selection",
              "morphological-analysis",
              "morphological-inflection",
              "morphological-tagging",
              "mortality-prediction",
              "motion-capture",
              "motion-estimation",
              "motion-planning",
              "motion-segmentation",
              "multi-agent-reinforcement-learning",
              "multi-armed-bandits",
              "multi-modal",
              "multi-task-learning",
              "multilayer-perceptrons",
              "multilingual",
              "multinomial-regression",
              "music-generation",
              "mxnet",
              "naive-bayes",
              "named-entity-recognition",
              "natural-language-inference",
              "natural-language-processing",
              "natural-language-understanding",
              "navigation",
              "neural-networks",
              "node-classification",
              "node-js",
              "object-classification",
              "object-counting",
              "object-detection",
              "object-localization",
              "object-recognition",
              "object-reconstruction",
              "object-tracking",
              "one-shot-learning",
              "onnx",
              "open-refine",
              "optical-character-recognition",
              "optical-flow-estimation",
              "optimizer",
              "outlier-detection",
              "paddlepaddle",
              "paraphrase-identification",
              "part-of-speech-tagging",
              "passage-re-ranking",
              "phenotyping",
              "php",
              "phrase-grounding",
              "point-cloud-generation",
              "policy-gradient-methods",
              "pose-estimation",
              "pose-tracking",
              "preprocessing",
              "pretraining",
              "principal-component-analysis",
              "privacy",
              "production",
              "pruning",
              "python",
              "pytorch",
              "q-learning",
              "quantization",
              "quantum-machine-learning",
              "quasi-recurrent-neural-networks",
              "question-answering",
              "question-generation",
              "question-similarity",
              "r",
              "random-forests",
              "react",
              "reading-comprehension",
              "recommendation-systems",
              "recurrent-neural-networks",
              "recursive-neural-networks",
              "regression",
              "reinforcement-learning",
              "relation-classification",
              "relation-extraction",
              "relational-reasoning",
              "representation-learning",
              "residual-networks",
              "robotics",
              "ruby",
              "saas",
              "safe-exploration",
              "sarcasm-detection",
              "scala",
              "scene-classification",
              "scene-generation",
              "scikit-learn",
              "search",
              "segmentation",
              "self-attention",
              "self-supervised-learning",
              "semantic-composition",
              "semantic-parsing",
              "semantic-role-labeling",
              "semantic-segmentation",
              "semi-supervised-learning",
              "sentence-embeddings",
              "sentiment-analysis",
              "sequence-to-sequence",
              "siamese-networks",
              "similarity-search",
              "slot-filling",
              "sonnet",
              "spacy",
              "spark",
              "spatial-temporal-cnn",
              "speaker-diarization",
              "speaker-identification",
              "speaker-separation",
              "speaker-verification",
              "speech",
              "speech-enhancement",
              "speech-recognition",
              "speech-separation",
              "speech-synthesis",
              "spoken-dialogue-systems",
              "sql",
              "stance-detection",
              "stata",
              "stereo-matching",
              "stochastic-optimization",
              "streaming-data",
              "streamlit",
              "style-transfer",
              "subjectivity-analysis",
              "super-resolution",
              "support-vector-machines",
              "surveillance",
              "survival-analysis",
              "swift",
              "systems-design",
              "tabular",
              "temporal-cnn",
              "tensor-networks",
              "tensorflow",
              "tensorflow-js",
              "tensorflow-lite",
              "text-attribute-transfer",
              "text-classification",
              "text-generation",
              "text-matching",
              "text-similarity",
              "text-simplification",
              "text-summarization",
              "text-to-speech-synthesis",
              "theano",
              "time-series",
              "time-series-classification",
              "time-series-clustering",
              "time-series-forecasting",
              "time-series-prediction",
              "tokenization",
              "topic-modeling",
              "torch",
              "transfer-learning",
              "transformers",
              "unit-tests",
              "unsupervised-learning",
              "variational-autoencoders",
              "video-captioning",
              "video-classification",
              "video-question-answering",
              "video-semantic-segmentation",
              "video-summarization",
              "visual-navigation",
              "visual-odometry",
              "visual-question-answering",
              "visual-reasoning",
              "visual-tracking",
              "visualization",
              "wandb",
              "word-alignment",
              "word-embeddings",
              "word-sense-disambiguation",
              "word-sense-induction",
              "xgboost",
              "xlnet",
              "zero-shot-learning"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_14313753724d46bc9959f20b1de5a608",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 283,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c444d43423f4416eb7e0066e624889a7"
          }
        },
        "5460c265079245548bed7ec01c0a95f8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "{\n  \"aliases\": [\n    \"qa\"\n  ],\n  \"parents\": [\n    \"natural-language-processing\"\n  ]\n}\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_aa5547df5ad342c98541d12d097f50c6",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "14313753724d46bc9959f20b1de5a608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c444d43423f4416eb7e0066e624889a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa5547df5ad342c98541d12d097f50c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1a21017f50f4a0f835c10de761e93c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c5cf2a2926d47d7b2e9f591730abfdb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd380765d8e148ddb4d5691abca164a3",
              "IPY_MODEL_23f1b491eb1c4a94aa85e44d1b767d70"
            ]
          }
        },
        "3c5cf2a2926d47d7b2e9f591730abfdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd380765d8e148ddb4d5691abca164a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_dc627c2815704a458f7c27b3052fd986",
            "_dom_classes": [],
            "description": "min_tag_freq",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 429,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b585277eb664b89ae566d4db856bb1b"
          }
        },
        "23f1b491eb1c4a94aa85e44d1b767d70": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Most popular tags:\n [('natural-language-processing', 429), ('computer-vision', 388), ('pytorch', 258), ('tensorflow', 213), ('transformers', 196)]\n\nTags that just made the cut:\n [('time-series', 34), ('flask', 34), ('node-classification', 33), ('question-answering', 32), ('pretraining', 30)]\n\nTags that just missed the cut:\n [('model-compression', 29), ('fastai', 29), ('graph-classification', 29), ('recurrent-neural-networks', 28), ('adversarial-learning', 28)]\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_0793921498f3447cb300c5f4577be822",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "dc627c2815704a458f7c27b3052fd986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b585277eb664b89ae566d4db856bb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0793921498f3447cb300c5f4577be822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2f231d1abb14e0f819be2f68117ff90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a99b559961154c5f91e211b663168ebc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_337017c4dc3547d5ad9fa54e1d631045",
              "IPY_MODEL_040ad9b9e38248b0bba5a8ef0dc39367"
            ]
          }
        },
        "a99b559961154c5f91e211b663168ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "337017c4dc3547d5ad9fa54e1d631045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "natural-language-processing",
              "computer-vision",
              "pytorch",
              "tensorflow",
              "transformers",
              "attention",
              "convolutional-neural-networks",
              "keras",
              "graphs",
              "embeddings",
              "generative-adversarial-networks",
              "object-detection",
              "huggingface",
              "scikit-learn",
              "reinforcement-learning",
              "representation-learning",
              "interpretability",
              "image-classification",
              "production",
              "language-modeling",
              "graph-neural-networks",
              "regression",
              "segmentation",
              "transfer-learning",
              "data-augmentation",
              "autoencoders",
              "self-supervised-learning",
              "tensorflow-js",
              "unsupervised-learning",
              "wandb",
              "time-series",
              "flask",
              "node-classification",
              "question-answering",
              "pretraining"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_3a04f53d93e44a968866c2742d72dab4",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_794af930e54a49e2b1c3a203769cf3ac"
          }
        },
        "040ad9b9e38248b0bba5a8ef0dc39367": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": [],
                  "needs_background": "light"
                },
                "image/png": "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\n",
                "text/plain": "<Figure size 1080x360 with 1 Axes>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_75ffa2d59a8d4cc883cea933f70970e0",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "3a04f53d93e44a968866c2742d72dab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "794af930e54a49e2b1c3a203769cf3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ffa2d59a8d4cc883cea933f70970e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "050f82f5336746b5b0978a1a2708df17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8096326052a14cb4bdb780ba78d9b287",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_95c5b5af3be84fa1b338ab462d38a390",
              "IPY_MODEL_40540669ea7f482b99e12e5d9947896c",
              "IPY_MODEL_4e4352e6ad0f4d558808083c7f207959"
            ]
          }
        },
        "8096326052a14cb4bdb780ba78d9b287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95c5b5af3be84fa1b338ab462d38a390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "state": {
            "_view_name": "CheckboxView",
            "style": "IPY_MODEL_aa3505ba598a4092b471166e5323e6cd",
            "_dom_classes": [],
            "description": "lower",
            "_model_name": "CheckboxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": true,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "indent": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be38026bd1194171b19590886dc60477"
          }
        },
        "40540669ea7f482b99e12e5d9947896c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "state": {
            "_view_name": "CheckboxView",
            "style": "IPY_MODEL_e3513ec3018c48ed9ea80a714bf6f2d7",
            "_dom_classes": [],
            "description": "stem",
            "_model_name": "CheckboxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": false,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "indent": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7647a427de14f61b062c0f389b36a49"
          }
        },
        "4e4352e6ad0f4d558808083c7f207959": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "conditional image generation using variational autoencoders gans\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_e433a26e48ab4fc78c9b4b39bc1eaf84",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "aa3505ba598a4092b471166e5323e6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be38026bd1194171b19590886dc60477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3513ec3018c48ed9ea80a714bf6f2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7647a427de14f61b062c0f389b36a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e433a26e48ab4fc78c9b4b39bc1eaf84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3ec0cdbd314e92a4ed737d33b2b27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43411873c18c4c40ab710efb93615794",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33044effcf444563a2df73bc36dcebf8",
              "IPY_MODEL_80fbd1d56723455ab37e5a78c658771e"
            ]
          }
        },
        "43411873c18c4c40ab710efb93615794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33044effcf444563a2df73bc36dcebf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1febe73192464f6f90dd0938bdbd2f72",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aeee3fee49354d76b40dc6a900f8d8ce"
          }
        },
        "80fbd1d56723455ab37e5a78c658771e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71e74527f1414dec85e3d9bc773a39c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 2.46kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a35a6cd5614a4ca3b06771e415bf406e"
          }
        },
        "1febe73192464f6f90dd0938bdbd2f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aeee3fee49354d76b40dc6a900f8d8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71e74527f1414dec85e3d9bc773a39c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a35a6cd5614a4ca3b06771e415bf406e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c593338e7de345009d299de42c886891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d78745c170745218570e12242d4cfb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e802334372f64a77b068ca707fb5f6f9",
              "IPY_MODEL_60047798552a44a9b5125322115b7d68"
            ]
          }
        },
        "7d78745c170745218570e12242d4cfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e802334372f64a77b068ca707fb5f6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41fa49c6a79f442b8183727277af83c7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85bb57e1594e4a10a67fab793ecb8cb7"
          }
        },
        "60047798552a44a9b5125322115b7d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_224e844057b940f3bfc52a3192e8a96d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.95MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f88370f1da9946898315681920379d65"
          }
        },
        "41fa49c6a79f442b8183727277af83c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85bb57e1594e4a10a67fab793ecb8cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "224e844057b940f3bfc52a3192e8a96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f88370f1da9946898315681920379d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "419b7c6013514b4f8858193b428c5a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b62d235a40d1454aa14a81fa6c89ef03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bdca700a61e480badf147aa601499e3",
              "IPY_MODEL_9e6377687e8e408e89133d9693718b48"
            ]
          }
        },
        "b62d235a40d1454aa14a81fa6c89ef03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bdca700a61e480badf147aa601499e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed615f1835094c84b20e241fbcc9739c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d8f3e7e878c4cb59363258008b476ca"
          }
        },
        "9e6377687e8e408e89133d9693718b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d22a2c74c4034fb595b73b5b50e8bd17",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:04&lt;00:00, 54.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35cc9d2677d6465a9396987b62959aed"
          }
        },
        "ed615f1835094c84b20e241fbcc9739c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d8f3e7e878c4cb59363258008b476ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d22a2c74c4034fb595b73b5b50e8bd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35cc9d2677d6465a9396987b62959aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca113cb62ea14cf3a4191bfbcb6aa3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf6d7d3de6b74149a8fd163996b27dca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6559491ac044429ea5fba0b41424d5c6",
              "IPY_MODEL_60a95824964d4e12a82912125c337568"
            ]
          }
        },
        "bf6d7d3de6b74149a8fd163996b27dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6559491ac044429ea5fba0b41424d5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "autoencoders",
              "pytorch",
              "keras",
              "generative-adversarial-networks",
              "tensorflow",
              "interpretability",
              "question-answering",
              "production",
              "representation-learning",
              "regression",
              "scikit-learn",
              "segmentation",
              "reinforcement-learning",
              "self-supervised-learning",
              "wandb",
              "embeddings",
              "language-modeling",
              "natural-language-processing",
              "transformers",
              "tensorflow-js",
              "pretraining",
              "time-series",
              "convolutional-neural-networks",
              "object-detection",
              "graphs",
              "unsupervised-learning",
              "computer-vision",
              "huggingface",
              "attention",
              "flask",
              "graph-neural-networks",
              "image-classification",
              "transfer-learning",
              "data-augmentation",
              "node-classification"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_2aa0dd0c4ab340b1899a43790a784ec2",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 18,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f268772c427d402381687dd21e25660e"
          }
        },
        "60a95824964d4e12a82912125c337568": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "{\n  \"precision\": 0.9285714285714286,\n  \"recall\": 0.48148148148148145,\n  \"f1\": 0.6341463414634146,\n  \"num_samples\": 27.0\n}\n\n=== True positives ===\n  insight project insight design creat nlp servic code base front end gui streamlit backend server fastapi usag transform\n    true: ['attention', 'huggingface', 'natural-language-processing', 'pytorch', 'transfer-learning', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  hyperparamet optim transform guid basic grid search optim fact hyperparamet choos signific impact final model perform\n    true: ['natural-language-processing', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  transform neural network architectur explain time explain transform work look easi explan exactli right\n    true: ['attention', 'natural-language-processing', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n=== False positives === \n  multi target albument mani imag mani mask bound box key point transform sync\n    true: ['computer-vision', 'data-augmentation']\n    pred: ['natural-language-processing', 'transformers']\n\n=== False negatives ===\n  size fill blank multi mask fill roberta size fill blank condit text fill idea fill miss word sentenc probabl choic word\n    true: ['attention', 'huggingface', 'language-modeling', 'natural-language-processing', 'transformers']\n    pred: []\n\n  gpt3 work visual anim compil thread explain gpt3\n    true: ['natural-language-processing', 'transformers']\n    pred: []\n\n  tinybert tinybert 7 5x smaller 9 4x faster infer bert base achiev competit perform task natur languag understand\n    true: ['attention', 'natural-language-processing', 'transformers']\n    pred: []\n\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_62aa50cffeca4f44acf8de4c08f2ca5f",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "2aa0dd0c4ab340b1899a43790a784ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f268772c427d402381687dd21e25660e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62aa50cffeca4f44acf8de4c08f2ca5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e3107c9123439090eac647ce56b21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f4bc42d74d0496babe3c47450288a47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f9103c05ddf4c07a49badc34ed41c5b",
              "IPY_MODEL_d9a54f89006b40cbab734598232849e9"
            ]
          }
        },
        "0f4bc42d74d0496babe3c47450288a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f9103c05ddf4c07a49badc34ed41c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "autoencoders",
              "pytorch",
              "keras",
              "generative-adversarial-networks",
              "tensorflow",
              "interpretability",
              "question-answering",
              "production",
              "representation-learning",
              "regression",
              "scikit-learn",
              "segmentation",
              "reinforcement-learning",
              "self-supervised-learning",
              "wandb",
              "embeddings",
              "language-modeling",
              "natural-language-processing",
              "transformers",
              "tensorflow-js",
              "pretraining",
              "time-series",
              "convolutional-neural-networks",
              "object-detection",
              "graphs",
              "unsupervised-learning",
              "computer-vision",
              "huggingface",
              "attention",
              "flask",
              "graph-neural-networks",
              "image-classification",
              "transfer-learning",
              "data-augmentation",
              "node-classification"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_72153fed4b6143b1828d0ed17445e5cc",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 18,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d311cd50521b46e6b606f7319b4fa7bf"
          }
        },
        "d9a54f89006b40cbab734598232849e9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "{\n  \"precision\": 0.9444444444444444,\n  \"recall\": 0.68,\n  \"f1\": 0.7906976744186047,\n  \"num_samples\": 25.0\n}\n\n=== True positives ===\n\n  insight project insight designed create nlp service code base front end gui streamlit backend server fastapi usage transformers\n    true: ['attention', 'huggingface', 'natural-language-processing', 'pytorch', 'transfer-learning', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  transformer neural network architecture explained time explain transformers work looking easy explanation exactly right\n    true: ['attention', 'natural-language-processing', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  multi task training hugging face transformers nlp recipe multi task training transformers trainer nlp datasets\n    true: ['huggingface', 'natural-language-processing', 'transformers']\n    pred: ['attention', 'huggingface', 'natural-language-processing', 'transformers']\n\n=== False positives ===\n\n  lda2vec tools interpreting natural language lda2vec model tries mix best parts word2vec lda single framework\n    true: ['embeddings', 'interpretability', 'natural-language-processing']\n    pred: ['natural-language-processing', 'transformers']\n\n=== False negatives ===\n\n  sized fill blank multi mask filling roberta sized fill blank conditional text filling idea filling missing words sentence probable choice words\n    true: ['attention', 'huggingface', 'language-modeling', 'natural-language-processing', 'transformers']\n    pred: ['natural-language-processing']\n\n  gpt3 works visualizations animations compilation threads explaining gpt3\n    true: ['natural-language-processing', 'transformers']\n    pred: ['natural-language-processing']\n\n  multimodal meme classification uniter given state art results various image text related problems project aims finetuning uniter solve hateful memes challenge\n    true: ['attention', 'computer-vision', 'image-classification', 'natural-language-processing', 'transformers']\n    pred: ['computer-vision']\n\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_15a1173858fe4576a3923bcc0169b375",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "72153fed4b6143b1828d0ed17445e5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d311cd50521b46e6b606f7319b4fa7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15a1173858fe4576a3923bcc0169b375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d55c23d4f3294206acbc961246886289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bcf2c14093b416a9424e4cadddc8339",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07d2813a45e24689baae3c6b6daf0a19",
              "IPY_MODEL_b5f1a10bc8de4e4fa2ad84100870f793"
            ]
          }
        },
        "7bcf2c14093b416a9424e4cadddc8339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07d2813a45e24689baae3c6b6daf0a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "autoencoders",
              "pytorch",
              "keras",
              "generative-adversarial-networks",
              "tensorflow",
              "interpretability",
              "question-answering",
              "production",
              "representation-learning",
              "regression",
              "scikit-learn",
              "segmentation",
              "reinforcement-learning",
              "self-supervised-learning",
              "wandb",
              "embeddings",
              "language-modeling",
              "natural-language-processing",
              "transformers",
              "tensorflow-js",
              "pretraining",
              "time-series",
              "convolutional-neural-networks",
              "object-detection",
              "graphs",
              "unsupervised-learning",
              "computer-vision",
              "huggingface",
              "attention",
              "flask",
              "graph-neural-networks",
              "image-classification",
              "transfer-learning",
              "data-augmentation",
              "node-classification"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_4d729dd457054c2595292fc0e4a31660",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 18,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4adbad95a9744015898234875e7c250b"
          }
        },
        "b5f1a10bc8de4e4fa2ad84100870f793": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "{\n  \"precision\": 0.3793103448275862,\n  \"recall\": 0.44,\n  \"f1\": 0.4074074074074074,\n  \"num_samples\": 25.0\n}\n\n=== True positives ===\n  insight project insight designed create nlp service code base front end gui streamlit backend server fastapi usage transformers\n    true: ['attention', 'huggingface', 'natural-language-processing', 'pytorch', 'transfer-learning', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  transformer neural network architecture explained time explain transformers work looking easy explanation exactly right\n    true: ['attention', 'natural-language-processing', 'transformers']\n    pred: ['attention', 'natural-language-processing', 'transformers']\n\n  multi task training hugging face transformers nlp recipe multi task training transformers trainer nlp datasets\n    true: ['huggingface', 'natural-language-processing', 'transformers']\n    pred: ['attention', 'huggingface', 'language-modeling', 'natural-language-processing', 'transformers']\n\n=== False positives === \n  evaluation metrics language modeling article focus traditional intrinsic metrics extremely useful process training language model\n    true: ['language-modeling', 'natural-language-processing']\n    pred: ['natural-language-processing', 'transformers']\n\n  neural networks nlp cmu cs 11 747 class start brief overview neural networks spend majority class demonstrating apply neural networks language\n    true: ['natural-language-processing']\n    pred: ['natural-language-processing', 'transformers']\n\n  cs294 158 sp19 deep unsupervised learning course cover two areas deep learning labeled data required deep generative models self supervised learning\n    true: ['self-supervised-learning', 'unsupervised-learning']\n    pred: ['natural-language-processing', 'self-supervised-learning', 'transformers']\n\n=== False negatives ===\n  sized fill blank multi mask filling roberta sized fill blank conditional text filling idea filling missing words sentence probable choice words\n    true: ['attention', 'huggingface', 'language-modeling', 'natural-language-processing', 'transformers']\n    pred: ['computer-vision', 'tensorflow']\n\n  gpt3 works visualizations animations compilation threads explaining gpt3\n    true: ['natural-language-processing', 'transformers']\n    pred: ['natural-language-processing']\n\n  pruning bert accelerate inference previously discussing various ways accelerating models like bert blog post empirically evaluate pruning approach\n    true: ['attention', 'natural-language-processing', 'transformers']\n    pred: ['natural-language-processing', 'pytorch']\n\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_a25ebb3fe003432db2e804dc95880692",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "4d729dd457054c2595292fc0e4a31660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4adbad95a9744015898234875e7c250b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a25ebb3fe003432db2e804dc95880692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6903228530ae4e0a84d8886bc04de5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a87ef850764e4d5f8b7d723877a29145",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9098a6d0aeb142b2a21e149bcf7249e2",
              "IPY_MODEL_82cd21df2e6b4b558bee08c8757c717e"
            ]
          }
        },
        "a87ef850764e4d5f8b7d723877a29145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9098a6d0aeb142b2a21e149bcf7249e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b907baf2fbd1403cbb9bc43cea0bf4f6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 227845,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227845,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2161fece84148408c3a363e1e097fc7"
          }
        },
        "82cd21df2e6b4b558bee08c8757c717e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_202c1962949444c1beb3fdf9843110ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 228k/228k [00:00&lt;00:00, 1.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23c5897ffd06401594fa1ee393cdb6cf"
          }
        },
        "b907baf2fbd1403cbb9bc43cea0bf4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2161fece84148408c3a363e1e097fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "202c1962949444c1beb3fdf9843110ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23c5897ffd06401594fa1ee393cdb6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b45373c2f984479ae78d8b08c37a8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09ab19fb14644de4b73e3037b9c08cd1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a3fec33dc0c4f4ba947aaecfc4a57ee",
              "IPY_MODEL_c678b8d54e45432cbc460b51035702d4"
            ]
          }
        },
        "09ab19fb14644de4b73e3037b9c08cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a3fec33dc0c4f4ba947aaecfc4a57ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_687dfe83a92e404fa2134b4a37fa6518",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_069cebd21baa4cc2833c4f29b0e47c0f"
          }
        },
        "c678b8d54e45432cbc460b51035702d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f2bc9176cac4485ae5e0cf763a0394c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:07&lt;00:00, 53.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24a5007aa67a4c1d918f7c537a693050"
          }
        },
        "687dfe83a92e404fa2134b4a37fa6518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "069cebd21baa4cc2833c4f29b0e47c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f2bc9176cac4485ae5e0cf763a0394c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24a5007aa67a4c1d918f7c537a693050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b35f6b1e3be246f583c5f2d34e307a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55070a3d30474b3ab79e31e68f75faee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74572d30e1674fc59451c304f2414ff1",
              "IPY_MODEL_850a37f960314f179eb1ab31394c82ba"
            ]
          }
        },
        "55070a3d30474b3ab79e31e68f75faee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74572d30e1674fc59451c304f2414ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_706ae7a6af8544a487b7487d1d546d36",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442221694,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442221694,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15c7236a62a84622a552dd76642a68db"
          }
        },
        "850a37f960314f179eb1ab31394c82ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_afbb479e0884486abe0ab426acd76fa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:06&lt;00:00, 63.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d047e13ce694f71b6165de361d780bc"
          }
        },
        "706ae7a6af8544a487b7487d1d546d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15c7236a62a84622a552dd76642a68db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afbb479e0884486abe0ab426acd76fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d047e13ce694f71b6165de361d780bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e84e28d0a48d4335be91d40ac1582f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d561f46e437480ea213b1ffe789690d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb581c3ecda14096a0e60042018e22bf",
              "IPY_MODEL_ef6f95e7daa14bce8d13a8dc0071843e"
            ]
          }
        },
        "9d561f46e437480ea213b1ffe789690d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb581c3ecda14096a0e60042018e22bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "autoencoders",
              "pytorch",
              "keras",
              "generative-adversarial-networks",
              "tensorflow",
              "interpretability",
              "question-answering",
              "production",
              "representation-learning",
              "regression",
              "scikit-learn",
              "segmentation",
              "reinforcement-learning",
              "self-supervised-learning",
              "wandb",
              "embeddings",
              "language-modeling",
              "natural-language-processing",
              "transformers",
              "tensorflow-js",
              "pretraining",
              "time-series",
              "convolutional-neural-networks",
              "object-detection",
              "graphs",
              "unsupervised-learning",
              "computer-vision",
              "huggingface",
              "attention",
              "flask",
              "graph-neural-networks",
              "image-classification",
              "transfer-learning",
              "data-augmentation",
              "node-classification"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_f5c4a70ba6334f3dbee76d4372e51160",
            "_dom_classes": [],
            "description": "tag",
            "_model_name": "DropdownModel",
            "index": 18,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0f1ad3515154bb09916038691022aed"
          }
        },
        "ef6f95e7daa14bce8d13a8dc0071843e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "{\n  \"precision\": 0.6774193548387096,\n  \"recall\": 0.84,\n  \"f1\": 0.75,\n  \"num_samples\": 25.0\n}\n\n=== True positives ===\n  insight project insight designed create nlp service code base front end gui streamlit backend server fastapi usage transformers\n    true: ['attention', 'huggingface', 'natural-language-processing', 'pytorch', 'transfer-learning', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  sized fill blank multi mask filling roberta sized fill blank conditional text filling idea filling missing words sentence probable choice words\n    true: ['attention', 'huggingface', 'language-modeling', 'natural-language-processing', 'transformers']\n    pred: ['natural-language-processing', 'transformers']\n\n  transformer neural network architecture explained time explain transformers work looking easy explanation exactly right\n    true: ['attention', 'natural-language-processing', 'transformers']\n    pred: ['attention', 'natural-language-processing', 'transformers']\n\n=== False positives === \n  evaluation metrics language modeling article focus traditional intrinsic metrics extremely useful process training language model\n    true: ['language-modeling', 'natural-language-processing']\n    pred: ['language-modeling', 'natural-language-processing', 'transformers']\n\n  rasa nlu examples experimental components rasa nlu pipelines\n    true: ['natural-language-processing']\n    pred: ['natural-language-processing', 'transformers']\n\n  abstraction reasoning corpus arc computer learn complex abstract tasks examples arc used measure human like form general fluid intelligence\n    true: ['natural-language-processing']\n    pred: ['attention', 'natural-language-processing', 'transformers']\n\n=== False negatives ===\n  multimodal meme classification uniter given state art results various image text related problems project aims finetuning uniter solve hateful memes challenge\n    true: ['attention', 'computer-vision', 'image-classification', 'natural-language-processing', 'transformers']\n    pred: ['computer-vision']\n\n  pre trained word embeddings pre trained language models static word embedding dynamic contextualized word embedding\n    true: ['attention', 'embeddings', 'language-modeling', 'natural-language-processing', 'pretraining', 'transformers']\n    pred: ['embeddings', 'natural-language-processing']\n\n  t5 sentiment span extraction exploring t5 works applying sentiment span extraction\n    true: ['natural-language-processing', 'transformers']\n    pred: ['natural-language-processing']\n\n",
                "stream": "stdout"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_bd735b1b05b0403ebd8b4da28a0a0942",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "f5c4a70ba6334f3dbee76d4372e51160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0f1ad3515154bb09916038691022aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd735b1b05b0403ebd8b4da28a0a0942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acbetMKBt825"
      },
      "source": [
        "<div align=\"center\">\n",
        "<h1><img width=\"30\" src=\"https://madewithml.com/static/images/rounded_logo.png\">&nbsp;<a href=\"https://madewithml.com/\">Made With ML</a></h1>\n",
        "Applied ML · MLOps · Production\n",
        "<br>\n",
        "Join 20K+ developers in learning how to responsibly <a href=\"https://madewithml.com/about/\">deliver value</a> with ML.\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "    <a target=\"_blank\" href=\"https://newsletter.madewithml.com\"><img src=\"https://img.shields.io/badge/Subscribe-20K-brightgreen\"></a>&nbsp;\n",
        "    <a target=\"_blank\" href=\"https://github.com/GokuMohandas/madewithml\"><img src=\"https://img.shields.io/github/stars/GokuMohandas/madewithml.svg?style=social&label=Star\"></a>&nbsp;\n",
        "    <a target=\"_blank\" href=\"https://www.linkedin.com/in/goku\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n",
        "    <a target=\"_blank\" href=\"https://twitter.com/GokuMohandas\"><img src=\"https://img.shields.io/twitter/follow/GokuMohandas.svg?label=Follow&style=social\"></a>\n",
        "    <p>🔥&nbsp; Among the <a href=\"https://github.com/topics/deep-learning\" target=\"_blank\">top ML</a> repositories on GitHub</p>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbHqEEy3NkSU"
      },
      "source": [
        "# MLOps - Tagifai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTNsIiUrqoJW"
      },
      "source": [
        "<div align=\"left\">\n",
        "<a target=\"_blank\" href=\"https://madewithml.com/#mlops\"><img src=\"https://img.shields.io/badge/📖 Read-lessons-9cf\"></a>&nbsp;\n",
        "<a href=\"https://github.com/GokuMohandas/mlops/blob/main/notebooks/tagifai.ipynb\" role=\"button\"><img src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
        "<a href=\"https://colab.research.google.com/github/GokuMohandas/mlops/blob/main/notebooks/tagifai.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh-HuNfDrPg0"
      },
      "source": [
        "This notebooks contains the code for our `Tagifai` feature including 🔢&nbsp; Data and 📈&nbsp; Modeling. After this, we'll be moving all of this code to Python scripts with proper styling, testing, etc.\n",
        "\n",
        "> Be sure to read the detailed accompanying [lessons](https://madewithml.com/#applied-ml) as opposed to just running the code here. We help you develop an intuition before jumping into the application. Also, once we wrap up optimization, we will be moving our code from notebooks to Python scripts which will only be on the [course page](https://madewithml.com/#applied-ml)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbqAqitENkSU"
      },
      "source": [
        "# 🔢&nbsp; Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ROgHAeQNkSU"
      },
      "source": [
        "## Annotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdrrsquiNkSU"
      },
      "source": [
        "from collections import Counter, OrderedDict\n",
        "import ipywidgets as widgets\n",
        "import itertools\n",
        "import json\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB-2nm6NNkSU",
        "outputId": "3678ae46-1711-4685-f55a-15de1388c065"
      },
      "source": [
        "# Load projects\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/projects.json\"\n",
        "projects = json.loads(urlopen(url).read())\n",
        "print (json.dumps(projects[-305], indent=2))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": 324,\n",
            "  \"title\": \"AdverTorch\",\n",
            "  \"description\": \"A Toolbox for Adversarial Robustness Research\",\n",
            "  \"tags\": [\n",
            "    \"code\",\n",
            "    \"library\",\n",
            "    \"security\",\n",
            "    \"adversarial-learning\",\n",
            "    \"adversarial-attacks\",\n",
            "    \"adversarial-perturbations\"\n",
            "  ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pJcQOR7NkSU",
        "outputId": "bfab40f7-51ac-45dc-86d2-51d6adbcbde7"
      },
      "source": [
        "# Load tags\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/tags.json\"\n",
        "tags = json.loads(urlopen(url).read())\n",
        "tags_dict = {}\n",
        "for item in tags:\n",
        "    key = item.pop(\"tag\")\n",
        "    tags_dict[key] = item\n",
        "print (f\"{len(tags_dict)} tags\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400 tags\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "42da19ab1c944b76a2f0ef935839550e",
            "644721e1a14c418e9e0fcada51fbffe2",
            "8fc242b3d87742a39ac1cd99e7607eb8",
            "5460c265079245548bed7ec01c0a95f8",
            "14313753724d46bc9959f20b1de5a608",
            "c444d43423f4416eb7e0066e624889a7",
            "aa5547df5ad342c98541d12d097f50c6"
          ]
        },
        "id": "l8GWm_unNkSU",
        "outputId": "80c85682-4359-405c-e835-fb1c96217077"
      },
      "source": [
        "@widgets.interact(tag=list(tags_dict.keys()))\n",
        "def display_tag_details(tag='question-answering'):\n",
        "    print (json.dumps(tags_dict[tag], indent=2))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42da19ab1c944b76a2f0ef935839550e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=283, options=('3d', 'action-localization', 'action-rec…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ZAYXvZ_TNkSU",
        "outputId": "5536537b-2d90-48b1-c951-1ca1cc17a498"
      },
      "source": [
        "# Create dataframe\n",
        "df = pd.DataFrame(projects)\n",
        "print (f\"{len(df)} projects\")\n",
        "df.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2032 projects\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2438</td>\n",
              "      <td>How to Deal with Files in Google Colab: What Y...</td>\n",
              "      <td>How to supercharge your Google Colab experienc...</td>\n",
              "      <td>[article, google-colab, colab, file-system]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2437</td>\n",
              "      <td>Rasoee</td>\n",
              "      <td>A powerful web and mobile application that ide...</td>\n",
              "      <td>[api, article, code, dataset, paper, research,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2436</td>\n",
              "      <td>Machine Learning Methods Explained (+ Examples)</td>\n",
              "      <td>Most common techniques used in data science pr...</td>\n",
              "      <td>[article, deep-learning, machine-learning, dim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2435</td>\n",
              "      <td>Top “Applied Data Science” Papers from ECML-PK...</td>\n",
              "      <td>Explore the innovative world of Machine Learni...</td>\n",
              "      <td>[article, deep-learning, machine-learning, adv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2434</td>\n",
              "      <td>OpenMMLab Computer Vision</td>\n",
              "      <td>MMCV is a python library for CV research and s...</td>\n",
              "      <td>[article, code, pytorch, library, 3d, computer...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                               tags\n",
              "0  2438  ...        [article, google-colab, colab, file-system]\n",
              "1  2437  ...  [api, article, code, dataset, paper, research,...\n",
              "2  2436  ...  [article, deep-learning, machine-learning, dim...\n",
              "3  2435  ...  [article, deep-learning, machine-learning, adv...\n",
              "4  2434  ...  [article, code, pytorch, library, 3d, computer...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x1ldAFQNkSU"
      },
      "source": [
        "# Input\n",
        "df['text'] = df.title + \" \" + df.description"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt9j3gz1NkSU"
      },
      "source": [
        "def filter(l, include=[], exclude=[]):\n",
        "    \"\"\"Filter a list using inclusion and exclusion lists of items.\"\"\"\n",
        "    filtered = [item for item in l if item in include and item not in exclude]\n",
        "    return filtered"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1H1lnKXNkSU"
      },
      "source": [
        "# Inclusion/exclusion criteria for tags\n",
        "include = list(tags_dict.keys())\n",
        "exclude = ['machine-learning', 'deep-learning',  'data-science',\n",
        "           'neural-networks', 'python', 'r', 'visualization', 'wandb']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF9cfyfaNkSU"
      },
      "source": [
        "# Filter tags for each project\n",
        "df.tags = df.tags.apply(filter, include=include, exclude=exclude)\n",
        "tags = Counter(itertools.chain.from_iterable(df.tags.values))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "e1a21017f50f4a0f835c10de761e93c7",
            "3c5cf2a2926d47d7b2e9f591730abfdb",
            "bd380765d8e148ddb4d5691abca164a3",
            "23f1b491eb1c4a94aa85e44d1b767d70",
            "dc627c2815704a458f7c27b3052fd986",
            "2b585277eb664b89ae566d4db856bb1b",
            "0793921498f3447cb300c5f4577be822"
          ]
        },
        "id": "k1GcLzL6NkSU",
        "outputId": "4f807904-fea7-41eb-d44a-764e48b1c6dd"
      },
      "source": [
        "@widgets.interact(min_tag_freq=(0, tags.most_common()[0][1]))\n",
        "def separate_tags_by_freq(min_tag_freq=30):\n",
        "    tags_above_freq = Counter(tag for tag in tags.elements()\n",
        "                                    if tags[tag] >= min_tag_freq)\n",
        "    tags_below_freq = Counter(tag for tag in tags.elements()\n",
        "                                    if tags[tag] < min_tag_freq)\n",
        "    print (\"Most popular tags:\\n\", tags_above_freq.most_common(5))\n",
        "    print (\"\\nTags that just made the cut:\\n\", tags_above_freq.most_common()[-5:])\n",
        "    print (\"\\nTags that just missed the cut:\\n\", tags_below_freq.most_common(5))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1a21017f50f4a0f835c10de761e93c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=30, description='min_tag_freq', max=429), Output()), _dom_classes=('widg…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjaEbjzONkSV"
      },
      "source": [
        "# Filter tags that have fewer than <min_tag_freq> occurrences\n",
        "min_tag_freq = 30\n",
        "tags_above_freq = Counter(tag for tag in tags.elements() \n",
        "                          if tags[tag] >= min_tag_freq)\n",
        "df.tags = df.tags.apply(filter, include=list(tags_above_freq.keys()))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRK_c_CFNkSV",
        "outputId": "fdd2cdd9-9170-455b-f3c4-07c00ded67e3"
      },
      "source": [
        "# Remove projects with no more remaining relevant tags\n",
        "df = df[df.tags.map(len) > 0]\n",
        "print (f\"{len(df)} projects\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1444 projects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuCrsbxbNkSV"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHdQmqTBNkSV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "2hGuYu5ONkSV",
        "outputId": "26d42a05-abf9-44dc-b648-5844c5f50907"
      },
      "source": [
        "# Number of tags per project\n",
        "num_tags_per_project = [len(tags) for tags in df.tags]\n",
        "num_tags, num_projects = zip(*Counter(num_tags_per_project).items())\n",
        "plt.figure(figsize=(10, 3))\n",
        "ax = sns.barplot(list(num_tags), list(num_projects))\n",
        "plt.title(\"Tags per project\", fontsize=20)\n",
        "plt.xlabel(\"Number of tags\", fontsize=16)\n",
        "ax.set_xticklabels(range(1, len(num_tags)+1), rotation=0, fontsize=16)\n",
        "plt.ylabel(\"Number of projects\", fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "5JuX5Ju-NkSV",
        "outputId": "ea2e86ca-5ccd-44ea-9906-ffc7e0219905"
      },
      "source": [
        "# Distribution of tags\n",
        "all_tags = list(itertools.chain.from_iterable(df.tags.values))\n",
        "tags, tag_counts = zip(*Counter(all_tags).most_common())\n",
        "plt.figure(figsize=(25, 5))\n",
        "ax = sns.barplot(list(tags), list(tag_counts))\n",
        "plt.title(\"Tag distribution\", fontsize=20)\n",
        "plt.xlabel(\"Tag\", fontsize=16)\n",
        "ax.set_xticklabels(tags, rotation=90, fontsize=14)\n",
        "plt.ylabel(\"Number of projects\", fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "e2f231d1abb14e0f819be2f68117ff90",
            "a99b559961154c5f91e211b663168ebc",
            "337017c4dc3547d5ad9fa54e1d631045",
            "040ad9b9e38248b0bba5a8ef0dc39367",
            "3a04f53d93e44a968866c2742d72dab4",
            "794af930e54a49e2b1c3a203769cf3ac",
            "75ffa2d59a8d4cc883cea933f70970e0"
          ]
        },
        "id": "NgMGuIQrNkSV",
        "outputId": "607e127a-8682-44c2-87bb-546a47f2373e"
      },
      "source": [
        "@widgets.interact(tag=list(tags))\n",
        "def display_word_cloud(tag='pytorch'):\n",
        "    # Plot word clouds top top tags\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    subset = df[df.tags.apply(lambda tags: tag in tags)]\n",
        "    text = subset.text.values\n",
        "    cloud = WordCloud(\n",
        "        stopwords=STOPWORDS, background_color='black', collocations=False,\n",
        "        width=500, height=300).generate(\" \".join(text))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(cloud)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f231d1abb14e0f819be2f68117ff90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=2, options=('natural-language-processing', 'computer-v…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sfzg9CMNkSV"
      },
      "source": [
        "## Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYKtkRjlNkSV"
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-khYwAVNkSV"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytQ6_8v7NkSV"
      },
      "source": [
        "# Shuffle\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4lC_E14NkSV"
      },
      "source": [
        "# Get data\n",
        "X = df.text.to_numpy()\n",
        "y = df.tags"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT6FHkqyNkSV"
      },
      "source": [
        "We'll be writing our own LabelEncoder which is based on scikit-learn's [implementation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPmj1XANkSV"
      },
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(list(itertools.chain.from_iterable(y)))\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        y_one_hot = np.zeros((len(y), len(self.class_to_index)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            for class_ in item:\n",
        "                y_one_hot[i][self.class_to_index[class_]] = 1\n",
        "        return y_one_hot\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            indices = np.where(item == 1)[0]\n",
        "            classes.append([self.index_to_class[index] for index in indices])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIcGw6MNNkSV"
      },
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "num_classes = len(label_encoder)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLzecFwWNkSV",
        "outputId": "41ad98af-88a6-4e82-94b5-c2666efaaeb0"
      },
      "source": [
        "label_encoder.class_to_index"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention': 0,\n",
              " 'autoencoders': 1,\n",
              " 'computer-vision': 2,\n",
              " 'convolutional-neural-networks': 3,\n",
              " 'data-augmentation': 4,\n",
              " 'embeddings': 5,\n",
              " 'flask': 6,\n",
              " 'generative-adversarial-networks': 7,\n",
              " 'graph-neural-networks': 8,\n",
              " 'graphs': 9,\n",
              " 'huggingface': 10,\n",
              " 'image-classification': 11,\n",
              " 'interpretability': 12,\n",
              " 'keras': 13,\n",
              " 'language-modeling': 14,\n",
              " 'natural-language-processing': 15,\n",
              " 'node-classification': 16,\n",
              " 'object-detection': 17,\n",
              " 'pretraining': 18,\n",
              " 'production': 19,\n",
              " 'pytorch': 20,\n",
              " 'question-answering': 21,\n",
              " 'regression': 22,\n",
              " 'reinforcement-learning': 23,\n",
              " 'representation-learning': 24,\n",
              " 'scikit-learn': 25,\n",
              " 'segmentation': 26,\n",
              " 'self-supervised-learning': 27,\n",
              " 'tensorflow': 28,\n",
              " 'tensorflow-js': 29,\n",
              " 'time-series': 30,\n",
              " 'transfer-learning': 31,\n",
              " 'transformers': 32,\n",
              " 'unsupervised-learning': 33,\n",
              " 'wandb': 34}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8na7YazNkSW",
        "outputId": "48a7bfdf-d974-4007-b5bc-032c41a81ad4"
      },
      "source": [
        "# Sample\n",
        "label_encoder.encode([[\"attention\", \"data-augmentation\"]])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMyIbacNNkSW"
      },
      "source": [
        "# Encode all our labels\n",
        "y = label_encoder.encode(y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufCNlDjQNkSW"
      },
      "source": [
        "## Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOfLfpMKNxy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be74062b-112e-4a99-e677-583ca6f7283e"
      },
      "source": [
        "!pip install scikit-multilearn==0.2.0 -q"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▊                            | 10kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 32.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 24.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 19.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 8.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBRwUKtfNkSW"
      },
      "source": [
        "You need to [clean](https://madewithml.com/courses/applied-ml/preprocessing/) your data first before splitting, at least for the features that splitting depends on. So the process is more like: preprocessing (global, cleaning) → splitting → preprocessing (local, transformations). We're splitting using the tag labels which have already been inspected and cleaned during EDA. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XMXpueENkSW"
      },
      "source": [
        "**Naive split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEhp9SMFNkSW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTUju11uNkSW"
      },
      "source": [
        "# Split sizes\n",
        "train_size = 0.7\n",
        "val_size = 0.15\n",
        "test_size = 0.15"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTRQWabKNkSW"
      },
      "source": [
        "For simple multiclass classification, you can specify how to stratify the split by adding the [`stratify`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) keyword argument. But our task is multilabel classification, so we'll need to use other techniques to create even splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw83_zitNkSW"
      },
      "source": [
        "# Split (train)\n",
        "X_train, X_, y_train, y_ = train_test_split(X, y, train_size=train_size)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPVutu_dNkSW",
        "outputId": "c65f0820-5d6e-47c1-dd09-cfe65e22555c"
      },
      "source": [
        "print (f\"train: {len(X_train)} ({(len(X_train) / len(X)):.2f})\\n\"\n",
        "       f\"remaining: {len(X_)} ({(len(X_) / len(X)):.2f})\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 1010 (0.70)\n",
            "remaining: 434 (0.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-CFrR7pNkSW"
      },
      "source": [
        "# Split (test)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_, y_, train_size=0.5)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-evG0mc1NkSW",
        "outputId": "0b14538c-2805-4494-a6ca-8b52c6deb2dc"
      },
      "source": [
        "print(f\"train: {len(X_train)} ({len(X_train)/len(X):.2f})\\n\"\n",
        "      f\"val: {len(X_val)} ({len(X_val)/len(X):.2f})\\n\"\n",
        "      f\"test: {len(X_test)} ({len(X_test)/len(X):.2f})\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 1010 (0.70)\n",
            "val: 217 (0.15)\n",
            "test: 217 (0.15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7KBZxsNkSW"
      },
      "source": [
        "# Get counts for each class\n",
        "counts = {}\n",
        "counts['train_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_train, order=1) for combination in row)\n",
        "counts['val_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_val, order=1) for combination in row)\n",
        "counts['test_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_test, order=1) for combination in row)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "XsqdznxBNkSW",
        "outputId": "9059fa8c-db35-4627-cdfa-a90afab4bf97"
      },
      "source": [
        "# View distributions\n",
        "pd.DataFrame({\n",
        "    'train': counts['train_counts'],\n",
        "    'val': counts['val_counts'],\n",
        "    'test': counts['test_counts']\n",
        "}).T.fillna(0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(15,)</th>\n",
              "      <th>(19,)</th>\n",
              "      <th>(33,)</th>\n",
              "      <th>(21,)</th>\n",
              "      <th>(32,)</th>\n",
              "      <th>(14,)</th>\n",
              "      <th>(2,)</th>\n",
              "      <th>(20,)</th>\n",
              "      <th>(24,)</th>\n",
              "      <th>(5,)</th>\n",
              "      <th>(16,)</th>\n",
              "      <th>(9,)</th>\n",
              "      <th>(22,)</th>\n",
              "      <th>(12,)</th>\n",
              "      <th>(23,)</th>\n",
              "      <th>(0,)</th>\n",
              "      <th>(25,)</th>\n",
              "      <th>(34,)</th>\n",
              "      <th>(28,)</th>\n",
              "      <th>(10,)</th>\n",
              "      <th>(26,)</th>\n",
              "      <th>(27,)</th>\n",
              "      <th>(13,)</th>\n",
              "      <th>(17,)</th>\n",
              "      <th>(3,)</th>\n",
              "      <th>(1,)</th>\n",
              "      <th>(7,)</th>\n",
              "      <th>(11,)</th>\n",
              "      <th>(18,)</th>\n",
              "      <th>(4,)</th>\n",
              "      <th>(6,)</th>\n",
              "      <th>(29,)</th>\n",
              "      <th>(8,)</th>\n",
              "      <th>(31,)</th>\n",
              "      <th>(30,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>314</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>145</td>\n",
              "      <td>33</td>\n",
              "      <td>274</td>\n",
              "      <td>191</td>\n",
              "      <td>41</td>\n",
              "      <td>55</td>\n",
              "      <td>26</td>\n",
              "      <td>56</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>90</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>136</td>\n",
              "      <td>44</td>\n",
              "      <td>30</td>\n",
              "      <td>31</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>64</td>\n",
              "      <td>27</td>\n",
              "      <td>50</td>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>58</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>53</td>\n",
              "      <td>33</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>57</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>61</td>\n",
              "      <td>34</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       (15,)  (19,)  (33,)  (21,)  (32,)  ...  (6,)  (29,)  (8,)  (31,)  (30,)\n",
              "train    314     37     26     26    145  ...    24     24    32     33     23\n",
              "val       58      8      4      2     29  ...     5      7    10      7      4\n",
              "test      57      6      9      4     22  ...     5      9     9      6      7\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UIGPYZCNkSW"
      },
      "source": [
        "It's hard to compare these because our train and test proportions are different. Let's see what the distribution looks like once we balance it out. What do we need to multiply our test ratio by so that we have the same amount as our train ratio?\n",
        "\n",
        "$$ \\alpha * N_{test} = N_{train} $$\n",
        "\n",
        "$$ \\alpha = \\frac{N_{train}}{N_{test}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu1CRlQRNkSW"
      },
      "source": [
        "# Adjust counts across splits\n",
        "for k in counts['val_counts'].keys():\n",
        "    counts['val_counts'][k] = int(counts['val_counts'][k] * \\\n",
        "        (train_size/val_size))\n",
        "for k in counts['test_counts'].keys():\n",
        "    counts['test_counts'][k] = int(counts['test_counts'][k] * \\\n",
        "        (train_size/test_size))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "TRZcPnAkNkSW",
        "outputId": "dfd72f30-fd42-4d52-be83-50b101f35cb7"
      },
      "source": [
        "dist_df = pd.DataFrame({\n",
        "    'train': counts['train_counts'],\n",
        "    'val': counts['val_counts'],\n",
        "    'test': counts['test_counts']\n",
        "}).T.fillna(0)\n",
        "dist_df"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(15,)</th>\n",
              "      <th>(19,)</th>\n",
              "      <th>(33,)</th>\n",
              "      <th>(21,)</th>\n",
              "      <th>(32,)</th>\n",
              "      <th>(14,)</th>\n",
              "      <th>(2,)</th>\n",
              "      <th>(20,)</th>\n",
              "      <th>(24,)</th>\n",
              "      <th>(5,)</th>\n",
              "      <th>(16,)</th>\n",
              "      <th>(9,)</th>\n",
              "      <th>(22,)</th>\n",
              "      <th>(12,)</th>\n",
              "      <th>(23,)</th>\n",
              "      <th>(0,)</th>\n",
              "      <th>(25,)</th>\n",
              "      <th>(34,)</th>\n",
              "      <th>(28,)</th>\n",
              "      <th>(10,)</th>\n",
              "      <th>(26,)</th>\n",
              "      <th>(27,)</th>\n",
              "      <th>(13,)</th>\n",
              "      <th>(17,)</th>\n",
              "      <th>(3,)</th>\n",
              "      <th>(1,)</th>\n",
              "      <th>(7,)</th>\n",
              "      <th>(11,)</th>\n",
              "      <th>(18,)</th>\n",
              "      <th>(4,)</th>\n",
              "      <th>(6,)</th>\n",
              "      <th>(29,)</th>\n",
              "      <th>(8,)</th>\n",
              "      <th>(31,)</th>\n",
              "      <th>(30,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>314</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>145</td>\n",
              "      <td>33</td>\n",
              "      <td>274</td>\n",
              "      <td>191</td>\n",
              "      <td>41</td>\n",
              "      <td>55</td>\n",
              "      <td>26</td>\n",
              "      <td>56</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>90</td>\n",
              "      <td>44</td>\n",
              "      <td>28</td>\n",
              "      <td>136</td>\n",
              "      <td>44</td>\n",
              "      <td>30</td>\n",
              "      <td>31</td>\n",
              "      <td>63</td>\n",
              "      <td>45</td>\n",
              "      <td>64</td>\n",
              "      <td>27</td>\n",
              "      <td>50</td>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>270</td>\n",
              "      <td>37</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>135</td>\n",
              "      <td>37</td>\n",
              "      <td>247</td>\n",
              "      <td>154</td>\n",
              "      <td>32</td>\n",
              "      <td>42</td>\n",
              "      <td>18</td>\n",
              "      <td>51</td>\n",
              "      <td>42</td>\n",
              "      <td>46</td>\n",
              "      <td>51</td>\n",
              "      <td>93</td>\n",
              "      <td>32</td>\n",
              "      <td>9</td>\n",
              "      <td>196</td>\n",
              "      <td>60</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>79</td>\n",
              "      <td>14</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>23</td>\n",
              "      <td>32</td>\n",
              "      <td>46</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>266</td>\n",
              "      <td>28</td>\n",
              "      <td>42</td>\n",
              "      <td>18</td>\n",
              "      <td>102</td>\n",
              "      <td>46</td>\n",
              "      <td>284</td>\n",
              "      <td>158</td>\n",
              "      <td>42</td>\n",
              "      <td>51</td>\n",
              "      <td>14</td>\n",
              "      <td>51</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>46</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>163</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>74</td>\n",
              "      <td>46</td>\n",
              "      <td>116</td>\n",
              "      <td>51</td>\n",
              "      <td>74</td>\n",
              "      <td>51</td>\n",
              "      <td>28</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       (15,)  (19,)  (33,)  (21,)  (32,)  ...  (6,)  (29,)  (8,)  (31,)  (30,)\n",
              "train    314     37     26     26    145  ...    24     24    32     33     23\n",
              "val      270     37     18      9    135  ...    23     32    46     32     18\n",
              "test     266     28     42     18    102  ...    23     42    42     28     32\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-XWskGRNkSW"
      },
      "source": [
        "We can see how much deviance there is in our naive data splits by computing the standard deviation of each split's class counts from the mean (ideal split).\n",
        "\n",
        "$ \\sigma = \\sqrt{\\frac{(x - \\bar{x})^2}{N}} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYL9nvKvNkSW",
        "outputId": "a74397d2-7135-4e94-df60-6a44aa774f8a"
      },
      "source": [
        "# Standard deviation\n",
        "np.mean(np.std(dist_df.to_numpy(), axis=0))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.936725114942407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vorJjssYNkSW"
      },
      "source": [
        "Some of these distributions are not great. Let's try and balance this out a bit better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etOP2EetNkSW"
      },
      "source": [
        "**Stratified split**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whQp6BPxvQaz"
      },
      "source": [
        "Now we'll apply [iterative stratification](http://lpis.csd.auth.gr/publications/sechidis-ecmlpkdd-2011.pdf) via the [skmultilearn](http://scikit.ml/index.html) library, which essentially splits each input into subsets (where each label is considered individually) and then it distributes the samples starting with fewest \"positive\" samples and working up to the inputs that have the most labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31BlT7xPNkSW"
      },
      "source": [
        "from skmultilearn.model_selection import IterativeStratification"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1WZAQJGNkSW"
      },
      "source": [
        "def iterative_train_test_split(X, y, train_size):\n",
        "    \"\"\"Custom iterative train test split which \n",
        "    'maintains balanced representation with respect \n",
        "    to order-th label combinations.'\n",
        "    \"\"\"\n",
        "    stratifier = IterativeStratification(\n",
        "        n_splits=2, order=1, sample_distribution_per_fold=[1.0-train_size, train_size, ])\n",
        "    train_indices, test_indices = next(stratifier.split(X, y))\n",
        "    X_train, y_train = X[train_indices], y[train_indices]\n",
        "    X_test, y_test = X[test_indices], y[test_indices]\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jghaS1edNkSW"
      },
      "source": [
        "# Get data\n",
        "X = df.text.to_numpy()\n",
        "y = df.tags"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv0baiseNkSW"
      },
      "source": [
        "# Binarize y\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "y = label_encoder.encode(y)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMaDgwX7NkSW"
      },
      "source": [
        "# Split\n",
        "X_train, X_, y_train, y_ = iterative_train_test_split(\n",
        "    X, y, train_size=train_size)\n",
        "X_val, X_test, y_val, y_test = iterative_train_test_split(\n",
        "    X_, y_, train_size=0.5)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV1HlPP_NkSW",
        "outputId": "c139d412-b7c6-462c-f292-e4480fecc5e9"
      },
      "source": [
        "print(f\"train: {len(X_train)} ({len(X_train)/len(X):.2f})\\n\"\n",
        "      f\"val: {len(X_val)} ({len(X_val)/len(X):.2f})\\n\"\n",
        "      f\"test: {len(X_test)} ({len(X_test)/len(X):.2f})\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 1000 (0.69)\n",
            "val: 214 (0.15)\n",
            "test: 230 (0.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqjXL-lRNkSX"
      },
      "source": [
        "# Get counts for each class\n",
        "counts = {}\n",
        "counts['train_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_train, order=1) for combination in row)\n",
        "counts['val_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_val, order=1) for combination in row)\n",
        "counts['test_counts'] = Counter(str(combination) for row in get_combination_wise_output_matrix(\n",
        "    y_test, order=1) for combination in row)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKFGUgfkNkSX"
      },
      "source": [
        "# Adjust counts across splits\n",
        "for k in counts['val_counts'].keys():\n",
        "    counts['val_counts'][k] = int(counts['val_counts'][k] * \\\n",
        "        (train_size/val_size))\n",
        "for k in counts['test_counts'].keys():\n",
        "    counts['test_counts'][k] = int(counts['test_counts'][k] * \\\n",
        "        (train_size/test_size))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "Pn6kIt0HNkSX",
        "outputId": "0b2eebdd-a50b-46b1-f412-3b189af79bca"
      },
      "source": [
        "# View distributions\n",
        "pd.DataFrame({\n",
        "    'train': counts['train_counts'],\n",
        "    'val': counts['val_counts'],\n",
        "    'test': counts['test_counts']\n",
        "}).T.fillna(0)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(2,)</th>\n",
              "      <th>(4,)</th>\n",
              "      <th>(15,)</th>\n",
              "      <th>(14,)</th>\n",
              "      <th>(30,)</th>\n",
              "      <th>(34,)</th>\n",
              "      <th>(1,)</th>\n",
              "      <th>(26,)</th>\n",
              "      <th>(32,)</th>\n",
              "      <th>(20,)</th>\n",
              "      <th>(33,)</th>\n",
              "      <th>(25,)</th>\n",
              "      <th>(17,)</th>\n",
              "      <th>(21,)</th>\n",
              "      <th>(0,)</th>\n",
              "      <th>(24,)</th>\n",
              "      <th>(27,)</th>\n",
              "      <th>(6,)</th>\n",
              "      <th>(13,)</th>\n",
              "      <th>(3,)</th>\n",
              "      <th>(5,)</th>\n",
              "      <th>(16,)</th>\n",
              "      <th>(9,)</th>\n",
              "      <th>(19,)</th>\n",
              "      <th>(7,)</th>\n",
              "      <th>(28,)</th>\n",
              "      <th>(11,)</th>\n",
              "      <th>(22,)</th>\n",
              "      <th>(8,)</th>\n",
              "      <th>(29,)</th>\n",
              "      <th>(23,)</th>\n",
              "      <th>(31,)</th>\n",
              "      <th>(10,)</th>\n",
              "      <th>(18,)</th>\n",
              "      <th>(12,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>272.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>270.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>298.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>270.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        (2,)  (4,)  (15,)  (14,)  (30,)  ...  (23,)  (31,)  (10,)  (18,)  (12,)\n",
              "train  272.0  29.0  300.0   36.0   24.0  ...   41.0   32.0   45.0   21.0   38.0\n",
              "val    270.0  32.0  298.0   28.0   23.0  ...   42.0   32.0   46.0   23.0   42.0\n",
              "test   270.0  23.0  303.0   42.0   23.0  ...   42.0   32.0   42.0   18.0   37.0\n",
              "\n",
              "[3 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftgmBEVdNkSX"
      },
      "source": [
        "dist_df = pd.DataFrame({\n",
        "    'train': counts['train_counts'],\n",
        "    'val': counts['val_counts'],\n",
        "    'test': counts['test_counts']\n",
        "}).T.fillna(0)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02UhVufNkSX",
        "outputId": "49371b54-09b1-4dba-e998-5f4f9330891e"
      },
      "source": [
        "# Standard deviation\n",
        "np.mean(np.std(dist_df.to_numpy(), axis=0))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.142338654518357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GvMA5m0vWVr"
      },
      "source": [
        "> [Iterative stratification](http://scikit.ml/_modules/skmultilearn/model_selection/iterative_stratification.html#IterativeStratification) essentially creates splits while \"trying to maintain balanced representation with respect to order-th label combinations\". We used to an `order=1` for our iterative split which means we cared about providing representative distribution of each tag across the splits. But we can account for [higher-order](https://arxiv.org/abs/1704.08756) label relationships as well where we may care about the distribution of label combinations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGGV_zxqNkSX"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92iCUpQNkSX"
      },
      "source": [
        "Certain preprocessing steps are global (don't depend on our dataset) and others are local (constructs are learned from the training splits). For the local, dataset-dependent preprocessing steps, we want to ensure that we split the data first before preprocessing to avoid data leaks. \n",
        "\n",
        "We covered splitting first since many preprocessing transformations depend on the training split and our data splits were dependent only on the target labels (tags) which were already cleaned. However, you need to clean your data first before splitting, at least for the features that splitting depends on. So the process is more like: preprocessing (global, cleaning) → splitting → preprocessing (local, transformations)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAkat0GRNkSX"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYUFK7KWNkSX",
        "outputId": "694c0619-8a0e-45d1-f990-b31e8c2cf65c"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words('english')\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFoCaWPHNkSX"
      },
      "source": [
        "def preprocess(text, lower=True, stem=False, \n",
        "               filters=\"[!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~]\", \n",
        "               stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    if lower: \n",
        "        text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(filters, r\"\", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Remove links\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Stemming\n",
        "    if stem:\n",
        "        text = \" \".join([porter.stem(word) for word in text.split(' ')])\n",
        "\n",
        "    return text"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "050f82f5336746b5b0978a1a2708df17",
            "8096326052a14cb4bdb780ba78d9b287",
            "95c5b5af3be84fa1b338ab462d38a390",
            "40540669ea7f482b99e12e5d9947896c",
            "4e4352e6ad0f4d558808083c7f207959",
            "aa3505ba598a4092b471166e5323e6cd",
            "be38026bd1194171b19590886dc60477",
            "e3513ec3018c48ed9ea80a714bf6f2d7",
            "b7647a427de14f61b062c0f389b36a49",
            "e433a26e48ab4fc78c9b4b39bc1eaf84"
          ]
        },
        "id": "j1WDYA2jNkSX",
        "outputId": "6a49314d-4014-44eb-ff50-306bd9c8c935"
      },
      "source": [
        "@widgets.interact(lower=True, stem=False)\n",
        "def display_preprocessed_text(lower, stem):\n",
        "    text = \"Conditional image generation using Variational Autoencoders and GANs.\"\n",
        "    preprocessed_text = preprocess(text=text, lower=lower, stem=stem)\n",
        "    print (preprocessed_text)    "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "050f82f5336746b5b0978a1a2708df17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Checkbox(value=True, description='lower'), Checkbox(value=False, description='stem'), Ou…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaGO7f9dNkSX",
        "outputId": "0109a07c-ebdb-4657-e693-9df09500bd1c"
      },
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True, stem=False)\n",
        "print (f\"{df.text.values[0]}\\n{preprocessed_df.text.values[0]}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Albumentations Fast image augmentation library and easy to use wrapper around other libraries.\n",
            "albumentations fast image augmentation library easy use wrapper around libraries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsR6To1zNkSX"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQNks8TNkSX"
      },
      "source": [
        "This is not used in this course so please feel free to skip this section. We'll cover data augmentation (CV, NLP, audio, etc.) as a separate unit course in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR9WLz0jc3GO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf6ec03-244d-4bb0-eac4-325fe9d2b55e"
      },
      "source": [
        "!pip install nlpaug==1.1.0 transformers==3.0.2 -q"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 389kB 13.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 778kB 55.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 32.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 53.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 56.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6MX5Gm8NkSX"
      },
      "source": [
        "import nlpaug.augmenter.word as naw"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9kUIKpsNkSX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "9b3ec0cdbd314e92a4ed737d33b2b27d",
            "43411873c18c4c40ab710efb93615794",
            "33044effcf444563a2df73bc36dcebf8",
            "80fbd1d56723455ab37e5a78c658771e",
            "1febe73192464f6f90dd0938bdbd2f72",
            "aeee3fee49354d76b40dc6a900f8d8ce",
            "71e74527f1414dec85e3d9bc773a39c7",
            "a35a6cd5614a4ca3b06771e415bf406e",
            "c593338e7de345009d299de42c886891",
            "7d78745c170745218570e12242d4cfb6",
            "e802334372f64a77b068ca707fb5f6f9",
            "60047798552a44a9b5125322115b7d68",
            "41fa49c6a79f442b8183727277af83c7",
            "85bb57e1594e4a10a67fab793ecb8cb7",
            "224e844057b940f3bfc52a3192e8a96d",
            "f88370f1da9946898315681920379d65",
            "419b7c6013514b4f8858193b428c5a38",
            "b62d235a40d1454aa14a81fa6c89ef03",
            "4bdca700a61e480badf147aa601499e3",
            "9e6377687e8e408e89133d9693718b48",
            "ed615f1835094c84b20e241fbcc9739c",
            "2d8f3e7e878c4cb59363258008b476ca",
            "d22a2c74c4034fb595b73b5b50e8bd17",
            "35cc9d2677d6465a9396987b62959aed"
          ]
        },
        "outputId": "39fba32d-fcc3-4d31-d504-f67d968bcfa0"
      },
      "source": [
        "# Load tokenizers and transformers\n",
        "substitution = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', action=\"substitute\")\n",
        "insertion = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', action=\"insert\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b3ec0cdbd314e92a4ed737d33b2b27d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c593338e7de345009d299de42c886891",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "419b7c6013514b4f8858193b428c5a38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YWn96hxNkSX"
      },
      "source": [
        "text = \"Conditional image generation using Variational Autoencoders and GANs.\""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLt1kYXkg3L8",
        "outputId": "97755b5c-771c-47d4-ccbc-fa6aac1e6290"
      },
      "source": [
        "# Substitutions\n",
        "augmented_text = substitution.augment(text)\n",
        "print (augmented_text)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simplified regression representation using variational regression and gans.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36DzpSqbNkSX"
      },
      "source": [
        "Substitution doesn't seem like a great idea for us because there are certain keywords that provide strong signal for our tags so we don't want to alter those. Also, note that these augmentations are NOT deterministic and will vary every time we run them. Let's try insertion..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK8PV0FWb7pE",
        "outputId": "09feb0f7-f3fd-40b6-d489-4e848fec262c"
      },
      "source": [
        "# Insertions\n",
        "augmented_text = insertion.augment(text)\n",
        "print (augmented_text)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enabling conditional 2d image generation filters using hybrid variational autoencoders and gans.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5K29gM5NkSX"
      },
      "source": [
        "A little better but still quite fragile and now it can potentially insert key words that can influence false positive tags to appear. For now, we'll skip the data augmentation because it's quite fickle and our case is very unique. But we can see how this can be very effective once we can control what type of vocabulary to augment on (ex. don't alter tokens matching or relating to any algorithms and tasks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGvI2YuuNkSX"
      },
      "source": [
        "# 📈&nbsp; Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdQjMSQgNkSX"
      },
      "source": [
        "We'll begin modeling by starting with the simplest baseline and slowly adding complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4O57X2dNkSY"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXd8flJuNkSY"
      },
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "720j4HxQNkSY"
      },
      "source": [
        "def get_data_splits(df, train_size=0.7):\n",
        "    \"\"\"\"\"\"\n",
        "    # Get data\n",
        "    X = df.text.to_numpy()\n",
        "    y = df.tags\n",
        "\n",
        "    # Binarize y\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(y)\n",
        "    y = label_encoder.encode(y)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_, y_train, y_ = iterative_train_test_split(\n",
        "        X, y, train_size=train_size)\n",
        "    X_val, X_test, y_val, y_test = iterative_train_test_split(\n",
        "        X_, y_, train_size=0.5)\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, label_encoder"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q9C95ZAhJHv"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wr3x6ZESKB1"
      },
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAQjRWHCNkSY"
      },
      "source": [
        "## Random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StAbvxEGkSmS"
      },
      "source": [
        "<u><i>motivation</i></u>: We want to know what random (chance) performance looks like. All of our efforts should be well above this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6R-g-5INkSY"
      },
      "source": [
        "# Set seeds\n",
        "set_seeds()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIYPLUMnNkSY",
        "outputId": "e3583bca-fa93-4af1-c0a5-ba6524d53880"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True, stem=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (1000,), y_train: (1000, 35)\n",
            "X_val: (227,), y_val: (227, 35)\n",
            "X_test: (217,), y_test: (217, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UWsFo8cNkSY",
        "outputId": "d0f48680-2e81-4bad-efe1-793ff343bd39"
      },
      "source": [
        "# Label encoder\n",
        "print (label_encoder)\n",
        "print (label_encoder.classes)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<LabelEncoder(num_classes=35)>\n",
            "['attention', 'autoencoders', 'computer-vision', 'convolutional-neural-networks', 'data-augmentation', 'embeddings', 'flask', 'generative-adversarial-networks', 'graph-neural-networks', 'graphs', 'huggingface', 'image-classification', 'interpretability', 'keras', 'language-modeling', 'natural-language-processing', 'node-classification', 'object-detection', 'pretraining', 'production', 'pytorch', 'question-answering', 'regression', 'reinforcement-learning', 'representation-learning', 'scikit-learn', 'segmentation', 'self-supervised-learning', 'tensorflow', 'tensorflow-js', 'time-series', 'transfer-learning', 'transformers', 'unsupervised-learning', 'wandb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXTrB3ToNkSY",
        "outputId": "33bc0bbb-b455-4cd7-e35a-86b2854e55d2"
      },
      "source": [
        "# Generate random predictions\n",
        "y_pred = np.random.randint(low=0, high=2, size=(len(y_test), len(label_encoder.classes)))\n",
        "print (y_pred.shape)\n",
        "print (y_pred[0:5])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(217, 35)\n",
            "[[0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1]\n",
            " [1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1]\n",
            " [0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 0]\n",
            " [0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAAoXyNANkSY",
        "outputId": "c486df9a-8bbf-44c8-815a-b17e43581c23"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.0662941602216066,\n",
            "  \"recall\": 0.5065299488415251,\n",
            "  \"f1\": 0.10819194263879019,\n",
            "  \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLzOP5fIkYWl"
      },
      "source": [
        "We made the assumption that there is an equal probability for whether an input has a tag or not but this isn't true. Let's use the **train split** to figure out what the true probability is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN6tq9z6iW7a",
        "outputId": "0c222e27-7b11-4800-f7b7-ebf4a5e347a7"
      },
      "source": [
        "# Percentage of 1s (tag presence)\n",
        "tag_p = np.sum(np.sum(y_train)) / (len(y_train) * len(label_encoder.classes))\n",
        "print (tag_p)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06291428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vInlz4R1iA4i"
      },
      "source": [
        "# Generate weighted random predictions\n",
        "y_pred = np.random.choice(\n",
        "    np.arange(0, 2), size=(len(y_test), len(label_encoder.classes)), \n",
        "    p=[1-tag_p, tag_p])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LnLd-Arj5t0",
        "outputId": "8b306d69-c849-4cd3-b5f0-3e8e06b03b2d"
      },
      "source": [
        "# Validate percentage\n",
        "np.sum(np.sum(y_pred)) / (len(y_pred) * len(label_encoder.classes))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06240947992100066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpfBiruhkJME",
        "outputId": "37c37955-c1d8-4157-debc-7c201c9a9adc"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.060484184552507536,\n",
            "  \"recall\": 0.053727634571230636,\n",
            "  \"f1\": 0.048704498064854516,\n",
            "  \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC9ConMQlPgg"
      },
      "source": [
        "<u><i>limitations</i></u>: we didn't use the tokens in our input to affect our predictions so nothing was learned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVzBKdt3NkSY"
      },
      "source": [
        "## Rule-based"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_XWLBgQlSn-"
      },
      "source": [
        "<u><i>motivation</i></u>: we want to use signals in our inputs (along with domain expertise and auxiliary data) to determine the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXlgWoyFNkSY"
      },
      "source": [
        "# Set seeds\n",
        "set_seeds()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RzG44f6mx_4"
      },
      "source": [
        "### Unstemmed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhXtWZcgmxWW"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N961xapm1wS",
        "outputId": "1133c3ad-237a-464e-fdb6-7fc401e04ffd"
      },
      "source": [
        "# Restrict to relevant tags\n",
        "print (len(tags_dict))\n",
        "tags_dict = {tag: tags_dict[tag] for tag in label_encoder.classes}\n",
        "print (len(tags_dict))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sN9-ZfEm10i",
        "outputId": "b817d12a-52d3-4fa5-a183-7bb5924ffd02"
      },
      "source": [
        "# Map aliases\n",
        "aliases = {}\n",
        "for tag, values in tags_dict.items():\n",
        "    aliases[preprocess(tag)] = tag\n",
        "    for alias in values['aliases']:\n",
        "        aliases[preprocess(alias)] = tag\n",
        "aliases"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ae': 'autoencoders',\n",
              " 'attention': 'attention',\n",
              " 'autoencoders': 'autoencoders',\n",
              " 'cnn': 'convolutional-neural-networks',\n",
              " 'computer vision': 'computer-vision',\n",
              " 'convolutional neural networks': 'convolutional-neural-networks',\n",
              " 'cv': 'computer-vision',\n",
              " 'data augmentation': 'data-augmentation',\n",
              " 'embeddings': 'embeddings',\n",
              " 'flask': 'flask',\n",
              " 'gan': 'generative-adversarial-networks',\n",
              " 'generative adversarial networks': 'generative-adversarial-networks',\n",
              " 'gnn': 'graph-neural-networks',\n",
              " 'graph neural networks': 'graph-neural-networks',\n",
              " 'graphs': 'graphs',\n",
              " 'huggingface': 'huggingface',\n",
              " 'image classification': 'image-classification',\n",
              " 'image segmentation': 'segmentation',\n",
              " 'interpretability': 'interpretability',\n",
              " 'keras': 'keras',\n",
              " 'language modeling': 'language-modeling',\n",
              " 'lm': 'language-modeling',\n",
              " 'natural language processing': 'natural-language-processing',\n",
              " 'nlp': 'natural-language-processing',\n",
              " 'nlproc': 'natural-language-processing',\n",
              " 'node classification': 'node-classification',\n",
              " 'object detection': 'object-detection',\n",
              " 'pre training': 'pretraining',\n",
              " 'pretraining': 'pretraining',\n",
              " 'production': 'production',\n",
              " 'pytorch': 'pytorch',\n",
              " 'qa': 'question-answering',\n",
              " 'question answering': 'question-answering',\n",
              " 'regression': 'regression',\n",
              " 'reinforcement learning': 'reinforcement-learning',\n",
              " 'representation learning': 'representation-learning',\n",
              " 'rl': 'reinforcement-learning',\n",
              " 'scikit learn': 'scikit-learn',\n",
              " 'segmentation': 'segmentation',\n",
              " 'self supervised learning': 'self-supervised-learning',\n",
              " 'sklearn': 'scikit-learn',\n",
              " 'tensorflow': 'tensorflow',\n",
              " 'tensorflow js': 'tensorflow-js',\n",
              " 'tf': 'tensorflow',\n",
              " 'tf js': 'tensorflow-js',\n",
              " 'time series': 'time-series',\n",
              " 'time series analysis': 'time-series',\n",
              " 'transfer learning': 'transfer-learning',\n",
              " 'transformers': 'transformers',\n",
              " 'unsupervised learning': 'unsupervised-learning',\n",
              " 'vision': 'computer-vision',\n",
              " 'wandb': 'wandb',\n",
              " 'weights biases': 'wandb'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntVJvdVBm14U"
      },
      "source": [
        "def get_classes(text, aliases, tags_dict):\n",
        "    \"\"\"If a token matches an alias, \n",
        "    then add the corresponding tag\n",
        "    class (and parent tags if any).\"\"\"\n",
        "    classes = []\n",
        "    for alias, tag in aliases.items():\n",
        "        if alias in text:\n",
        "            classes.append(tag)\n",
        "            for parent in tags_dict[tag][\"parents\"]:\n",
        "                classes.append(parent)\n",
        "    return list(set(classes))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKHKKwNCnBzX",
        "outputId": "2d6bb274-1a05-47a3-b7ff-d26c1c2fa2a1"
      },
      "source": [
        "# Sample\n",
        "text = \"This project extends gans for data augmentation specifically for object detection tasks.\"\n",
        "get_classes(text=preprocess(text), aliases=aliases, tags_dict=tags_dict)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data-augmentation',\n",
              " 'object-detection',\n",
              " 'generative-adversarial-networks',\n",
              " 'computer-vision']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-w5gcjnB29"
      },
      "source": [
        "# Prediction\n",
        "y_pred = []\n",
        "for text in X_test:\n",
        "    classes = get_classes(text, aliases, tags_dict)\n",
        "    y_pred.append(classes)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEcszZaGnZye"
      },
      "source": [
        "# Encode labels\n",
        "y_pred = label_encoder.encode(y_pred)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erYMwIffnB66",
        "outputId": "91ce7359-95f8-4ef7-edf5-f39df73016c5"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=4))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"precision\": 0.8527917293434535,\n",
            "    \"recall\": 0.38066760941576216,\n",
            "    \"f1\": 0.48975323243320396,\n",
            "    \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAjYzJFYSmgU",
        "outputId": "f94ac65b-2e02-4878-bda6-9452b0081f9f"
      },
      "source": [
        "# Inspection\n",
        "tag = \"transformers\"\n",
        "print (json.dumps(performance[\"class\"][tag], indent=2))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 1.0,\n",
            "  \"recall\": 0.32,\n",
            "  \"f1\": 0.48484848484848486,\n",
            "  \"num_samples\": 25.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKbvhmgam2yG"
      },
      "source": [
        "### Stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id2HJmqXnxPr"
      },
      "source": [
        "Before we do a more involved analysis, let's see if we can do better. We're looking for exact matches with the aliases which isn't always perfect, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcr2o2HjoI_O",
        "outputId": "4e0cb6f2-0523-403d-b968-879aea889daa"
      },
      "source": [
        "print (aliases[preprocess('gan')])\n",
        "# print (aliases[preprocess('gans')]) # this won't find any match\n",
        "print (aliases[preprocess('generative adversarial networks')])\n",
        "# print (aliases[preprocess('generative adversarial network')]) # this won't find any match"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generative-adversarial-networks\n",
            "generative-adversarial-networks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjv6GFJZoV6x"
      },
      "source": [
        "We don't want to keep adding explicit rules but we can use [stemming](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) to represent different forms of a word uniformly, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8YcWdTqpagt",
        "outputId": "cc400e9d-6682-4f86-f7e4-cc9d2f9c95c4"
      },
      "source": [
        "print (porter.stem(\"democracy\"))\n",
        "print (porter.stem(\"democracies\"))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "democraci\n",
            "democraci\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKCMUotL9wLr"
      },
      "source": [
        "So let's now stem our aliases as well as the tokens in our input text and then look for matches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEuiYEpJNkSY"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True, stem=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J4YQRZ_NkSY",
        "outputId": "0adae733-d18d-4213-a940-1a2ec3391dd8"
      },
      "source": [
        "# Map aliases\n",
        "aliases = {}\n",
        "for tag, values in tags_dict.items():\n",
        "    aliases[preprocess(tag, stem=True)] = tag\n",
        "    for alias in values['aliases']:\n",
        "        aliases[preprocess(alias, stem=True)] = tag\n",
        "aliases"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ae': 'autoencoders',\n",
              " 'attent': 'attention',\n",
              " 'autoencod': 'autoencoders',\n",
              " 'cnn': 'convolutional-neural-networks',\n",
              " 'comput vision': 'computer-vision',\n",
              " 'convolut neural network': 'convolutional-neural-networks',\n",
              " 'cv': 'computer-vision',\n",
              " 'data augment': 'data-augmentation',\n",
              " 'embed': 'embeddings',\n",
              " 'flask': 'flask',\n",
              " 'gan': 'generative-adversarial-networks',\n",
              " 'gener adversari network': 'generative-adversarial-networks',\n",
              " 'gnn': 'graph-neural-networks',\n",
              " 'graph': 'graphs',\n",
              " 'graph neural network': 'graph-neural-networks',\n",
              " 'huggingfac': 'huggingface',\n",
              " 'imag classif': 'image-classification',\n",
              " 'imag segment': 'segmentation',\n",
              " 'interpret': 'interpretability',\n",
              " 'kera': 'keras',\n",
              " 'languag model': 'language-modeling',\n",
              " 'lm': 'language-modeling',\n",
              " 'natur languag process': 'natural-language-processing',\n",
              " 'nlp': 'natural-language-processing',\n",
              " 'nlproc': 'natural-language-processing',\n",
              " 'node classif': 'node-classification',\n",
              " 'object detect': 'object-detection',\n",
              " 'pre train': 'pretraining',\n",
              " 'pretrain': 'pretraining',\n",
              " 'product': 'production',\n",
              " 'pytorch': 'pytorch',\n",
              " 'qa': 'question-answering',\n",
              " 'question answer': 'question-answering',\n",
              " 'regress': 'regression',\n",
              " 'reinforc learn': 'reinforcement-learning',\n",
              " 'represent learn': 'representation-learning',\n",
              " 'rl': 'reinforcement-learning',\n",
              " 'scikit learn': 'scikit-learn',\n",
              " 'segment': 'segmentation',\n",
              " 'self supervis learn': 'self-supervised-learning',\n",
              " 'sklearn': 'scikit-learn',\n",
              " 'tensorflow': 'tensorflow',\n",
              " 'tensorflow js': 'tensorflow-js',\n",
              " 'tf': 'tensorflow',\n",
              " 'tf js': 'tensorflow-js',\n",
              " 'time seri': 'time-series',\n",
              " 'time seri analysi': 'time-series',\n",
              " 'transfer learn': 'transfer-learning',\n",
              " 'transform': 'transformers',\n",
              " 'unsupervis learn': 'unsupervised-learning',\n",
              " 'vision': 'computer-vision',\n",
              " 'wandb': 'wandb',\n",
              " 'weight bias': 'wandb'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx-tmDpbNkSY",
        "outputId": "e085f7b9-ce5e-441f-d547-e7dd73af895f"
      },
      "source": [
        "# Checks (we will write proper tests soon)\n",
        "print (aliases[preprocess('gan', stem=True)])\n",
        "print (aliases[preprocess('gans', stem=True)])\n",
        "print (aliases[preprocess('generative adversarial network', stem=True)])\n",
        "print (aliases[preprocess('generative adversarial networks', stem=True)])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generative-adversarial-networks\n",
            "generative-adversarial-networks\n",
            "generative-adversarial-networks\n",
            "generative-adversarial-networks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXoeXojANkSY",
        "outputId": "504c454d-71ce-4b24-e594-d7fd6256e5cb"
      },
      "source": [
        "# Sample\n",
        "text = \"This project extends gans for data augmentation specifically for object detection tasks.\"\n",
        "get_classes(text=preprocess(text, stem=True), aliases=aliases, tags_dict=tags_dict)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data-augmentation',\n",
              " 'object-detection',\n",
              " 'generative-adversarial-networks',\n",
              " 'computer-vision']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mw2GDgLNkSY"
      },
      "source": [
        "# Prediction\n",
        "y_pred = []\n",
        "for text in X_test:\n",
        "    classes = get_classes(text, aliases, tags_dict)\n",
        "    y_pred.append(classes)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcOkiIEXNkSY"
      },
      "source": [
        "# Encode labels\n",
        "y_pred = label_encoder.encode(y_pred)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCtq0fynVCBa"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0UobHBcNkSY",
        "outputId": "a0414ef6-7288-4cf2-e874-2788d9c26f32"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=4))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"precision\": 0.8405837971552256,\n",
            "    \"recall\": 0.48656350456551384,\n",
            "    \"f1\": 0.5794244643481148,\n",
            "    \"num_samples\": 473.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqAI4feLNkSZ",
        "outputId": "647f7af5-565c-4757-cb40-cce6a168f4f5"
      },
      "source": [
        "# Inspection\n",
        "tag = \"transformers\"\n",
        "print (json.dumps(performance[\"class\"][tag], indent=2))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.9285714285714286,\n",
            "  \"recall\": 0.48148148148148145,\n",
            "  \"f1\": 0.6341463414634146,\n",
            "  \"num_samples\": 27.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R-FEdESNkSZ"
      },
      "source": [
        "# TP, FP, FN samples\n",
        "index = label_encoder.class_to_index[tag]\n",
        "tp, fp, fn = [], [], []\n",
        "for i in range(len(y_test)):\n",
        "    true = y_test[i][index]\n",
        "    pred = y_pred[i][index]\n",
        "    if true and pred:\n",
        "        tp.append(i)\n",
        "    elif not true and pred:\n",
        "        fp.append(i)\n",
        "    elif true and not pred:\n",
        "        fn.append(i)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIz1zqOBNkSZ",
        "outputId": "71f43aaa-eca5-49d1-afdc-0e2d26d5e827"
      },
      "source": [
        "print (tp)\n",
        "print (fp)\n",
        "print (fn)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 15, 28, 46, 54, 94, 160, 165, 169, 190, 194, 199]\n",
            "[49]\n",
            "[4, 18, 61, 63, 72, 75, 89, 99, 137, 141, 142, 163, 174, 206]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mD8rsKpNkSZ",
        "outputId": "f6c60814-80ad-45bb-b794-961a3b056f7c"
      },
      "source": [
        "index = tp[0]\n",
        "print (X_test[index])\n",
        "print (f\"true: {label_encoder.decode([y_test[index]])[0]}\")\n",
        "print (f\"pred: {label_encoder.decode([y_pred[index]])[0]}\\n\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insight project insight design creat nlp servic code base front end gui streamlit backend server fastapi usag transform\n",
            "true: ['attention', 'huggingface', 'natural-language-processing', 'pytorch', 'transfer-learning', 'transformers']\n",
            "pred: ['natural-language-processing', 'transformers']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1zL5M2GNkSZ"
      },
      "source": [
        "# Sorted tags\n",
        "sorted_tags_by_f1 = OrderedDict(sorted(\n",
        "        performance['class'].items(), key=lambda tag: tag[1]['f1'], reverse=True))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695,
          "referenced_widgets": [
            "ca113cb62ea14cf3a4191bfbcb6aa3d0",
            "bf6d7d3de6b74149a8fd163996b27dca",
            "6559491ac044429ea5fba0b41424d5c6",
            "60a95824964d4e12a82912125c337568",
            "2aa0dd0c4ab340b1899a43790a784ec2",
            "f268772c427d402381687dd21e25660e",
            "62aa50cffeca4f44acf8de4c08f2ca5f"
          ]
        },
        "id": "s9rL5YbSNkSZ",
        "outputId": "5495b45c-d3d9-48a7-a082-88786e997e1f"
      },
      "source": [
        "@widgets.interact(tag=list(sorted_tags_by_f1.keys()))\n",
        "def display_tag_analysis(tag='transformers'):\n",
        "    # Performance\n",
        "    print (json.dumps(performance[\"class\"][tag], indent=2))\n",
        "    \n",
        "    # TP, FP, FN samples\n",
        "    index = label_encoder.class_to_index[tag]\n",
        "    tp, fp, fn = [], [], []\n",
        "    for i in range(len(y_test)):\n",
        "        true = y_test[i][index]\n",
        "        pred = y_pred[i][index]\n",
        "        if true and pred:\n",
        "            tp.append(i)\n",
        "        elif not true and pred:\n",
        "            fp.append(i)\n",
        "        elif true and not pred:\n",
        "            fn.append(i)\n",
        "            \n",
        "    # Samples\n",
        "    num_samples = 3\n",
        "    if len(tp): \n",
        "        print (\"\\n=== True positives ===\")\n",
        "        for i in tp[:num_samples]:        \n",
        "            print (f\"  {X_test[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fp): \n",
        "        print (\"=== False positives === \")\n",
        "        for i in fp[:num_samples]:        \n",
        "            print (f\"  {X_test[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fn): \n",
        "        print (\"=== False negatives ===\")\n",
        "        for i in fn[:num_samples]:        \n",
        "            print (f\"  {X_test[i]}\") \n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca113cb62ea14cf3a4191bfbcb6aa3d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=18, options=('autoencoders', 'pytorch', 'keras', 'gene…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcMrqlr_fUa7"
      },
      "source": [
        "> You can use false positives/negatives to discover potential errors in annotation. This can be especially useful when analyzing FP/FNs from rule-based approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qdSlJCMfyBT"
      },
      "source": [
        "Though we achieved decent precision, the recall is quite low. This is because rule-based approaches can yield labels with high certainty when there is an absolute condition match but it fails to generalize or learn implicit patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjoBs0D8VI23"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j4iNdkfVLRX",
        "outputId": "32bea2bf-7c0b-4a6f-958d-5ffba9f1a5de"
      },
      "source": [
        "# Infer\n",
        "text = \"Transfer learning with transformers for self-supervised learning\"\n",
        "print (preprocess(text, stem=True))\n",
        "get_classes(text=preprocess(text, stem=True), aliases=aliases, tags_dict=tags_dict)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transfer learn transform self supervis learn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['transfer-learning',\n",
              " 'self-supervised-learning',\n",
              " 'natural-language-processing',\n",
              " 'transformers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSvxZVVcFFMO"
      },
      "source": [
        "Now let's see what happens when we replace the word *transformers* with *BERT*. Sure we can add this as an alias but we can't keep doing this. This is where it makes sense to learn from the data as opposed to creating explicit rules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7cWn6Fgfxp2",
        "outputId": "b43c708e-60b6-49ae-88e9-56853dfc8665"
      },
      "source": [
        "# Infer\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "print (preprocess(text, stem=True))\n",
        "get_classes(text=preprocess(text, stem=True), aliases=aliases, tags_dict=tags_dict)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transfer learn bert self supervis learn\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['transfer-learning', 'self-supervised-learning']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdzlfoIzloqc"
      },
      "source": [
        "<u><i>limitations</i></u>: we failed to generalize or learn any implicit patterns to predict the labels because we treat the tokens in our input as isolated entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6rPM9Q8fX3-"
      },
      "source": [
        "> We would ideally spend more time tuning our model because it's so simple and quick to train. This approach also applies to all the other models we'll look at as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoa5oVgaNkSZ"
      },
      "source": [
        "## Simple ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqg_kc3VmHb9"
      },
      "source": [
        "<u><i>motivation</i></u>:\n",
        "- *representation*: use term frequency-inverse document frequency [(TF-IDF)](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to capture the significance of a token to a particular input with respect to all the inputs, as opposed to treating the words in our input text as isolated tokens.\n",
        "- *architecture*: we want our model to meaningfully extract the encoded signal to predict the output labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOJW4AONNkSZ"
      },
      "source": [
        "So far we've treated the words in our input text as isolated tokens and we haven't really captured any meaning between tokens. Let's use term frequency–inverse document frequency (**TF-IDF**) to capture the significance of a token to a particular input with respect to all the inputs.\n",
        "\n",
        "$$ w_{i, j} = \\text{tf}_{i, j} * log(\\frac{N}{\\text{df}_i}) $$\n",
        "\n",
        "$$ w_{i, j}: \\text{tf-idf weight for term i in document j} $$\n",
        "$$ \\text{tf}_{i, j}: \\text{# of times term i appear in document j} $$\n",
        "$$ N: \\text{total # of documents} $$\n",
        "$$ {\\text{df}_i}: \\text{# of documents with token i} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiRzEi9iNkSZ"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2P0kMvKNkSZ"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrJ6fqmlNkSZ"
      },
      "source": [
        "# Set seeds\n",
        "set_seeds()"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIaiaykFNkSZ"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True, stem=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipggqVfzNkSZ",
        "outputId": "5c205064-e15f-4bfd-aaf9-4d28d697d0fc"
      },
      "source": [
        "# Tf-idf\n",
        "vectorizer = TfidfVectorizer()\n",
        "print (X_train[0])\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_val = vectorizer.transform(X_val)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "print (X_train.shape)\n",
        "print (X_train[0]) # scipy.sparse.csr_matrix"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "albument fast imag augment librari easi use wrapper around librari\n",
            "(1000, 2654)\n",
            "  (0, 190)\t0.34307733697679055\n",
            "  (0, 2630)\t0.3991510203964918\n",
            "  (0, 2522)\t0.14859192074955896\n",
            "  (0, 728)\t0.29210630687446\n",
            "  (0, 1356)\t0.4515371929370289\n",
            "  (0, 217)\t0.2870036535570893\n",
            "  (0, 1157)\t0.18851186612963625\n",
            "  (0, 876)\t0.31431481238098835\n",
            "  (0, 118)\t0.44156912440424356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEShazTUNkSZ"
      },
      "source": [
        "def fit_and_evaluate(model):\n",
        "    \"\"\"Fit and evaluate each model.\"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    performance = get_metrics(\n",
        "        y_true=y_test, y_pred=y_pred, classes=list(label_encoder.classes))\n",
        "    return performance['overall']"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YN1FqKrNkSZ",
        "outputId": "efb4cd0b-4dda-4f28-d1fa-e1eb22bf28ce"
      },
      "source": [
        "# Models\n",
        "performance = {}\n",
        "performance['logistic-regression'] = fit_and_evaluate(OneVsRestClassifier(\n",
        "    LogisticRegression(), n_jobs=1))\n",
        "performance['k-nearest-neighbors'] = fit_and_evaluate(\n",
        "    KNeighborsClassifier())\n",
        "performance['random-forest'] = fit_and_evaluate(\n",
        "    RandomForestClassifier(n_jobs=-1))\n",
        "performance['gradient-boosting-machine'] = fit_and_evaluate(OneVsRestClassifier(\n",
        "    GradientBoostingClassifier()))\n",
        "performance['support-vector-machine'] = fit_and_evaluate(OneVsRestClassifier(\n",
        "    LinearSVC(), n_jobs=-1))\n",
        "print (json.dumps(performance, indent=2))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"logistic-regression\": {\n",
            "    \"precision\": 0.3563624338624338,\n",
            "    \"recall\": 0.0858365150175495,\n",
            "    \"f1\": 0.13067443826527078,\n",
            "    \"num_samples\": 480.0\n",
            "  },\n",
            "  \"k-nearest-neighbors\": {\n",
            "    \"precision\": 0.6172562358276645,\n",
            "    \"recall\": 0.3213868500136974,\n",
            "    \"f1\": 0.400741288236766,\n",
            "    \"num_samples\": 480.0\n",
            "  },\n",
            "  \"random-forest\": {\n",
            "    \"precision\": 0.5851306333244963,\n",
            "    \"recall\": 0.21548369514995133,\n",
            "    \"f1\": 0.29582560665419344,\n",
            "    \"num_samples\": 480.0\n",
            "  },\n",
            "  \"gradient-boosting-machine\": {\n",
            "    \"precision\": 0.7104917071723794,\n",
            "    \"recall\": 0.5106819976684509,\n",
            "    \"f1\": 0.575225354377256,\n",
            "    \"num_samples\": 480.0\n",
            "  },\n",
            "  \"support-vector-machine\": {\n",
            "    \"precision\": 0.8059313061625735,\n",
            "    \"recall\": 0.40445445906037036,\n",
            "    \"f1\": 0.5164548230244397,\n",
            "    \"num_samples\": 480.0\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyv7n9ZKpXRu"
      },
      "source": [
        "<u><i>limitations</i></u>:\n",
        "- *representation*: TF-IDF representations don't encapsulate much signal beyond frequency but we require more fine-grained token representations.\n",
        "- *architecture*: we want to develop models that can use better represented encodings in a more contextual manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW_93sOnNkSZ"
      },
      "source": [
        "## CNN w/ Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jERhoo07l0b"
      },
      "source": [
        "<u><i>motivation</i></u>:\n",
        "- *representation*: we want to have more robust (split tokens to characters) and meaningful ([embeddings](https://madewithml.com/courses/ml-foundations/embeddings/) representations for our input tokens.\n",
        "- *architecture*: we want to process our encoded inputs using [convolution (CNN)](https://madewithml.com/courses/ml-foundations/convolutional-neural-networks/) filters that can learn to analyze windows of embedded tokens to extract meaningful signal (n-gram feature extractors)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XD7VH1MNkSZ"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8X3qlEbNkSZ"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLn8Z4AINkSZ"
      },
      "source": [
        "# Set seeds\n",
        "set_seeds()"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbSoGGmPNkSZ"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "X_test_raw = X_test"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT0xmkCfNuy5",
        "outputId": "7d8bff3a-07f6-4f70-9fdc-aba0fea4fa84"
      },
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device('cuda' if (\n",
        "    torch.cuda.is_available() and cuda) else 'cpu')\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "print (device)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6r8kfAkNkSZ"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg0IROLfJY_3"
      },
      "source": [
        "We're going to tokenize our input text as character tokens so we can be robust to spelling errors and learn to generalize across tags. (ex. learning that RoBERTa, or any other future BERT based archiecture, warrants same tag as BERT)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krnCpNE6qJvq"
      },
      "source": [
        "<img width=\"500px\" src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/ml-foundations/cnn/inputs.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCZn1stNkSZ"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None, \n",
        "                 pad_token='<PAD>', oov_token='<UNK>',\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(' ')\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {\n",
        "                'char_level': self.char_level,\n",
        "                'oov_token': self.oov_token,\n",
        "                'token_to_index': self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibPSo_PBNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12169daa-203d-4b37-c48e-685b173f2cb0"
      },
      "source": [
        "# Tokenize\n",
        "char_level = True\n",
        "tokenizer = Tokenizer(char_level=char_level)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "vocab_size = len(tokenizer)\n",
        "print (tokenizer)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokenizer(num_tokens=39)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84JQQqJrNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c111395f-f6c1-4cf8-cfbd-7ce8a0130a74"
      },
      "source": [
        "tokenizer.token_to_index"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 2,\n",
              " '0': 30,\n",
              " '1': 31,\n",
              " '2': 26,\n",
              " '3': 32,\n",
              " '4': 37,\n",
              " '5': 33,\n",
              " '6': 36,\n",
              " '7': 38,\n",
              " '8': 35,\n",
              " '9': 34,\n",
              " '<PAD>': 0,\n",
              " '<UNK>': 1,\n",
              " 'a': 7,\n",
              " 'b': 20,\n",
              " 'c': 12,\n",
              " 'd': 15,\n",
              " 'e': 3,\n",
              " 'f': 19,\n",
              " 'g': 14,\n",
              " 'h': 18,\n",
              " 'i': 4,\n",
              " 'j': 28,\n",
              " 'k': 24,\n",
              " 'l': 11,\n",
              " 'm': 16,\n",
              " 'n': 5,\n",
              " 'o': 10,\n",
              " 'p': 13,\n",
              " 'q': 29,\n",
              " 'r': 8,\n",
              " 's': 9,\n",
              " 't': 6,\n",
              " 'u': 17,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 25,\n",
              " 'y': 21,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqFL_J_UNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a9cd5e-0e86-4ee9-8604-9d91e68b09ab"
      },
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → albumentations fast image augmentation library easy use wrapper around libraries\n",
            "  (tokenized) → [ 7 11 20 17 16  3  5  6  7  6  4 10  5  9  2 19  7  9  6  2  4 16  7 14\n",
            "  3  2  7 17 14 16  3  5  6  7  6  4 10  5  2 11  4 20  8  7  8 21  2  3\n",
            "  7  9 21  2 17  9  3  2 23  8  7 13 13  3  8  2  7  8 10 17  5 15  2 11\n",
            "  4 20  8  7  8  4  3  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUrzrb06NkSa"
      },
      "source": [
        "### Data imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUiU_-XVNkSa"
      },
      "source": [
        "We'll factor class weights in our objective function ([binary cross entropy with logits](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)) to help with class imbalance. There are many other techniques such as over sampling from underrepresented classes, undersampling, etc. but we'll cover these in a separate unit lesson on data imbalance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETiBnH_JNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ecaa3f3-bc1a-40d2-b2e3-0f1549900bd1"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class counts: [120  41 388 106  41  75  34  73  51  78  64  51  55  93  51 429  33  69\n",
            "  30  51 258  32  49  59  57  60  48  40 213  40  34  46 196  39  39],\n",
            "class weights: {0: 0.008333333333333333, 1: 0.024390243902439025, 2: 0.002577319587628866, 3: 0.009433962264150943, 4: 0.024390243902439025, 5: 0.013333333333333334, 6: 0.029411764705882353, 7: 0.0136986301369863, 8: 0.0196078431372549, 9: 0.01282051282051282, 10: 0.015625, 11: 0.0196078431372549, 12: 0.01818181818181818, 13: 0.010752688172043012, 14: 0.0196078431372549, 15: 0.002331002331002331, 16: 0.030303030303030304, 17: 0.014492753623188406, 18: 0.03333333333333333, 19: 0.0196078431372549, 20: 0.003875968992248062, 21: 0.03125, 22: 0.02040816326530612, 23: 0.01694915254237288, 24: 0.017543859649122806, 25: 0.016666666666666666, 26: 0.020833333333333332, 27: 0.025, 28: 0.004694835680751174, 29: 0.025, 30: 0.029411764705882353, 31: 0.021739130434782608, 32: 0.00510204081632653, 33: 0.02564102564102564, 34: 0.02564102564102564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UscX0dcrNkSa"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g02qQyaoJ9YT"
      },
      "source": [
        "We're going to place our data into a [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and use a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) to efficiently create batches for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhSPgWsvNkSa"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGoNL0oaNkSa"
      },
      "source": [
        "class CNNTextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        y = np.stack(batch[:, 1], axis=0)\n",
        "\n",
        "        # Pad inputs\n",
        "        X = pad_sequences(sequences=X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        y = torch.FloatTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            pin_memory=True)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcsLQ-xcNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9517092c-cf34-4e1e-afd4-e3db07ee3bb3"
      },
      "source": [
        "# Create datasets\n",
        "filter_sizes = list(range(1, 11))\n",
        "train_dataset = CNNTextDataset(\n",
        "    X=X_train, y=y_train, max_filter_size=max(filter_sizes))\n",
        "val_dataset = CNNTextDataset(\n",
        "    X=X_val, y=y_val, max_filter_size=max(filter_sizes))\n",
        "test_dataset = CNNTextDataset(\n",
        "    X=X_test, y=y_test, max_filter_size=max(filter_sizes))\n",
        "print (\"Data splits:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  y: {train_dataset[0][1]}\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data splits:\n",
            "  Train dataset:<Dataset(N=1000)>\n",
            "  Val dataset: <Dataset(N=227)>\n",
            "  Test dataset: <Dataset(N=217)>\n",
            "Sample point:\n",
            "  X: [ 7 11 20 17 16  3  5  6  7  6  4 10  5  9  2 19  7  9  6  2  4 16  7 14\n",
            "  3  2  7 17 14 16  3  5  6  7  6  4 10  5  2 11  4 20  8  7  8 21  2  3\n",
            "  7  9 21  2 17  9  3  2 23  8  7 13 13  3  8  2  7  8 10 17  5 15  2 11\n",
            "  4 20  8  7  8  4  3  9]\n",
            "  y: [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUkm-47FNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f2d8dc-7cec-4d5f-f4b1-84942e4b791a"
      },
      "source": [
        "# Create dataloaders\n",
        "batch_size = 128\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  X: [128, 196]\n",
            "  y: [128, 35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8UyFr9xNkSa"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HSHRnFmKg5g"
      },
      "source": [
        "We'll be using a convolutional neural network on top of our embedded tokens to extract meaningful spatial signal. This time, we'll be using many filter widths to act as n-gram feature extractors. If you're not familiar with CNNs be sure to check out the [CNN lesson](https://madewithml.com/courses/ml-foundations/convolutional-neural-networks/) where we walkthrough every component of the architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJdHiBArqaaH"
      },
      "source": [
        "<img width=\"500px\" src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/ml-foundations/cnn/convolution.gif\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs2AeywNL3yt"
      },
      "source": [
        "Let's visualize the model's forward pass.\n",
        "\n",
        "1. We'll first tokenize our inputs (`batch_size`, `max_seq_len`).\n",
        "2. Then we'll embed our tokenized inputs (`batch_size`, `max_seq_len`, `embedding_dim`).\n",
        "3. We'll apply convolution via filters (`filter_size`, `vocab_size`, `num_filters`) followed by batch normalization. Our filters act as character level n-gram detecors. We have three different filter sizes (2, 3 and 4) and they will act as bi-gram, tri-gram and 4-gram feature extractors, respectivelyy. \n",
        "4. We'll apply 1D global max pooling which will extract the most relevant information from the feature maps for making the decision.\n",
        "5. We feed the pool outputs to a fully-connected (FC) layer (with dropout).\n",
        "6. We use one more FC layer with softmax to derive class probabilities. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHRtownxL6X1"
      },
      "source": [
        "<img width=\"5000px\" src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/ml-foundations/cnn/model.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhteynQANkSa"
      },
      "source": [
        "# Arguments\n",
        "embedding_dim = 128\n",
        "num_filters = 128\n",
        "hidden_dim = 128\n",
        "dropout_p = 0.5"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWe7ktNMNkSa"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters, filter_sizes,\n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "\n",
        "        # Conv weights\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)  # (N, channels, sequence length)\n",
        "\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "\n",
        "            # `SAME` padding\n",
        "            padding_left = int(\n",
        "                (self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil(\n",
        "                (self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "\n",
        "            # Pool\n",
        "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
        "            z.append(_z)\n",
        "\n",
        "        # Concat outputs\n",
        "        z = torch.cat(z, 1)\n",
        "\n",
        "        # FC\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "\n",
        "        return z"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugjRPCGClmCc"
      },
      "source": [
        "Padding types:\n",
        "* **VALID**: no padding, the filters only use the \"valid\" values in the input. If the filter cannot reach all the input values (filters go left to right), the extra values on the right are dropped.\n",
        "* **SAME**: adds padding evenly to the right (preferred) and left sides of the input so that all values in the input are processed.\n",
        "\n",
        "<div align=\"left\">\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/ml-foundations/cnn/padding.png\" width=\"500\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXZ6ZD6AKbfr"
      },
      "source": [
        "We're add padding so that the convolutional outputs are the same shape as our inputs. The amount of padding for the `SAME` padding can be determined using the same equation. We want out output to have the same width as our input, so we solve for P:\n",
        "\n",
        "$ \\frac{W-F+2P}{S} + 1 = W $\n",
        "\n",
        "$ P = \\frac{S(W-1) - W + F}{2} $\n",
        "\n",
        "If $P$ is not a whole number, we round up (using `math.ceil`) and place the extra padding on the right side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suLpR5raNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d5be7d-60d7-46d6-86c9-cf9e6e387d25"
      },
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=vocab_size,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p,\n",
        "    num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
            "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
            "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
            "    (5): Conv1d(128, 128, kernel_size=(6,), stride=(1,))\n",
            "    (6): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
            "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,))\n",
            "    (8): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
            "    (9): Conv1d(128, 128, kernel_size=(10,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfcCItXQNkSa"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XYetoGvNkSa"
      },
      "source": [
        "# Arguments\n",
        "lr = 2e-4\n",
        "num_epochs = 200\n",
        "patience = 10"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmPoArUeNkSa"
      },
      "source": [
        "# Define loss\n",
        "class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfP6jpAsNkSa"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=5)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36OkuM21NkSa"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn, \n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvmUpxZRNkSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e7453a-36ed-466d-8d76-eee2033749b6"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    num_epochs, patience, train_dataloader, val_dataloader)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00796, val_loss: 0.00338, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00437, val_loss: 0.00281, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00407, val_loss: 0.00286, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 4 | train_loss: 0.00382, val_loss: 0.00276, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00357, val_loss: 0.00266, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00339, val_loss: 0.00260, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00334, val_loss: 0.00258, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00321, val_loss: 0.00256, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00311, val_loss: 0.00253, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00305, val_loss: 0.00250, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00298, val_loss: 0.00247, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00289, val_loss: 0.00245, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00287, val_loss: 0.00240, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00276, val_loss: 0.00237, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00265, val_loss: 0.00234, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00263, val_loss: 0.00230, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00254, val_loss: 0.00225, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00250, val_loss: 0.00222, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00239, val_loss: 0.00217, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00233, val_loss: 0.00213, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00227, val_loss: 0.00208, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00221, val_loss: 0.00205, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00215, val_loss: 0.00201, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00205, val_loss: 0.00198, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00203, val_loss: 0.00194, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00196, val_loss: 0.00191, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00189, val_loss: 0.00188, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00188, val_loss: 0.00184, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00181, val_loss: 0.00183, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00177, val_loss: 0.00181, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00171, val_loss: 0.00178, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00166, val_loss: 0.00175, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00163, val_loss: 0.00174, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00157, val_loss: 0.00173, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00158, val_loss: 0.00169, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00150, val_loss: 0.00170, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 37 | train_loss: 0.00146, val_loss: 0.00167, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00142, val_loss: 0.00166, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00142, val_loss: 0.00166, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00135, val_loss: 0.00163, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00132, val_loss: 0.00163, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 42 | train_loss: 0.00131, val_loss: 0.00163, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00127, val_loss: 0.00161, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 44 | train_loss: 0.00122, val_loss: 0.00161, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 45 | train_loss: 0.00119, val_loss: 0.00160, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00121, val_loss: 0.00161, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 47 | train_loss: 0.00112, val_loss: 0.00157, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 48 | train_loss: 0.00112, val_loss: 0.00157, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00110, val_loss: 0.00159, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 50 | train_loss: 0.00106, val_loss: 0.00158, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 51 | train_loss: 0.00103, val_loss: 0.00156, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00100, val_loss: 0.00158, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00099, val_loss: 0.00157, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 54 | train_loss: 0.00098, val_loss: 0.00156, lr: 2.00E-04, _patience: 7\n",
            "Epoch: 55 | train_loss: 0.00094, val_loss: 0.00154, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 56 | train_loss: 0.00092, val_loss: 0.00155, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 57 | train_loss: 0.00092, val_loss: 0.00152, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 58 | train_loss: 0.00089, val_loss: 0.00152, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 59 | train_loss: 0.00088, val_loss: 0.00152, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 60 | train_loss: 0.00085, val_loss: 0.00152, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 61 | train_loss: 0.00083, val_loss: 0.00151, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 62 | train_loss: 0.00082, val_loss: 0.00154, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 63 | train_loss: 0.00078, val_loss: 0.00153, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 64 | train_loss: 0.00077, val_loss: 0.00156, lr: 2.00E-04, _patience: 7\n",
            "Epoch: 65 | train_loss: 0.00074, val_loss: 0.00152, lr: 2.00E-04, _patience: 6\n",
            "Epoch: 66 | train_loss: 0.00074, val_loss: 0.00154, lr: 2.00E-04, _patience: 5\n",
            "Epoch: 67 | train_loss: 0.00072, val_loss: 0.00155, lr: 2.00E-05, _patience: 4\n",
            "Epoch: 68 | train_loss: 0.00070, val_loss: 0.00155, lr: 2.00E-05, _patience: 3\n",
            "Epoch: 69 | train_loss: 0.00071, val_loss: 0.00156, lr: 2.00E-05, _patience: 2\n",
            "Epoch: 70 | train_loss: 0.00068, val_loss: 0.00154, lr: 2.00E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nggIvJFoNkSa"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0igBVFnYNkSb"
      },
      "source": [
        "from pathlib import Path\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPA5ojyUNkSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "66452d87-79ca-4bd6-9012-6ddb79f650c7"
      },
      "source": [
        "# Threshold-PR curve\n",
        "train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "plt.plot(thresholds, precisions[:-1], \"r--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recalls[:-1], \"b-\", label=\"Recall\")\n",
        "plt.ylabel(\"Performance\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f534180e6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bF16I1WNkSb"
      },
      "source": [
        "# Determining the best threshold\n",
        "def find_best_threshold(y_true, y_prob):\n",
        "    \"\"\"Find the best threshold for maximum F1.\"\"\"\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_prob)\n",
        "    f1s = (2 * precisions * recalls) / (precisions + recalls)\n",
        "    return thresholds[np.argmax(f1s)]"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv9rdHebNkSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7544db8-ff7e-4071-be81-ae756171bb14"
      },
      "source": [
        "# Best threshold for f1\n",
        "threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "threshold"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31781667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0i2EYMYNkSb"
      },
      "source": [
        "# Determine predictions using threshold\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP9rWb-9NkSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b59d665-d607-4865-aea4-3c8414245365"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8716740083696184,\n",
            "  \"recall\": 0.48952525669459174,\n",
            "  \"f1\": 0.5994276061921316,\n",
            "  \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlKB1-sNkSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "18e3107c9123439090eac647ce56b21b",
            "0f4bc42d74d0496babe3c47450288a47",
            "3f9103c05ddf4c07a49badc34ed41c5b",
            "d9a54f89006b40cbab734598232849e9",
            "72153fed4b6143b1828d0ed17445e5cc",
            "d311cd50521b46e6b606f7319b4fa7bf",
            "15a1173858fe4576a3923bcc0169b375"
          ]
        },
        "outputId": "0a87821e-a65d-4c21-8d5a-672239c2ff7e"
      },
      "source": [
        "@widgets.interact(tag=list(sorted_tags_by_f1.keys()))\n",
        "def display_tag_analysis(tag='transformers'):\n",
        "    # Performance\n",
        "    print (json.dumps(performance[\"class\"][tag], indent=2))\n",
        "    \n",
        "    # TP, FP, FN samples\n",
        "    index = label_encoder.class_to_index[tag]\n",
        "    tp, fp, fn = [], [], []\n",
        "    for i in range(len(y_test)):\n",
        "        true = y_test[i][index]\n",
        "        pred = y_pred[i][index]\n",
        "        if true and pred:\n",
        "            tp.append(i)\n",
        "        elif not true and pred:\n",
        "            fp.append(i)\n",
        "        elif true and not pred:\n",
        "            fn.append(i)\n",
        "            \n",
        "    # Samples\n",
        "    num_samples = 3\n",
        "    if len(tp): \n",
        "        print (\"\\n=== True positives ===\\n\")\n",
        "        for i in tp[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fp): \n",
        "        print (\"=== False positives ===\\n\")\n",
        "        for i in fp[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fn): \n",
        "        print (\"=== False negatives ===\\n\")\n",
        "        for i in fn[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\") \n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18e3107c9123439090eac647ce56b21b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=18, options=('autoencoders', 'pytorch', 'keras', 'gene…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewsYvUnxNkSb"
      },
      "source": [
        "# Save artifacts\n",
        "dir = Path(\"cnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "tokenizer.save(fp=Path(dir, 'tokenzier.json'))\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4tJvSbaNkSb"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwI4ft7CNkSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c162c8a-7e9b-4916-d2cb-f809d461d93b"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenzier.json'))\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\n",
        "model = CNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=vocab_size,\n",
        "    num_filters=num_filters, filter_sizes=filter_sizes,\n",
        "    hidden_dim=hidden_dim, dropout_p=dropout_p,\n",
        "    num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "model.to(device)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
              "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
              "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
              "    (5): Conv1d(128, 128, kernel_size=(6,), stride=(1,))\n",
              "    (6): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
              "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,))\n",
              "    (8): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
              "    (9): Conv1d(128, 128, kernel_size=(10,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLeXU5LRYaal"
      },
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_SGtypzNkSb"
      },
      "source": [
        "# Dataloader\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "X = np.array(tokenizer.texts_to_sequences([preprocess(text)]))\n",
        "y_filler = label_encoder.encode([np.array([label_encoder.classes[0]]*len(X))])\n",
        "dataset = CNNTextDataset(\n",
        "    X=X, y=y_filler, max_filter_size=max(filter_sizes))\n",
        "dataloader = dataset.create_dataloader(\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRETV9QyNkSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea63ee5-99aa-43fc-9c43-dbf05c70e552"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural-language-processing',\n",
              "  'self-supervised-learning',\n",
              "  'transfer-learning',\n",
              "  'transformers']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYBoIl1Q8ZGB"
      },
      "source": [
        "<u><i>limitations</i></u>:\n",
        "- *representation*: embeddings are not contextual.\n",
        "- *architecture*: extracting signal from encoded inputs is limited by filter widths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWYOq-WNGaql"
      },
      "source": [
        "Since we're dealing with simple architectures and fast training times, it's a good opportunity to explore tuning and experiment with k-fold cross validation to properly reach any conclusions about performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAYcmAzRM-tV"
      },
      "source": [
        "## RNN w/ Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVVOVKAhNGE1"
      },
      "source": [
        "<u>*motivation*</u>: let's see if processing our embedded tokens in a sequential fashion using [recurrent neural networks (RNNs)](https://github.com/GokuMohandas/madewithml/blob/main/notebooks/13_Recurrent_Neural_Networks.ipynb) can yield better performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKnEtuvCNg6Q"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBxMouNuNcs_"
      },
      "source": [
        "# Set seeds\n",
        "set_seeds()"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brtcMErwNgCn"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "X_test_raw = X_test"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgaEU372U4UX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1a1580-b7ae-4d37-9ed0-3a4e34b9affe"
      },
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device('cuda' if (\n",
        "    torch.cuda.is_available() and cuda) else 'cpu')\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "print (device)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcf7hm4LN0K-"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNeDZnl6NgGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f10fc09-de92-4a32-ddd6-aeab2f5ecf8c"
      },
      "source": [
        "# Tokenize\n",
        "char_level = True\n",
        "tokenizer = Tokenizer(char_level=char_level)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "vocab_size = len(tokenizer)\n",
        "print (\"X tokenizer:\\n\"\n",
        "    f\"  {tokenizer}\")"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X tokenizer:\n",
            "  <Tokenizer(num_tokens=39)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LSM6nifbaWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8dce49-f247-4f13-b96f-1209a39f7229"
      },
      "source": [
        "tokenizer.token_to_index"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 2,\n",
              " '0': 30,\n",
              " '1': 31,\n",
              " '2': 26,\n",
              " '3': 32,\n",
              " '4': 37,\n",
              " '5': 33,\n",
              " '6': 36,\n",
              " '7': 38,\n",
              " '8': 35,\n",
              " '9': 34,\n",
              " '<PAD>': 0,\n",
              " '<UNK>': 1,\n",
              " 'a': 7,\n",
              " 'b': 20,\n",
              " 'c': 12,\n",
              " 'd': 15,\n",
              " 'e': 3,\n",
              " 'f': 19,\n",
              " 'g': 14,\n",
              " 'h': 18,\n",
              " 'i': 4,\n",
              " 'j': 28,\n",
              " 'k': 24,\n",
              " 'l': 11,\n",
              " 'm': 16,\n",
              " 'n': 5,\n",
              " 'o': 10,\n",
              " 'p': 13,\n",
              " 'q': 29,\n",
              " 'r': 8,\n",
              " 's': 9,\n",
              " 't': 6,\n",
              " 'u': 17,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 25,\n",
              " 'y': 21,\n",
              " 'z': 27}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU_CrrTpNgLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a45a764-73f0-444c-a58a-57d70b620d4c"
      },
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → albumentations fast image augmentation library easy use wrapper around libraries\n",
            "  (tokenized) → [ 7 11 20 17 16  3  5  6  7  6  4 10  5  9  2 19  7  9  6  2  4 16  7 14\n",
            "  3  2  7 17 14 16  3  5  6  7  6  4 10  5  2 11  4 20  8  7  8 21  2  3\n",
            "  7  9 21  2 17  9  3  2 23  8  7 13 13  3  8  2  7  8 10 17  5 15  2 11\n",
            "  4 20  8  7  8  4  3  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6HozknZOnBJ"
      },
      "source": [
        "### Data imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnSATH4wNgPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e0c873-294e-44fa-c79b-6712d9ca01c1"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (\"class counts:\\n\"\n",
        "    f\"  {counts}\\n\"\n",
        "    \"class weights:\\n\"\n",
        "    f\"  {class_weights}\")"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class counts:\n",
            "  [120  41 388 106  41  75  34  73  51  78  64  51  55  93  51 429  33  69\n",
            "  30  51 258  32  49  59  57  60  48  40 213  40  34  46 196  39  39]\n",
            "class weights:\n",
            "  {0: 0.008333333333333333, 1: 0.024390243902439025, 2: 0.002577319587628866, 3: 0.009433962264150943, 4: 0.024390243902439025, 5: 0.013333333333333334, 6: 0.029411764705882353, 7: 0.0136986301369863, 8: 0.0196078431372549, 9: 0.01282051282051282, 10: 0.015625, 11: 0.0196078431372549, 12: 0.01818181818181818, 13: 0.010752688172043012, 14: 0.0196078431372549, 15: 0.002331002331002331, 16: 0.030303030303030304, 17: 0.014492753623188406, 18: 0.03333333333333333, 19: 0.0196078431372549, 20: 0.003875968992248062, 21: 0.03125, 22: 0.02040816326530612, 23: 0.01694915254237288, 24: 0.017543859649122806, 25: 0.016666666666666666, 26: 0.020833333333333332, 27: 0.025, 28: 0.004694835680751174, 29: 0.025, 30: 0.029411764705882353, 31: 0.021739130434782608, 32: 0.00510204081632653, 33: 0.02564102564102564, 34: 0.02564102564102564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEVGPqP9OvJz"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Nj7QfJQnuv"
      },
      "source": [
        "class RNNTextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, len(X), y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        seq_lens = batch[:, 1]\n",
        "        y = np.stack(batch[:, 2], axis=0)\n",
        "\n",
        "        # Pad inputs\n",
        "        X = pad_sequences(sequences=X)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        seq_lens = torch.LongTensor(seq_lens.astype(np.int32))\n",
        "        y = torch.FloatTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, seq_lens, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            pin_memory=True)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzyPpgIfOwyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3baf51-fecf-4d60-f27e-745128e58993"
      },
      "source": [
        "# Create datasets\n",
        "batch_size = 128\n",
        "train_dataset = RNNTextDataset(\n",
        "    X=X_train, y=y_train)\n",
        "val_dataset = RNNTextDataset(\n",
        "    X=X_val, y=y_val)\n",
        "test_dataset = RNNTextDataset(\n",
        "    X=X_test, y=y_test)\n",
        "print (\"Data splits:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  seq_len: {train_dataset[0][1]}\\n\"\n",
        "    f\"  y: {train_dataset[0][2]}\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data splits:\n",
            "  Train dataset:<Dataset(N=1000)>\n",
            "  Val dataset: <Dataset(N=227)>\n",
            "  Test dataset: <Dataset(N=217)>\n",
            "Sample point:\n",
            "  X: [ 7 11 20 17 16  3  5  6  7  6  4 10  5  9  2 19  7  9  6  2  4 16  7 14\n",
            "  3  2  7 17 14 16  3  5  6  7  6  4 10  5  2 11  4 20  8  7  8 21  2  3\n",
            "  7  9 21  2 17  9  3  2 23  8  7 13 13  3  8  2  7  8 10 17  5 15  2 11\n",
            "  4 20  8  7  8  4  3  9]\n",
            "  seq_len: 80\n",
            "  y: [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPsMsTwHTLlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736ab1d4-ce09-4239-ba47-36c83052bec0"
      },
      "source": [
        "# Create dataloaders\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch_X, batch_seq_lens, batch_y = next(iter(train_dataloader))\n",
        "print (batch_X.shape)\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  seq_lens: {list(batch_seq_lens.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\")"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 196])\n",
            "Sample batch:\n",
            "  X: [128, 196]\n",
            "  seq_lens: [128]\n",
            "  y: [128, 35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEw7PfWIO2R1"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqUD-n0GWpRs"
      },
      "source": [
        "We'll be using a recurrent neural network to process our embedded tokens one at a time (sequentially). If you're not familiar with RNNs be sure to check out the [RNN lesson](https://github.com/GokuMohandas/madewithml/blob/main/notebooks/13_Recurrent_Neural_Networks.ipynb) *where* we walkthrough every component of the architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpY0eW_7rHix"
      },
      "source": [
        "<div align=\"left\">\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/ml-foundations/rnn/vanilla.png\" width=\"500\">\n",
        "</div>\n",
        "\n",
        "RNN forward pass for a single time step $X_t$:\n",
        "\n",
        "$h_t = tanh(W_{hh}h_{t-1} + W_{xh}X_t+b_h)$\n",
        "\n",
        "*where*:\n",
        "* $W_{hh}$ = hidden units weights| $\\in \\mathbb{R}^{HXH}$ ($H$ is the hidden dim)\n",
        "* $h_{t-1}$ = previous timestep's hidden state $\\in \\mathbb{R}^{NXH}$\n",
        "* $W_{xh}$ = input weights| $\\in \\mathbb{R}^{EXH}$\n",
        "* $X_t$ = input at time step t | $\\in \\mathbb{R}^{NXE}$ ($N$ is the batch size, $E$ is the embedding dim)\n",
        "* $b_h$ = hidden units bias $\\in \\mathbb{R}^{HX1}$\n",
        "* $h_t$ = output from RNN for timestep $t$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXQzFDkJOw2n"
      },
      "source": [
        "# Arguments\n",
        "embedding_dim = 128\n",
        "rnn_hidden_dim = 128\n",
        "hidden_dim = 128\n",
        "dropout_p = 0.5"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhqmFMVaTqqB"
      },
      "source": [
        "def gather_last_relevant_hidden(hiddens, seq_lens):\n",
        "    \"\"\"Extract and collect the last relevant \n",
        "    hidden state based on the sequence length.\"\"\"\n",
        "    seq_lens = seq_lens.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(seq_lens):\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1sno1LrOw6m"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim,\n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        # Initialize embeddings\n",
        "        self.embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                       num_embeddings=vocab_size,\n",
        "                                       padding_idx=padding_idx)\n",
        "        \n",
        "        # RNN\n",
        "        self.rnn = nn.GRU(embedding_dim, rnn_hidden_dim, \n",
        "                          batch_first=True, bidirectional=True)\n",
        "     \n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_dim*2, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Inputs\n",
        "        x_in, seq_lens = inputs\n",
        "\n",
        "        # Embed\n",
        "        x_in = self.embeddings(x_in)\n",
        "            \n",
        "        # Rnn outputs\n",
        "        out, h_n = self.rnn(x_in)\n",
        "        z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "\n",
        "        return z"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61A-Sy6vPz-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc560195-afa6-45b1-9d8e-6616dc8081b7"
      },
      "source": [
        "# Initialize model\n",
        "model = RNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=vocab_size,\n",
        "    rnn_hidden_dim=rnn_hidden_dim, hidden_dim=hidden_dim, \n",
        "    dropout_p=dropout_p, num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of RNN(\n",
            "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
            "  (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efUNgqnQQKgV"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyJTjWB9QJ7X"
      },
      "source": [
        "# Arguments\n",
        "lr = 2e-3\n",
        "num_epochs = 200\n",
        "patience = 10"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NciXFi3aQJ_D"
      },
      "source": [
        "# Define loss\n",
        "class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIrgvCcrQS-J"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=5)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3qUo_VYQTDf"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn, \n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W6hNCSeQTIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c5fc09-9d47-4961-aeab-45ac445bc3db"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    num_epochs, patience, train_dataloader, val_dataloader)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00811, val_loss: 0.00306, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00399, val_loss: 0.00314, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 3 | train_loss: 0.00331, val_loss: 0.00281, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00308, val_loss: 0.00270, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00299, val_loss: 0.00264, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00291, val_loss: 0.00259, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00283, val_loss: 0.00257, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00281, val_loss: 0.00256, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00276, val_loss: 0.00255, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00275, val_loss: 0.00254, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00274, val_loss: 0.00253, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00272, val_loss: 0.00253, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00268, val_loss: 0.00254, lr: 2.00E-03, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00269, val_loss: 0.00253, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00265, val_loss: 0.00253, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00263, val_loss: 0.00252, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00262, val_loss: 0.00252, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00261, val_loss: 0.00252, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00257, val_loss: 0.00252, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00255, val_loss: 0.00251, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00254, val_loss: 0.00251, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00255, val_loss: 0.00252, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00248, val_loss: 0.00253, lr: 2.00E-03, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00244, val_loss: 0.00252, lr: 2.00E-03, _patience: 7\n",
            "Epoch: 25 | train_loss: 0.00244, val_loss: 0.00253, lr: 2.00E-03, _patience: 6\n",
            "Epoch: 26 | train_loss: 0.00240, val_loss: 0.00252, lr: 2.00E-03, _patience: 5\n",
            "Epoch: 27 | train_loss: 0.00236, val_loss: 0.00250, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00232, val_loss: 0.00250, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00229, val_loss: 0.00250, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00225, val_loss: 0.00250, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00220, val_loss: 0.00249, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00219, val_loss: 0.00248, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00214, val_loss: 0.00247, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00211, val_loss: 0.00250, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00209, val_loss: 0.00258, lr: 2.00E-03, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00210, val_loss: 0.00257, lr: 2.00E-03, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00208, val_loss: 0.00248, lr: 2.00E-03, _patience: 6\n",
            "Epoch: 38 | train_loss: 0.00200, val_loss: 0.00248, lr: 2.00E-03, _patience: 5\n",
            "Epoch: 39 | train_loss: 0.00192, val_loss: 0.00246, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00188, val_loss: 0.00251, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 41 | train_loss: 0.00183, val_loss: 0.00247, lr: 2.00E-03, _patience: 8\n",
            "Epoch: 42 | train_loss: 0.00178, val_loss: 0.00245, lr: 2.00E-03, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00173, val_loss: 0.00249, lr: 2.00E-03, _patience: 9\n",
            "Epoch: 44 | train_loss: 0.00170, val_loss: 0.00253, lr: 2.00E-03, _patience: 8\n",
            "Epoch: 45 | train_loss: 0.00169, val_loss: 0.00251, lr: 2.00E-03, _patience: 7\n",
            "Epoch: 46 | train_loss: 0.00162, val_loss: 0.00250, lr: 2.00E-03, _patience: 6\n",
            "Epoch: 47 | train_loss: 0.00159, val_loss: 0.00254, lr: 2.00E-03, _patience: 5\n",
            "Epoch: 48 | train_loss: 0.00157, val_loss: 0.00263, lr: 2.00E-04, _patience: 4\n",
            "Epoch: 49 | train_loss: 0.00151, val_loss: 0.00256, lr: 2.00E-04, _patience: 3\n",
            "Epoch: 50 | train_loss: 0.00148, val_loss: 0.00253, lr: 2.00E-04, _patience: 2\n",
            "Epoch: 51 | train_loss: 0.00147, val_loss: 0.00256, lr: 2.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4E5eYKmVrYV"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxG61tqVQcxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1f99d2c9-5aa6-4c6e-e0ed-709ef490d79b"
      },
      "source": [
        "# Threshold-PR curve\n",
        "train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "plt.plot(thresholds, precisions[:-1], \"r--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recalls[:-1], \"b-\", label=\"Recall\")\n",
        "plt.ylabel(\"Performance\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f53417e0550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yuPcOr8Qc-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c732b1f3-5631-417c-c65d-257bd0e71ae1"
      },
      "source": [
        "# Best threshold for f1\n",
        "threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "threshold"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24712393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdAnAZxyVvZs"
      },
      "source": [
        "# Determine predictions using threshold\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uevxq2UfVvdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15e6723-07fa-42fd-9d73-a6db30604311"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.28786588616637876,\n",
            "  \"recall\": 0.20581707591806114,\n",
            "  \"f1\": 0.22363324596852793,\n",
            "  \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QJfxShLVvia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831,
          "referenced_widgets": [
            "d55c23d4f3294206acbc961246886289",
            "7bcf2c14093b416a9424e4cadddc8339",
            "07d2813a45e24689baae3c6b6daf0a19",
            "b5f1a10bc8de4e4fa2ad84100870f793",
            "4d729dd457054c2595292fc0e4a31660",
            "4adbad95a9744015898234875e7c250b",
            "a25ebb3fe003432db2e804dc95880692"
          ]
        },
        "outputId": "43819f86-6b87-4ff7-f59c-b2cc0460cede"
      },
      "source": [
        "@widgets.interact(tag=list(sorted_tags_by_f1.keys()))\n",
        "def display_tag_analysis(tag='transformers'):\n",
        "    # Performance\n",
        "    print (json.dumps(performance[\"class\"][tag], indent=2))\n",
        "    \n",
        "    # TP, FP, FN samples\n",
        "    index = label_encoder.class_to_index[tag]\n",
        "    tp, fp, fn = [], [], []\n",
        "    for i in range(len(y_test)):\n",
        "        true = y_test[i][index]\n",
        "        pred = y_pred[i][index]\n",
        "        if true and pred:\n",
        "            tp.append(i)\n",
        "        elif not true and pred:\n",
        "            fp.append(i)\n",
        "        elif true and not pred:\n",
        "            fn.append(i)\n",
        "            \n",
        "    # Samples\n",
        "    num_samples = 3\n",
        "    if len(tp): \n",
        "        print (\"\\n=== True positives ===\")\n",
        "        for i in tp[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fp): \n",
        "        print (\"=== False positives === \")\n",
        "        for i in fp[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fn): \n",
        "        print (\"=== False negatives ===\")\n",
        "        for i in fn[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\") \n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d55c23d4f3294206acbc961246886289",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=18, options=('autoencoders', 'pytorch', 'keras', 'gene…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xscxEDmwWWdB"
      },
      "source": [
        "# Save artifacts\n",
        "dir = Path(\"rnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "tokenizer.save(fp=Path(dir, 'tokenzier.json'))\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXI1A8XiWWkD"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbd-eEuy7kT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d60873-4d3e-4b2b-f9cd-374454e91834"
      },
      "source": [
        "# Initialize model\n",
        "model = RNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=vocab_size,\n",
        "    rnn_hidden_dim=rnn_hidden_dim, hidden_dim=hidden_dim, \n",
        "    dropout_p=dropout_p, num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "print (f\"Model:\\n{model.named_parameters}\")"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model:\n",
            "<bound method Module.named_parameters of RNN(\n",
            "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
            "  (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkBEcU9cWWsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3746ed9-ec40-4d21-f0a6-a5f0421bab30"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenzier.json'))\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\n",
        "model = RNN(\n",
        "    embedding_dim=embedding_dim, vocab_size=vocab_size,\n",
        "    rnn_hidden_dim=rnn_hidden_dim, hidden_dim=hidden_dim, \n",
        "    dropout_p=dropout_p, num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "model.to(device)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
              "  (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCXEeIw_YIUX"
      },
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD332lkVWWyi"
      },
      "source": [
        "# Dataloader\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "X = np.array(tokenizer.texts_to_sequences([preprocess(text)]))\n",
        "y_filler = label_encoder.encode([np.array([label_encoder.classes[0]]*len(X))])\n",
        "dataset = RNNTextDataset(X=X, y=y_filler)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34FiTvOmWW2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e4c83f-b922-48ca-b6e3-e52b10fdedae"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYS04mT89hKZ"
      },
      "source": [
        "<u>*limitation*</u>: since we're using character embeddings our encoded sequences are quite long (>100), the RNNs may potentially be suffering from memory issues. We also can't process our tokens in parallel because we're restricted by sequential processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unvvTilYfbVA"
      },
      "source": [
        "> Don't be afraid to experiment with stacking models if they're able to extract unique signal from your encoded data, for example applying CNNs on the outputs from the RNN (outputs from all tokens, not just last relevant one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AslFYdF4NkSb"
      },
      "source": [
        "## Transformers w/ Contextual Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45KENcpNkSb"
      },
      "source": [
        "<u><i>motivation</i></u>:\n",
        "- *representation*: we want better representation for our input tokens via contextual embeddings where the token representation is based on the specific neighboring tokens. We can also use sub-word tokens, as opposed to character tokens, since they can hold more meaningful representation for many of our keywords, prefixes, suffixes, etc.\n",
        "- *architecture*: we want to use [Transformers](https://www.youtube.com/watch?v=LwV7LKunDbs) to attend (in parallel) to all the tokens in our input, as opposed to being limited by filter spans (CNNs) or memory issues from sequential processing (RNNs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB5tS8LC8L8Y"
      },
      "source": [
        "<a href=\"https://miro.medium.com/max/2880/1*BHzGVskWGS_3jEcYYi6miQ.png\" target=\"_blank\"><img width=\"400px\" src=\"https://miro.medium.com/max/2880/1*BHzGVskWGS_3jEcYYi6miQ.png\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39TY4RkINkSb"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3CgT_-cNkSb"
      },
      "source": [
        "# Set seeds\n",
        "set_seeds()"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW7jskt_NkSb"
      },
      "source": [
        "# Get data splits\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "X_test_raw = X_test"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK7pKjSBU58y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4eab93-7805-40cb-d767-46b4369e155d"
      },
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device('cuda' if (\n",
        "    torch.cuda.is_available() and cuda) else 'cpu')\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "print (device)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUMhZv-PNkSb"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRhChKSKVaf9"
      },
      "source": [
        "We'll be using the [BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer) to tokenize our input text in to sub-word tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmS7KQqNkSb"
      },
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJvnrCK7NkSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "6903228530ae4e0a84d8886bc04de5c2",
            "a87ef850764e4d5f8b7d723877a29145",
            "9098a6d0aeb142b2a21e149bcf7249e2",
            "82cd21df2e6b4b558bee08c8757c717e",
            "b907baf2fbd1403cbb9bc43cea0bf4f6",
            "c2161fece84148408c3a363e1e097fc7",
            "202c1962949444c1beb3fdf9843110ac",
            "23c5897ffd06401594fa1ee393cdb6cf"
          ]
        },
        "outputId": "faa0e21d-56ab-419c-faae-fe12b2f62fd7"
      },
      "source": [
        "# Load tokenizer and model\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "vocab_size = len(tokenizer)\n",
        "print (vocab_size)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6903228530ae4e0a84d8886bc04de5c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=227845.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "31090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtFzLXhmNkSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7175106d-70ae-4b75-9f66-d61836b3ac6f"
      },
      "source": [
        "# Tokenize inputs\n",
        "encoded_input = tokenizer(X_train.tolist(), return_tensors='pt', padding=True)\n",
        "X_train_ids = encoded_input['input_ids']\n",
        "X_train_masks = encoded_input['attention_mask']\n",
        "print (X_train_ids.shape, X_train_masks.shape)\n",
        "encoded_input = tokenizer(X_val.tolist(), return_tensors='pt', padding=True)\n",
        "X_val_ids = encoded_input['input_ids']\n",
        "X_val_masks = encoded_input['attention_mask']\n",
        "print (X_val_ids.shape, X_val_masks.shape)\n",
        "encoded_input = tokenizer(X_test.tolist(), return_tensors='pt', padding=True)\n",
        "X_test_ids = encoded_input['input_ids']\n",
        "X_test_masks = encoded_input['attention_mask']\n",
        "print (X_test_ids.shape, X_test_masks.shape)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 41]) torch.Size([1000, 41])\n",
            "torch.Size([227, 38]) torch.Size([227, 38])\n",
            "torch.Size([217, 38]) torch.Size([217, 38])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75NI7Fk-NkSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88033db-d2d9-4bd1-d71e-abc73e68ba38"
      },
      "source": [
        "# Decode\n",
        "print (f\"{X_train_ids[0]}\\n{tokenizer.decode(X_train_ids[0])}\")"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  102,  6160,  1923,   288,  3254,  1572, 18205,  5560,  4578,   626,\n",
            "        23474,   291,  2715, 10558,   103,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0])\n",
            "[CLS] albumentations fast image augmentation library easy use wrapper around libraries [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RI5iY4F7trN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c822530c-b40e-4671-d5c2-13fdd407f438"
      },
      "source": [
        "# Sub-word tokens\n",
        "print (tokenizer.convert_ids_to_tokens(ids=X_train_ids[0]))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'alb', '##ument', '##ations', 'fast', 'image', 'augmentation', 'library', 'easy', 'use', 'wrap', '##per', 'around', 'libraries', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKkuRLt1NkSc"
      },
      "source": [
        "### Data imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72i2z1sDNkSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5467592f-47f0-4380-b087-88480d380b04"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (\"class counts:\\n\"\n",
        "    f\"  {counts}\\n\\n\"\n",
        "    \"class weights:\\n\"\n",
        "    f\"  {class_weights}\")"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class counts:\n",
            "  [120  41 388 106  41  75  34  73  51  78  64  51  55  93  51 429  33  69\n",
            "  30  51 258  32  49  59  57  60  48  40 213  40  34  46 196  39  39]\n",
            "\n",
            "class weights:\n",
            "  {0: 0.008333333333333333, 1: 0.024390243902439025, 2: 0.002577319587628866, 3: 0.009433962264150943, 4: 0.024390243902439025, 5: 0.013333333333333334, 6: 0.029411764705882353, 7: 0.0136986301369863, 8: 0.0196078431372549, 9: 0.01282051282051282, 10: 0.015625, 11: 0.0196078431372549, 12: 0.01818181818181818, 13: 0.010752688172043012, 14: 0.0196078431372549, 15: 0.002331002331002331, 16: 0.030303030303030304, 17: 0.014492753623188406, 18: 0.03333333333333333, 19: 0.0196078431372549, 20: 0.003875968992248062, 21: 0.03125, 22: 0.02040816326530612, 23: 0.01694915254237288, 24: 0.017543859649122806, 25: 0.016666666666666666, 26: 0.020833333333333332, 27: 0.025, 28: 0.004694835680751174, 29: 0.025, 30: 0.029411764705882353, 31: 0.021739130434782608, 32: 0.00510204081632653, 33: 0.02564102564102564, 34: 0.02564102564102564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsD_YsMcNkSc"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5R3ZbNONkSc"
      },
      "source": [
        "class TransformerTextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ids, masks, targets):\n",
        "        self.ids = ids\n",
        "        self.masks = masks\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ids = torch.tensor(self.ids[index], dtype=torch.long)\n",
        "        masks = torch.tensor(self.masks[index], dtype=torch.long)\n",
        "        targets = torch.FloatTensor(self.targets[index])\n",
        "        return ids, masks, targets\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            pin_memory=False)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHrWMiXtNkSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd1da7c-4ba2-43ac-c862-cee2388cdf82"
      },
      "source": [
        "# Create datasets\n",
        "train_dataset = TransformerTextDataset(ids=X_train_ids, masks=X_train_masks, targets=y_train)\n",
        "val_dataset = TransformerTextDataset(ids=X_val_ids, masks=X_val_masks, targets=y_val)\n",
        "test_dataset = TransformerTextDataset(ids=X_test_ids, masks=X_test_masks, targets=y_test)\n",
        "print (\"Data splits:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  ids: {train_dataset[0][0]}\\n\"\n",
        "    f\"  masks: {train_dataset[0][1]}\\n\"\n",
        "    f\"  targets: {train_dataset[0][2]}\")"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data splits:\n",
            "  Train dataset:<Dataset(N=1000)>\n",
            "  Val dataset: <Dataset(N=227)>\n",
            "  Test dataset: <Dataset(N=217)>\n",
            "Sample point:\n",
            "  ids: tensor([  102,  6160,  1923,   288,  3254,  1572, 18205,  5560,  4578,   626,\n",
            "        23474,   291,  2715, 10558,   103,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0])\n",
            "  masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "  targets: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cpu')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cImZSZiCNkSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420c2313-e51a-41ff-cf7e-60ef1f15db7e"
      },
      "source": [
        "# Create dataloaders\n",
        "batch_size = 128\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  ids: {batch[0].size()}\\n\"\n",
        "    f\"  masks: {batch[1].size()}\\n\"\n",
        "    f\"  targets: {batch[2].size()}\")"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  ids: torch.Size([128, 41])\n",
            "  masks: torch.Size([128, 41])\n",
            "  targets: torch.Size([128, 35])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2l_aGxANkSc"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-NsgwcaN4AY"
      },
      "source": [
        "We're going to use a pretrained [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) to act as a feature extractor. We'll only use the encoder to receive sequential and pooled outputs (`is_decoder=False` is default)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1RY5Bm3NkSc"
      },
      "source": [
        "from transformers import BertModel"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB04rtOLNkSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "6b45373c2f984479ae78d8b08c37a8d2",
            "09ab19fb14644de4b73e3037b9c08cd1",
            "7a3fec33dc0c4f4ba947aaecfc4a57ee",
            "c678b8d54e45432cbc460b51035702d4",
            "687dfe83a92e404fa2134b4a37fa6518",
            "069cebd21baa4cc2833c4f29b0e47c0f",
            "9f2bc9176cac4485ae5e0cf763a0394c",
            "24a5007aa67a4c1d918f7c537a693050",
            "b35f6b1e3be246f583c5f2d34e307a04",
            "55070a3d30474b3ab79e31e68f75faee",
            "74572d30e1674fc59451c304f2414ff1",
            "850a37f960314f179eb1ab31394c82ba",
            "706ae7a6af8544a487b7487d1d546d36",
            "15c7236a62a84622a552dd76642a68db",
            "afbb479e0884486abe0ab426acd76fa3",
            "7d047e13ce694f71b6165de361d780bc"
          ]
        },
        "outputId": "2a94da48-3fbf-42dc-e9d4-ecdf787e13a9"
      },
      "source": [
        "# transformer = BertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "# embedding_dim = transformer.config.dim\n",
        "transformer = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "embedding_dim = transformer.config.hidden_size"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b45373c2f984479ae78d8b08c37a8d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b35f6b1e3be246f583c5f2d34e307a04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442221694.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw9lFfTUNkSc"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, transformer, dropout_p, embedding_dim, num_classes):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.transformer = transformer\n",
        "        self.dropout = torch.nn.Dropout(dropout_p)\n",
        "        self.fc1 = torch.nn.Linear(embedding_dim, num_classes)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        ids, masks = inputs\n",
        "        seq, pool = self.transformer(input_ids=ids, attention_mask=masks)\n",
        "        z = self.dropout(pool)\n",
        "        z = self.fc1(z)\n",
        "        return z"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDpIBF93GTHc"
      },
      "source": [
        "> We decided to work with the pooled output, but we could have just as easily worked with the sequential output (encoder representation for each sub-token) and applied a CNN (or other decoder options) on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwsSieXuNkSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5c385c-8f32-48f9-95ac-95d1551a2904"
      },
      "source": [
        "# Initialize model\n",
        "dropout_p = 0.5\n",
        "model = Transformer(\n",
        "    transformer=transformer, dropout_p=dropout_p,\n",
        "    embedding_dim=embedding_dim, num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of Transformer(\n",
            "  (transformer): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=768, out_features=35, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE1z99NzNkSc"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DiS2w0TNkSc"
      },
      "source": [
        "# Arguments\n",
        "lr = 1e-4\n",
        "num_epochs = 200\n",
        "patience = 10"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U8CGbQhNkSc"
      },
      "source": [
        "# Define loss\n",
        "class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSV6ni8iNkSc"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=5)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F36BCeq-NkSc"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn, \n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXbFrWiuNkSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e943ac8c-0d32-4490-81d9-ab3493d2bb18"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    num_epochs, patience, train_dataloader, val_dataloader)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00839, val_loss: 0.00510, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00454, val_loss: 0.00350, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00349, val_loss: 0.00296, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00311, val_loss: 0.00276, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00297, val_loss: 0.00269, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00292, val_loss: 0.00268, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00291, val_loss: 0.00267, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00291, val_loss: 0.00267, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00288, val_loss: 0.00267, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00292, val_loss: 0.00267, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00291, val_loss: 0.00267, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00290, val_loss: 0.00266, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00288, val_loss: 0.00267, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00285, val_loss: 0.00276, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 15 | train_loss: 0.00290, val_loss: 0.00267, lr: 1.00E-04, _patience: 7\n",
            "Epoch: 16 | train_loss: 0.00290, val_loss: 0.00267, lr: 1.00E-04, _patience: 6\n",
            "Epoch: 17 | train_loss: 0.00288, val_loss: 0.00264, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00283, val_loss: 0.00260, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00276, val_loss: 0.00253, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00265, val_loss: 0.00242, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00251, val_loss: 0.00235, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00239, val_loss: 0.00227, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00226, val_loss: 0.00216, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00215, val_loss: 0.00211, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00203, val_loss: 0.00205, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00189, val_loss: 0.00200, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00175, val_loss: 0.00190, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00163, val_loss: 0.00184, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00154, val_loss: 0.00176, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00144, val_loss: 0.00177, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00138, val_loss: 0.00178, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00132, val_loss: 0.00169, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00125, val_loss: 0.00166, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00116, val_loss: 0.00157, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00109, val_loss: 0.00153, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00101, val_loss: 0.00150, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00095, val_loss: 0.00149, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00092, val_loss: 0.00146, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00088, val_loss: 0.00152, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00084, val_loss: 0.00153, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 41 | train_loss: 0.00081, val_loss: 0.00141, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00076, val_loss: 0.00144, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00072, val_loss: 0.00142, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 44 | train_loss: 0.00069, val_loss: 0.00142, lr: 1.00E-04, _patience: 7\n",
            "Epoch: 45 | train_loss: 0.00065, val_loss: 0.00141, lr: 1.00E-04, _patience: 6\n",
            "Epoch: 46 | train_loss: 0.00062, val_loss: 0.00141, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00060, val_loss: 0.00144, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 48 | train_loss: 0.00058, val_loss: 0.00141, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 49 | train_loss: 0.00055, val_loss: 0.00143, lr: 1.00E-04, _patience: 7\n",
            "Epoch: 50 | train_loss: 0.00054, val_loss: 0.00141, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00052, val_loss: 0.00143, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 52 | train_loss: 0.00051, val_loss: 0.00138, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 53 | train_loss: 0.00049, val_loss: 0.00139, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 54 | train_loss: 0.00047, val_loss: 0.00139, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 55 | train_loss: 0.00046, val_loss: 0.00139, lr: 1.00E-04, _patience: 7\n",
            "Epoch: 56 | train_loss: 0.00044, val_loss: 0.00141, lr: 1.00E-04, _patience: 6\n",
            "Epoch: 57 | train_loss: 0.00043, val_loss: 0.00138, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 58 | train_loss: 0.00042, val_loss: 0.00136, lr: 1.00E-04, _patience: 10\n",
            "Epoch: 59 | train_loss: 0.00041, val_loss: 0.00139, lr: 1.00E-04, _patience: 9\n",
            "Epoch: 60 | train_loss: 0.00040, val_loss: 0.00139, lr: 1.00E-04, _patience: 8\n",
            "Epoch: 61 | train_loss: 0.00039, val_loss: 0.00139, lr: 1.00E-04, _patience: 7\n",
            "Epoch: 62 | train_loss: 0.00038, val_loss: 0.00138, lr: 1.00E-04, _patience: 6\n",
            "Epoch: 63 | train_loss: 0.00037, val_loss: 0.00137, lr: 1.00E-04, _patience: 5\n",
            "Epoch: 64 | train_loss: 0.00035, val_loss: 0.00140, lr: 1.00E-05, _patience: 4\n",
            "Epoch: 65 | train_loss: 0.00035, val_loss: 0.00139, lr: 1.00E-05, _patience: 3\n",
            "Epoch: 66 | train_loss: 0.00034, val_loss: 0.00138, lr: 1.00E-05, _patience: 2\n",
            "Epoch: 67 | train_loss: 0.00034, val_loss: 0.00138, lr: 1.00E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BrqyPBdShND"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hZEYRRESjOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7a69e38c-27dd-4fc5-943b-59fb61972bb7"
      },
      "source": [
        "# Threshold-PR curve\n",
        "train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "plt.plot(thresholds, precisions[:-1], \"r--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recalls[:-1], \"b-\", label=\"Recall\")\n",
        "plt.ylabel(\"Performance\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f534113f320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5zNdf7A8dd7GAZpXLNyCVEochkKodJFKoputgutsu1223Zrq8d239rfVra7Zal0V9KSSikktSFDbpFMUkYXl5A7w/v3x/uMGWPGHOOc8z2X9/PxOI9z+XznnPd3hvP+fu6iqjjnnEtdaUEH4JxzLlieCJxzLsV5InDOuRTnicA551KcJwLnnEtx5YMO4GDVqlVLGzVqFHQYzjmXUObMmbNWVWsXV5ZwiaBRo0ZkZ2cHHYZzziUUEfmupDJvGnLOuRTnicA551KcJwLnnEtxngiccy7FeSJwzrkUF7VEICLPichqEVlUQrmIyJMikiMiC0SkXbRicc45V7Jo1gieB3oeoPxsoFnoNhgYFsVYnHPOlSBq8whUdbqINDrAIX2AF9XWwZ4pItVEpK6q/hiNeJYtg8cfh+OPh3LlIC3N7os+rlULqlWDKlWgbl2oUAHS0+0YkWhE5lJKXh789BPUq2f/oFavhvXrYc8e2L3bbqrQpo0dP3cufPddQfmePfYPsl8/K588GZYvhw0bYPNme61GDfjTn+zxqFHw7bf7xlC3LvzhD/Z4+HD44Yd9y486CgYNssdPPglr1+5bfswxcPnl9viRR2DTpn3Ljz8eLr7YHj/4IOzYsW95+/bQp489vvvu/X9HnTrB2WfDzp3wwAP7l59yCpx2mn3uI4/sX37mmXDyybBuHTzxxP7l550HHTrYeQ8fvn95v35wwgmwYgU899z+5b/9LTRvDkuXwiuv7F8+cCA0aQILF8Ibb+xf/vvf298/OxsmTNi//IYboHZt+OwzeP/9gtcL/14jTVWjdgMaAYtKKHsHOLnQ8ylAVgnHDgaygeyGDRtqWTz8sKr9Dyv7rWJF1aZNVbt1U/3LX1Rfekk1J0c1L69MIbl4smWL6saNquvXq/7yi+qOHfb69u2qP/2k+uOPqqtWqebmqn7/veq2bVb+7beqw4erPv646pAhqv/3f6p//7vq6tVW/t//qvburdqpk2q9egX/mHbutPI//nH/f2gVKhTEdcUV+5fXqlVQfsEFBa+L2K1Zs4LyU08teD3/1q5dQXmHDvuXd+9eUN68+f7l55xTUF6v3v7ll15aUH744fuXX3NNQXnRMhHVP//ZyjZvLr78nnus/Mcfiy9/+GEr//rr4suHDbPyOXOKL3/5ZSufNq348rfesvJ33im+fOpUKx89uvjyzz+38hEjii9fssTK//Wvkn+vZQBkawnf1aJR3JgmVCN4R1WPL6bsHeCfqvpp6PkU4DZVPeC04aysLC3rzOING2D79n0vvgo/3r7dLtC2bbOLoPXrYdcuu4jbtcuer15tFwKLFtnPgNUWqle3JF6tml2wpadDRoYl/sMPh/r1ITMTmjWDhg3hiCOs3EXBr7/aH7ZaNfjlF3j2WbsKz8kp+GPecotdOc6YAb162T+OwsaPt6vWd96xK8iipkyxq9KXXoIrr9y/fMECaNXKrsgff9yqmg0bQp06cOSRcN11VgWdPduqq4WrpuXLQ+/e9j4rVlhsRcubNrXytWvtirtKFTtf50ogInNUNau4siCXmFgFNCj0vH7otaiJ5P+TvDz4/HOYP99q3r/+CqtW2f/JXbvs/qefrPb3yy92fFFVq1ry6NwZWrSwhJGebs1RtWpZcsnIsKRx+OFQsaLd0lJ9rNe6dfYLPvJIuxa+6y7L0j/8YL/w3Fz45z/httvs9b/+1b48W7SwX2D58vZHAvjNb+CyyyxjV6xozTUiVg0H+zIfOrSgbTD/vnlzKz/3XGu6qVrV3rfwDeCqq+xWkg4d7FaS0tbVqlUrrF+ZcwcSZI3gHOB6oBdwIvCkqnYs7T0PpUYQlN277btrzRqrSfz6K6xcaU2cixfDzJn2WriOOgoaN7bkUKmSNdkee6zVOJo3h6OPTrL+jBdesCv3FSss8/70k10xv/WWledXw/KrZaedBhdcAO3aWc1g61b7RZUrF+hpOBekQGoEIjIaOAWoJSK5wD1AOoCqDgcmYkkgB9gKHOCyKbGVK2dX9UccAccdt3+5qiWCXbusf2zrVvuu277dksWPP9rj9estgWzZYvfr11v5G2/Y912++vUtGeRf/ObfKla0BNKlC7RuXdBfGYg9ewqqNv/7HyxZYpnym2+s7S0tDT7+2MpHjbKmlnr14Kyz7Gq9ffuC91q/vuQTSUuDww6L7rk4l+CiOWqofynlClwXrc9PJCJ2NV9YfhNwOLZssdaQ1athzhz46COrgWzfbrWRvDy7bdwIo0cX/FzdutCzp923bm2tDFWrWhKpXj2CTVA5OTB2rF3VL11qo1vWr7cgMzLgxRdhxAg7tkYNy5atWxf8/Pjx9gsq6cs+qao/zsVeVJuGoiERm4biydatdqG9cCG8/rqNTixOnTo2Sq5XL2uKatr0IL5v16yxbNSmjbVb/fvf1jl6zDHW5p6ZCTVrwt/+Zo/XrbPAKla0apNzLuIO1DTkiSDF7dljzVLffms1hu+/tz7XWbNswEx+J/dxx9mIp0qV7CL+sMMK+lfr1tlD8x8/otnX71J55lRrxwcYNgyuvdZGtuzcaZ27zrlAxOuoIRcH0tKsr7Vt2/3L1q61kVFff23zXr75BrZt3UPON0XbjNKAHkAP6lVYTY06SvPjynPKzkxqvwHp6bVsNNSXNoKySRPr23XOxQevEbjwzJkDr75q7flr17LnmObs6Pdbtt1yF7m58NW737B0429Y/nMVfvnFmpxyc0t+u+rVrRWoWTM45xzrq6hfv2DUpXMusrxG4A7epk3WuduypX1DT5oETz8N3bvD1VeTdvHFVAIqYf27rVsfvc+PqxYMkd2500ZEbd5stYoff7SO7Z9+gjfftCYosKama6+12knVqjafonp1GxrrnIserxG4AqrWg/zvf9s6J7t326zYm26yDoT0dKhcOaIfuWULTJtm8ymeecaaoYqTP0WgalULoX5963c+/XRLFIcfHtGwnEs63lnsSqdqU5xnzrRhQpddBt262WtVq8YsjNxcmze2c6dNHl682PoqNm2ywUhbtljN4rvv7Lh8PXrYOmX9+3uftHPF8UTg9vf99zBypC3J8O671mt85502TvSKKxJiFm5OjrVejRkDX35ZsMhmgwa2TFDbtjbvrHVrn2rgnCcCV2DqVFuHZ/JkqwUce6zVApJgwbJly+Af/7DmpfnzrfYAth7bccfZhLnzzrNaQ9EJfM4lO08EqSx//YrMTLtsPv54G65z7bW2pnyzZkFHGBW7d1uNYfx4m8y8apU1Jy1dauVHHWV9DK1awc03W/+Dc8nME0GqysmBAQOs0Tx/g4w33rAe1urVg40tAKrw6ad2W7jQVoDOybFJzp07Q1aWDYpq08ZrDC75+PDRVDRqFFx/vY3BvPrqgtcvuii4mAImAl272i3f1Knw2GPWnPT22wWvt2tnq2J07mwL9VWsGPt4nYsVTwTJZudOW4J54kT7xnv1VRtr6Yp12ml2A5vfMHeu1Rj++9+C3RrT0+HEE6220LSptaYdcYQlCJ8A55KBNw0lG1XrGe3XD+65x7+pymjPHlteIyfH9pD44APrgC683HdmJnTsaHPuWrWybW7btk2IAVcuBXkfQTJTtfGTI0dac1CDBnZpW7du0JElnV27bJ/4FSvsVzxunCWKFSts8VSwTuiOHW0wVpcutg+79ze4eOB9BMlIFT78EIYMsfsmTWxNhwYNPAlESXq6fcHnL3kxcKDd79ljCWLqVGtSmjfP7nfvtgpZt25269rVmpiqVAnsFJwrltcIEtVNN8GTT9oCPTfeCH/5i7dJxJHNm22y2zvvwPTp1qykaomhXTurKXTvDuef75PdXGx401CyUYU77rD2iEce8SEtCWDjRksMn3xit+xs2LbNOp7PO6+gM7pOnaAjdcnKE0Gy+Pprmxl16qn2XNUvJxNUXp4tsjd2LEyZYq+lpdl8vzZtCub9nXKK9Ts4d6g8ESSD0aNtPkBmpjVIZ2QEHZGLkJ9/tknfU6fatg/z5tkS3WBNSWecYdM/evXyGoMrO+8sTnTjxtlyEK1bw1tveRJIMnXq2C1/PgPAhg22Zehzz9mgsPfes9dPOsl2AD3hBK8MusjxGkG8+/hjOOssG6A+ebIPOUlBu3fbuoCTJ8OjjxYsHdW6tdUUOnWyxODbf7oD8RpBIps2zYaGvvOOJ4EUVa6czUno0gX+8AerIL75pu3VcOONdkylStChgyWFvn1tLoNz4fIaQbwq3BG8aVNMN4dxiWPlSttMbsYMu2Vn27yGBg3g5JMLVlht1QoaNvTmpFTmncWJ5uef7bLuiitsuWjnwrRpEzz0EHzxha2wunJlQVnVqjYaqXVru/3ud97dlEo8ESSSFSvgnHNsu60337T9F50ro40bba2khQstOcyebclh7VobkXT22dby2LRpwWOvNSQn7yNIFBs22NCRlSttgLknAXeIMjML+hcK++9/bQBadrYNW83fza1lS9vArmdP73xOJWlBB+BCVG2j3ZUrrSbQp0/QEbkk1rcvvPCCzV/YtMlqC489Bjt2QO/e1qdw//22LLdLft40FE/Gj7cppxdeGHQkLkVt22ZzFx9/3JqUVG3BvLvvtlnOvpxV4jpQ05DXCIK2YoVdeqnaCmSeBFyAKlWyTuQFC2DdOnjgAduX4fTTbcfTW2+15wl2/ehK4YkgSMuW2USx4cNtgXvn4kj16vC3v9lyF6NH257OTzxhC+Q1amQL3v7wQ9BRukiIaiIQkZ4islREckTk9mLKG4rIRyLyhYgsEJFe0YwnruTlwW9/ax3E77xjl1vOxaHMTLj0Unj3XRvZ/PzzNvz00UdtrsK4cV5DSHRRSwQiUg4YCpwNtAT6i0jLIofdCYxR1bbApcC/oxVP3Bk50oZsjB5tC9Q7lwCqV4cBA+Dtt23Ji927reO5aVO44QbIzQ06QlcW0awRdARyVHW5qu4EXgOKDoVR4PDQ40wgNSqau3fDv/5lC9BffHHQ0ThXJj16WOvmiBG2r8LIkTZ7ecAAWL066OjcwYhmIqgHFJrXSG7otcLuBS4XkVxgInBDcW8kIoNFJFtEstesWRONWGOrXDl49VV46SVbhN65BFWhAlxzDbz/vg1Fvflmq+S2aGEJ4tdfg47QhSPob6H+wPOqWh/oBbwkIvvFpKojVDVLVbNq164d8yAjZtky+PvfYft2WxWsQYOgI3IuYo4+2iq68+bZxLTf/976F3r2tFFI3o8Qv6KZCFYBhb/p6odeK2wQMAZAVWcAGUCtKMYUnC1bbE/Cxx7bdwEY55JMy5a2evrkyVZb+PRTWya7b1/IyQk6OlecaCaC2UAzEWksIhWwzuAJRY75HugBICItsESQBG0/xbjrLttq8s03rUHVuSSWlmZ9CCNG2LJZd95pHcwtW8K999qOqy5+RC0RqGoecD0wCViCjQ76UkTuF5HeocP+AlwjIvOB0cBATbSpzuEYMwaeegoGDizYb9i5FFG7trWIfvutbbd53302D2HIkKAjc/l8iYlo27IFjj0W6ta1HrWaNYOOyLlA5eTAbbfZwnd33mlJwkWfrz4apCpVbOeQSpU8CTiHzTkYPdo6kx94wDqR77nHVzsNUtCjhpKXKnzwAWzdaoOrE3m0k3MRVqECDBtmi+w++KCNOPrPf4KOKnV5IoiWxx+3TeeffTboSJyLSxkZtjzF22/DYYfZZnyXXFKwN4KLHU8E0fDll7Za19lnw/XXBx2Nc3FLBM49F+bPt8loY8bAEUfYLq2//BJ0dKnDE0Gk7dkDf/2rzR5++mnf98+5MKSn22S0jz+2JDB6tK3O7mLDO4sjbehQmDjRlmZs0iToaJxLGCK2CU63brZT2rBhNgmtW7egI0t+XiOItN69baH2P/0p6EicS1j33gt16tjyFNOnBx1N8vNEEEmqcNRRNlPGm4ScK7OjjoJp02zZ6+7dYdSooCNKbp4IImXhQhsl9NNPQUfiXFJo0gQWL7YVWX73O1ve2kcURYcngkh58EH45BMo790uzkVKZiZ88YUNwnv5ZVuiYuvWoKNKPp4IImHJEnj9dRv/Vis5F091LihVqtgM5Geftf4C736LPL98jYSRI238m/8LdS5qBg60KTpDhtjSXffe611xkeKJ4FDt2AEvvmhz5Y84IuhonEtqDzwA33xjcwxWrrQhphUrBh1V4vNEcKjy8uCWW+Dkk4OOxLmkV7GizT6+6iobSbRtG7zwgq1d5MrOE8GhqlIFbr896CicSxnly9t233Xq2Gzkli1t3ydXdt5ZfCjmzLHLkp07g47EuZQzZIjt/jpkCEyZEnQ0ic0TwaF44gnrIM7LCzoS51LSww9D1apw+unWmbxnT9ARJSZPBGX1668wdiz07w+VKwcdjXMpqXlzWLYMbrzR+gpefDHoiBKTJ4KyGjvWeqoGDgw6EudSWqVK1jzUsSMMHmyJwR0cTwRl9cILcMwxcOKJQUfiXMpLT7elq9PSYNAgb609WJ4IyiIvz2oDl13mM1qcixNNmsCIEbbSy5VXen/BwfDho2VRvjzMmmWTyZxzcePKK2328cMP2zpFw4YFHVFi8ERQFnl5lgwyMoKOxDlXxD//aSO6H38cevSACy8MOqL4501DB2vDBqhRw4cnOBenROChh6BDB7jmGli1KuiI4p8ngoP16quwaRMce2zQkTjnSlChgl2r/for3HFH0NHEv7ASgYhUFpG7RGRk6HkzETk3uqHFIVUYPhzat/fRQs7FuebNbRmwl16y0d6uZOHWCEYBO4BOoeergAeiElE8mzvXdiK75pqgI3HOheH++6FpU7j+elizJuho4le4ieBoVX0Y2AWgqluB1Bs3+fzztvzhJZcEHYlzLgwVK8Jrr8HGjXDFFUFHE7/CTQQ7RaQSoAAicjRWQ0gtN9xgi8xVqxZ0JM65MLVvD3feCZMmwbx5QUcTn8JNBPcA7wMNROQVYArw16hFFa+OOcbWFnLOJZTf/x5q1rQ1iVSDjib+hJUIVPVDoC8wEBgNZKnqtNJ+TkR6ishSEckRkWIX7ReRi0VksYh8KSKvhh96DO3ZAz172pRF51zCqVXL+gs++QSeeSboaOJPuKOGLgDyVPVdVX0HyBOR80v5mXLAUOBsoCXQX0RaFjmmGXAH0EVVjwPic9Pft9+2euU33wQdiXOujAYPhlNPhT//GdauDTqa+BJ205Cqbsx/oqobsOaiA+kI5KjqclXdCbwG9ClyzDXAUFVdH3rf1WHGE1uvhioql14abBzOuTIrXx6GDoWtW+Huu4OOJr6EmwiKO6605SnqASsLPc8NvVbYMcAxIvI/EZkpIj2LeyMRGSwi2SKSvSbWY8BWr4Zx4+Cmm3xJCecSXIsWNvp72DBYujToaOJHuIkgW0QeFZGjQ7dHgTkR+PzyQDPgFKA/MFJE9huSo6ojVDVLVbNq164dgY89CG+8Abt2Wb3SOZfw7r3X7l97LdAw4kq4ieAGYCfweui2A7iulJ9ZBTQo9Lx+6LXCcoEJqrpLVb8FvsYSQ/yoWxf69rUdsp1zCe83v4GTTvLtxgsLd9TQFlW9Pf+qXFXvUNUtpfzYbKCZiDQWkQrApcCEIseMx2oDiEgtrKlo+UGdQbT17Qtvvhl0FM65CLrnHvjuO1sxxoU/augYERkhIh+IyNT824F+RlXzgOuBScASYIyqfiki94tI79Bhk4B1IrIY+Ai4VVXXlf10ImzmTFu1yjmXVM46Czp3toSwpbRL2hQgGsbsChGZDwzH+gV257+uqpHoJzgoWVlZmp2dHf0P2rHDmoXOPhteeSX6n+eci6kxY2y1mClT4LTTgo4m+kRkjqpmFVcW7sY0eaqaWnv9TJoE69fD5ZcHHYlzLgp69rTlqidOTI1EcCDhdha/LSJ/FJG6IlIj/xbVyIL26qs2HfH004OOxDkXBYcfbk1Ezz4LP/wQdDTBCjcRDABuBT7DmofmADFonwnIpk0wYQJcdBGkpwcdjXMuSh5+2EaHX3ZZ0JEEK6ymIVVtHO1A4srUqbBtG/z2t0FH4pyLoubN4dZb4b77bBfaVF1YOOytKkXk+NACcVfm36IZWKD69IGvvrJhBc65pHb66bYi6ZgxQUcSnHCHj94DPBW6nQo8DPQ+4A8lumOPhTTf0tm5ZNe5M7RrByNGBB1JcML9prsQ6AH8pKpXAScAmVGLKkivvWZjynz+gHMpQQR69bJNa1auLP34ZBRuItimqnuw5acPB1az7/IRyWP0aJtIVrVq0JE452Lk8sutAeCf/ww6kmAczKJz1YCR2IihucCMqEUVlLw8mDbNxpRJ6m3J7FyqOvZY23xw1ChbeiLVhLvW0B9VdYOqDgfOAAaEmoiSyxdfWJNQqs8ucS4F3X03bN9uS1SnmoMZNdQ6tEZQO6CpiPSNXlgBefddqwmcemrQkTjnYuzoo6FDB6sVpNq+xuGOGnoOeA7oB5wXup0bxbiCkZlpu1bUqRN0JM65AAwcaHtRffVV0JHEVriLzi1W1bhYkD9mi84551LOjz9Cw4Zw88026ziZHGjRuXCbhmYU3Xg+6fzwg6046pxLWXXrQteu8MEHQUcSW+EmghexZLBURBaIyEIRWRDNwGLuqqugY8ego3DOBezMM2H+fPjpp6AjiZ1wE8GzwBVATwr6B86LVlAxt26drS909tlBR+KcC1iPHnb/4YfBxhFL4SaCNao6QVW/VdXv8m9RjSyWxo+3OQSXXBJ0JM65gLVvD/Xr2zDSVBk9FG4i+EJEXhWR/iLSN/8W1chiadIkOPJIaNMm6EiccwFLS4M//AFmzIBFi4KOJjbCTQSVgB3AmSTb8NHt222LonPO8dnEzjkABg2yhPDgg6lRKyh1PwIRKQesU9VbYhBP7JUvb42BtWsHHYlzLk7UqQN33WX7FFx9dfJvVBjuPIIZqtopBvGUyucROOdiYccOaNIE6tWzdSgTfVX6SMwjmCciE0TkiqTqI1CFv/4V5s4NOhLnXJypWNFqBbNnJ/9XRLiJIANYB5xGMvURzJ8PjzyS/H9l51yZ9OtnXYfvvBN0JNEV7p7FybfSKNgmNOXLw/nnBx2Jcy4O1a5ta1C+9JKtTprozUMlCXfRufoiMk5EVodub4pI/WgHF1WqMG4cnHIK1KoVdDTOuTg1YAAsXw4ffRR0JNETbn4bBUwAjgzd3g69lrgWLoSvv4a+id/V4ZyLnksugerVbXnqZBVuIqitqqNUNS90ex5I7PGWK1dCgwbQu3fQkTjn4ljFinDxxdaAsHlz0NFER7iJYJ2IXC4i5UK3y7HO48R1zjnw/fc2Nsw55w7g8sth61ZLBsko3ETwO+Bi4CfgR+BCIHE7kFVTY7qgcy4iOneGRo3g5ZeDjiQ6DpgIROSh0MOOqtpbVWur6hGqer6qfh+D+KJj3jzbfeJ//ws6EudcAkhLs1rB5MmwZk3Q0UReaTWCXiIiwB2xCCZmPv4YcnPhqKOCjsQ5lyD69IE9e5JzTkFpieB9YD3QWkR+FZFNhe9Le3MR6RnazCZHRG4/wHH9RERFpNjpzxE3fbrNHa+f2CNgnXOx0769LVL8zDPJ17J8wESgqreqajXgXVU9XFWrFr4/0M+GFqsbCpwNtAT6F7fdpYhUBW4CZpX5LA6GqiWCbt1i8nHOueQgYktOfPaZNSokk1I7i0Nf6Af80i9BRyBHVZer6k7gNaBPMcf9HXgI2F6Gzzh4X39tO5J17hyTj3POJY8BA6BKFRg7NuhIIqvURKCqu4E9IpJ5kO9dD1hZ6Hlu6LW9RKQd0EBV3z3QG4nIYBHJFpHsNYfaU1O+PFx3XcF+dM45F6ZKleCkk5JvlnFYaw0Bm4GFIvIhsCX/RVW9sawfLCJpwKPAwNKOVdURwAiwZajL+pkAHH00PP30Ib2Fcy51nX8+3HADLFkCLVoEHU1khDuP4L/AXcB0YE6h24GsAhoUel4/9Fq+qsDxwDQRWQGcBEyIaofx7t3w+efW9e+cc2VwwQXWXzBmTNCRRE5YiUBVXwDGADNV9YX8Wyk/NhtoJiKNRaQCcCm2XlH+e25U1Vqq2khVGwEzgd6qGr1dZ2bPhhNPTL4GPudczNSrZ2tVvvxy8lxThrv66HnAPGw4KSLSRkQmHOhnVDUPuB6YBCwBxqjqlyJyv4gEs8DP+PHWR3DGGYF8vHMuOfTvDzk51jyUDMLtI7gXGwU0DUBV54lIk9J+SFUnAhOLvHZ3CceeEmYsZTdpEnTpYksJOudcGXUKbdw7Zw4cd1ywsURCuH0Eu1R1Y5HXEqtStG6dLS2R7LtQO+eirmVLu56cNi3oSCIj3ETwpYj8FignIs1E5CngsyjGFXnTp9uCIaecEnQkzrkEl5Zm15QffJAcs4zDTQQ3AMcBO4BXgY3An6IVVFS0amV7D3TsGHQkzrkkcMYZsGpVcvQTHLCPQEQygGuBpsBCoFOoEzjxNG2avIuJO+diLr+V+aOPrKkokZVWI3gByMKSwNnAkKhH5JxzCaBRI9vcfu7coCM5dKWNGmqpqq0ARORZ4PPoh+Scc/FPBNq0gS++CDqSQ1dajWBX/oOEbRJyzrkoOekkmD8f1q8POpJDU1oiOCG0/8CvIrKJIvsSxCJA55yLV2eeabOLp04NOpJDU9p+BOVC+w/k70FQPtz9CJxzLtmdeKKtSDp9etCRHJpwh48655wrIj3d9rh6772gIzk0ngicc+4Q9O4Ny5bB0qVBR1J2ngicc+4QnHuu3U844DKc8c0TgXPOHYKGDW0YqScC55xLYeeeC//7H/yaoGMpPRE459wh6tjRFp+bNy/oSMrGE4Fzzh2irl0hIwNefz3oSMrGE4Fzzh2iatXgrLNs76tE5InAOecioH17+OYb2LIl6EgOnicC55yLgPwtKxNxfwJPBM45FwH5exIsXtb3AUQAABF2SURBVBxsHGXhicA55yKgSROoUAEWLgw6koPnicA55yKgQgXo1CkxO4w9ETjnXISccYbVCDZtCjqSg+OJwDnnIqRNG7vPzg42joPlicA55yKkSxfbwvKTT4KO5OB4InDOuQipVg2aNUu8fYw9ETjnXAR17AgzZgQdxcHxROCccxHUpg38/LPdEoUnAueci6COHe1+1qxg4zgYngiccy6CsrJsJdKPPw46kvBFNRGISE8RWSoiOSJyezHlfxaRxSKyQESmiMhR0YzHOeeirVIlW3dowYKgIwlf1BKBiJQDhgJnAy2B/iLSsshhXwBZqtoaGAs8HK14nHMuVjp0gM8+S5yVSKNZI+gI5KjqclXdCbwG9Cl8gKp+pKpbQ09nAvWjGI9zzsVEv36wdWviNA9FMxHUA1YWep4beq0kg4D3iisQkcEiki0i2WvWrIlgiM45F3mdOkH58raPcSKIi85iEbkcyAIeKa5cVUeoapaqZtWuXTu2wTnn3EGqUgXatYNPPw06kvBEMxGsAhoUel4/9No+ROR04G9Ab1XdEcV4nHMuZk4+GT7/HHYkwLdaNBPBbKCZiDQWkQrApcCEwgeISFvgP1gSWB3FWJxzLqZOPhm2b4e5c4OOpHRRSwSqmgdcD0wClgBjVPVLEblfRHqHDnsEOAx4Q0TmiciEEt7OOecSSpcudp8I/QTlo/nmqjoRmFjktbsLPT49mp/vnHNBOeIIOPLIxJhPEBedxc45l4yaNYNvvw06itJ5InDOuSg56ihYvjzoKErnicA556KkfXv44QdYsSLoSA7ME4FzzkXJGWfY/QcfBBtHaTwROOdclDRvDvXrw6RJQUdyYJ4InHMuSkTgzDNh6lTYvTvoaEoW1eGjsbJr1y5yc3PZvn170KEkpIyMDOrXr096enrQoTiXdE49FZ57DhYutN3L4lFSJILc3FyqVq1Ko0aNEJGgw0koqsq6devIzc2lcePGQYfjXNLp1s3up0+P30SQFE1D27dvp2bNmp4EykBEqFmzptemnIuShg1tGOn06UFHUrKkSASAJ4FD4L8756KrWzdLBKpBR1K8pEkEzjkXr7p1gzVrYOnSoCMpnieCCClXrhxt2rTh+OOP56KLLmLr1q2l/1Ap7r77biZPnlxi+fDhw3nxxRcP+XOcc9HVtavdx+v+BJ4IIqRSpUrMmzePRYsWUaFCBYYPH75PeV5e3kG/5/3338/pp5e8Lt+1117LlVdeedDv65yLrWbN4PDDYc6coCMpXnImglNO2f/2739b2datxZc//7yVr127f9lB6tq1Kzk5OUybNo2uXbvSu3dvWrZsye7du7n11lvp0KEDrVu35j//+c/en3nooYdo1aoVJ5xwArfffjsAAwcOZOzYsQDcfvvttGzZktatW3PLLbcAcO+99zJkyBAA5s2bx0knnUTr1q254IILWL9+fehXcQq33XYbHTt25JhjjuGTTz456PNxzh2atDTo3Dl+9zBOiuGj8SQvL4/33nuPnj17AjB37lwWLVpE48aNGTFiBJmZmcyePZsdO3bQpUsXzjzzTL766iveeustZs2aReXKlfnll1/2ec9169Yxbtw4vvrqK0SEDRs27Pe5V155JU899RTdu3fn7rvv5r777uPxxx/fG9Pnn3/OxIkTue+++w7Y3OSci44uXeD99+HXX612EE+SMxFMm1ZyWeXKBy6vVevA5SXYtm0bbUKDhLt27cqgQYP47LPP6Nix497x+R988AELFizYe5W/ceNGli1bxuTJk7nqqquoXLkyADVq1NjnvTMzM8nIyGDQoEGce+65nHvuufuUb9y4kQ0bNtC9e3cABgwYwEUXXbS3vG/fvgC0b9+eFfG++pVzSSory+7nzLFJZvEkORNBAPL7CIqqUqXK3seqylNPPcVZZ521zzGTSlmIpHz58nz++edMmTKFsWPH8vTTTzN16tSwY6tYsSJgHdpl6atwzh26jh3t/rPP4i8RJGcfQZw666yzGDZsGLt27QLg66+/ZsuWLZxxxhmMGjVq70ijok1DmzdvZuPGjfTq1YvHHnuM+fPn71OemZlJ9erV97b/v/TSS3trB865+FCjhs0s/vDDoCPZn9cIYujqq69mxYoVtGvXDlWldu3ajB8/np49ezJv3jyysrKoUKECvXr14h//+Mfen9u0aRN9+vRh+/btqCqPPvrofu/9wgsvcO2117J161aaNGnCqFGjYnlqzrkw9OwJQ4bEXz+BaLxOdStBVlaWZmdn7/PakiVLaNGiRUARJQf/HToXfZ9+anMKRo6Eq6+O7WeLyBxVzSquzJuGnHMuRrp0gbZtrVYQT8tSeyJwzrkYEYE77rClJt54I+hoCngicM65GOrXD447Du65B7ZtCzoa44nAOediKC3NmoaWLYMLLrDFDoLmicA552KsZ0945hnby/iEE4JPBp4InHMuAL/7HYwaBTk5cNFFsGlTcLF4IoiQwstQn3feecWuB3QoGjVqxNq1awE47LDDIvrezrlgDBgA998PEyfa+pavvRbM5jWeCCKk8DLUNWrUYOjQoUGH5JyLcyJw113w6KOwfDn0729DTGfNim0cSTez+E9/gmKW/DkkbdpAaCHPsHTq1IkFCxYA8M0333DdddexZs0aKleuzMiRI2nevDk///wz1157LcuXLwdg2LBhdO7cmfPPP5+VK1eyfft2brrpJgYPHhzZk3HOxZ2bb4abboKnn4YHHoCTT7Ylqzt3js3nJ10iCNru3buZMmUKgwYNAmDw4MEMHz6cZs2aMWvWLP74xz8ydepUbrzxRrp37864cePYvXs3mzdvBuC5556jRo0abNu2jQ4dOtCvXz9q1qwZ5Ck552IgLQ1uvNGGl554Ipx1FixaZBvfR1vSJYKDuXKPpPxlqFetWkWLFi0444wz2Lx5M5999tk+S0Lv2LEDgKlTp+7dZrJcuXJkZmYC8OSTTzJu3DgAVq5cybJlyzwROJdC6tWDd9+1JqJevWD+fCgf5W/qqPYRiEhPEVkqIjkicnsx5RVF5PVQ+SwRaRTNeKIpv4/gu+++Q1UZOnQoe/bsoVq1asybN2/vbcmSJSW+x7Rp05g8eTIzZsxg/vz5tG3blu3bt8fwLJxz8eCEE2DECFi8GKZMif7nRS0RiEg5YChwNtAS6C8iLYscNghYr6pNgceAh6IVT6xUrlyZJ598kn/9619UrlyZxo0b80ZoLrmq7l1CukePHgwbNgyw5qSNGzeyceNGqlevTuXKlfnqq6+YOXNmYOfhnAtW375Qpw5cdhm8+ipEcyuRaNYIOgI5qrpcVXcCrwF9ihzTB3gh9Hgs0ENEJIoxxUTbtm1p3bo1o0eP5pVXXuHZZ5/lhBNO4LjjjuOtt94C4IknnuCjjz6iVatWtG/fnsWLF9OzZ0/y8vJo0aIFt99+OyeddFLAZ+KcC0pGBrz3HhxxhCWDhg1h9OjofFY0W57qASsLPc8FTizpGFXNE5GNQE1gbeGDRGQwMBigYcOG0Yr3kOR39uZ7++239z5+//339zu+Tp06e5NCYe+9916x7194i8min+WcS05t21qH8VtvwZgx8JvfROdzEqKzWFVHACPA9iMIOBznnIuZtDRbk+iCC6L4GdF7a1YBDQo9rx96rdhjRKQ8kAmsi2JMzjnniohmIpgNNBORxiJSAbgUmFDkmAnAgNDjC4GpWsYt0xJtp7V44r8751Jb1BKBquYB1wOTgCXAGFX9UkTuF5HeocOeBWqKSA7wZ2C/IabhyMjIYN26df6FVgaqyrp168jIyAg6FOdcQJJiz+Jdu3aRm5vrY+7LKCMjg/r165Oenh50KM65KDnQnsUJ0VlcmvT0dBo3bhx0GM45l5B89VHnnEtxngiccy7FeSJwzrkUl3CdxSKyBviu0Eu1KDITOcWk8vmn8rlDap9/Kp87lO38j1LV2sUVJFwiKEpEskvqCU8FqXz+qXzukNrnn8rnDpE/f28acs65FOeJwDnnUlwyJIIRQQcQsFQ+/1Q+d0jt80/lc4cIn3/C9xE455w7NMlQI3DOOXcIPBE451yKS5hEICI9RWRpaKP7/VYpFZGKIvJ6qHyWiDSKfZTREca5/1lEFovIAhGZIiJHBRFntJR2/oWO6yciKiJJM6wwnHMXkYtDf/8vReTVWMcYTWH8228oIh+JyBehf/+9gogzGkTkORFZLSKLSigXEXky9LtZICLtyvxhqhr3N6Ac8A3QBKgAzAdaFjnmj8Dw0ONLgdeDjjuG534qUDn0+A/Jcu7hnn/ouKrAdGAmkBV03DH82zcDvgCqh54fEXTcMT7/EcAfQo9bAiuCjjuC598NaAcsKqG8F/AeIMBJwKyyflai1Ag6AjmqulxVdwKvYRvfF9YHeCH0eCzQQ0QkhjFGS6nnrqofqerW0NOZ2G5wySKcvz3A34GHgGRaizycc78GGKqq6wFUdXWMY4ymcM5fgcNDjzOBH2IYX1Sp6nTglwMc0gd4Uc1MoJqI1C3LZyVKIti7yX1Ibui1Yo9R2xRnI1AzJtFFVzjnXtgg7CohWZR6/qEqcQNVfTeWgcVAOH/7Y4BjROR/IjJTRHrGLLroC+f87wUuF5FcYCJwQ2xCiwsH+91QoqTYj8AZEbkcyAK6Bx1LrIhIGvAoMDDgUIJSHmseOgWrCU4XkVaquiHQqGKnP/C8qv5LRDoBL4nI8aq6J+jAEkmi1Aj2bnIfUj/0WrHHiEh5rJq4LibRRVc4546InA78DeitqjtiFFsslHb+VYHjgWkisgJrK52QJB3G4fztc4EJqrpLVb8FvsYSQzII5/wHAWMAVHUGkIEtyJYKwvpuCEeiJILZQDMRaSwiFbDO4AlFjpkADAg9vhCYqqEelQRX6rmLSFvgP1gSSKY2Yijl/FV1o6rWUtVGqtoI6yPprarZxb9dQgnn3/14rDaAiNTCmoqWxzLIKArn/L8HegCISAssEayJaZTBmQBcGRo9dBKwUVV/LMsbJUTTkKrmicj1wCRsJMFzqvqliNwPZKvqBOBZrFqYg3WwXBpcxJET5rk/AhwGvBHqH/9eVXsHFnQEhXn+SSnMc58EnCkii4HdwK2qmgw14XDP/y/ASBG5Ges4HpgkF4CIyGgsydcK9YHcA6QDqOpwrE+kF5ADbAWuKvNnJcnvzDnnXBklStOQc865KPFE4JxzKc4TgXPOpThPBM45l+I8ETjnXIrzROBShojUFJF5odtPIrIq9HhDaPhlpD/vXhG55SB/ZnMJrz8vIhdGJjLn9uWJwKUMVV2nqm1UtQ0wHHgs9LgNUOqSBKEZ684lHU8EzplyIjIytKb/ByJSCUBEponI4yKSDdwkIu1F5GMRmSMik/JXexSRGwvtCfFaofdtGXqP5SJyY/6LYntILArd/lQ0mNBs0adDa/FPBo6I8vm7FOZXOM6ZZkB/Vb1GRMYA/YCXQ2UVVDVLRNKBj4E+qrpGRC4BHgR+B9wONFbVHSJSrdD7Nsf2i6gKLBWRYUBrbBboidha8rNE5GNV/aLQz10AHIutsV8HWAw8F5UzdynPE4Fz5ltVnRd6PAdoVKjs9dD9sdgCdx+GlvIoB+Sv7bIAeEVExmPr/+R7N7QI4A4RWY19qZ8MjFPVLQAi8l+gK7bBTL5uwGhV3Q38ICJTI3KWzhXDE4FzpvCKrbuBSoWebwndC/ClqnYq5ufPwb68zwP+JiKtSnhf/z/n4o73ETgXvqVA7dC694hIuogcF9oToYGqfgTchi2BftgB3ucT4HwRqSwiVbBmoE+KHDMduEREyoX6IU6N9Mk4l8+vTpwLk6ruDA3hfFJEMrH/P49jewC8HHpNgCdVdUNJO6Wq6lwReR74PPTSM0X6BwDGAadhfQPfAzMifT7O5fPVR51zLsV505BzzqU4TwTOOZfiPBE451yK80TgnHMpzhOBc86lOE8EzjmX4jwROOdcivt/pi7kb5wga9gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfbIfZUrSkJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2332014d-d7bd-4085-cbf1-ca2c3347b33e"
      },
      "source": [
        "# Best threshold for f1\n",
        "threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "threshold"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34006014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ7bdvXhSljE"
      },
      "source": [
        "# Determine predictions using threshold\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fHBjSytSnnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c91d8c7-27fd-47dd-8fca-ccbcaebfccc1"
      },
      "source": [
        "# Evaluate\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.7223406679549775,\n",
            "  \"recall\": 0.5297012076593357,\n",
            "  \"f1\": 0.5868288723603842,\n",
            "  \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKTveiiTSpUc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831,
          "referenced_widgets": [
            "e84e28d0a48d4335be91d40ac1582f9c",
            "9d561f46e437480ea213b1ffe789690d",
            "cb581c3ecda14096a0e60042018e22bf",
            "ef6f95e7daa14bce8d13a8dc0071843e",
            "f5c4a70ba6334f3dbee76d4372e51160",
            "a0f1ad3515154bb09916038691022aed",
            "bd735b1b05b0403ebd8b4da28a0a0942"
          ]
        },
        "outputId": "bd5fe1b9-4529-444d-e539-9eb42ffc1aa0"
      },
      "source": [
        "@widgets.interact(tag=list(sorted_tags_by_f1.keys()))\n",
        "def display_tag_analysis(tag='transformers'):\n",
        "    # Performance\n",
        "    print (json.dumps(performance[\"class\"][tag], indent=2))\n",
        "    \n",
        "    # TP, FP, FN samples\n",
        "    index = label_encoder.class_to_index[tag]\n",
        "    tp, fp, fn = [], [], []\n",
        "    for i in range(len(y_test)):\n",
        "        true = y_test[i][index]\n",
        "        pred = y_pred[i][index]\n",
        "        if true and pred:\n",
        "            tp.append(i)\n",
        "        elif not true and pred:\n",
        "            fp.append(i)\n",
        "        elif true and not pred:\n",
        "            fn.append(i)\n",
        "            \n",
        "    # Samples\n",
        "    num_samples = 3\n",
        "    if len(tp): \n",
        "        print (\"\\n=== True positives ===\")\n",
        "        for i in tp[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fp): \n",
        "        print (\"=== False positives === \")\n",
        "        for i in fp[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\")\n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")\n",
        "    if len(fn): \n",
        "        print (\"=== False negatives ===\")\n",
        "        for i in fn[:num_samples]:        \n",
        "            print (f\"  {X_test_raw[i]}\") \n",
        "            print (f\"    true: {label_encoder.decode([y_test[i]])[0]}\")\n",
        "            print (f\"    pred: {label_encoder.decode([y_pred[i]])[0]}\\n\")"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e84e28d0a48d4335be91d40ac1582f9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(Dropdown(description='tag', index=18, options=('autoencoders', 'pytorch', 'keras', 'gene…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx_JHbWxStJg"
      },
      "source": [
        "# Save artifacts\n",
        "dir = Path(\"transformers\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1zVg2uS8yu"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INdKvMVKS0wy"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\n",
        "transformer = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "embedding_dim = transformer.config.hidden_size\n",
        "model = Transformer(\n",
        "    transformer=transformer, dropout_p=dropout_p,\n",
        "    embedding_dim=embedding_dim, num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "model.to(device);"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sad3mW-KYgE0"
      },
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pmHeyT7S9yE"
      },
      "source": [
        "# Dataloader\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "X = preprocess(text)\n",
        "encoded_input = tokenizer(X, return_tensors='pt', padding=True).to(torch.device(\"cpu\"))\n",
        "ids = encoded_input['input_ids']\n",
        "masks = encoded_input['attention_mask']\n",
        "y_filler = label_encoder.encode([np.array([label_encoder.classes[0]] * len(X))])\n",
        "dataset = TransformerTextDataset(ids=ids, masks=masks, targets=y_filler)\n",
        "dataloader = dataset.create_dataloader(batch_size=int(batch_size))"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ZgpaSxTKTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc2830e-a3ed-439a-cf8a-b96079cebc73"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['transfer-learning']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU6XRmWhME2H"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHFXbvLWmRZo"
      },
      "source": [
        "Let's visualize the self-attention weights from each of the attention heads in the encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJy4WqNrMpgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549a5506-d0da-4a70-8538-e6f1371a9470"
      },
      "source": [
        "import sys\n",
        "!rm -r bertviz_repo\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'bertviz_repo': No such file or directory\n",
            "Cloning into 'bertviz_repo'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 1239 (delta 12), reused 21 (delta 8), pack-reused 1203\u001b[K\n",
            "Receiving objects: 100% (1239/1239), 200.99 MiB | 27.76 MiB/s, done.\n",
            "Resolving deltas: 100% (775/775), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hFuxdCvMpzk"
      },
      "source": [
        "from bertviz import head_view"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDQkN0ta2e7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8e10ae-81c5-4c59-c7d9-b5430c3ccab3"
      },
      "source": [
        "print (ids)\n",
        "print (tokenizer.batch_decode(ids))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  102,  2268,  1904, 24921,  1968, 13749,  1904,   103]],\n",
            "       device='cpu')\n",
            "['[CLS] transfer learning bert self supervised learning [SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNGME8Tr2FCj"
      },
      "source": [
        "# Get encoder attentions\n",
        "seq, pool, attn = model.transformer(input_ids=ids, attention_mask=masks, output_attentions=True)"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6jEu0Jk2FHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214223cd-c20f-4fc7-a72c-300f69b19b74"
      },
      "source": [
        "print (len(attn)) # 12 attention layers (heads)\n",
        "print (attn[0].shape)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "torch.Size([1, 12, 8, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY4ImZbvRnRv"
      },
      "source": [
        "# HTML set up\n",
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQDw9PZGEpV",
        "colab": {
          "resources": {
            "http://localhost:8080/static/components/requirejs/require.js": {
              "data": "/** vim: et:ts=4:sw=4:sts=4
 * @license RequireJS 2.1.22 Copyright (c) 2010-2015, The Dojo Foundation All Rights Reserved.
 * Available via the MIT or new BSD license.
 * see: http://github.com/jrburke/requirejs for details
 */
//Not using strict: uneven strict support in browsers, #392, and causes
//problems with requirejs.exec()/transpiler plugins that may not be strict.
/*jslint regexp: true, nomen: true, sloppy: true */
/*global window, navigator, document, importScripts, setTimeout, opera */

var requirejs, require, define;
(function (global) {
    var req, s, head, baseElement, dataMain, src,
        interactiveScript, currentlyAddingScript, mainScript, subPath,
        version = '2.1.22',
        commentRegExp = /(\/\*([\s\S]*?)\*\/|([^:]|^)\/\/(.*)$)/mg,
        cjsRequireRegExp = /[^.]\s*require\s*\(\s*["']([^'"\s]+)["']\s*\)/g,
        jsSuffixRegExp = /\.js$/,
        currDirRegExp = /^\.\//,
        op = Object.prototype,
        ostring = op.toString,
        hasOwn = op.hasOwnProperty,
        ap = Array.prototype,
        isBrowser = !!(typeof window !== 'undefined' && typeof navigator !== 'undefined' && window.document),
        isWebWorker = !isBrowser && typeof importScripts !== 'undefined',
        //PS3 indicates loaded and complete, but need to wait for complete
        //specifically. Sequence is 'loading', 'loaded', execution,
        // then 'complete'. The UA check is unfortunate, but not sure how
        //to feature test w/o causing perf issues.
        readyRegExp = isBrowser && navigator.platform === 'PLAYSTATION 3' ?
                      /^complete$/ : /^(complete|loaded)$/,
        defContextName = '_',
        //Oh the tragedy, detecting opera. See the usage of isOpera for reason.
        isOpera = typeof opera !== 'undefined' && opera.toString() === '[object Opera]',
        contexts = {},
        cfg = {},
        globalDefQueue = [],
        useInteractive = false;

    function isFunction(it) {
        return ostring.call(it) === '[object Function]';
    }

    function isArray(it) {
        return ostring.call(it) === '[object Array]';
    }

    /**
     * Helper function for iterating over an array. If the func returns
     * a true value, it will break out of the loop.
     */
    function each(ary, func) {
        if (ary) {
            var i;
            for (i = 0; i < ary.length; i += 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    /**
     * Helper function for iterating over an array backwards. If the func
     * returns a true value, it will break out of the loop.
     */
    function eachReverse(ary, func) {
        if (ary) {
            var i;
            for (i = ary.length - 1; i > -1; i -= 1) {
                if (ary[i] && func(ary[i], i, ary)) {
                    break;
                }
            }
        }
    }

    function hasProp(obj, prop) {
        return hasOwn.call(obj, prop);
    }

    function getOwn(obj, prop) {
        return hasProp(obj, prop) && obj[prop];
    }

    /**
     * Cycles over properties in an object and calls a function for each
     * property value. If the function returns a truthy value, then the
     * iteration is stopped.
     */
    function eachProp(obj, func) {
        var prop;
        for (prop in obj) {
            if (hasProp(obj, prop)) {
                if (func(obj[prop], prop)) {
                    break;
                }
            }
        }
    }

    /**
     * Simple function to mix in properties from source into target,
     * but only if target does not already have a property of the same name.
     */
    function mixin(target, source, force, deepStringMixin) {
        if (source) {
            eachProp(source, function (value, prop) {
                if (force || !hasProp(target, prop)) {
                    if (deepStringMixin && typeof value === 'object' && value &&
                        !isArray(value) && !isFunction(value) &&
                        !(value instanceof RegExp)) {

                        if (!target[prop]) {
                            target[prop] = {};
                        }
                        mixin(target[prop], value, force, deepStringMixin);
                    } else {
                        target[prop] = value;
                    }
                }
            });
        }
        return target;
    }

    //Similar to Function.prototype.bind, but the 'this' object is specified
    //first, since it is easier to read/figure out what 'this' will be.
    function bind(obj, fn) {
        return function () {
            return fn.apply(obj, arguments);
        };
    }

    function scripts() {
        return document.getElementsByTagName('script');
    }

    function defaultOnError(err) {
        throw err;
    }

    //Allow getting a global that is expressed in
    //dot notation, like 'a.b.c'.
    function getGlobal(value) {
        if (!value) {
            return value;
        }
        var g = global;
        each(value.split('.'), function (part) {
            g = g[part];
        });
        return g;
    }

    /**
     * Constructs an error with a pointer to an URL with more information.
     * @param {String} id the error ID that maps to an ID on a web page.
     * @param {String} message human readable error.
     * @param {Error} [err] the original error, if there is one.
     *
     * @returns {Error}
     */
    function makeError(id, msg, err, requireModules) {
        var e = new Error(msg + '\nhttp://requirejs.org/docs/errors.html#' + id);
        e.requireType = id;
        e.requireModules = requireModules;
        if (err) {
            e.originalError = err;
        }
        return e;
    }

    if (typeof define !== 'undefined') {
        //If a define is already in play via another AMD loader,
        //do not overwrite.
        return;
    }

    if (typeof requirejs !== 'undefined') {
        if (isFunction(requirejs)) {
            //Do not overwrite an existing requirejs instance.
            return;
        }
        cfg = requirejs;
        requirejs = undefined;
    }

    //Allow for a require config object
    if (typeof require !== 'undefined' && !isFunction(require)) {
        //assume it is a config object.
        cfg = require;
        require = undefined;
    }

    function newContext(contextName) {
        var inCheckLoaded, Module, context, handlers,
            checkLoadedTimeoutId,
            config = {
                //Defaults. Do not set a default for map
                //config to speed up normalize(), which
                //will run faster if there is no default.
                waitSeconds: 7,
                baseUrl: './',
                paths: {},
                bundles: {},
                pkgs: {},
                shim: {},
                config: {}
            },
            registry = {},
            //registry of just enabled modules, to speed
            //cycle breaking code when lots of modules
            //are registered, but not activated.
            enabledRegistry = {},
            undefEvents = {},
            defQueue = [],
            defined = {},
            urlFetched = {},
            bundlesMap = {},
            requireCounter = 1,
            unnormalizedCounter = 1;

        /**
         * Trims the . and .. from an array of path segments.
         * It will keep a leading path segment if a .. will become
         * the first path segment, to help with module name lookups,
         * which act like paths, but can be remapped. But the end result,
         * all paths that use this function should look normalized.
         * NOTE: this method MODIFIES the input array.
         * @param {Array} ary the array of path segments.
         */
        function trimDots(ary) {
            var i, part;
            for (i = 0; i < ary.length; i++) {
                part = ary[i];
                if (part === '.') {
                    ary.splice(i, 1);
                    i -= 1;
                } else if (part === '..') {
                    // If at the start, or previous value is still ..,
                    // keep them so that when converted to a path it may
                    // still work when converted to a path, even though
                    // as an ID it is less than ideal. In larger point
                    // releases, may be better to just kick out an error.
                    if (i === 0 || (i === 1 && ary[2] === '..') || ary[i - 1] === '..') {
                        continue;
                    } else if (i > 0) {
                        ary.splice(i - 1, 2);
                        i -= 2;
                    }
                }
            }
        }

        /**
         * Given a relative module name, like ./something, normalize it to
         * a real name that can be mapped to a path.
         * @param {String} name the relative name
         * @param {String} baseName a real name that the name arg is relative
         * to.
         * @param {Boolean} applyMap apply the map config to the value. Should
         * only be done if this normalization is for a dependency ID.
         * @returns {String} normalized name
         */
        function normalize(name, baseName, applyMap) {
            var pkgMain, mapValue, nameParts, i, j, nameSegment, lastIndex,
                foundMap, foundI, foundStarMap, starI, normalizedBaseParts,
                baseParts = (baseName && baseName.split('/')),
                map = config.map,
                starMap = map && map['*'];

            //Adjust any relative paths.
            if (name) {
                name = name.split('/');
                lastIndex = name.length - 1;

                // If wanting node ID compatibility, strip .js from end
                // of IDs. Have to do this here, and not in nameToUrl
                // because node allows either .js or non .js to map
                // to same file.
                if (config.nodeIdCompat && jsSuffixRegExp.test(name[lastIndex])) {
                    name[lastIndex] = name[lastIndex].replace(jsSuffixRegExp, '');
                }

                // Starts with a '.' so need the baseName
                if (name[0].charAt(0) === '.' && baseParts) {
                    //Convert baseName to array, and lop off the last part,
                    //so that . matches that 'directory' and not name of the baseName's
                    //module. For instance, baseName of 'one/two/three', maps to
                    //'one/two/three.js', but we want the directory, 'one/two' for
                    //this normalization.
                    normalizedBaseParts = baseParts.slice(0, baseParts.length - 1);
                    name = normalizedBaseParts.concat(name);
                }

                trimDots(name);
                name = name.join('/');
            }

            //Apply map config if available.
            if (applyMap && map && (baseParts || starMap)) {
                nameParts = name.split('/');

                outerLoop: for (i = nameParts.length; i > 0; i -= 1) {
                    nameSegment = nameParts.slice(0, i).join('/');

                    if (baseParts) {
                        //Find the longest baseName segment match in the config.
                        //So, do joins on the biggest to smallest lengths of baseParts.
                        for (j = baseParts.length; j > 0; j -= 1) {
                            mapValue = getOwn(map, baseParts.slice(0, j).join('/'));

                            //baseName segment has config, find if it has one for
                            //this name.
                            if (mapValue) {
                                mapValue = getOwn(mapValue, nameSegment);
                                if (mapValue) {
                                    //Match, update name to the new value.
                                    foundMap = mapValue;
                                    foundI = i;
                                    break outerLoop;
                                }
                            }
                        }
                    }

                    //Check for a star map match, but just hold on to it,
                    //if there is a shorter segment match later in a matching
                    //config, then favor over this star map.
                    if (!foundStarMap && starMap && getOwn(starMap, nameSegment)) {
                        foundStarMap = getOwn(starMap, nameSegment);
                        starI = i;
                    }
                }

                if (!foundMap && foundStarMap) {
                    foundMap = foundStarMap;
                    foundI = starI;
                }

                if (foundMap) {
                    nameParts.splice(0, foundI, foundMap);
                    name = nameParts.join('/');
                }
            }

            // If the name points to a package's name, use
            // the package main instead.
            pkgMain = getOwn(config.pkgs, name);

            return pkgMain ? pkgMain : name;
        }

        function removeScript(name) {
            if (isBrowser) {
                each(scripts(), function (scriptNode) {
                    if (scriptNode.getAttribute('data-requiremodule') === name &&
                            scriptNode.getAttribute('data-requirecontext') === context.contextName) {
                        scriptNode.parentNode.removeChild(scriptNode);
                        return true;
                    }
                });
            }
        }

        function hasPathFallback(id) {
            var pathConfig = getOwn(config.paths, id);
            if (pathConfig && isArray(pathConfig) && pathConfig.length > 1) {
                //Pop off the first array value, since it failed, and
                //retry
                pathConfig.shift();
                context.require.undef(id);

                //Custom require that does not do map translation, since
                //ID is "absolute", already mapped/resolved.
                context.makeRequire(null, {
                    skipMap: true
                })([id]);

                return true;
            }
        }

        //Turns a plugin!resource to [plugin, resource]
        //with the plugin being undefined if the name
        //did not have a plugin prefix.
        function splitPrefix(name) {
            var prefix,
                index = name ? name.indexOf('!') : -1;
            if (index > -1) {
                prefix = name.substring(0, index);
                name = name.substring(index + 1, name.length);
            }
            return [prefix, name];
        }

        /**
         * Creates a module mapping that includes plugin prefix, module
         * name, and path. If parentModuleMap is provided it will
         * also normalize the name via require.normalize()
         *
         * @param {String} name the module name
         * @param {String} [parentModuleMap] parent module map
         * for the module name, used to resolve relative names.
         * @param {Boolean} isNormalized: is the ID already normalized.
         * This is true if this call is done for a define() module ID.
         * @param {Boolean} applyMap: apply the map config to the ID.
         * Should only be true if this map is for a dependency.
         *
         * @returns {Object}
         */
        function makeModuleMap(name, parentModuleMap, isNormalized, applyMap) {
            var url, pluginModule, suffix, nameParts,
                prefix = null,
                parentName = parentModuleMap ? parentModuleMap.name : null,
                originalName = name,
                isDefine = true,
                normalizedName = '';

            //If no name, then it means it is a require call, generate an
            //internal name.
            if (!name) {
                isDefine = false;
                name = '_@r' + (requireCounter += 1);
            }

            nameParts = splitPrefix(name);
            prefix = nameParts[0];
            name = nameParts[1];

            if (prefix) {
                prefix = normalize(prefix, parentName, applyMap);
                pluginModule = getOwn(defined, prefix);
            }

            //Account for relative paths if there is a base name.
            if (name) {
                if (prefix) {
                    if (pluginModule && pluginModule.normalize) {
                        //Plugin is loaded, use its normalize method.
                        normalizedName = pluginModule.normalize(name, function (name) {
                            return normalize(name, parentName, applyMap);
                        });
                    } else {
                        // If nested plugin references, then do not try to
                        // normalize, as it will not normalize correctly. This
                        // places a restriction on resourceIds, and the longer
                        // term solution is not to normalize until plugins are
                        // loaded and all normalizations to allow for async
                        // loading of a loader plugin. But for now, fixes the
                        // common uses. Details in #1131
                        normalizedName = name.indexOf('!') === -1 ?
                                         normalize(name, parentName, applyMap) :
                                         name;
                    }
                } else {
                    //A regular module.
                    normalizedName = normalize(name, parentName, applyMap);

                    //Normalized name may be a plugin ID due to map config
                    //application in normalize. The map config values must
                    //already be normalized, so do not need to redo that part.
                    nameParts = splitPrefix(normalizedName);
                    prefix = nameParts[0];
                    normalizedName = nameParts[1];
                    isNormalized = true;

                    url = context.nameToUrl(normalizedName);
                }
            }

            //If the id is a plugin id that cannot be determined if it needs
            //normalization, stamp it with a unique ID so two matching relative
            //ids that may conflict can be separate.
            suffix = prefix && !pluginModule && !isNormalized ?
                     '_unnormalized' + (unnormalizedCounter += 1) :
                     '';

            return {
                prefix: prefix,
                name: normalizedName,
                parentMap: parentModuleMap,
                unnormalized: !!suffix,
                url: url,
                originalName: originalName,
                isDefine: isDefine,
                id: (prefix ?
                        prefix + '!' + normalizedName :
                        normalizedName) + suffix
            };
        }

        function getModule(depMap) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (!mod) {
                mod = registry[id] = new context.Module(depMap);
            }

            return mod;
        }

        function on(depMap, name, fn) {
            var id = depMap.id,
                mod = getOwn(registry, id);

            if (hasProp(defined, id) &&
                    (!mod || mod.defineEmitComplete)) {
                if (name === 'defined') {
                    fn(defined[id]);
                }
            } else {
                mod = getModule(depMap);
                if (mod.error && name === 'error') {
                    fn(mod.error);
                } else {
                    mod.on(name, fn);
                }
            }
        }

        function onError(err, errback) {
            var ids = err.requireModules,
                notified = false;

            if (errback) {
                errback(err);
            } else {
                each(ids, function (id) {
                    var mod = getOwn(registry, id);
                    if (mod) {
                        //Set error on module, so it skips timeout checks.
                        mod.error = err;
                        if (mod.events.error) {
                            notified = true;
                            mod.emit('error', err);
                        }
                    }
                });

                if (!notified) {
                    req.onError(err);
                }
            }
        }

        /**
         * Internal method to transfer globalQueue items to this context's
         * defQueue.
         */
        function takeGlobalQueue() {
            //Push all the globalDefQueue items into the context's defQueue
            if (globalDefQueue.length) {
                each(globalDefQueue, function(queueItem) {
                    var id = queueItem[0];
                    if (typeof id === 'string') {
                        context.defQueueMap[id] = true;
                    }
                    defQueue.push(queueItem);
                });
                globalDefQueue = [];
            }
        }

        handlers = {
            'require': function (mod) {
                if (mod.require) {
                    return mod.require;
                } else {
                    return (mod.require = context.makeRequire(mod.map));
                }
            },
            'exports': function (mod) {
                mod.usingExports = true;
                if (mod.map.isDefine) {
                    if (mod.exports) {
                        return (defined[mod.map.id] = mod.exports);
                    } else {
                        return (mod.exports = defined[mod.map.id] = {});
                    }
                }
            },
            'module': function (mod) {
                if (mod.module) {
                    return mod.module;
                } else {
                    return (mod.module = {
                        id: mod.map.id,
                        uri: mod.map.url,
                        config: function () {
                            return getOwn(config.config, mod.map.id) || {};
                        },
                        exports: mod.exports || (mod.exports = {})
                    });
                }
            }
        };

        function cleanRegistry(id) {
            //Clean up machinery used for waiting modules.
            delete registry[id];
            delete enabledRegistry[id];
        }

        function breakCycle(mod, traced, processed) {
            var id = mod.map.id;

            if (mod.error) {
                mod.emit('error', mod.error);
            } else {
                traced[id] = true;
                each(mod.depMaps, function (depMap, i) {
                    var depId = depMap.id,
                        dep = getOwn(registry, depId);

                    //Only force things that have not completed
                    //being defined, so still in the registry,
                    //and only if it has not been matched up
                    //in the module already.
                    if (dep && !mod.depMatched[i] && !processed[depId]) {
                        if (getOwn(traced, depId)) {
                            mod.defineDep(i, defined[depId]);
                            mod.check(); //pass false?
                        } else {
                            breakCycle(dep, traced, processed);
                        }
                    }
                });
                processed[id] = true;
            }
        }

        function checkLoaded() {
            var err, usingPathFallback,
                waitInterval = config.waitSeconds * 1000,
                //It is possible to disable the wait interval by using waitSeconds of 0.
                expired = waitInterval && (context.startTime + waitInterval) < new Date().getTime(),
                noLoads = [],
                reqCalls = [],
                stillLoading = false,
                needCycleCheck = true;

            //Do not bother if this call was a result of a cycle break.
            if (inCheckLoaded) {
                return;
            }

            inCheckLoaded = true;

            //Figure out the state of all the modules.
            eachProp(enabledRegistry, function (mod) {
                var map = mod.map,
                    modId = map.id;

                //Skip things that are not enabled or in error state.
                if (!mod.enabled) {
                    return;
                }

                if (!map.isDefine) {
                    reqCalls.push(mod);
                }

                if (!mod.error) {
                    //If the module should be executed, and it has not
                    //been inited and time is up, remember it.
                    if (!mod.inited && expired) {
                        if (hasPathFallback(modId)) {
                            usingPathFallback = true;
                            stillLoading = true;
                        } else {
                            noLoads.push(modId);
                            removeScript(modId);
                        }
                    } else if (!mod.inited && mod.fetched && map.isDefine) {
                        stillLoading = true;
                        if (!map.prefix) {
                            //No reason to keep looking for unfinished
                            //loading. If the only stillLoading is a
                            //plugin resource though, keep going,
                            //because it may be that a plugin resource
                            //is waiting on a non-plugin cycle.
                            return (needCycleCheck = false);
                        }
                    }
                }
            });

            if (expired && noLoads.length) {
                //If wait time expired, throw error of unloaded modules.
                err = makeError('timeout', 'Load timeout for modules: ' + noLoads, null, noLoads);
                err.contextName = context.contextName;
                return onError(err);
            }

            //Not expired, check for a cycle.
            if (needCycleCheck) {
                each(reqCalls, function (mod) {
                    breakCycle(mod, {}, {});
                });
            }

            //If still waiting on loads, and the waiting load is something
            //other than a plugin resource, or there are still outstanding
            //scripts, then just try back later.
            if ((!expired || usingPathFallback) && stillLoading) {
                //Something is still waiting to load. Wait for it, but only
                //if a timeout is not already in effect.
                if ((isBrowser || isWebWorker) && !checkLoadedTimeoutId) {
                    checkLoadedTimeoutId = setTimeout(function () {
                        checkLoadedTimeoutId = 0;
                        checkLoaded();
                    }, 50);
                }
            }

            inCheckLoaded = false;
        }

        Module = function (map) {
            this.events = getOwn(undefEvents, map.id) || {};
            this.map = map;
            this.shim = getOwn(config.shim, map.id);
            this.depExports = [];
            this.depMaps = [];
            this.depMatched = [];
            this.pluginMaps = {};
            this.depCount = 0;

            /* this.exports this.factory
               this.depMaps = [],
               this.enabled, this.fetched
            */
        };

        Module.prototype = {
            init: function (depMaps, factory, errback, options) {
                options = options || {};

                //Do not do more inits if already done. Can happen if there
                //are multiple define calls for the same module. That is not
                //a normal, common case, but it is also not unexpected.
                if (this.inited) {
                    return;
                }

                this.factory = factory;

                if (errback) {
                    //Register for errors on this module.
                    this.on('error', errback);
                } else if (this.events.error) {
                    //If no errback already, but there are error listeners
                    //on this module, set up an errback to pass to the deps.
                    errback = bind(this, function (err) {
                        this.emit('error', err);
                    });
                }

                //Do a copy of the dependency array, so that
                //source inputs are not modified. For example
                //"shim" deps are passed in here directly, and
                //doing a direct modification of the depMaps array
                //would affect that config.
                this.depMaps = depMaps && depMaps.slice(0);

                this.errback = errback;

                //Indicate this module has be initialized
                this.inited = true;

                this.ignore = options.ignore;

                //Could have option to init this module in enabled mode,
                //or could have been previously marked as enabled. However,
                //the dependencies are not known until init is called. So
                //if enabled previously, now trigger dependencies as enabled.
                if (options.enabled || this.enabled) {
                    //Enable this module and dependencies.
                    //Will call this.check()
                    this.enable();
                } else {
                    this.check();
                }
            },

            defineDep: function (i, depExports) {
                //Because of cycles, defined callback for a given
                //export can be called more than once.
                if (!this.depMatched[i]) {
                    this.depMatched[i] = true;
                    this.depCount -= 1;
                    this.depExports[i] = depExports;
                }
            },

            fetch: function () {
                if (this.fetched) {
                    return;
                }
                this.fetched = true;

                context.startTime = (new Date()).getTime();

                var map = this.map;

                //If the manager is for a plugin managed resource,
                //ask the plugin to load it now.
                if (this.shim) {
                    context.makeRequire(this.map, {
                        enableBuildCallback: true
                    })(this.shim.deps || [], bind(this, function () {
                        return map.prefix ? this.callPlugin() : this.load();
                    }));
                } else {
                    //Regular dependency.
                    return map.prefix ? this.callPlugin() : this.load();
                }
            },

            load: function () {
                var url = this.map.url;

                //Regular dependency.
                if (!urlFetched[url]) {
                    urlFetched[url] = true;
                    context.load(this.map.id, url);
                }
            },

            /**
             * Checks if the module is ready to define itself, and if so,
             * define it.
             */
            check: function () {
                if (!this.enabled || this.enabling) {
                    return;
                }

                var err, cjsModule,
                    id = this.map.id,
                    depExports = this.depExports,
                    exports = this.exports,
                    factory = this.factory;

                if (!this.inited) {
                    // Only fetch if not already in the defQueue.
                    if (!hasProp(context.defQueueMap, id)) {
                        this.fetch();
                    }
                } else if (this.error) {
                    this.emit('error', this.error);
                } else if (!this.defining) {
                    //The factory could trigger another require call
                    //that would result in checking this module to
                    //define itself again. If already in the process
                    //of doing that, skip this work.
                    this.defining = true;

                    if (this.depCount < 1 && !this.defined) {
                        if (isFunction(factory)) {
                            try {
                                exports = context.execCb(id, factory, depExports, exports);
                            } catch (e) {
                                err = e;
                            }

                            // Favor return value over exports. If node/cjs in play,
                            // then will not have a return value anyway. Favor
                            // module.exports assignment over exports object.
                            if (this.map.isDefine && exports === undefined) {
                                cjsModule = this.module;
                                if (cjsModule) {
                                    exports = cjsModule.exports;
                                } else if (this.usingExports) {
                                    //exports already set the defined value.
                                    exports = this.exports;
                                }
                            }

                            if (err) {
                                // If there is an error listener, favor passing
                                // to that instead of throwing an error. However,
                                // only do it for define()'d  modules. require
                                // errbacks should not be called for failures in
                                // their callbacks (#699). However if a global
                                // onError is set, use that.
                                if ((this.events.error && this.map.isDefine) ||
                                    req.onError !== defaultOnError) {
                                    err.requireMap = this.map;
                                    err.requireModules = this.map.isDefine ? [this.map.id] : null;
                                    err.requireType = this.map.isDefine ? 'define' : 'require';
                                    return onError((this.error = err));
                                } else if (typeof console !== 'undefined' &&
                                           console.error) {
                                    // Log the error for debugging. If promises could be
                                    // used, this would be different, but making do.
                                    console.error(err);
                                } else {
                                    // Do not want to completely lose the error. While this
                                    // will mess up processing and lead to similar results
                                    // as bug 1440, it at least surfaces the error.
                                    req.onError(err);
                                }
                            }
                        } else {
                            //Just a literal value
                            exports = factory;
                        }

                        this.exports = exports;

                        if (this.map.isDefine && !this.ignore) {
                            defined[id] = exports;

                            if (req.onResourceLoad) {
                                var resLoadMaps = [];
                                each(this.depMaps, function (depMap) {
                                    resLoadMaps.push(depMap.normalizedMap || depMap);
                                });
                                req.onResourceLoad(context, this.map, resLoadMaps);
                            }
                        }

                        //Clean up
                        cleanRegistry(id);

                        this.defined = true;
                    }

                    //Finished the define stage. Allow calling check again
                    //to allow define notifications below in the case of a
                    //cycle.
                    this.defining = false;

                    if (this.defined && !this.defineEmitted) {
                        this.defineEmitted = true;
                        this.emit('defined', this.exports);
                        this.defineEmitComplete = true;
                    }

                }
            },

            callPlugin: function () {
                var map = this.map,
                    id = map.id,
                    //Map already normalized the prefix.
                    pluginMap = makeModuleMap(map.prefix);

                //Mark this as a dependency for this plugin, so it
                //can be traced for cycles.
                this.depMaps.push(pluginMap);

                on(pluginMap, 'defined', bind(this, function (plugin) {
                    var load, normalizedMap, normalizedMod,
                        bundleId = getOwn(bundlesMap, this.map.id),
                        name = this.map.name,
                        parentName = this.map.parentMap ? this.map.parentMap.name : null,
                        localRequire = context.makeRequire(map.parentMap, {
                            enableBuildCallback: true
                        });

                    //If current map is not normalized, wait for that
                    //normalized name to load instead of continuing.
                    if (this.map.unnormalized) {
                        //Normalize the ID if the plugin allows it.
                        if (plugin.normalize) {
                            name = plugin.normalize(name, function (name) {
                                return normalize(name, parentName, true);
                            }) || '';
                        }

                        //prefix and name should already be normalized, no need
                        //for applying map config again either.
                        normalizedMap = makeModuleMap(map.prefix + '!' + name,
                                                      this.map.parentMap);
                        on(normalizedMap,
                            'defined', bind(this, function (value) {
                                this.map.normalizedMap = normalizedMap;
                                this.init([], function () { return value; }, null, {
                                    enabled: true,
                                    ignore: true
                                });
                            }));

                        normalizedMod = getOwn(registry, normalizedMap.id);
                        if (normalizedMod) {
                            //Mark this as a dependency for this plugin, so it
                            //can be traced for cycles.
                            this.depMaps.push(normalizedMap);

                            if (this.events.error) {
                                normalizedMod.on('error', bind(this, function (err) {
                                    this.emit('error', err);
                                }));
                            }
                            normalizedMod.enable();
                        }

                        return;
                    }

                    //If a paths config, then just load that file instead to
                    //resolve the plugin, as it is built into that paths layer.
                    if (bundleId) {
                        this.map.url = context.nameToUrl(bundleId);
                        this.load();
                        return;
                    }

                    load = bind(this, function (value) {
                        this.init([], function () { return value; }, null, {
                            enabled: true
                        });
                    });

                    load.error = bind(this, function (err) {
                        this.inited = true;
                        this.error = err;
                        err.requireModules = [id];

                        //Remove temp unnormalized modules for this module,
                        //since they will never be resolved otherwise now.
                        eachProp(registry, function (mod) {
                            if (mod.map.id.indexOf(id + '_unnormalized') === 0) {
                                cleanRegistry(mod.map.id);
                            }
                        });

                        onError(err);
                    });

                    //Allow plugins to load other code without having to know the
                    //context or how to 'complete' the load.
                    load.fromText = bind(this, function (text, textAlt) {
                        /*jslint evil: true */
                        var moduleName = map.name,
                            moduleMap = makeModuleMap(moduleName),
                            hasInteractive = useInteractive;

                        //As of 2.1.0, support just passing the text, to reinforce
                        //fromText only being called once per resource. Still
                        //support old style of passing moduleName but discard
                        //that moduleName in favor of the internal ref.
                        if (textAlt) {
                            text = textAlt;
                        }

                        //Turn off interactive script matching for IE for any define
                        //calls in the text, then turn it back on at the end.
                        if (hasInteractive) {
                            useInteractive = false;
                        }

                        //Prime the system by creating a module instance for
                        //it.
                        getModule(moduleMap);

                        //Transfer any config to this other module.
                        if (hasProp(config.config, id)) {
                            config.config[moduleName] = config.config[id];
                        }

                        try {
                            req.exec(text);
                        } catch (e) {
                            return onError(makeError('fromtexteval',
                                             'fromText eval for ' + id +
                                            ' failed: ' + e,
                                             e,
                                             [id]));
                        }

                        if (hasInteractive) {
                            useInteractive = true;
                        }

                        //Mark this as a dependency for the plugin
                        //resource
                        this.depMaps.push(moduleMap);

                        //Support anonymous modules.
                        context.completeLoad(moduleName);

                        //Bind the value of that module to the value for this
                        //resource ID.
                        localRequire([moduleName], load);
                    });

                    //Use parentName here since the plugin's name is not reliable,
                    //could be some weird string with no path that actually wants to
                    //reference the parentName's path.
                    plugin.load(map.name, localRequire, load, config);
                }));

                context.enable(pluginMap, this);
                this.pluginMaps[pluginMap.id] = pluginMap;
            },

            enable: function () {
                enabledRegistry[this.map.id] = this;
                this.enabled = true;

                //Set flag mentioning that the module is enabling,
                //so that immediate calls to the defined callbacks
                //for dependencies do not trigger inadvertent load
                //with the depCount still being zero.
                this.enabling = true;

                //Enable each dependency
                each(this.depMaps, bind(this, function (depMap, i) {
                    var id, mod, handler;

                    if (typeof depMap === 'string') {
                        //Dependency needs to be converted to a depMap
                        //and wired up to this module.
                        depMap = makeModuleMap(depMap,
                                               (this.map.isDefine ? this.map : this.map.parentMap),
                                               false,
                                               !this.skipMap);
                        this.depMaps[i] = depMap;

                        handler = getOwn(handlers, depMap.id);

                        if (handler) {
                            this.depExports[i] = handler(this);
                            return;
                        }

                        this.depCount += 1;

                        on(depMap, 'defined', bind(this, function (depExports) {
                            if (this.undefed) {
                                return;
                            }
                            this.defineDep(i, depExports);
                            this.check();
                        }));

                        if (this.errback) {
                            on(depMap, 'error', bind(this, this.errback));
                        } else if (this.events.error) {
                            // No direct errback on this module, but something
                            // else is listening for errors, so be sure to
                            // propagate the error correctly.
                            on(depMap, 'error', bind(this, function(err) {
                                this.emit('error', err);
                            }));
                        }
                    }

                    id = depMap.id;
                    mod = registry[id];

                    //Skip special modules like 'require', 'exports', 'module'
                    //Also, don't call enable if it is already enabled,
                    //important in circular dependency cases.
                    if (!hasProp(handlers, id) && mod && !mod.enabled) {
                        context.enable(depMap, this);
                    }
                }));

                //Enable each plugin that is used in
                //a dependency
                eachProp(this.pluginMaps, bind(this, function (pluginMap) {
                    var mod = getOwn(registry, pluginMap.id);
                    if (mod && !mod.enabled) {
                        context.enable(pluginMap, this);
                    }
                }));

                this.enabling = false;

                this.check();
            },

            on: function (name, cb) {
                var cbs = this.events[name];
                if (!cbs) {
                    cbs = this.events[name] = [];
                }
                cbs.push(cb);
            },

            emit: function (name, evt) {
                each(this.events[name], function (cb) {
                    cb(evt);
                });
                if (name === 'error') {
                    //Now that the error handler was triggered, remove
                    //the listeners, since this broken Module instance
                    //can stay around for a while in the registry.
                    delete this.events[name];
                }
            }
        };

        function callGetModule(args) {
            //Skip modules already defined.
            if (!hasProp(defined, args[0])) {
                getModule(makeModuleMap(args[0], null, true)).init(args[1], args[2]);
            }
        }

        function removeListener(node, func, name, ieName) {
            //Favor detachEvent because of IE9
            //issue, see attachEvent/addEventListener comment elsewhere
            //in this file.
            if (node.detachEvent && !isOpera) {
                //Probably IE. If not it will throw an error, which will be
                //useful to know.
                if (ieName) {
                    node.detachEvent(ieName, func);
                }
            } else {
                node.removeEventListener(name, func, false);
            }
        }

        /**
         * Given an event from a script node, get the requirejs info from it,
         * and then removes the event listeners on the node.
         * @param {Event} evt
         * @returns {Object}
         */
        function getScriptData(evt) {
            //Using currentTarget instead of target for Firefox 2.0's sake. Not
            //all old browsers will be supported, but this one was easy enough
            //to support and still makes sense.
            var node = evt.currentTarget || evt.srcElement;

            //Remove the listeners once here.
            removeListener(node, context.onScriptLoad, 'load', 'onreadystatechange');
            removeListener(node, context.onScriptError, 'error');

            return {
                node: node,
                id: node && node.getAttribute('data-requiremodule')
            };
        }

        function intakeDefines() {
            var args;

            //Any defined modules in the global queue, intake them now.
            takeGlobalQueue();

            //Make sure any remaining defQueue items get properly processed.
            while (defQueue.length) {
                args = defQueue.shift();
                if (args[0] === null) {
                    return onError(makeError('mismatch', 'Mismatched anonymous define() module: ' +
                        args[args.length - 1]));
                } else {
                    //args are id, deps, factory. Should be normalized by the
                    //define() function.
                    callGetModule(args);
                }
            }
            context.defQueueMap = {};
        }

        context = {
            config: config,
            contextName: contextName,
            registry: registry,
            defined: defined,
            urlFetched: urlFetched,
            defQueue: defQueue,
            defQueueMap: {},
            Module: Module,
            makeModuleMap: makeModuleMap,
            nextTick: req.nextTick,
            onError: onError,

            /**
             * Set a configuration for the context.
             * @param {Object} cfg config object to integrate.
             */
            configure: function (cfg) {
                //Make sure the baseUrl ends in a slash.
                if (cfg.baseUrl) {
                    if (cfg.baseUrl.charAt(cfg.baseUrl.length - 1) !== '/') {
                        cfg.baseUrl += '/';
                    }
                }

                //Save off the paths since they require special processing,
                //they are additive.
                var shim = config.shim,
                    objs = {
                        paths: true,
                        bundles: true,
                        config: true,
                        map: true
                    };

                eachProp(cfg, function (value, prop) {
                    if (objs[prop]) {
                        if (!config[prop]) {
                            config[prop] = {};
                        }
                        mixin(config[prop], value, true, true);
                    } else {
                        config[prop] = value;
                    }
                });

                //Reverse map the bundles
                if (cfg.bundles) {
                    eachProp(cfg.bundles, function (value, prop) {
                        each(value, function (v) {
                            if (v !== prop) {
                                bundlesMap[v] = prop;
                            }
                        });
                    });
                }

                //Merge shim
                if (cfg.shim) {
                    eachProp(cfg.shim, function (value, id) {
                        //Normalize the structure
                        if (isArray(value)) {
                            value = {
                                deps: value
                            };
                        }
                        if ((value.exports || value.init) && !value.exportsFn) {
                            value.exportsFn = context.makeShimExports(value);
                        }
                        shim[id] = value;
                    });
                    config.shim = shim;
                }

                //Adjust packages if necessary.
                if (cfg.packages) {
                    each(cfg.packages, function (pkgObj) {
                        var location, name;

                        pkgObj = typeof pkgObj === 'string' ? {name: pkgObj} : pkgObj;

                        name = pkgObj.name;
                        location = pkgObj.location;
                        if (location) {
                            config.paths[name] = pkgObj.location;
                        }

                        //Save pointer to main module ID for pkg name.
                        //Remove leading dot in main, so main paths are normalized,
                        //and remove any trailing .js, since different package
                        //envs have different conventions: some use a module name,
                        //some use a file name.
                        config.pkgs[name] = pkgObj.name + '/' + (pkgObj.main || 'main')
                                     .replace(currDirRegExp, '')
                                     .replace(jsSuffixRegExp, '');
                    });
                }

                //If there are any "waiting to execute" modules in the registry,
                //update the maps for them, since their info, like URLs to load,
                //may have changed.
                eachProp(registry, function (mod, id) {
                    //If module already has init called, since it is too
                    //late to modify them, and ignore unnormalized ones
                    //since they are transient.
                    if (!mod.inited && !mod.map.unnormalized) {
                        mod.map = makeModuleMap(id, null, true);
                    }
                });

                //If a deps array or a config callback is specified, then call
                //require with those args. This is useful when require is defined as a
                //config object before require.js is loaded.
                if (cfg.deps || cfg.callback) {
                    context.require(cfg.deps || [], cfg.callback);
                }
            },

            makeShimExports: function (value) {
                function fn() {
                    var ret;
                    if (value.init) {
                        ret = value.init.apply(global, arguments);
                    }
                    return ret || (value.exports && getGlobal(value.exports));
                }
                return fn;
            },

            makeRequire: function (relMap, options) {
                options = options || {};

                function localRequire(deps, callback, errback) {
                    var id, map, requireMod;

                    if (options.enableBuildCallback && callback && isFunction(callback)) {
                        callback.__requireJsBuild = true;
                    }

                    if (typeof deps === 'string') {
                        if (isFunction(callback)) {
                            //Invalid call
                            return onError(makeError('requireargs', 'Invalid require call'), errback);
                        }

                        //If require|exports|module are requested, get the
                        //value for them from the special handlers. Caveat:
                        //this only works while module is being defined.
                        if (relMap && hasProp(handlers, deps)) {
                            return handlers[deps](registry[relMap.id]);
                        }

                        //Synchronous access to one module. If require.get is
                        //available (as in the Node adapter), prefer that.
                        if (req.get) {
                            return req.get(context, deps, relMap, localRequire);
                        }

                        //Normalize module name, if it contains . or ..
                        map = makeModuleMap(deps, relMap, false, true);
                        id = map.id;

                        if (!hasProp(defined, id)) {
                            return onError(makeError('notloaded', 'Module name "' +
                                        id +
                                        '" has not been loaded yet for context: ' +
                                        contextName +
                                        (relMap ? '' : '. Use require([])')));
                        }
                        return defined[id];
                    }

                    //Grab defines waiting in the global queue.
                    intakeDefines();

                    //Mark all the dependencies as needing to be loaded.
                    context.nextTick(function () {
                        //Some defines could have been added since the
                        //require call, collect them.
                        intakeDefines();

                        requireMod = getModule(makeModuleMap(null, relMap));

                        //Store if map config should be applied to this require
                        //call for dependencies.
                        requireMod.skipMap = options.skipMap;

                        requireMod.init(deps, callback, errback, {
                            enabled: true
                        });

                        checkLoaded();
                    });

                    return localRequire;
                }

                mixin(localRequire, {
                    isBrowser: isBrowser,

                    /**
                     * Converts a module name + .extension into an URL path.
                     * *Requires* the use of a module name. It does not support using
                     * plain URLs like nameToUrl.
                     */
                    toUrl: function (moduleNamePlusExt) {
                        var ext,
                            index = moduleNamePlusExt.lastIndexOf('.'),
                            segment = moduleNamePlusExt.split('/')[0],
                            isRelative = segment === '.' || segment === '..';

                        //Have a file extension alias, and it is not the
                        //dots from a relative path.
                        if (index !== -1 && (!isRelative || index > 1)) {
                            ext = moduleNamePlusExt.substring(index, moduleNamePlusExt.length);
                            moduleNamePlusExt = moduleNamePlusExt.substring(0, index);
                        }

                        return context.nameToUrl(normalize(moduleNamePlusExt,
                                                relMap && relMap.id, true), ext,  true);
                    },

                    defined: function (id) {
                        return hasProp(defined, makeModuleMap(id, relMap, false, true).id);
                    },

                    specified: function (id) {
                        id = makeModuleMap(id, relMap, false, true).id;
                        return hasProp(defined, id) || hasProp(registry, id);
                    }
                });

                //Only allow undef on top level require calls
                if (!relMap) {
                    localRequire.undef = function (id) {
                        //Bind any waiting define() calls to this context,
                        //fix for #408
                        takeGlobalQueue();

                        var map = makeModuleMap(id, relMap, true),
                            mod = getOwn(registry, id);

                        mod.undefed = true;
                        removeScript(id);

                        delete defined[id];
                        delete urlFetched[map.url];
                        delete undefEvents[id];

                        //Clean queued defines too. Go backwards
                        //in array so that the splices do not
                        //mess up the iteration.
                        eachReverse(defQueue, function(args, i) {
                            if (args[0] === id) {
                                defQueue.splice(i, 1);
                            }
                        });
                        delete context.defQueueMap[id];

                        if (mod) {
                            //Hold on to listeners in case the
                            //module will be attempted to be reloaded
                            //using a different config.
                            if (mod.events.defined) {
                                undefEvents[id] = mod.events;
                            }

                            cleanRegistry(id);
                        }
                    };
                }

                return localRequire;
            },

            /**
             * Called to enable a module if it is still in the registry
             * awaiting enablement. A second arg, parent, the parent module,
             * is passed in for context, when this method is overridden by
             * the optimizer. Not shown here to keep code compact.
             */
            enable: function (depMap) {
                var mod = getOwn(registry, depMap.id);
                if (mod) {
                    getModule(depMap).enable();
                }
            },

            /**
             * Internal method used by environment adapters to complete a load event.
             * A load event could be a script load or just a load pass from a synchronous
             * load call.
             * @param {String} moduleName the name of the module to potentially complete.
             */
            completeLoad: function (moduleName) {
                var found, args, mod,
                    shim = getOwn(config.shim, moduleName) || {},
                    shExports = shim.exports;

                takeGlobalQueue();

                while (defQueue.length) {
                    args = defQueue.shift();
                    if (args[0] === null) {
                        args[0] = moduleName;
                        //If already found an anonymous module and bound it
                        //to this name, then this is some other anon module
                        //waiting for its completeLoad to fire.
                        if (found) {
                            break;
                        }
                        found = true;
                    } else if (args[0] === moduleName) {
                        //Found matching define call for this script!
                        found = true;
                    }

                    callGetModule(args);
                }
                context.defQueueMap = {};

                //Do this after the cycle of callGetModule in case the result
                //of those calls/init calls changes the registry.
                mod = getOwn(registry, moduleName);

                if (!found && !hasProp(defined, moduleName) && mod && !mod.inited) {
                    if (config.enforceDefine && (!shExports || !getGlobal(shExports))) {
                        if (hasPathFallback(moduleName)) {
                            return;
                        } else {
                            return onError(makeError('nodefine',
                                             'No define call for ' + moduleName,
                                             null,
                                             [moduleName]));
                        }
                    } else {
                        //A script that does not call define(), so just simulate
                        //the call for it.
                        callGetModule([moduleName, (shim.deps || []), shim.exportsFn]);
                    }
                }

                checkLoaded();
            },

            /**
             * Converts a module name to a file path. Supports cases where
             * moduleName may actually be just an URL.
             * Note that it **does not** call normalize on the moduleName,
             * it is assumed to have already been normalized. This is an
             * internal API, not a public one. Use toUrl for the public API.
             */
            nameToUrl: function (moduleName, ext, skipExt) {
                var paths, syms, i, parentModule, url,
                    parentPath, bundleId,
                    pkgMain = getOwn(config.pkgs, moduleName);

                if (pkgMain) {
                    moduleName = pkgMain;
                }

                bundleId = getOwn(bundlesMap, moduleName);

                if (bundleId) {
                    return context.nameToUrl(bundleId, ext, skipExt);
                }

                //If a colon is in the URL, it indicates a protocol is used and it is just
                //an URL to a file, or if it starts with a slash, contains a query arg (i.e. ?)
                //or ends with .js, then assume the user meant to use an url and not a module id.
                //The slash is important for protocol-less URLs as well as full paths.
                if (req.jsExtRegExp.test(moduleName)) {
                    //Just a plain path, not module name lookup, so just return it.
                    //Add extension if it is included. This is a bit wonky, only non-.js things pass
                    //an extension, this method probably needs to be reworked.
                    url = moduleName + (ext || '');
                } else {
                    //A module that needs to be converted to a path.
                    paths = config.paths;

                    syms = moduleName.split('/');
                    //For each module name segment, see if there is a path
                    //registered for it. Start with most specific name
                    //and work up from it.
                    for (i = syms.length; i > 0; i -= 1) {
                        parentModule = syms.slice(0, i).join('/');

                        parentPath = getOwn(paths, parentModule);
                        if (parentPath) {
                            //If an array, it means there are a few choices,
                            //Choose the one that is desired
                            if (isArray(parentPath)) {
                                parentPath = parentPath[0];
                            }
                            syms.splice(0, i, parentPath);
                            break;
                        }
                    }

                    //Join the path parts together, then figure out if baseUrl is needed.
                    url = syms.join('/');
                    url += (ext || (/^data\:|\?/.test(url) || skipExt ? '' : '.js'));
                    url = (url.charAt(0) === '/' || url.match(/^[\w\+\.\-]+:/) ? '' : config.baseUrl) + url;
                }

                return config.urlArgs ? url +
                                        ((url.indexOf('?') === -1 ? '?' : '&') +
                                         config.urlArgs) : url;
            },

            //Delegates to req.load. Broken out as a separate function to
            //allow overriding in the optimizer.
            load: function (id, url) {
                req.load(context, id, url);
            },

            /**
             * Executes a module callback function. Broken out as a separate function
             * solely to allow the build system to sequence the files in the built
             * layer in the right sequence.
             *
             * @private
             */
            execCb: function (name, callback, args, exports) {
                return callback.apply(exports, args);
            },

            /**
             * callback for script loads, used to check status of loading.
             *
             * @param {Event} evt the event from the browser for the script
             * that was loaded.
             */
            onScriptLoad: function (evt) {
                //Using currentTarget instead of target for Firefox 2.0's sake. Not
                //all old browsers will be supported, but this one was easy enough
                //to support and still makes sense.
                if (evt.type === 'load' ||
                        (readyRegExp.test((evt.currentTarget || evt.srcElement).readyState))) {
                    //Reset interactive script so a script node is not held onto for
                    //to long.
                    interactiveScript = null;

                    //Pull out the name of the module and the context.
                    var data = getScriptData(evt);
                    context.completeLoad(data.id);
                }
            },

            /**
             * Callback for script errors.
             */
            onScriptError: function (evt) {
                var data = getScriptData(evt);
                if (!hasPathFallback(data.id)) {
                    var parents = [];
                    eachProp(registry, function(value, key) {
                        if (key.indexOf('_@r') !== 0) {
                            each(value.depMaps, function(depMap) {
                                if (depMap.id === data.id) {
                                    parents.push(key);
                                }
                                return true;
                            });
                        }
                    });
                    return onError(makeError('scripterror', 'Script error for "' + data.id +
                                             (parents.length ?
                                             '", needed by: ' + parents.join(', ') :
                                             '"'), evt, [data.id]));
                }
            }
        };

        context.require = context.makeRequire();
        return context;
    }

    /**
     * Main entry point.
     *
     * If the only argument to require is a string, then the module that
     * is represented by that string is fetched for the appropriate context.
     *
     * If the first argument is an array, then it will be treated as an array
     * of dependency string names to fetch. An optional function callback can
     * be specified to execute when all of those dependencies are available.
     *
     * Make a local req variable to help Caja compliance (it assumes things
     * on a require that are not standardized), and to give a short
     * name for minification/local scope use.
     */
    req = requirejs = function (deps, callback, errback, optional) {

        //Find the right context, use default
        var context, config,
            contextName = defContextName;

        // Determine if have config object in the call.
        if (!isArray(deps) && typeof deps !== 'string') {
            // deps is a config object
            config = deps;
            if (isArray(callback)) {
                // Adjust args if there are dependencies
                deps = callback;
                callback = errback;
                errback = optional;
            } else {
                deps = [];
            }
        }

        if (config && config.context) {
            contextName = config.context;
        }

        context = getOwn(contexts, contextName);
        if (!context) {
            context = contexts[contextName] = req.s.newContext(contextName);
        }

        if (config) {
            context.configure(config);
        }

        return context.require(deps, callback, errback);
    };

    /**
     * Support require.config() to make it easier to cooperate with other
     * AMD loaders on globally agreed names.
     */
    req.config = function (config) {
        return req(config);
    };

    /**
     * Execute something after the current tick
     * of the event loop. Override for other envs
     * that have a better solution than setTimeout.
     * @param  {Function} fn function to execute later.
     */
    req.nextTick = typeof setTimeout !== 'undefined' ? function (fn) {
        setTimeout(fn, 4);
    } : function (fn) { fn(); };

    /**
     * Export require as a global, but only if it does not already exist.
     */
    if (!require) {
        require = req;
    }

    req.version = version;

    //Used to filter out dependencies that are already paths.
    req.jsExtRegExp = /^\/|:|\?|\.js$/;
    req.isBrowser = isBrowser;
    s = req.s = {
        contexts: contexts,
        newContext: newContext
    };

    //Create default context.
    req({});

    //Exports some context-sensitive methods on global require.
    each([
        'toUrl',
        'undef',
        'defined',
        'specified'
    ], function (prop) {
        //Reference from contexts instead of early binding to default context,
        //so that during builds, the latest instance of the default context
        //with its config gets used.
        req[prop] = function () {
            var ctx = contexts[defContextName];
            return ctx.require[prop].apply(ctx, arguments);
        };
    });

    if (isBrowser) {
        head = s.head = document.getElementsByTagName('head')[0];
        //If BASE tag is in play, using appendChild is a problem for IE6.
        //When that browser dies, this can be removed. Details in this jQuery bug:
        //http://dev.jquery.com/ticket/2709
        baseElement = document.getElementsByTagName('base')[0];
        if (baseElement) {
            head = s.head = baseElement.parentNode;
        }
    }

    /**
     * Any errors that require explicitly generates will be passed to this
     * function. Intercept/override it if you want custom error handling.
     * @param {Error} err the error object.
     */
    req.onError = defaultOnError;

    /**
     * Creates the node for the load command. Only used in browser envs.
     */
    req.createNode = function (config, moduleName, url) {
        var node = config.xhtml ?
                document.createElementNS('http://www.w3.org/1999/xhtml', 'html:script') :
                document.createElement('script');
        node.type = config.scriptType || 'text/javascript';
        node.charset = 'utf-8';
        node.async = true;
        return node;
    };

    /**
     * Does the request to load a module for the browser case.
     * Make this a separate function to allow other environments
     * to override it.
     *
     * @param {Object} context the require context to find state.
     * @param {String} moduleName the name of the module.
     * @param {Object} url the URL to the module.
     */
    req.load = function (context, moduleName, url) {
        var config = (context && context.config) || {},
            node;
        if (isBrowser) {
            //In the browser so use a script tag
            node = req.createNode(config, moduleName, url);
            if (config.onNodeCreated) {
                config.onNodeCreated(node, config, moduleName, url);
            }

            node.setAttribute('data-requirecontext', context.contextName);
            node.setAttribute('data-requiremodule', moduleName);

            //Set up load listener. Test attachEvent first because IE9 has
            //a subtle issue in its addEventListener and script onload firings
            //that do not match the behavior of all other browsers with
            //addEventListener support, which fire the onload event for a
            //script right after the script execution. See:
            //https://connect.microsoft.com/IE/feedback/details/648057/script-onload-event-is-not-fired-immediately-after-script-execution
            //UNFORTUNATELY Opera implements attachEvent but does not follow the script
            //script execution mode.
            if (node.attachEvent &&
                    //Check if node.attachEvent is artificially added by custom script or
                    //natively supported by browser
                    //read https://github.com/jrburke/requirejs/issues/187
                    //if we can NOT find [native code] then it must NOT natively supported.
                    //in IE8, node.attachEvent does not have toString()
                    //Note the test for "[native code" with no closing brace, see:
                    //https://github.com/jrburke/requirejs/issues/273
                    !(node.attachEvent.toString && node.attachEvent.toString().indexOf('[native code') < 0) &&
                    !isOpera) {
                //Probably IE. IE (at least 6-8) do not fire
                //script onload right after executing the script, so
                //we cannot tie the anonymous define call to a name.
                //However, IE reports the script as being in 'interactive'
                //readyState at the time of the define call.
                useInteractive = true;

                node.attachEvent('onreadystatechange', context.onScriptLoad);
                //It would be great to add an error handler here to catch
                //404s in IE9+. However, onreadystatechange will fire before
                //the error handler, so that does not help. If addEventListener
                //is used, then IE will fire error before load, but we cannot
                //use that pathway given the connect.microsoft.com issue
                //mentioned above about not doing the 'script execute,
                //then fire the script load event listener before execute
                //next script' that other browsers do.
                //Best hope: IE10 fixes the issues,
                //and then destroys all installs of IE 6-9.
                //node.attachEvent('onerror', context.onScriptError);
            } else {
                node.addEventListener('load', context.onScriptLoad, false);
                node.addEventListener('error', context.onScriptError, false);
            }
            node.src = url;

            //For some cache cases in IE 6-8, the script executes before the end
            //of the appendChild execution, so to tie an anonymous define
            //call to the module name (which is stored on the node), hold on
            //to a reference to this node, but clear after the DOM insertion.
            currentlyAddingScript = node;
            if (baseElement) {
                head.insertBefore(node, baseElement);
            } else {
                head.appendChild(node);
            }
            currentlyAddingScript = null;

            return node;
        } else if (isWebWorker) {
            try {
                //In a web worker, use importScripts. This is not a very
                //efficient use of importScripts, importScripts will block until
                //its script is downloaded and evaluated. However, if web workers
                //are in play, the expectation is that a build has been done so
                //that only one script needs to be loaded anyway. This may need
                //to be reevaluated if other use cases become common.
                importScripts(url);

                //Account for anonymous modules
                context.completeLoad(moduleName);
            } catch (e) {
                context.onError(makeError('importscripts',
                                'importScripts failed for ' +
                                    moduleName + ' at ' + url,
                                e,
                                [moduleName]));
            }
        }
    };

    function getInteractiveScript() {
        if (interactiveScript && interactiveScript.readyState === 'interactive') {
            return interactiveScript;
        }

        eachReverse(scripts(), function (script) {
            if (script.readyState === 'interactive') {
                return (interactiveScript = script);
            }
        });
        return interactiveScript;
    }

    //Look for a data-main script attribute, which could also adjust the baseUrl.
    if (isBrowser && !cfg.skipDataMain) {
        //Figure out baseUrl. Get it from the script tag with require.js in it.
        eachReverse(scripts(), function (script) {
            //Set the 'head' where we can append children by
            //using the script's parent.
            if (!head) {
                head = script.parentNode;
            }

            //Look for a data-main attribute to set main script for the page
            //to load. If it is there, the path to data main becomes the
            //baseUrl, if it is not already set.
            dataMain = script.getAttribute('data-main');
            if (dataMain) {
                //Preserve dataMain in case it is a path (i.e. contains '?')
                mainScript = dataMain;

                //Set final baseUrl if there is not already an explicit one.
                if (!cfg.baseUrl) {
                    //Pull off the directory of data-main for use as the
                    //baseUrl.
                    src = mainScript.split('/');
                    mainScript = src.pop();
                    subPath = src.length ? src.join('/')  + '/' : './';

                    cfg.baseUrl = subPath;
                }

                //Strip off any trailing .js since mainScript is now
                //like a module name.
                mainScript = mainScript.replace(jsSuffixRegExp, '');

                //If mainScript is still a path, fall back to dataMain
                if (req.jsExtRegExp.test(mainScript)) {
                    mainScript = dataMain;
                }

                //Put the data-main script in the files to load.
                cfg.deps = cfg.deps ? cfg.deps.concat(mainScript) : [mainScript];

                return true;
            }
        });
    }

    /**
     * The function that handles definitions of modules. Differs from
     * require() in that a string for the module should be the first argument,
     * and the function to execute after dependencies are loaded should
     * return a value to define the module corresponding to the first argument's
     * name.
     */
    define = function (name, deps, callback) {
        var node, context;

        //Allow for anonymous modules
        if (typeof name !== 'string') {
            //Adjust args appropriately
            callback = deps;
            deps = name;
            name = null;
        }

        //This module may not have dependencies
        if (!isArray(deps)) {
            callback = deps;
            deps = null;
        }

        //If no name, and callback is a function, then figure out if it a
        //CommonJS thing with dependencies.
        if (!deps && isFunction(callback)) {
            deps = [];
            //Remove comments from the callback string,
            //look for require calls, and pull them into the dependencies,
            //but only if there are function args.
            if (callback.length) {
                callback
                    .toString()
                    .replace(commentRegExp, '')
                    .replace(cjsRequireRegExp, function (match, dep) {
                        deps.push(dep);
                    });

                //May be a CommonJS thing even without require calls, but still
                //could use exports, and module. Avoid doing exports and module
                //work though if it just needs require.
                //REQUIRES the function to expect the CommonJS variables in the
                //order listed below.
                deps = (callback.length === 1 ? ['require'] : ['require', 'exports', 'module']).concat(deps);
            }
        }

        //If in IE 6-8 and hit an anonymous define() call, do the interactive
        //work.
        if (useInteractive) {
            node = currentlyAddingScript || getInteractiveScript();
            if (node) {
                if (!name) {
                    name = node.getAttribute('data-requiremodule');
                }
                context = contexts[node.getAttribute('data-requirecontext')];
            }
        }

        //Always save off evaluating the def call until the script onload handler.
        //This allows multiple modules to be in a file without prematurely
        //tracing dependencies, and allows for anonymous module support,
        //where the module name is not known until the script onload event
        //occurs. If no context, use the global queue, and get it processed
        //in the onscript load callback.
        if (context) {
            context.defQueue.push([name, deps, callback]);
            context.defQueueMap[name] = true;
        } else {
            globalDefQueue.push([name, deps, callback]);
        }
    };

    define.amd = {
        jQuery: true
    };

    /**
     * Executes the text. Normally just uses eval, but can be modified
     * to use a better, environment-specific call. Only used for transpiling
     * loader plugins, not for plain JS modules.
     * @param {String} text the text to execute/evaluate.
     */
    req.exec = function (text) {
        /*jslint evil: true */
        return eval(text);
    };

    //Set up with config info.
    req(cfg);
}(this));
",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "5c170688-f547-42eb-b9d2-999f304f00a4"
      },
      "source": [
        "# Visualize self-attention weights\n",
        "call_html()\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids[0])\n",
        "head_view(attention=attn, tokens=tokens)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
              "        <script>\n",
              "          requirejs.config({\n",
              "            paths: {\n",
              "              base: '/static/base',\n",
              "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
              "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "            },\n",
              "          });\n",
              "        </script>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "            <div id='bertviz-a492ca45f33b492b8b9f5bdbcc1f9407'>\n",
              "              <span style=\"user-select:none\">\n",
              "                Layer: <select id=\"layer\"></select>\n",
              "              </span>\n",
              "              <div id='vis'></div> \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/**\n",
              " * @fileoverview Transformer Visualization D3 javascript code.\n",
              " *\n",
              " *\n",
              " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
              " *\n",
              " * Change log:\n",
              " *\n",
              " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
              " * 12/29/20  Jesse Vig   Significant refactor.\n",
              " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
              " **/\n",
              "\n",
              "\n",
              "requirejs(['jquery', 'd3'], function ($, d3) {\n",
              "\n",
              "    const params = {\"attention\": {\"all\": {\"attn\": [[[[0.021471688523888588, 0.11818783730268478, 0.1273571401834488, 0.2520386576652527, 0.10933373868465424, 0.1178814098238945, 0.15705224871635437, 0.09667724370956421], [0.10270272940397263, 0.017381325364112854, 0.05789373070001602, 0.08408740162849426, 0.08054445683956146, 0.2913025915622711, 0.04208483546972275, 0.32400283217430115], [0.3185310661792755, 0.11833782494068146, 0.0042231157422065735, 0.12728507816791534, 0.22116777300834656, 0.05979571491479874, 0.002291534561663866, 0.14836783707141876], [0.040530070662498474, 0.07783496379852295, 0.06516934186220169, 0.03245235234498978, 0.10647381842136383, 0.3262057900428772, 0.06160903349518776, 0.28972455859184265], [0.13867415487766266, 0.12491236627101898, 0.08309179544448853, 0.13896462321281433, 0.0130592817440629, 0.2026725560426712, 0.0763663649559021, 0.2222588211297989], [0.10300623625516891, 0.08243090659379959, 0.017215300351381302, 0.2749914228916168, 0.0827358216047287, 0.006487335078418255, 0.014078550040721893, 0.41905441880226135], [0.2649904787540436, 0.11882265657186508, 0.0036927477922290564, 0.1314265877008438, 0.24017192423343658, 0.056132424622774124, 0.0024685722310096025, 0.18229462206363678], [0.17776252329349518, 0.06566043943166733, 0.07044108211994171, 0.07944270968437195, 0.05321170389652252, 0.10840796679258347, 0.10247717052698135, 0.34259647130966187]], [[0.0407116524875164, 0.007977649569511414, 0.010935850441455841, 0.02050274983048439, 0.019624413922429085, 0.029081294313073158, 0.010466326028108597, 0.8607001304626465], [0.11282382905483246, 0.3458743691444397, 0.0814504474401474, 0.07759799063205719, 0.08560600131750107, 0.11402241140604019, 0.10046899318695068, 0.08215600252151489], [0.04868807643651962, 0.02670900523662567, 0.09160330891609192, 0.02968820556998253, 0.025803573429584503, 0.5686190128326416, 0.11745785921812057, 0.09143085032701492], [0.03175055980682373, 0.027990145608782768, 0.013317928649485111, 0.8325313925743103, 0.011151199229061604, 0.050997789949178696, 0.018496999517083168, 0.013763919472694397], [0.08689813315868378, 0.1538286954164505, 0.07249999046325684, 0.08512748777866364, 0.2715543508529663, 0.18654409050941467, 0.08051747828722, 0.06302981823682785], [0.07168255001306534, 0.02218780294060707, 0.031140003353357315, 0.04638856649398804, 0.022614674642682076, 0.6478307843208313, 0.029250305145978928, 0.12890535593032837], [0.05020177736878395, 0.027533795684576035, 0.0849190503358841, 0.034008607268333435, 0.028074482455849648, 0.6080073714256287, 0.07085362076759338, 0.09640135616064072], [0.10163801163434982, 0.08469211310148239, 0.030895262956619263, 0.1586379110813141, 0.054850462824106216, 0.07821355015039444, 0.022920724004507065, 0.46815189719200134]], [[0.1206345409154892, 0.07879675924777985, 0.05775400623679161, 0.14818106591701508, 0.05476881563663483, 0.09271449595689774, 0.07811647653579712, 0.3690338134765625], [0.11172175407409668, 0.7367271184921265, 0.005667654797434807, 0.015947047621011734, 0.04044328257441521, 0.017992829903960228, 0.010149202309548855, 0.06135107949376106], [0.0032172424253076315, 0.003084961324930191, 0.13508717715740204, 0.004572948440909386, 0.009971353225409985, 0.013347161002457142, 0.8187121152877808, 0.012007026933133602], [0.02940969541668892, 0.008233967237174511, 0.00320526584982872, 0.9084973931312561, 0.0014565306482836604, 0.0068294997327029705, 0.005420546513050795, 0.03694705665111542], [0.17426200211048126, 0.06351236253976822, 0.016434859484434128, 0.0067700534127652645, 0.4286414682865143, 0.03621549531817436, 0.0158087071031332, 0.2583550810813904], [0.08640388399362564, 0.00787245575338602, 0.019306622445583344, 0.018896859139204025, 0.008439583703875542, 0.7756121158599854, 0.011928964406251907, 0.07153958827257156], [0.004353116732090712, 0.007265493739396334, 0.7428044080734253, 0.012583031319081783, 0.007947330363094807, 0.0059435004368424416, 0.21394632756710052, 0.0051568238995969296], [0.4254843592643738, 0.10188346356153488, 0.039558738470077515, 0.1489831954240799, 0.03327791020274162, 0.07676193863153458, 0.013236467726528645, 0.16081389784812927]], [[0.7577022910118103, 0.015325352549552917, 0.0422976054251194, 0.023204103112220764, 0.016970431432127953, 0.016413597390055656, 0.035216331481933594, 0.09287011623382568], [0.010225605219602585, 0.07772418111562729, 0.14943188428878784, 0.07621122151613235, 0.18733562529087067, 0.23837481439113617, 0.16144797205924988, 0.09924869984388351], [0.10490033030509949, 0.04999538138508797, 0.028924409300088882, 0.056648775935173035, 0.04736774414777756, 0.12121973186731339, 0.03720111772418022, 0.553742527961731], [0.00395099027082324, 0.12540781497955322, 0.09602333605289459, 0.18643417954444885, 0.1690593808889389, 0.2335607409477234, 0.13733385503292084, 0.0482296496629715], [0.012024850584566593, 0.1668165922164917, 0.21052157878875732, 0.040826354175806046, 0.030015740543603897, 0.1534535437822342, 0.26806625723838806, 0.11827510595321655], [0.019895637407898903, 0.08929508924484253, 0.1458849161863327, 0.07957526296377182, 0.1356533318758011, 0.25124791264533997, 0.13983815908432007, 0.1386096328496933], [0.09570496529340744, 0.06420950591564178, 0.03970567509531975, 0.07052619755268097, 0.06202278658747673, 0.1358882635831833, 0.04344959929585457, 0.4884929955005646], [0.20170989632606506, 0.07049639523029327, 0.05832545831799507, 0.2050817459821701, 0.12242201715707779, 0.09737671911716461, 0.05922793224453926, 0.1853599101305008]], [[0.47134721279144287, 0.035104990005493164, 0.10972526669502258, 0.12242025136947632, 0.02998363971710205, 0.038672126829624176, 0.12249429523944855, 0.0702522024512291], [0.006798149552196264, 0.06942520290613174, 0.10122837871313095, 0.30507564544677734, 0.27176058292388916, 0.04662668704986572, 0.12209724634885788, 0.07698805630207062], [0.014498528093099594, 0.18418624997138977, 0.029602419584989548, 0.13087604939937592, 0.37408387660980225, 0.1890348345041275, 0.03676261752843857, 0.040955401957035065], [0.029406065121293068, 0.0718308538198471, 0.08112069964408875, 0.15324810147285461, 0.046834975481033325, 0.07996471226215363, 0.10982675105333328, 0.427767813205719], [0.007055839989334345, 0.23295801877975464, 0.08575888723134995, 0.23656678199768066, 0.08220486342906952, 0.2052188217639923, 0.09232737869024277, 0.05790933594107628], [0.017934957519173622, 0.2567504048347473, 0.11829658597707748, 0.09023672342300415, 0.2426222562789917, 0.06258274614810944, 0.14532645046710968, 0.06624992936849594], [0.009883584454655647, 0.2157512754201889, 0.025735918432474136, 0.13362380862236023, 0.3439098298549652, 0.20434099435806274, 0.030224692076444626, 0.03652988746762276], [0.18744561076164246, 0.057522594928741455, 0.03516869992017746, 0.1374415010213852, 0.03618650138378143, 0.0462883822619915, 0.04344644024968147, 0.45650023221969604]], [[0.8942770957946777, 0.009896082803606987, 0.005542676895856857, 0.0060235895216465, 0.02905900403857231, 0.010259916074573994, 0.004390742629766464, 0.04055095836520195], [0.020996950566768646, 0.06554192304611206, 0.14937041699886322, 0.06135530397295952, 0.3539215922355652, 0.07966604828834534, 0.126323401927948, 0.14282436668872833], [0.04967644438147545, 0.1887095719575882, 0.006725625600665808, 0.04451966658234596, 0.6060479879379272, 0.021812520921230316, 0.004949432332068682, 0.07755867391824722], [0.003219911828637123, 0.06664253026247025, 0.014448627829551697, 0.6837857365608215, 0.08562610298395157, 0.02917187660932541, 0.016713358461856842, 0.10039182752370834], [0.008593816310167313, 0.2810300588607788, 0.168934166431427, 0.11092272400856018, 0.06207966431975365, 0.03391663357615471, 0.1772753894329071, 0.1572476178407669], [0.002828266005963087, 0.025432495400309563, 0.0037990594282746315, 0.06518229842185974, 0.8416959047317505, 0.011276080273091793, 0.004874010570347309, 0.04491191729903221], [0.01543775387108326, 0.06494764983654022, 0.003198701422661543, 0.03384480997920036, 0.776537299156189, 0.026477152481675148, 0.004008834715932608, 0.07554765790700912], [0.035026777535676956, 0.15370765328407288, 0.008801005780696869, 0.2045493870973587, 0.4395006000995636, 0.06852395832538605, 0.010022198781371117, 0.07986850291490555]], [[0.42171287536621094, 0.03875601664185524, 0.043698500841856, 0.048433735966682434, 0.05885818973183632, 0.050756994634866714, 0.02628549560904503, 0.31149807572364807], [0.009404572658240795, 0.006425682455301285, 0.7700634002685547, 0.031769219785928726, 0.06801306456327438, 0.016837850213050842, 0.08076851069927216, 0.01671769469976425], [0.029085621237754822, 0.09933630377054214, 0.03618260845541954, 0.2512584328651428, 0.4865887463092804, 0.05260034278035164, 0.002963659120723605, 0.04198431223630905], [0.03440961614251137, 0.020100656896829605, 0.061726443469524384, 0.028047440573573112, 0.4599679112434387, 0.093656525015831, 0.1348918229341507, 0.16719965636730194], [0.0015403962461277843, 0.016711724922060966, 0.03553806245326996, 0.03070434369146824, 0.0859232097864151, 0.17160223424434662, 0.5519510507583618, 0.10602903366088867], [0.04711703583598137, 0.011188512668013573, 0.021322311833500862, 0.0023892875760793686, 0.027110321447253227, 0.012749813497066498, 0.6764894723892212, 0.2016332596540451], [0.011231622658669949, 0.019534384831786156, 0.0010225425940006971, 0.01836572028696537, 0.040591537952423096, 0.03431578725576401, 0.012959958985447884, 0.8619784712791443], [0.49713870882987976, 0.016321802511811256, 0.01081320084631443, 0.050838567316532135, 0.09228529036045074, 0.036229733377695084, 0.07743167132139206, 0.2189410775899887]], [[0.05272819101810455, 0.015783900395035744, 0.013865047134459019, 0.020464003086090088, 0.04532293230295181, 0.009132209233939648, 0.017565516754984856, 0.8251381516456604], [0.002139737131074071, 0.021385686472058296, 0.3235270380973816, 0.16609223186969757, 0.01425822265446186, 0.09160368144512177, 0.36745885014533997, 0.013534566387534142], [0.020569035783410072, 0.00600788090378046, 0.008501380681991577, 0.011467373929917812, 0.05493544042110443, 0.8546163439750671, 0.009534620679914951, 0.03436795249581337], [0.09872465580701828, 0.11508657038211823, 0.0741937980055809, 0.27946558594703674, 0.09253279864788055, 0.16041086614131927, 0.0786796510219574, 0.1009061336517334], [0.250691294670105, 0.05414477735757828, 0.05867752060294151, 0.03350270912051201, 0.21528807282447815, 0.27873659133911133, 0.0634666457772255, 0.04549238458275795], [0.09854541718959808, 0.026735765859484673, 0.06250122934579849, 0.14600180089473724, 0.26033011078834534, 0.21321840584278107, 0.06532472372055054, 0.1273425817489624], [0.018337642773985863, 0.00654919957742095, 0.008287215605378151, 0.013893510214984417, 0.05237918347120285, 0.8565787076950073, 0.008766092360019684, 0.03520835563540459], [0.05268581211566925, 0.08788977563381195, 0.013114131055772305, 0.3294703960418701, 0.08630944788455963, 0.04505159333348274, 0.018023407086730003, 0.36745545268058777]], [[0.29260575771331787, 0.09154874086380005, 0.03734234720468521, 0.19319400191307068, 0.05860329046845436, 0.04112362861633301, 0.029504599049687386, 0.25607767701148987], [0.05278302729129791, 0.09393826872110367, 0.08308645337820053, 0.07856923341751099, 0.17054963111877441, 0.3805864751338959, 0.13058936595916748, 0.009897500276565552], [0.01404661126434803, 0.15685653686523438, 0.015334276482462883, 0.014604093506932259, 0.30936142802238464, 0.44330039620399475, 0.024755528196692467, 0.021741211414337158], [0.659001886844635, 0.03429969772696495, 0.031217919662594795, 0.047064509242773056, 0.059166163206100464, 0.009948941878974438, 0.035038892179727554, 0.12426184117794037], [0.10737919807434082, 0.28597667813301086, 0.08430129289627075, 0.037537019699811935, 0.18300585448741913, 0.151278555393219, 0.10382933169603348, 0.046692006289958954], [0.022930895909667015, 0.33493754267692566, 0.10541751235723495, 0.011582932434976101, 0.1803947538137436, 0.10405189543962479, 0.15825387835502625, 0.08243061602115631], [0.016123933717608452, 0.19749979674816132, 0.016267213970422745, 0.01842876337468624, 0.24961325526237488, 0.45316293835639954, 0.02468664012849331, 0.024217549711465836], [0.2647956609725952, 0.05159040167927742, 0.028540244325995445, 0.17157228291034698, 0.0710943192243576, 0.027542050927877426, 0.031389180570840836, 0.3534758388996124]], [[0.31483194231987, 0.052349258214235306, 0.14906077086925507, 0.1213754341006279, 0.03193305432796478, 0.096764475107193, 0.16199181973934174, 0.07169324904680252], [0.04752199724316597, 0.2554153501987457, 0.08893968164920807, 0.05758949741721153, 0.17264984548091888, 0.2653430700302124, 0.08177944272756577, 0.030761076137423515], [0.00505095673725009, 0.30400949716567993, 0.030699923634529114, 0.0861530676484108, 0.07715601474046707, 0.44403406977653503, 0.03867726027965546, 0.014219232834875584], [0.44731709361076355, 0.1402100771665573, 0.019967304542660713, 0.14659519493579865, 0.0848962664604187, 0.03708021715283394, 0.019227491691708565, 0.10470626503229141], [0.019624121487140656, 0.17774663865566254, 0.13483655452728271, 0.10507044941186905, 0.18620792031288147, 0.17542269825935364, 0.16444887220859528, 0.03664278984069824], [0.10875245183706284, 0.16345961391925812, 0.03414337337017059, 0.1296858936548233, 0.37315136194229126, 0.06403370946645737, 0.036755286157131195, 0.0900183618068695], [0.00318325636908412, 0.35653212666511536, 0.02672324888408184, 0.0840984359383583, 0.08104889839887619, 0.4073435664176941, 0.03249230608344078, 0.008578204549849033], [0.8607511520385742, 0.024567101150751114, 0.0070968265645205975, 0.03966781497001648, 0.014702708460390568, 0.013121245428919792, 0.0063948906026780605, 0.03369820863008499]], [[0.9703182578086853, 0.0021002902649343014, 0.0018539230804890394, 0.00670267641544342, 0.006661528721451759, 0.004659128841012716, 0.0016359619330614805, 0.006068293005228043], [0.02706011012196541, 0.11130930483341217, 0.07061789184808731, 0.145772784948349, 0.17763298749923706, 0.21516115963459015, 0.0688634142279625, 0.1835823804140091], [0.00256175035610795, 0.08301801234483719, 0.01328063290566206, 0.26004815101623535, 0.023575423285365105, 0.5936261415481567, 0.016074631363153458, 0.007815255783498287], [0.4642695486545563, 0.046843044459819794, 0.0708102434873581, 0.020206548273563385, 0.016396356746554375, 0.061752721667289734, 0.09259387105703354, 0.22712768614292145], [0.03446163982152939, 0.1277792602777481, 0.07092101126909256, 0.2510322630405426, 0.10564415156841278, 0.21634332835674286, 0.0726432278752327, 0.12117503583431244], [0.06763479113578796, 0.1435547173023224, 0.09432581812143326, 0.21616363525390625, 0.15439167618751526, 0.17801471054553986, 0.0842912495136261, 0.06162343546748161], [0.0020440667867660522, 0.10513298213481903, 0.012893467210233212, 0.24563166499137878, 0.020653843879699707, 0.5921642780303955, 0.014499601908028126, 0.006980065256357193], [0.9370508790016174, 0.006072002463042736, 0.0014256502036005259, 0.010766706429421902, 0.009175198152661324, 0.01611444354057312, 0.0014679147861897945, 0.017927100881934166]], [[0.9433727264404297, 0.0020571460481733084, 0.003001623786985874, 0.006801769603043795, 0.006996781099587679, 0.001607094774954021, 0.0025984745007008314, 0.03356439620256424], [0.0474449098110199, 0.01151583343744278, 0.6942529082298279, 0.010227230377495289, 0.06550207734107971, 0.04148280620574951, 0.11841809749603271, 0.01115613803267479], [0.005398353096097708, 0.9290728569030762, 0.003448615549132228, 0.010666749440133572, 0.026407092809677124, 0.022784970700740814, 0.00036656323936767876, 0.0018547337967902422], [0.16396890580654144, 0.05180935189127922, 0.3693680763244629, 0.17079560458660126, 0.08731380850076675, 0.06638725101947784, 0.04838736727833748, 0.04196956008672714], [0.011876084841787815, 0.13767574727535248, 0.27895602583885193, 0.025973109528422356, 0.07745363563299179, 0.32983776926994324, 0.09953486919403076, 0.038692642003297806], [0.2168094366788864, 0.0071740229614079, 0.030327128246426582, 0.007211386691778898, 0.5666447877883911, 0.010117675177752972, 0.1118701696395874, 0.049845367670059204], [0.009053081274032593, 0.1500590741634369, 0.0002746123354882002, 0.01375899650156498, 0.13563573360443115, 0.6291595101356506, 0.009196602739393711, 0.052862342447042465], [0.9757063388824463, 5.398916619014926e-05, 8.936564699979499e-05, 0.0012246784754097462, 0.003424322698265314, 0.0021721746306866407, 0.0030006456654518843, 0.014328515157103539]]], [[[0.6463747024536133, 0.015984689816832542, 0.013849921524524689, 0.021047402173280716, 0.01964288204908371, 0.02096586488187313, 0.023477252572774887, 0.23865735530853271], [0.6503119468688965, 0.1523979753255844, 0.017982181161642075, 0.00995629746466875, 0.08424269407987595, 0.0061574699357151985, 0.02144056372344494, 0.0575108677148819], [0.018134133890271187, 0.010337969288229942, 0.12838980555534363, 0.0036229791585355997, 0.0026558039244264364, 0.004153591580688953, 0.8186590671539307, 0.01404664944857359], [0.48123449087142944, 0.012461498379707336, 0.038840699940919876, 0.37371042370796204, 0.01166674867272377, 0.006434858310967684, 0.052576251327991486, 0.023075062781572342], [0.2660391330718994, 0.06215012073516846, 0.01742531731724739, 0.00438943225890398, 0.48931992053985596, 0.11772681027650833, 0.01050359383225441, 0.03244568780064583], [0.10327248275279999, 0.00876823253929615, 0.007784364279359579, 0.004810729529708624, 0.017365949228405952, 0.8229702115058899, 0.006108491215854883, 0.02891954779624939], [0.05528882518410683, 0.020629918202757835, 0.652289628982544, 0.007362705189734697, 0.003696998581290245, 0.007419401314109564, 0.2394130676984787, 0.01389950793236494], [0.7424921989440918, 0.008563279174268246, 0.025619296357035637, 0.027382176369428635, 0.051012881100177765, 0.054540738463401794, 0.012546176090836525, 0.07784327864646912]], [[0.22654055058956146, 0.0963054895401001, 0.1730431765317917, 0.04842643439769745, 0.1443185955286026, 0.0711379200220108, 0.15479066967964172, 0.08543720841407776], [0.04746638983488083, 0.06877217441797256, 0.14928601682186127, 0.12896519899368286, 0.19716233015060425, 0.13579680025577545, 0.12017115205526352, 0.15238003432750702], [0.02888605371117592, 0.1560075879096985, 0.012637456879019737, 0.04547842592000961, 0.48954686522483826, 0.18005293607711792, 0.011390767060220242, 0.07599986344575882], [0.28194648027420044, 0.049538254737854004, 0.06262224167585373, 0.18321241438388824, 0.06748419255018234, 0.0408594086766243, 0.06437108665704727, 0.24996589124202728], [0.041627198457717896, 0.15454591810703278, 0.04136064276099205, 0.04874589294195175, 0.27811840176582336, 0.27706846594810486, 0.03421163558959961, 0.12432179600000381], [0.037660256028175354, 0.24833597242832184, 0.10310319066047668, 0.017617085948586464, 0.3764772415161133, 0.052805397659540176, 0.07788403332233429, 0.08611676841974258], [0.021535448729991913, 0.18237635493278503, 0.010878462344408035, 0.08700799942016602, 0.4022807776927948, 0.1912735551595688, 0.008005932904779911, 0.09664160758256912], [0.09130392968654633, 0.11782689392566681, 0.07085081189870834, 0.0751589983701706, 0.34618642926216125, 0.09958281368017197, 0.0632600486278534, 0.13583017885684967]], [[0.5115909576416016, 0.07468347996473312, 0.042368333786726, 0.07572736591100693, 0.1715310662984848, 0.04222807660698891, 0.02485048398375511, 0.05702020600438118], [0.2595946788787842, 0.07356332242488861, 0.28477099537849426, 0.02655605785548687, 0.1732032597064972, 0.10256747901439667, 0.00801482331007719, 0.07172936201095581], [0.03457588702440262, 0.10368933528661728, 0.004064579494297504, 0.021644694730639458, 0.8316331505775452, 0.0027678373735398054, 2.778341695375275e-05, 0.0015967590734362602], [0.852299690246582, 0.005905137397348881, 0.0071694375947117805, 0.05233130231499672, 0.03880264237523079, 0.01296300534158945, 0.0021456326358020306, 0.02838314324617386], [0.12494358420372009, 0.00875945296138525, 0.036229848861694336, 0.019153151661157608, 0.05839503929018974, 0.6138701438903809, 0.10511308908462524, 0.0335356742143631], [0.016652178019285202, 0.0011119056725874543, 0.000993717578239739, 0.0004838491149712354, 0.9386332035064697, 0.0009565797518007457, 0.028921877965331078, 0.01224667951464653], [0.03371454030275345, 0.02884453535079956, 8.040719694690779e-05, 0.0072661940939724445, 0.6611404418945312, 0.193736270070076, 0.002781073097139597, 0.0724366307258606], [0.3855246901512146, 0.05951862782239914, 0.007979311048984528, 0.016040757298469543, 0.09083730727434158, 0.05667491629719734, 0.07411535829305649, 0.3093090057373047]], [[0.061507824808359146, 0.004986283835023642, 0.009816857054829597, 0.07514869421720505, 0.014307225123047829, 0.009592472575604916, 0.008735141716897488, 0.8159054517745972], [0.6936283707618713, 0.0034856575075536966, 0.017981410026550293, 0.01926223747432232, 0.038159891963005066, 0.1278093010187149, 0.024989880621433258, 0.07468316704034805], [0.652849018573761, 0.028495971113443375, 0.0017546508461236954, 0.03165152296423912, 0.09031364321708679, 0.02440478280186653, 0.0024394532665610313, 0.16809092462062836], [0.6573171615600586, 0.01937190629541874, 0.030498238280415535, 0.003067685291171074, 0.12997685372829437, 0.06937044858932495, 0.03320953622460365, 0.0571882463991642], [0.5022286176681519, 0.02390853688120842, 0.047651257365942, 0.06722987443208694, 0.026876086369156837, 0.05948801711201668, 0.05216461420059204, 0.22045299410820007], [0.4551982283592224, 0.12741941213607788, 0.009735074825584888, 0.04626713693141937, 0.17061921954154968, 0.011488097719848156, 0.011208719573915005, 0.16806408762931824], [0.6686170101165771, 0.0323091484606266, 0.002050392096862197, 0.031197700649499893, 0.07351170480251312, 0.023515067994594574, 0.002725988393649459, 0.16607296466827393], [0.027827898040413857, 0.006076654884964228, 0.02478516846895218, 0.05346723645925522, 0.04188399016857147, 0.013200240209698677, 0.025900790467858315, 0.8068580031394958]], [[0.37314048409461975, 0.021659530699253082, 0.0068834396079182625, 0.012100204825401306, 0.015690261498093605, 0.0117213549092412, 0.006088954862207174, 0.5527158379554749], [0.17211830615997314, 0.10364583134651184, 0.1301177591085434, 0.018486587330698967, 0.16217869520187378, 0.2301998883485794, 0.11315572261810303, 0.0700971931219101], [0.127826526761055, 0.22351288795471191, 0.011492833495140076, 0.02002270705997944, 0.27154844999313354, 0.2418150007724762, 0.014552944339811802, 0.08922874927520752], [0.06043564900755882, 0.2236536145210266, 0.014078116975724697, 0.4781205654144287, 0.147333562374115, 0.03151123970746994, 0.02375037595629692, 0.021116793155670166], [0.30136212706565857, 0.23937353491783142, 0.026709187775850296, 0.009023210033774376, 0.1032920554280281, 0.08444643765687943, 0.019722646102309227, 0.21607083082199097], [0.3582819402217865, 0.23183543980121613, 0.016988638788461685, 0.009715518914163113, 0.18971988558769226, 0.061987318098545074, 0.016949601471424103, 0.11452160775661469], [0.17772692441940308, 0.29963552951812744, 0.009281638078391552, 0.024924851953983307, 0.2214791178703308, 0.16478899121284485, 0.007413079962134361, 0.09474991261959076], [0.4654928147792816, 0.008104012347757816, 0.004996109288185835, 0.005109735298901796, 0.0022489074617624283, 0.005616891197860241, 0.005293205380439758, 0.5031382441520691]], [[0.32516294717788696, 0.05195345729589462, 0.05868571251630783, 0.09858476370573044, 0.018880117684602737, 0.035638418048620224, 0.06707505136728287, 0.34401947259902954], [0.34796974062919617, 0.0205382090061903, 0.03472105413675308, 0.01129847951233387, 0.2005143165588379, 0.0325164794921875, 0.041761964559555054, 0.31067976355552673], [0.4990384578704834, 0.052962224930524826, 0.01959570124745369, 0.006823993753641844, 0.13235898315906525, 0.058755598962306976, 0.02537553198635578, 0.20508944988250732], [0.16853070259094238, 0.07116549462080002, 0.010323697701096535, 0.641282320022583, 0.04777121916413307, 0.018559755757451057, 0.017880234867334366, 0.024486495181918144], [0.32847610116004944, 0.13795273005962372, 0.0429055280983448, 0.017877832055091858, 0.020245159044861794, 0.06881272047758102, 0.03249341994524002, 0.3512364625930786], [0.6089703440666199, 0.08981002867221832, 0.06743787974119186, 0.021137459203600883, 0.06924913823604584, 0.013632402755320072, 0.046718910336494446, 0.08304383605718613], [0.5474951267242432, 0.0640471950173378, 0.02393644116818905, 0.012628615833818913, 0.15073655545711517, 0.04183092340826988, 0.014984801411628723, 0.144340381026268], [0.22702613472938538, 0.1166316568851471, 0.12158145755529404, 0.059729959815740585, 0.07013487070798874, 0.06855633854866028, 0.08453648537397385, 0.25180312991142273]], [[0.23177692294120789, 0.07106755673885345, 0.09083788841962814, 0.052608612924814224, 0.11866630613803864, 0.08092959970235825, 0.10823573917150497, 0.2458774298429489], [0.05008746311068535, 0.9071791768074036, 0.011075121350586414, 0.0033851657062768936, 0.0013047298416495323, 0.0023669209331274033, 0.00799394492059946, 0.0166074950248003], [0.011280752718448639, 0.012810920365154743, 0.6478146314620972, 0.0001252702932106331, 0.0005299689364619553, 0.0030737051274627447, 0.320393443107605, 0.00397133082151413], [0.013934544287621975, 0.0008706855587661266, 2.196325294789858e-05, 0.9825156927108765, 0.00019722621073015034, 0.00025616338825784624, 1.3778138054476585e-05, 0.0021899191197007895], [0.04946361854672432, 0.012715776450932026, 0.004179408773779869, 0.0020629235077649355, 0.9165554642677307, 0.004639063961803913, 0.0010368094081059098, 0.009347072802484035], [0.024397682398557663, 0.016373269259929657, 0.021411115303635597, 0.006017624866217375, 0.013227240182459354, 0.9061394929885864, 0.005666240584105253, 0.0067673493176698685], [0.004556960891932249, 0.007396268658339977, 0.8303858041763306, 7.510435534641147e-05, 0.00040022245957516134, 0.002635061042383313, 0.15173038840293884, 0.0028200848028063774], [0.15955699980258942, 0.164989173412323, 0.18811315298080444, 0.06665091961622238, 0.11844762414693832, 0.06048513948917389, 0.0741359293460846, 0.16762112081050873]], [[0.23096993565559387, 0.022094199433922768, 0.006907739210873842, 0.03260308876633644, 0.07543440908193588, 0.02995281293988228, 0.008113711141049862, 0.5939241051673889], [0.014215970411896706, 0.09941413998603821, 0.3274126648902893, 0.05224282294511795, 0.12152573466300964, 0.21468064188957214, 0.16576091945171356, 0.004747138824313879], [0.01653105393052101, 0.1571933478116989, 0.00286175892688334, 0.016035500913858414, 0.18120470643043518, 0.6183955669403076, 0.0031689018942415714, 0.004609070252627134], [0.06494282931089401, 0.013422232121229172, 0.004351973067969084, 0.8438374996185303, 0.0021331198513507843, 0.01371854729950428, 0.0028363356832414865, 0.054757505655288696], [0.015980403870344162, 0.39125362038612366, 0.029664665460586548, 0.029971089214086533, 0.3427659869194031, 0.15237721800804138, 0.019196579232811928, 0.018790477886795998], [0.006722535938024521, 0.010192631743848324, 0.0025560923386365175, 0.0029197814874351025, 0.9604284763336182, 0.007977462373673916, 0.0025294520892202854, 0.006673522759228945], [0.016234813258051872, 0.0708569884300232, 0.0022277962416410446, 0.023645849898457527, 0.13088080286979675, 0.7500472068786621, 0.0024812319315969944, 0.0036254313308745623], [0.04695603996515274, 0.02222830429673195, 0.002104147570207715, 0.007211680058389902, 0.02083907090127468, 0.0069567118771374226, 0.0024497213307768106, 0.8912543654441833]], [[0.37432634830474854, 0.12012062966823578, 0.11431621760129929, 0.26436567306518555, 0.05188949406147003, 0.02554706484079361, 0.024243298918008804, 0.02519121952354908], [0.4708598256111145, 0.3073054552078247, 0.019229386001825333, 0.0013174260966479778, 0.0019605588167905807, 0.0097580561414361, 0.0612870454788208, 0.12828221917152405], [0.08721638470888138, 0.8477073311805725, 0.0060676634311676025, 0.026804091408848763, 0.0022430988028645515, 0.0007727952906861901, 4.2524316086201e-06, 0.02918442338705063], [0.5687860250473022, 0.03031921572983265, 0.18561358749866486, 0.21049439907073975, 0.000536516250576824, 2.0967812815797515e-05, 0.0001274324458790943, 0.004101915750652552], [0.4388923943042755, 0.0056887720711529255, 0.021345390006899834, 0.43549060821533203, 0.09328281879425049, 0.0050484295934438705, 3.957430453738198e-05, 0.00021211974672041833], [4.44415672973264e-05, 2.5544872528371343e-07, 1.8009177438216284e-07, 3.42858511430677e-05, 0.999894380569458, 2.436284012219403e-05, 1.754192908265395e-06, 3.0385115223907633e-07], [0.0023087160661816597, 2.7358006263966672e-05, 3.23849569383583e-09, 0.00010809687955770642, 0.08591807633638382, 0.9109966158866882, 0.0001854546571848914, 0.00045567337656393647], [0.06220272555947304, 0.012949603609740734, 4.074903699802235e-05, 0.0007212741766124964, 0.0021399555262178183, 0.08636347204446793, 0.7385498881340027, 0.097032330930233]], [[0.5705273747444153, 0.09941532462835312, 0.026664312928915024, 0.07433290034532547, 0.05465018004179001, 0.032215919345617294, 0.023897111415863037, 0.11829690635204315], [0.18915246427059174, 0.14583230018615723, 0.060214024037122726, 0.055503640323877335, 0.207358255982399, 0.17269711196422577, 0.06488457322120667, 0.10435760021209717], [0.2948305010795593, 0.37612441182136536, 0.04532751813530922, 0.07229488343000412, 0.0670148953795433, 0.04879501089453697, 0.01161283627152443, 0.08400004357099533], [0.7285773158073425, 0.12414674460887909, 0.02443859912455082, 0.0292475838214159, 0.05259259045124054, 0.014122744090855122, 0.008368856273591518, 0.01850569248199463], [0.03883694112300873, 0.3613016903400421, 0.282673716545105, 0.08470508456230164, 0.08593498915433884, 0.07198580354452133, 0.03749614208936691, 0.037065643817186356], [0.0626014992594719, 0.24943587183952332, 0.10349496454000473, 0.14208057522773743, 0.3482964336872101, 0.03714170679450035, 0.013220871798694134, 0.04372808709740639], [0.04197202995419502, 0.11452856659889221, 0.03591115027666092, 0.1490740329027176, 0.4492402672767639, 0.1696920543909073, 0.013575269840657711, 0.02600664086639881], [0.104124516248703, 0.11107372492551804, 0.034636568278074265, 0.09604281932115555, 0.2707063555717468, 0.25232425332069397, 0.0767633393406868, 0.05432842671871185]], [[0.49281075596809387, 0.06777603179216385, 0.0320909209549427, 0.12199041247367859, 0.08602488040924072, 0.08306851983070374, 0.0380973182618618, 0.07814112305641174], [0.5045677423477173, 0.0019958235789090395, 0.008274255320429802, 0.047509972006082535, 0.15707597136497498, 0.019866054877638817, 0.010953059419989586, 0.24975717067718506], [0.34259089827537537, 0.010424750857055187, 0.005044217687100172, 0.06250599026679993, 0.10652288794517517, 0.041327252984046936, 0.005944816395640373, 0.42563921213150024], [0.46543341875076294, 0.014330855570733547, 0.046955760568380356, 0.002964757615700364, 0.12457997351884842, 0.1701129823923111, 0.062043461948633194, 0.11357877403497696], [0.3824474513530731, 0.16160273551940918, 0.07174894213676453, 0.046838246285915375, 0.004863458685576916, 0.04397314041852951, 0.07420314848423004, 0.21432289481163025], [0.27989956736564636, 0.04224467650055885, 0.006375844124704599, 0.3161732256412506, 0.05011150613427162, 0.0013874198775738478, 0.0052262842655181885, 0.29858145117759705], [0.3836717903614044, 0.010954215191304684, 0.0037486751098185778, 0.09446178376674652, 0.16251733899116516, 0.035259347409009933, 0.0045150709338486195, 0.30487173795700073], [0.25542524456977844, 0.07928185909986496, 0.06753561645746231, 0.23199768364429474, 0.06726896017789841, 0.09417888522148132, 0.06296490132808685, 0.14134684205055237]], [[0.5101070404052734, 0.04607206955552101, 0.008715823292732239, 0.018747428432106972, 0.06038355827331543, 0.023051660507917404, 0.008998927660286427, 0.32392340898513794], [0.05794176086783409, 0.06309250742197037, 0.01299362163990736, 0.017333222553133965, 0.6477261781692505, 0.14451074600219727, 0.020874924957752228, 0.03552701324224472], [0.0178472138941288, 0.1535504311323166, 0.0006408945773728192, 0.0031119436025619507, 0.7169285416603088, 0.09466126561164856, 0.0010667629539966583, 0.01219285186380148], [0.3327995240688324, 0.1992001235485077, 0.028376717120409012, 0.09949552267789841, 0.06920640170574188, 0.1076567992568016, 0.027799559757113457, 0.13546539843082428], [0.050820473581552505, 0.08555430918931961, 0.0038811052218079567, 0.008250550366938114, 0.6641672849655151, 0.061256103217601776, 0.007462869863957167, 0.1186072900891304], [0.0445331409573555, 0.06386175006628036, 0.0013895010342821479, 0.0012612753780558705, 0.8568770885467529, 0.006407692097127438, 0.002574256854131818, 0.02309529297053814], [0.01671077311038971, 0.1453532725572586, 0.0004975610645487905, 0.002941465936601162, 0.7179335951805115, 0.09635534882545471, 0.0008506744052283466, 0.019357332959771156], [0.39538097381591797, 0.03193436935544014, 0.00903250277042389, 0.010311814025044441, 0.10750748217105865, 0.024123361334204674, 0.012732558883726597, 0.4089770019054413]]], [[[0.5196425318717957, 0.01138569787144661, 0.003245145082473755, 0.02928265929222107, 0.005563313607126474, 0.00434377184137702, 0.0029544986318796873, 0.42358237504959106], [0.203314870595932, 0.6233835220336914, 0.02318795584142208, 0.004530611913651228, 0.013668619096279144, 0.028320422396063805, 0.011793406680226326, 0.09180064499378204], [0.011698299087584019, 0.9470238089561462, 0.006001747213304043, 0.004693630151450634, 0.004846682772040367, 0.016546104103326797, 0.0033589990343898535, 0.0058306059800088406], [0.40242820978164673, 0.1157413199543953, 0.031200749799609184, 0.20765237510204315, 0.0035143315326422453, 0.025653427466750145, 0.02148706465959549, 0.19232256710529327], [0.4345463514328003, 0.20750391483306885, 0.022308005020022392, 0.0017538758693262935, 0.03291594609618187, 0.047833409160375595, 0.013241465203464031, 0.23989702761173248], [0.3750551640987396, 0.13136176764965057, 0.023505035787820816, 0.0009256611228920519, 0.03285611793398857, 0.02935982495546341, 0.022045068442821503, 0.3848913311958313], [0.005207605194300413, 0.9607976675033569, 0.00593813881278038, 0.002331298543140292, 0.0039303782396018505, 0.014877952635288239, 0.0034472665283828974, 0.0034696648363023996], [0.5324410796165466, 0.006187204271554947, 0.004935906268656254, 0.016793305054306984, 0.0044795856811106205, 0.004639124032109976, 0.0034595488104969263, 0.4270643889904022]], [[0.3494865596294403, 0.04159921035170555, 0.040438879281282425, 0.05315172299742699, 0.0825556293129921, 0.036677684634923935, 0.041582562029361725, 0.3545078933238983], [0.16878536343574524, 0.07989595830440521, 0.11918269842863083, 0.0015622383216395974, 0.43921199440956116, 0.04291420802474022, 0.07624074816703796, 0.0722067579627037], [0.23556040227413177, 0.07412397116422653, 0.05673488974571228, 0.009733881801366806, 0.4511459171772003, 0.04229385033249855, 0.049257613718509674, 0.08114947378635406], [0.2850003242492676, 0.060983553528785706, 0.08015524595975876, 0.08638075739145279, 0.07489130645990372, 0.013675021938979626, 0.07393232733011246, 0.3249814510345459], [0.2413238286972046, 0.1047351062297821, 0.09992577880620956, 0.0023500046227127314, 0.3550298511981964, 0.03516245633363724, 0.06756436824798584, 0.09390858560800552], [0.5291825532913208, 0.02519182115793228, 0.024668028578162193, 0.007743256166577339, 0.14212723076343536, 0.03516913950443268, 0.01693633571267128, 0.2189815491437912], [0.21679532527923584, 0.05152006074786186, 0.0411435030400753, 0.009675621055066586, 0.4933089315891266, 0.051493365317583084, 0.044806741178035736, 0.09125638753175735], [0.7164539098739624, 0.026473060250282288, 0.01779986172914505, 0.026522299274802208, 0.03836076334118843, 0.05046295374631882, 0.018555762246251106, 0.10537140816450119]], [[0.2560795843601227, 0.09779997169971466, 0.08347774296998978, 0.04442361369729042, 0.1362779438495636, 0.06054935231804848, 0.07553161680698395, 0.24586012959480286], [0.23759257793426514, 0.000580218737013638, 0.0012038463028147817, 5.0108217692468315e-05, 0.0031317383982241154, 0.0012855062959715724, 0.0015591956907883286, 0.7545968294143677], [0.2669764459133148, 0.008842840790748596, 0.00457348907366395, 0.0015042121522128582, 0.024521201848983765, 0.00845293514430523, 0.00521265110000968, 0.679916262626648], [0.3593103885650635, 0.00023839778441470116, 0.0002929760084953159, 0.0005105437594465911, 0.001451803371310234, 0.0011992614017799497, 0.0006853505037724972, 0.6363112926483154], [0.22500811517238617, 0.003045446937903762, 0.0036691511049866676, 0.00028488290263339877, 0.008593457750976086, 0.003370349993929267, 0.0026306514628231525, 0.7533978819847107], [0.2690473794937134, 0.0006262868409976363, 0.00046101651969365776, 4.8805606638779864e-05, 0.002965083345770836, 0.0007183088455349207, 0.0004571162280626595, 0.7256759405136108], [0.347226619720459, 0.006903868168592453, 0.003493234049528837, 0.001331438310444355, 0.018428610637784004, 0.008616299368441105, 0.00258346414193511, 0.6114164590835571], [0.3682744801044464, 0.04437039792537689, 0.07374053448438644, 0.04669110104441643, 0.13634629547595978, 0.030375750735402107, 0.049248456954956055, 0.25095292925834656]], [[0.10355254262685776, 0.12388528138399124, 0.10961143672466278, 0.1265053153038025, 0.20479044318199158, 0.10564877837896347, 0.07099638134241104, 0.15500982105731964], [0.1912764310836792, 0.12796908617019653, 0.13806062936782837, 0.08882609754800797, 0.1465805321931839, 0.09980557858943939, 0.10303863883018494, 0.10444293916225433], [0.11942638456821442, 0.2193172723054886, 0.08375659584999084, 0.23122601211071014, 0.12991541624069214, 0.07538841664791107, 0.08960402011871338, 0.05136581510305405], [0.07830522954463959, 0.045927807688713074, 0.09736242890357971, 0.2761763334274292, 0.17341436445713043, 0.1709659844636917, 0.08440594375133514, 0.0734419897198677], [0.0642535611987114, 0.1536492556333542, 0.15784962475299835, 0.2434677630662918, 0.07275507599115372, 0.12476792186498642, 0.14667168259620667, 0.03658512979745865], [0.0873662680387497, 0.18265801668167114, 0.16615046560764313, 0.15363696217536926, 0.1537259966135025, 0.08244524896144867, 0.13540111482143402, 0.038615912199020386], [0.10562475025653839, 0.14184676110744476, 0.08366267383098602, 0.342235803604126, 0.1165543794631958, 0.06708376854658127, 0.09426809102296829, 0.04872376099228859], [0.19978567957878113, 0.10382338613271713, 0.09856998175382614, 0.06089109182357788, 0.13884961605072021, 0.12586206197738647, 0.05005091056227684, 0.22216717898845673]], [[0.29180169105529785, 0.0591089092195034, 0.025485491380095482, 0.07145343720912933, 0.026209216564893723, 0.07782501727342606, 0.04143137112259865, 0.40668490529060364], [0.11158925294876099, 0.6429012417793274, 0.008890517055988312, 0.0013016427401453257, 0.0006347691523842514, 0.007795777637511492, 0.00694163516163826, 0.21994519233703613], [0.029129520058631897, 0.006361203733831644, 0.17398834228515625, 0.0006594877340830863, 0.0010487991385161877, 0.00295412284322083, 0.7501970529556274, 0.03566153347492218], [0.008640546351671219, 4.74070075142663e-05, 2.66766164713772e-05, 0.9786419868469238, 6.703981489408761e-05, 0.00033242374774999917, 2.6797351893037558e-05, 0.012217086739838123], [0.2662560045719147, 0.0014371915021911263, 0.001877296599559486, 0.003031244035810232, 0.3673425614833832, 0.027847111225128174, 0.0009084941702894866, 0.33130013942718506], [0.1901874542236328, 0.005040443502366543, 0.0033200986217707396, 0.004717221483588219, 0.017999177798628807, 0.5889667868614197, 0.0012773032067343593, 0.18849146366119385], [0.03709268942475319, 0.011007944121956825, 0.8450267910957336, 0.0010429957183077931, 0.0009145983494818211, 0.001971675083041191, 0.08795955777168274, 0.014983708038926125], [0.4064842760562897, 0.04132836312055588, 0.026201331987977028, 0.0641905814409256, 0.02021893300116062, 0.04889436066150665, 0.013169857673346996, 0.3795122504234314]], [[0.050620388239622116, 0.11911308020353317, 0.12330275774002075, 0.22043251991271973, 0.1287059634923935, 0.12507426738739014, 0.1428094208240509, 0.08994166553020477], [0.021595457568764687, 0.6676000356674194, 0.09079601615667343, 0.04573917016386986, 0.021805107593536377, 0.03152820095419884, 0.09013108909130096, 0.030804935842752457], [0.00033206024090759456, 0.002448219573125243, 0.320136159658432, 4.8422993131680414e-05, 0.0027510218787938356, 0.010195239447057247, 0.6633445024490356, 0.0007444250513799489], [0.001045730896294117, 0.0006539783789776266, 2.5031424229382537e-05, 0.9949718713760376, 1.2653193152800668e-05, 4.498447378864512e-05, 2.583549212431535e-05, 0.0032199095003306866], [0.006817441899329424, 0.0037793279625475407, 0.03802042454481125, 0.0007317200652323663, 0.8240209221839905, 0.06226484104990959, 0.0509178563952446, 0.013447563163936138], [0.003175186924636364, 0.0067818863317370415, 0.06607306748628616, 0.0013993018073961139, 0.05187925323843956, 0.7497026920318604, 0.1171937882900238, 0.0037947942037135363], [0.000356605916749686, 0.00292345997877419, 0.4265701472759247, 5.944446456851438e-05, 0.0028959098272025585, 0.013940851204097271, 0.5525378584861755, 0.0007157087093219161], [0.08361717313528061, 0.16605955362319946, 0.11804387718439102, 0.21081297099590302, 0.07463439553976059, 0.09056703746318817, 0.13192136585712433, 0.12434370815753937]], [[0.26628196239471436, 0.11264508962631226, 0.06975775212049484, 0.07298874109983444, 0.1774655133485794, 0.09463614225387573, 0.07368424534797668, 0.13254055380821228], [0.2147480696439743, 0.10667271912097931, 0.274047315120697, 0.012847548350691795, 0.09800393879413605, 0.08140179514884949, 0.167030930519104, 0.04524771496653557], [0.2534951865673065, 0.08841413259506226, 0.03794461861252785, 0.05564458295702934, 0.3036384582519531, 0.09028732776641846, 0.03274466097354889, 0.13783100247383118], [0.6473450064659119, 0.020831244066357613, 0.009059889242053032, 0.12418235838413239, 0.02713010460138321, 0.014765151776373386, 0.022237028926610947, 0.13444925844669342], [0.07942035049200058, 0.09416671842336655, 0.03843800351023674, 0.00199121399782598, 0.04561898112297058, 0.43377581238746643, 0.28018948435783386, 0.026399459689855576], [0.14524485170841217, 0.2324141561985016, 0.07769623398780823, 0.003657365683466196, 0.07677823305130005, 0.08413361012935638, 0.34140047430992126, 0.03867499902844429], [0.3094787299633026, 0.06525856256484985, 0.013340619392693043, 0.039336416870355606, 0.14791470766067505, 0.11296460032463074, 0.06663388758897781, 0.24507245421409607], [0.2155054658651352, 0.10222671180963516, 0.08376257121562958, 0.0826445147395134, 0.18846452236175537, 0.05776534602046013, 0.09956230968236923, 0.17006856203079224]], [[0.2226928472518921, 0.12133507430553436, 0.06570715457201004, 0.3576356768608093, 0.03725689649581909, 0.027359597384929657, 0.06351664662361145, 0.1044960469007492], [0.19675306975841522, 0.2645280063152313, 0.11124969273805618, 0.05952325835824013, 0.11188884824514389, 0.10376156121492386, 0.06417158991098404, 0.08812404423952103], [0.09769613295793533, 0.6783900856971741, 0.019683316349983215, 0.01996757462620735, 0.06249760463833809, 0.0375230610370636, 0.01085041556507349, 0.07339189946651459], [0.000997378840111196, 1.2709959264611825e-05, 1.2241048352734651e-05, 0.9973466396331787, 3.41159466188401e-05, 3.8847396353958175e-05, 3.283859768998809e-05, 0.0015251269796863198], [0.29806241393089294, 0.0950760766863823, 0.01787104271352291, 0.0381411537528038, 0.271556556224823, 0.14041677117347717, 0.015661990270018578, 0.12321391701698303], [0.2769582271575928, 0.07864725589752197, 0.06758362054824829, 0.029800016433000565, 0.18363872170448303, 0.15559260547161102, 0.05781567469239235, 0.149963840842247], [0.11495951563119888, 0.5572694540023804, 0.03356575965881348, 0.025764191523194313, 0.08688468486070633, 0.0651988834142685, 0.02537304162979126, 0.0909845381975174], [0.23288846015930176, 0.044576022773981094, 0.016984563320875168, 0.5635581016540527, 0.010411752387881279, 0.010220111347734928, 0.01796325109899044, 0.10339774191379547]], [[0.3317427635192871, 0.07053609192371368, 0.04861629754304886, 0.11069820076227188, 0.0741690918803215, 0.10263148695230484, 0.05787433311343193, 0.2037317454814911], [0.4211222231388092, 0.010286745615303516, 0.03275614604353905, 0.03483392670750618, 0.13295559585094452, 0.13907895982265472, 0.033565811812877655, 0.1954006552696228], [0.45389923453330994, 0.0202352162450552, 0.0017944795545190573, 0.20991204679012299, 0.0717584639787674, 0.050260331481695175, 0.002101341262459755, 0.19003888964653015], [0.3036538362503052, 0.01774531602859497, 0.07321341335773468, 0.14325478672981262, 0.09055747091770172, 0.1620083749294281, 0.12069421261548996, 0.08887264132499695], [0.34592682123184204, 0.21887823939323425, 0.0468854196369648, 0.2159809172153473, 0.01076820120215416, 0.031304143369197845, 0.04159217327833176, 0.08866407722234726], [0.44147995114326477, 0.1277870237827301, 0.03913760185241699, 0.1965000480413437, 0.03174512833356857, 0.030047236010432243, 0.0395045131444931, 0.09379841387271881], [0.44428926706314087, 0.024074940010905266, 0.0018828004831448197, 0.3357801139354706, 0.08223600685596466, 0.04151713475584984, 0.0019489011028781533, 0.06827079504728317], [0.2619381248950958, 0.08662679046392441, 0.07271482795476913, 0.046930864453315735, 0.06032596901059151, 0.10792206972837448, 0.07936929911375046, 0.28417202830314636]], [[0.17036905884742737, 0.09374919533729553, 0.056285008788108826, 0.07880574464797974, 0.11792739480733871, 0.03320392221212387, 0.04921203479170799, 0.40044766664505005], [0.23079784214496613, 0.10086973011493683, 0.045393045991659164, 0.07953751087188721, 0.20811469852924347, 0.12353647500276566, 0.0502031072974205, 0.16154757142066956], [0.11766994744539261, 0.14583642780780792, 0.027642441913485527, 0.15445421636104584, 0.29655829071998596, 0.09770254790782928, 0.03711467608809471, 0.1230214312672615], [0.4688645601272583, 0.019385332241654396, 0.009252750314772129, 0.009190435521304607, 0.08619748800992966, 0.0785895586013794, 0.017971647903323174, 0.31054824590682983], [0.23604696989059448, 0.12220938503742218, 0.05268334597349167, 0.1532713621854782, 0.10156470537185669, 0.0655030757188797, 0.04173590987920761, 0.22698521614074707], [0.35775813460350037, 0.11568240076303482, 0.03710141032934189, 0.11355770379304886, 0.08414788544178009, 0.032787907868623734, 0.05120260268449783, 0.2077620029449463], [0.14463065564632416, 0.09246806055307388, 0.025685016065835953, 0.1874459981918335, 0.2766963839530945, 0.10948389768600464, 0.04394901916384697, 0.11964094638824463], [0.18020395934581757, 0.06629716604948044, 0.06115063279867172, 0.1312057077884674, 0.1254177838563919, 0.031851641833782196, 0.06378261744976044, 0.34009048342704773]], [[0.336747407913208, 0.06747261434793472, 0.04586166515946388, 0.04922793433070183, 0.15118440985679626, 0.10690439492464066, 0.03903232514858246, 0.20356929302215576], [0.010306148789823055, 0.7482750415802002, 0.062351495027542114, 0.0009479798609390855, 0.08355914801359177, 0.04582035541534424, 0.04491924121975899, 0.0038206465542316437], [0.033293526619672775, 0.6218602657318115, 0.031211521476507187, 0.0013937478652223945, 0.040449436753988266, 0.22143429517745972, 0.031995147466659546, 0.01836211048066616], [0.03938399627804756, 0.005099129863083363, 0.0007541029481217265, 0.9117987751960754, 0.0009483787580393255, 0.0026104592252522707, 0.0006884734611958265, 0.038716740906238556], [0.011509529314935207, 0.3493000566959381, 0.08537448197603226, 9.623405640013516e-05, 0.2656245231628418, 0.2514829635620117, 0.03090091235935688, 0.0057112304493784904], [0.028588294982910156, 0.4989347457885742, 0.08468275517225266, 0.0013154929038137197, 0.09597647935152054, 0.22805990278720856, 0.03937738016247749, 0.023065052926540375], [0.03964404761791229, 0.5695553421974182, 0.04802042990922928, 0.0018340471433475614, 0.05632602795958519, 0.2408268302679062, 0.02512924000620842, 0.018664121627807617], [0.43051114678382874, 0.04699878767132759, 0.04876933619379997, 0.08530368655920029, 0.08169656246900558, 0.08239924907684326, 0.035054389387369156, 0.18926678597927094]], [[0.10542326420545578, 0.1266256868839264, 0.10753358155488968, 0.19754943251609802, 0.08219078183174133, 0.15605735778808594, 0.142562136054039, 0.08205784112215042], [0.2635948657989502, 0.008173267357051373, 0.016553740948438644, 0.38369637727737427, 0.012388985604047775, 0.03136269375681877, 0.016881359741091728, 0.26734867691993713], [0.27557966113090515, 0.00711330771446228, 0.002657907083630562, 0.1606028825044632, 0.003814391791820526, 0.010721978731453419, 0.0031245690770447254, 0.5363853573799133], [0.19746020436286926, 0.09129729866981506, 0.06482209265232086, 0.2942626476287842, 0.03547756373882294, 0.06706167757511139, 0.07449784129858017, 0.17512069642543793], [0.2839234173297882, 0.06356432288885117, 0.030923238024115562, 0.22195695340633392, 0.0019394410774111748, 0.009605353698134422, 0.02105684205889702, 0.36703041195869446], [0.24098718166351318, 0.03124634176492691, 0.031069030985236168, 0.44642144441604614, 0.007903465069830418, 0.01133026834577322, 0.032777152955532074, 0.19826513528823853], [0.310398668050766, 0.007495925296097994, 0.0038398189935833216, 0.21262258291244507, 0.004803483374416828, 0.011717344634234905, 0.003608495695516467, 0.4455137252807617], [0.13234823942184448, 0.1558704525232315, 0.17771215736865997, 0.04767831414937973, 0.08120401948690414, 0.05962223932147026, 0.12556971609592438, 0.21999485790729523]]], [[[0.2607910931110382, 0.11253522336483002, 0.03295978158712387, 0.06016317009925842, 0.1524016559123993, 0.07244621962308884, 0.06901108473539352, 0.239691823720932], [0.1305890679359436, 0.27400290966033936, 0.024025918915867805, 0.0035065393894910812, 0.11734426021575928, 0.23014967143535614, 0.08000858873128891, 0.14037299156188965], [0.188144713640213, 0.06785055249929428, 0.04144931957125664, 0.008938535116612911, 0.1337752342224121, 0.1475876420736313, 0.23084217309951782, 0.18141184747219086], [0.1223558858036995, 0.005512073636054993, 0.001385029754601419, 0.6714786291122437, 0.004063135478645563, 0.0015673001762479544, 0.0035549141466617584, 0.19008295238018036], [0.21316000819206238, 0.04453202337026596, 0.006904024630784988, 0.0032217861153185368, 0.19554318487644196, 0.18842177093029022, 0.028555843979120255, 0.31966134905815125], [0.21943530440330505, 0.02099754847586155, 0.005595266353338957, 0.0005614268011413515, 0.04761456325650215, 0.54474937915802, 0.012526767328381538, 0.14851976931095123], [0.45414969325065613, 0.09039794653654099, 0.09972301870584488, 0.009511352516710758, 0.050941601395606995, 0.07905787974596024, 0.07380447536706924, 0.14241407811641693], [0.4113128185272217, 0.055123377591371536, 0.02839682623744011, 0.06644763797521591, 0.07164153456687927, 0.024901648983359337, 0.0304561760276556, 0.31171995401382446]], [[0.210384339094162, 0.08349688351154327, 0.07173537462949753, 0.09056375920772552, 0.11939135193824768, 0.11203742772340775, 0.07977215200662613, 0.23261870443820953], [0.2682461142539978, 0.014613986946642399, 0.04203887656331062, 0.17002445459365845, 0.058123212307691574, 0.03195761889219284, 0.05099283903837204, 0.36400288343429565], [0.21336399018764496, 0.04411306232213974, 0.019366556778550148, 0.2098989635705948, 0.027295252308249474, 0.024415483698248863, 0.024161214008927345, 0.4373854100704193], [0.12654051184654236, 0.1312001645565033, 0.14568130671977997, 0.003294913098216057, 0.0913986787199974, 0.11153916269540787, 0.19452278316020966, 0.19582241773605347], [0.3154485523700714, 0.0636277049779892, 0.03410904109477997, 0.15760596096515656, 0.006914426106959581, 0.03459079936146736, 0.04164468124508858, 0.3460588753223419], [0.4265236556529999, 0.0347447395324707, 0.02168351598083973, 0.12114595621824265, 0.025233326479792595, 0.012647328898310661, 0.02799171581864357, 0.33002978563308716], [0.21771982312202454, 0.04609312489628792, 0.024650869891047478, 0.22517254948616028, 0.02431756630539894, 0.02638200856745243, 0.027331173419952393, 0.408332884311676], [0.32788723707199097, 0.08594750612974167, 0.04430527985095978, 0.1426215022802353, 0.054855480790138245, 0.07305730134248734, 0.04659874364733696, 0.22472697496414185]], [[0.24588434398174286, 0.04422673583030701, 0.10402728617191315, 0.029708851128816605, 0.02296934276819229, 0.02573159709572792, 0.07679854333400726, 0.45065322518348694], [0.2341950535774231, 0.046753913164138794, 0.19183349609375, 0.0006317236693575978, 0.014484052546322346, 0.0030511810909956694, 0.13376404345035553, 0.3752865195274353], [0.2514256536960602, 0.023531002923846245, 0.15062165260314941, 0.004275746643543243, 0.011633104644715786, 0.002903283340856433, 0.14864760637283325, 0.4069618880748749], [0.2306247353553772, 0.006558806169778109, 0.13858290016651154, 0.11227235943078995, 0.010019679553806782, 0.0021023526787757874, 0.06795936822891235, 0.43187984824180603], [0.2697533667087555, 0.12316031754016876, 0.12561923265457153, 0.005833446979522705, 0.022329622879624367, 0.016733920201659203, 0.08837908506393433, 0.3481910526752472], [0.36249667406082153, 0.07295301556587219, 0.10807780921459198, 0.0009629730484448373, 0.03713027760386467, 0.015773873776197433, 0.0871211439371109, 0.31548425555229187], [0.26444029808044434, 0.021552717313170433, 0.12648014724254608, 0.004021698608994484, 0.008905965834856033, 0.0027608140371739864, 0.14228416979312897, 0.42955413460731506], [0.36420923471450806, 0.051437851041555405, 0.04941776022315025, 0.02817424014210701, 0.043167080730199814, 0.023825090378522873, 0.052755147218704224, 0.38701364398002625]], [[0.3765830099582672, 0.05816907063126564, 0.04181088134646416, 0.13221324980258942, 0.1562284678220749, 0.07744971662759781, 0.027178799733519554, 0.13036683201789856], [0.5193264484405518, 0.0025901063345372677, 0.015602825209498405, 0.352751761674881, 0.05048568174242973, 0.007324535399675369, 0.0009361962438561022, 0.0509825274348259], [0.2810536324977875, 0.003637624206021428, 0.005398365203291178, 0.5871676802635193, 0.08270519971847534, 0.010744161903858185, 0.0006440567085519433, 0.02864932082593441], [0.08746294677257538, 0.02183225005865097, 0.009354855865240097, 0.023380015045404434, 0.5625523328781128, 0.26649919152259827, 0.019179172813892365, 0.009739257395267487], [0.22373364865779877, 0.04708613455295563, 0.0025531246792525053, 0.17243728041648865, 0.007243013475090265, 0.058414045721292496, 0.1520300954580307, 0.33650264143943787], [0.40896275639533997, 0.09592314064502716, 0.004132031928747892, 0.10175859928131104, 0.0016413538251072168, 0.006692295894026756, 0.025378627702593803, 0.35551127791404724], [0.27546823024749756, 0.0118147237226367, 0.001176565419882536, 0.1880369931459427, 0.001570398802869022, 0.003222158644348383, 0.0037978491745889187, 0.514913022518158], [0.32509633898735046, 0.07714282721281052, 0.04903443902730942, 0.13073770701885223, 0.056081052869558334, 0.011741284281015396, 0.010914317332208157, 0.3392520844936371]], [[0.20000140368938446, 0.1259205937385559, 0.06354618817567825, 0.04487544298171997, 0.0620129220187664, 0.030467456206679344, 0.06144768372178078, 0.4117283523082733], [0.04916215315461159, 0.04093281552195549, 0.3425585627555847, 0.001917629037052393, 0.021389450877904892, 0.012085365131497383, 0.438119113445282, 0.09383495151996613], [0.10816267877817154, 0.1058226078748703, 0.25600650906562805, 0.019992409273982048, 0.011369571089744568, 0.005042532458901405, 0.3095996379852295, 0.1840040385723114], [0.05276937782764435, 0.004222098272293806, 0.03853599727153778, 0.7713826894760132, 0.004515719134360552, 0.0009263448882848024, 0.042119257152080536, 0.08552853018045425], [0.3518182039260864, 0.0953337550163269, 0.025921780616044998, 0.015006307512521744, 0.0060338713228702545, 0.022297142073512077, 0.03256881609559059, 0.45102012157440186], [0.2704657316207886, 0.21196411550045013, 0.0421563982963562, 0.0031917451415210962, 0.009127073921263218, 0.024406077340245247, 0.05640712007880211, 0.3822817802429199], [0.1394462287425995, 0.084314726293087, 0.22573480010032654, 0.021845774725079536, 0.007222507614642382, 0.0037611802108585835, 0.29528769850730896, 0.22238703072071075], [0.19335517287254333, 0.16168485581874847, 0.06462014466524124, 0.03257356956601143, 0.06398326903581619, 0.023481903597712517, 0.050320811569690704, 0.40998026728630066]], [[0.41572055220603943, 0.06225515529513359, 0.06848236918449402, 0.22336672246456146, 0.05358103662729263, 0.04357430711388588, 0.013918673619627953, 0.11910118907690048], [0.5653717517852783, 0.1414431929588318, 0.06710700690746307, 0.05179725959897041, 0.0018409707117825747, 0.0004805350035894662, 0.002481928328052163, 0.16947732865810394], [0.7516640424728394, 0.04753664880990982, 0.0019012719858437777, 0.12816035747528076, 0.0120718814432621, 0.0011632838286459446, 9.44253770285286e-05, 0.0574081726372242], [0.43521633744239807, 0.016656052321195602, 0.03959190100431442, 0.3231472373008728, 0.10280812531709671, 0.013543356209993362, 0.026583710685372353, 0.04245323687791824], [0.008282898925244808, 0.0012727356515824795, 0.0015312043251469731, 8.794408495305106e-05, 0.0025366079062223434, 0.7519065737724304, 0.23041792213916779, 0.003964135888963938], [0.005059296265244484, 0.003145357593894005, 0.00374247832223773, 1.5028510460979305e-05, 0.0009063688921742141, 0.002093956572934985, 0.9653088450431824, 0.01972869038581848], [0.06162463501095772, 0.1206449344754219, 0.00013940295320935547, 0.001860247110016644, 5.5792748753447086e-05, 0.0019794192630797625, 0.02579384297132492, 0.787901759147644], [0.15290385484695435, 0.12142058461904526, 0.02570776455104351, 0.16884924471378326, 0.005071927327662706, 0.005521093960851431, 0.0039937193505465984, 0.5165318250656128]], [[0.2359461486339569, 0.09183073788881302, 0.055439915508031845, 0.13411350548267365, 0.133743554353714, 0.02940532937645912, 0.046834517270326614, 0.272686243057251], [0.4061550498008728, 0.02137920819222927, 0.010076681151986122, 0.04384332150220871, 0.02251284569501877, 0.01219575572758913, 0.008043804205954075, 0.47579336166381836], [0.4271731674671173, 0.031572356820106506, 0.020235542207956314, 0.1375972181558609, 0.03367321193218231, 0.026196828112006187, 0.018641801550984383, 0.3049098253250122], [0.010807706043124199, 0.00029549820465035737, 0.0015287534333765507, 0.9767032265663147, 0.0002387637650826946, 0.00017978886899072677, 0.001960574882104993, 0.008285663090646267], [0.23933908343315125, 0.26204490661621094, 0.08059801161289215, 0.03583352640271187, 0.07917484641075134, 0.0702708289027214, 0.06505642831325531, 0.16768242418766022], [0.5095899105072021, 0.015039115212857723, 0.016085581853985786, 0.016470879316329956, 0.03422701358795166, 0.02692529745399952, 0.012831825762987137, 0.3688303232192993], [0.44571563601493835, 0.05376021936535835, 0.03473145514726639, 0.0756523534655571, 0.042157530784606934, 0.03972173109650612, 0.032450322061777115, 0.2758108079433441], [0.2222408652305603, 0.0854879766702652, 0.046315424144268036, 0.16284243762493134, 0.09421991556882858, 0.020068064332008362, 0.039220210164785385, 0.3296050429344177]], [[0.7653884887695312, 0.0002476693771313876, 0.001427812036126852, 0.22496995329856873, 0.007897387258708477, 5.31404430148541e-06, 3.4696259199051838e-09, 6.344463326968253e-05], [0.9050750732421875, 0.0018784564454108477, 0.0005228671943768859, 0.06869775056838989, 1.2077185918002442e-09, 1.2591701769801289e-12, 4.009449514069544e-16, 0.023825911805033684], [0.16034507751464844, 4.4700760781779536e-07, 4.144190768329281e-07, 0.8396499156951904, 4.231325419823406e-06, 2.465670246101781e-12, 1.3558816030935874e-21, 1.5323690760737918e-08], [0.017588108777999878, 6.85374885733836e-08, 1.5040714060887694e-05, 0.004445558413863182, 0.9779450297355652, 6.210652372828918e-06, 9.35906019350341e-10, 9.021579039369954e-09], [2.3237036828049895e-07, 9.29210527966795e-12, 3.0092383663041233e-13, 1.2206808008841108e-08, 0.0065815080888569355, 0.9820541143417358, 0.011364128440618515, 7.279229302659118e-11], [6.296686505535831e-10, 1.367711774946656e-07, 2.715023674361005e-14, 8.463227948313223e-15, 3.6514384181216e-13, 1.8271750377607532e-05, 0.9999731779098511, 8.49930802360177e-06], [1.0040717562942447e-10, 3.590165533751133e-06, 5.4274835507207496e-18, 5.266124005879377e-16, 9.299995665901525e-21, 2.202216631275178e-09, 0.00013920722994953394, 0.9998571872711182], [0.0007677633548155427, 0.0013133574975654483, 3.6069550333195366e-06, 1.6285343008348718e-05, 1.4751775376329462e-13, 7.514660314638603e-15, 5.324632878708768e-13, 0.9978989362716675]], [[0.18096919357776642, 0.08129599690437317, 0.06780652701854706, 0.07214730978012085, 0.1359674483537674, 0.11514142900705338, 0.07940949499607086, 0.26726260781288147], [0.2147289514541626, 0.05798080563545227, 0.08645470440387726, 0.1755412220954895, 0.12715867161750793, 0.0899081900715828, 0.05754261836409569, 0.19068488478660583], [0.08930803090333939, 0.061899833381175995, 0.010830068960785866, 0.7029405832290649, 0.0349845364689827, 0.029939426109194756, 0.00840546190738678, 0.06169210374355316], [0.09495075792074203, 0.040676601231098175, 0.3794444799423218, 0.02090083621442318, 0.0756727084517479, 0.07743324339389801, 0.2739194631576538, 0.03700196370482445], [0.2441413849592209, 0.21158915758132935, 0.05164855346083641, 0.062156375497579575, 0.010451214388012886, 0.029203565791249275, 0.04155586659908295, 0.3492538630962372], [0.24364443123340607, 0.09760606288909912, 0.05546291917562485, 0.12623441219329834, 0.0477822981774807, 0.03658442199230194, 0.04006637632846832, 0.3526190221309662], [0.1365480273962021, 0.059156548231840134, 0.01572345197200775, 0.6064568161964417, 0.03895163908600807, 0.03857862204313278, 0.012181572616100311, 0.09240332245826721], [0.14161129295825958, 0.1350780576467514, 0.08876180648803711, 0.05430717393755913, 0.10909415036439896, 0.08329477906227112, 0.08743195235729218, 0.3004208207130432]], [[0.030945684760808945, 0.18244707584381104, 0.21322934329509735, 0.08741999417543411, 0.053719863295555115, 0.11705092340707779, 0.27923616766929626, 0.03595094755291939], [0.09899003803730011, 0.22642964124679565, 0.16276727616786957, 0.05086229741573334, 0.07572664320468903, 0.11532565206289291, 0.19350722432136536, 0.07639122754335403], [0.07106183469295502, 0.21016444265842438, 0.12169443070888519, 0.19023096561431885, 0.06333206593990326, 0.11100748926401138, 0.15420976281166077, 0.07829893380403519], [0.06751108914613724, 0.10873254388570786, 0.18462178111076355, 0.24403907358646393, 0.04444591701030731, 0.05624838545918465, 0.26804155111312866, 0.026359694078564644], [0.1668316274881363, 0.17802618443965912, 0.09248121827840805, 0.06726525723934174, 0.03633077070116997, 0.11957530677318573, 0.11004837602376938, 0.2294413298368454], [0.24002671241760254, 0.10520337522029877, 0.05831097438931465, 0.036742471158504486, 0.04768611863255501, 0.08340735733509064, 0.0645671933889389, 0.3640557825565338], [0.09211453050374985, 0.17457059025764465, 0.12312821298837662, 0.18329863250255585, 0.05786637216806412, 0.1126120314002037, 0.15759815275669098, 0.09881146252155304], [0.1014765202999115, 0.12303707003593445, 0.18224085867404938, 0.15192674100399017, 0.054172106087207794, 0.09278729557991028, 0.2177136242389679, 0.07664574682712555]], [[0.341095894575119, 0.18426182866096497, 0.04858534410595894, 0.09763657301664352, 0.06497520953416824, 0.07307857275009155, 0.029075508937239647, 0.1612910032272339], [0.3606833219528198, 0.03136357292532921, 0.038888413459062576, 0.2599553167819977, 0.05004216730594635, 0.05624738335609436, 0.024221356958150864, 0.17859847843647003], [0.32320350408554077, 0.14249911904335022, 0.015364065766334534, 0.3122791349887848, 0.03393986448645592, 0.03236379101872444, 0.002162575488910079, 0.138187974691391], [0.2810293734073639, 0.18602105975151062, 0.18395841121673584, 0.013098851777613163, 0.1335042417049408, 0.08724334090948105, 0.033488187938928604, 0.08165651559829712], [0.28024494647979736, 0.054811473935842514, 0.029411816969513893, 0.5854120254516602, 0.008401565253734589, 0.005640995688736439, 0.0019147831480950117, 0.03416236490011215], [0.2670026421546936, 0.023840446025133133, 0.011162334121763706, 0.653820812702179, 0.01053899247199297, 0.003046796889975667, 0.006168863736093044, 0.024419071152806282], [0.1543482542037964, 0.03961915522813797, 0.004135345574468374, 0.4159132242202759, 0.1746961772441864, 0.13605698943138123, 0.017626255750656128, 0.05760453641414642], [0.24831372499465942, 0.09684286266565323, 0.02048049308359623, 0.08247985690832138, 0.08095674961805344, 0.0850282832980156, 0.06866797059774399, 0.3172300457954407]], [[0.1769888550043106, 0.136417955160141, 0.05657796189188957, 0.0939934104681015, 0.10469626635313034, 0.14240217208862305, 0.06872893124818802, 0.22019433975219727], [0.0012225902173668146, 0.9472531676292419, 0.02074575610458851, 2.6207264454569668e-05, 0.0006061098538339138, 0.0016455799341201782, 0.02734130248427391, 0.0011591026559472084], [0.04704184830188751, 0.5312251448631287, 0.10925206542015076, 0.024679914116859436, 0.007291178219020367, 0.015584016218781471, 0.18688081204891205, 0.07804502546787262], [0.005890951491892338, 0.00013536078040488064, 8.25075912871398e-05, 0.9894569516181946, 7.665869634365663e-05, 0.00016866964870132506, 9.595468873158097e-05, 0.004092842806130648], [0.21910855174064636, 0.13574784994125366, 0.03902416303753853, 0.0015554085839539766, 0.17124436795711517, 0.17013922333717346, 0.03872792795300484, 0.22445248067378998], [0.07156576216220856, 0.16234742105007172, 0.07644550502300262, 0.0006049371440894902, 0.08249501883983612, 0.4884229302406311, 0.053234197199344635, 0.06488431990146637], [0.062010910362005234, 0.5138973593711853, 0.23017601668834686, 0.027819477021694183, 0.008695931173861027, 0.013493238016963005, 0.08972575515508652, 0.0541813038289547], [0.25321000814437866, 0.18637700378894806, 0.10884464532136917, 0.06967616826295853, 0.11867894232273102, 0.06718339025974274, 0.07625110447406769, 0.11977875232696533]]], [[[0.0910516306757927, 0.4632015526294708, 0.11567742377519608, 0.019032513722777367, 0.03110060840845108, 0.03691175952553749, 0.06256958097219467, 0.18045499920845032], [0.10526259988546371, 0.39302581548690796, 0.05547574535012245, 0.07494177669286728, 0.07932444661855698, 0.05361679196357727, 0.13297481834888458, 0.10537805408239365], [0.05812210962176323, 0.7115265130996704, 0.11033540219068527, 0.04566943645477295, 0.005813707131892443, 0.006600131280720234, 0.018507543951272964, 0.04342515394091606], [0.27909713983535767, 0.22986428439617157, 0.28808724880218506, 0.0942310094833374, 0.01830575056374073, 0.003588563296943903, 0.006630613002926111, 0.08019544929265976], [0.2367941439151764, 0.17108489573001862, 0.34892213344573975, 0.10126549750566483, 0.13197778165340424, 0.002197759225964546, 0.0008633109391666949, 0.0068944282829761505], [0.11655902862548828, 0.02828548662364483, 0.05835608392953873, 0.08666850626468658, 0.6916383504867554, 0.009334330447018147, 0.005079299211502075, 0.0040788957849144936], [0.012572060339152813, 0.03498844429850578, 0.0066841100342571735, 0.12433237582445145, 0.7527581453323364, 0.03792796656489372, 0.027291525155305862, 0.0034453128464519978], [0.022632600739598274, 0.08677412569522858, 0.0031278375536203384, 0.02552880346775055, 0.24819475412368774, 0.27991271018981934, 0.2165304273366928, 0.11729878932237625]], [[0.3895530104637146, 0.5281021595001221, 0.06302981823682785, 2.0792687791981734e-05, 1.416282424671067e-09, 1.5121749408208984e-09, 5.518652557157111e-08, 0.019294140860438347], [0.00010231895430479199, 0.07902266085147858, 1.5318873920477927e-06, 2.614020777613746e-09, 4.255244601125696e-09, 0.00048203623737208545, 0.011222144588828087, 0.9091693162918091], [0.009340476244688034, 0.9839829206466675, 0.0010366386268287897, 2.7889146991810776e-08, 1.0341716420603372e-15, 3.6711278006244796e-13, 4.969094580253852e-12, 0.0056398408487439156], [0.022257519885897636, 0.0005032291519455612, 0.9766378402709961, 0.0006015017279423773, 8.38476754694284e-09, 6.88370843684419e-15, 5.62766837271185e-16, 2.6376460127153223e-08], [4.6644660756101075e-07, 2.7513234746034954e-11, 5.79425829982938e-07, 0.9974159002304077, 0.0025830527301877737, 4.8751255717896166e-14, 4.6906161718074866e-18, 2.0976143935848433e-17], [1.4257413609095049e-12, 2.522841744539983e-12, 8.62462075905011e-15, 3.0289928787397e-08, 0.9999274015426636, 7.20660318620503e-05, 5.309353241500503e-07, 1.6836010142035106e-15], [3.489238141464007e-16, 4.89900817395722e-13, 2.262400973488794e-21, 9.490640966256653e-14, 2.080758713418618e-05, 0.9893724322319031, 0.010606816969811916, 1.8186311831480673e-11], [1.6712524419926211e-10, 1.673823135206476e-05, 6.556578468087243e-14, 5.6135507687008444e-15, 5.55139538938737e-13, 9.606235107639804e-05, 0.9508981704711914, 0.04898902028799057]], [[0.43585631251335144, 0.09773663431406021, 0.3459720313549042, 0.07772380113601685, 0.03373454883694649, 0.0029208031482994556, 0.00025275861844420433, 0.005803184118121862], [0.1670154184103012, 0.010161112993955612, 0.7701616883277893, 0.00400434248149395, 0.0002768632839433849, 2.554633465479128e-05, 0.00048215477727353573, 0.0478728786110878], [0.15971586108207703, 0.01670781522989273, 0.20985135436058044, 0.6007914543151855, 0.012470551766455173, 0.0001570811145938933, 8.162307494785637e-06, 0.00029775401344522834], [0.0954175740480423, 0.0017901529790833592, 0.0058808522298932076, 0.20756061375141144, 0.6513143181800842, 0.036422163248062134, 0.0005551770445890725, 0.0010591750033199787], [0.002706035040318966, 0.004433713853359222, 4.0552586142439395e-05, 0.0026749668177217245, 0.11168529838323593, 0.7392945289611816, 0.13767310976982117, 0.0014918301021680236], [0.003931410610675812, 0.007982534356415272, 7.048398401821032e-05, 7.101149094523862e-06, 4.9969807150773704e-05, 0.028219768777489662, 0.6692856550216675, 0.29045310616493225], [0.000246861221967265, 0.008754933252930641, 8.331037679454312e-05, 1.002797762339469e-05, 1.6758415313233854e-06, 0.0030002493876963854, 0.846676230430603, 0.14122673869132996], [0.06461326032876968, 0.20530498027801514, 0.062162596732378006, 0.0008333955192938447, 1.0791081876959652e-05, 0.00030445627635344863, 0.007475459948182106, 0.6592950820922852]], [[0.16196636855602264, 2.1306852431735024e-05, 0.004778294824063778, 0.7906972765922546, 0.04253640025854111, 2.988810265946995e-08, 3.702349191114784e-12, 4.213581803469424e-07], [0.23583459854125977, 0.0007028084364719689, 0.7211873531341553, 0.04056259244680405, 2.2762488782746004e-08, 2.0521494226155568e-11, 1.0114273134298468e-11, 0.0017127543687820435], [0.0004921791260130703, 8.540225593378636e-08, 0.00013938159099780023, 0.9993525147438049, 1.5873634765739553e-05, 2.4237587323050524e-15, 8.77931758009368e-22, 1.279929667027252e-13], [6.645640269198339e-07, 2.1207584577354055e-09, 1.4586738927846454e-08, 0.0003817728138528764, 0.9996174573898315, 1.4834692763088242e-07, 8.104600974709331e-13, 9.061426332586733e-14], [2.511877695860615e-13, 3.875517406992657e-10, 1.4320144147073115e-16, 7.035610982697449e-11, 0.02279338613152504, 0.9739527106285095, 0.003253970993682742, 3.3826823720578547e-12], [5.0823162681384176e-14, 9.703654058057509e-08, 1.4238451260381786e-15, 1.5562769273963755e-16, 1.2103398625950678e-14, 2.739409865171183e-06, 0.9999598264694214, 3.7275574868544936e-05], [4.904049388798626e-12, 7.423512670357013e-06, 3.3247296788493225e-14, 1.784887281742269e-16, 2.239592542463088e-19, 1.9868516554222282e-10, 0.001111079822294414, 0.9988815188407898], [0.00011137629917357117, 0.003138691885396838, 1.6242403944488615e-05, 1.789517369843452e-07, 9.92325143971541e-16, 2.6784616665993626e-14, 4.336210834843257e-10, 0.996733546257019]], [[0.7871800065040588, 0.00020065985154360533, 0.0014235450653359294, 0.21111389994621277, 8.194654947146773e-05, 3.4611077892598985e-10, 8.423499392581565e-14, 2.6239352024504115e-08], [0.34938374161720276, 0.03366946429014206, 0.5068279504776001, 0.10839176923036575, 3.6670273484418203e-09, 6.573084437855314e-11, 1.960077586349307e-11, 0.0017270909156650305], [0.00017093669157475233, 4.359893353012012e-07, 4.8774596507428214e-05, 0.9997796416282654, 1.7948201502804295e-07, 5.73604147375271e-16, 1.7343250889513057e-22, 1.5487733166265338e-14], [5.641516054311069e-07, 2.9809921198165057e-09, 2.1854720699820973e-08, 0.0009941670577973127, 0.9990052580833435, 4.947445475522727e-08, 1.5992975173351187e-12, 4.946496229112085e-14], [7.218464920851625e-14, 6.045831890677533e-11, 8.156549260518976e-18, 4.840491202307007e-11, 0.023021627217531204, 0.9767410755157471, 0.0002373339084442705, 1.376625999608902e-13], [2.39082232201919e-14, 1.2635547363970545e-06, 1.1477582308915468e-16, 1.0335564182079447e-16, 2.165660805254852e-15, 3.4601598599692807e-05, 0.9999480247497559, 1.6095656974357553e-05], [8.861113232061513e-12, 0.006232377141714096, 3.0569466500252745e-14, 2.5370534124068145e-15, 1.699393066900413e-19, 7.725957118509541e-08, 0.013958403840661049, 0.9798091650009155], [5.586729821516201e-05, 0.11279561370611191, 1.084951600205386e-05, 8.628356340523169e-07, 3.262832785933384e-17, 3.851136515128873e-15, 1.6343677800012557e-10, 0.8871368169784546]], [[0.10001979023218155, 0.27790290117263794, 0.07114851474761963, 0.05579604580998421, 0.16762813925743103, 0.11318083852529526, 0.0913872942328453, 0.12293644994497299], [0.0893436074256897, 0.41653555631637573, 0.08589829504489899, 0.022549964487552643, 0.11973101645708084, 0.05887266620993614, 0.06149233877658844, 0.14557655155658722], [0.05561423301696777, 0.3359445631504059, 0.0490383580327034, 0.024569228291511536, 0.2686634361743927, 0.11582434922456741, 0.09092943370342255, 0.05941629782319069], [0.12124787271022797, 0.07392995059490204, 0.02823050320148468, 0.04258725047111511, 0.025009755045175552, 0.04690803214907646, 0.1714293509721756, 0.4906572997570038], [0.060948148369789124, 0.09020094573497772, 0.006339069921523333, 0.00637396052479744, 0.021819626912474632, 0.10373088717460632, 0.14179831743240356, 0.5687890648841858], [0.15959130227565765, 0.040810707956552505, 0.004591250326484442, 0.0020516528747975826, 0.003324134275317192, 0.010976884514093399, 0.019837021827697754, 0.7588170766830444], [0.10306438058614731, 0.27474379539489746, 0.02059229090809822, 0.019709352403879166, 0.012706205248832703, 0.03922940418124199, 0.07870732992887497, 0.4512472152709961], [0.19023792445659637, 0.2199219912290573, 0.03792127966880798, 0.042776621878147125, 0.03566695377230644, 0.027122285217046738, 0.031661488115787506, 0.4146915674209595]], [[0.26680800318717957, 0.3502981662750244, 0.0839574933052063, 0.027183162048459053, 0.022327203303575516, 0.007528252899646759, 0.022886965423822403, 0.21901074051856995], [0.18013180792331696, 0.5354639291763306, 0.07804358005523682, 0.008112381212413311, 0.013646368868649006, 0.04526336118578911, 0.020522451028227806, 0.11881618946790695], [0.13298888504505157, 0.6527820229530334, 0.06558211892843246, 0.0031326720491051674, 0.006537036504596472, 0.028548656031489372, 0.01783139444887638, 0.09259724617004395], [0.4005940556526184, 0.0974222719669342, 0.12835471332073212, 0.16208122670650482, 0.005551867187023163, 0.004390219692140818, 0.037026744335889816, 0.16457892954349518], [0.3950866758823395, 0.33328351378440857, 0.14526993036270142, 0.0038934682961553335, 0.004713136702775955, 0.005140128079801798, 0.007828197441995144, 0.10478518903255463], [0.6984498500823975, 0.07622870057821274, 0.07904984056949615, 0.0011729164980351925, 0.02908395789563656, 0.004705227445811033, 0.0056847394444048405, 0.10562480986118317], [0.182861328125, 0.5923111438751221, 0.1100698858499527, 0.004976707510650158, 0.009780565276741982, 0.026021376252174377, 0.015333608724176884, 0.058645375072956085], [0.3037327229976654, 0.2614564597606659, 0.08855953067541122, 0.06266964226961136, 0.06519058346748352, 0.014600242488086224, 0.02165828086435795, 0.18213261663913727]], [[0.19154919683933258, 0.12590764462947845, 0.18112905323505402, 0.020864006131887436, 0.06341731548309326, 0.08300026506185532, 0.1452329009771347, 0.18889960646629333], [0.3694984018802643, 0.023178575560450554, 0.04001415893435478, 0.012510129250586033, 0.008883300237357616, 0.010757431387901306, 0.03525878116488457, 0.4998992383480072], [0.36948758363723755, 0.04102712124586105, 0.025082848966121674, 0.0529695488512516, 0.010367967188358307, 0.009419210255146027, 0.01934802532196045, 0.4722977578639984], [0.18516507744789124, 0.05538897216320038, 0.23466691374778748, 0.026955699548125267, 0.042505718767642975, 0.055654555559158325, 0.15064682066440582, 0.24901624023914337], [0.44020986557006836, 0.017747165635228157, 0.026356294751167297, 0.02642083540558815, 0.0034138390328735113, 0.007623161654919386, 0.017886152490973473, 0.4603427052497864], [0.3619130551815033, 0.056823693215847015, 0.037794362753629684, 0.026558207347989082, 0.010519815608859062, 0.005796060897409916, 0.04635517671704292, 0.4542396366596222], [0.38394418358802795, 0.03176378831267357, 0.021203912794589996, 0.06371065974235535, 0.005226301494985819, 0.00711321085691452, 0.02052921988070011, 0.466508686542511], [0.18403436243534088, 0.17029941082000732, 0.14085230231285095, 0.013067692518234253, 0.043853674083948135, 0.06831210851669312, 0.0977354571223259, 0.2818450331687927]], [[0.3581104874610901, 0.059809934347867966, 0.027710827067494392, 0.031308986246585846, 0.03413717448711395, 0.04160166531801224, 0.035292938351631165, 0.4120279848575592], [0.012196873314678669, 0.9532812237739563, 0.0071846419014036655, 3.1654899430577643e-06, 4.7887016989989206e-05, 0.001647528144530952, 0.013626736588776112, 0.01201201044023037], [0.025674551725387573, 0.04145900160074234, 0.16231591999530792, 6.970225967961596e-06, 0.0004403212515171617, 0.011670802719891071, 0.7273749113082886, 0.031057532876729965], [0.1250072717666626, 0.000303753768093884, 0.0001324167533311993, 0.705817461013794, 0.00033210328547284007, 7.079037459334359e-05, 0.00013635550567414612, 0.1681998074054718], [0.1783047467470169, 0.005475573241710663, 0.004744979087263346, 0.00013174189371056855, 0.43326982855796814, 0.2490815669298172, 0.004491770640015602, 0.12449987977743149], [0.004168849904090166, 0.002901218831539154, 0.0015117917209863663, 8.746044954932586e-07, 0.0014686881331726909, 0.9857876300811768, 0.001626443350687623, 0.002534545725211501], [0.031188592314720154, 0.04861430078744888, 0.5844625234603882, 1.1191273188160267e-05, 0.00044209210318513215, 0.014653411693871021, 0.3051620125770569, 0.015465903095901012], [0.4030090570449829, 0.05161435902118683, 0.08338254690170288, 0.03718319162726402, 0.07376335561275482, 0.0720037892460823, 0.04293663799762726, 0.23610706627368927]], [[0.10375820845365524, 0.11890233308076859, 0.15872108936309814, 0.14251495897769928, 0.2091522216796875, 0.07152559608221054, 0.10111312568187714, 0.09431242197751999], [0.117201067507267, 0.2820527255535126, 0.10680832713842392, 0.027575267478823662, 0.03810693323612213, 0.11332244426012039, 0.11322294920682907, 0.20171023905277252], [0.10674567520618439, 0.3247331380844116, 0.03637063875794411, 0.23748116195201874, 0.05274573341012001, 0.08382489532232285, 0.03384731337428093, 0.12425144016742706], [0.23910817503929138, 0.022788096219301224, 0.09506868571043015, 0.12841707468032837, 0.15777133405208588, 0.04783749207854271, 0.08106625825166702, 0.22794286906719208], [0.1985820084810257, 0.0961528941988945, 0.05629570409655571, 0.3547166585922241, 0.0038313069380819798, 0.015546254813671112, 0.040994223207235336, 0.23388086259365082], [0.21105152368545532, 0.15220877528190613, 0.15000145137310028, 0.10304753482341766, 0.031869422644376755, 0.031634166836738586, 0.10062553733587265, 0.21956151723861694], [0.10553687810897827, 0.38160163164138794, 0.035881269723176956, 0.16978086531162262, 0.04404201731085777, 0.10195491462945938, 0.031601615250110626, 0.12960083782672882], [0.19687288999557495, 0.07144366949796677, 0.07948148995637894, 0.22888927161693573, 0.1045374646782875, 0.0500967800617218, 0.07271556556224823, 0.1959628313779831]], [[0.1111888438463211, 0.7454237937927246, 0.0802520364522934, 0.0018707362469285727, 0.00258454866707325, 0.0021256855688989162, 0.0016627046279609203, 0.054891735315322876], [0.00533426133915782, 0.5308873653411865, 0.019650300964713097, 4.350872040959075e-05, 7.696286957070697e-06, 0.004111583810299635, 0.2724979817867279, 0.16746728122234344], [0.021532202139496803, 0.9259887337684631, 0.018241295590996742, 5.534469164558686e-05, 1.90853870662977e-06, 8.058835373958573e-05, 0.00012295031046960503, 0.033977117389440536], [0.4988496005535126, 0.07032321393489838, 0.2889705002307892, 0.13373717665672302, 0.00033767276909202337, 8.70611984282732e-06, 2.117768417519983e-05, 0.007752018049359322], [0.24700278043746948, 0.0084513695910573, 0.020263101905584335, 0.6375101804733276, 0.08507528156042099, 0.001192031311802566, 0.0001228152250405401, 0.0003825179301202297], [0.008467171341180801, 0.005216025281697512, 0.0004399277677293867, 0.003765217261388898, 0.48330166935920715, 0.2667921781539917, 0.23033659160137177, 0.0016813096590340137], [4.968719440512359e-05, 0.001065259100869298, 9.933908131642966e-07, 1.993185833271127e-06, 0.003441739594563842, 0.5340927243232727, 0.4602266252040863, 0.0011209864169359207], [0.0006832886137999594, 0.030164213851094246, 5.0586779252626e-05, 3.517286586429691e-06, 0.00020528992172330618, 0.04899916052818298, 0.7780929803848267, 0.14180095493793488]], [[0.4080628752708435, 0.029739536345005035, 0.11355732381343842, 0.04149629548192024, 0.045784059911966324, 0.027273651212453842, 0.09315191209316254, 0.24093441665172577], [0.07222606241703033, 0.1266864687204361, 0.4511316418647766, 0.0016790522495284677, 0.0030657658353447914, 0.004054979886859655, 0.27416130900382996, 0.06699463725090027], [0.24166205525398254, 0.1272450089454651, 0.32114994525909424, 0.007817746140062809, 0.002215092536062002, 0.0019651881884783506, 0.15812425315380096, 0.13982068002223969], [0.3924476206302643, 0.0017452602041885257, 0.007685292046517134, 0.03402285277843475, 0.0018544795457273722, 0.0017225575866177678, 0.004602658562362194, 0.555919349193573], [0.5680015683174133, 0.019160864874720573, 0.07049258053302765, 0.0012178609613329172, 0.008444895967841148, 0.0027508779894560575, 0.017432577908039093, 0.3124987483024597], [0.40462422370910645, 0.07834932208061218, 0.14850863814353943, 0.0023164080921560526, 0.03841467946767807, 0.012739893049001694, 0.07675588876008987, 0.23829098045825958], [0.1848762184381485, 0.12345333397388458, 0.2951796054840088, 0.0020063072443008423, 0.001877856208011508, 0.001715292688459158, 0.23800213634967804, 0.15288935601711273], [0.31166312098503113, 0.01060927752405405, 0.05589474365115166, 0.02701600268483162, 0.024848725646734238, 0.017851779237389565, 0.050467733293771744, 0.5016486644744873]]], [[[0.052998919039964676, 0.4397948682308197, 0.06499941647052765, 0.04580384120345116, 0.061764564365148544, 0.1675010770559311, 0.0885365903377533, 0.07860065251588821], [0.06484977155923843, 0.19646629691123962, 0.10174163430929184, 0.05539156123995781, 0.0978829637169838, 0.2624107003211975, 0.03622544929385185, 0.18503159284591675], [0.021684857085347176, 0.39586055278778076, 0.11177030950784683, 0.09032004326581955, 0.07251322269439697, 0.20124739408493042, 0.06623166799545288, 0.040372055023908615], [0.015301906503736973, 0.13350537419319153, 0.009314199909567833, 0.025926116853952408, 0.09152437001466751, 0.2467760145664215, 0.3820853531360626, 0.09556666761636734], [0.0021900921128690243, 0.017343180254101753, 0.0013934227172285318, 0.0009252942400053144, 0.028400490060448647, 0.48664095997810364, 0.4207550287246704, 0.04235156998038292], [0.00916450098156929, 0.09375707805156708, 0.00908058974891901, 0.0023403766099363565, 0.021015644073486328, 0.29824182391166687, 0.40716180205345154, 0.15923820436000824], [0.0025627596769481897, 0.37484997510910034, 0.00853599701076746, 0.007583754602819681, 0.00999650452286005, 0.16411393880844116, 0.38067150115966797, 0.0516856387257576], [0.0468912273645401, 0.34614938497543335, 0.03629970923066139, 0.010155804455280304, 0.014946979470551014, 0.15231212973594666, 0.05603204295039177, 0.3372127413749695]], [[0.0965178832411766, 0.07243242114782333, 0.05712062120437622, 0.03545853868126869, 0.13930337131023407, 0.09174004942178726, 0.04283735528588295, 0.46458983421325684], [0.321464866399765, 0.04354073479771614, 0.07936442643404007, 0.053003694862127304, 0.07245628535747528, 0.12565813958644867, 0.09292570501565933, 0.21158599853515625], [0.08392056077718735, 0.09528584778308868, 0.06077560782432556, 0.016023047268390656, 0.1792328804731369, 0.29387181997299194, 0.1542094647884369, 0.1166808158159256], [0.15850062668323517, 0.056094612926244736, 0.0900413915514946, 0.14655421674251556, 0.09551408141851425, 0.08454472571611404, 0.09866408258676529, 0.2700863182544708], [0.12263462692499161, 0.06184415519237518, 0.06528639048337936, 0.05787867680191994, 0.1233246773481369, 0.13046680390834808, 0.15039941668510437, 0.28816521167755127], [0.16497556865215302, 0.04806344583630562, 0.07345806807279587, 0.05534652993083, 0.10812392085790634, 0.07843280583620071, 0.20198194682598114, 0.2696177661418915], [0.08643722534179688, 0.1308385729789734, 0.12375813722610474, 0.06796643882989883, 0.048370130360126495, 0.23030473291873932, 0.24073821306228638, 0.07158656418323517], [0.07919955998659134, 0.06341835856437683, 0.05490593612194061, 0.044042911380529404, 0.06792138516902924, 0.08918434381484985, 0.04737399145960808, 0.5539535284042358]], [[0.032411590218544006, 0.28774434328079224, 0.12053120136260986, 0.08945135772228241, 0.05347709357738495, 0.2910681664943695, 0.0739024356007576, 0.051413822919130325], [0.13098493218421936, 0.13463972508907318, 0.10900600254535675, 0.06755314767360687, 0.09899245947599411, 0.08663683384656906, 0.19355766475200653, 0.17862918972969055], [0.0600866936147213, 0.282356858253479, 0.0953342616558075, 0.2200823277235031, 0.06503170728683472, 0.19780783355236053, 0.03827856108546257, 0.041021928191185], [0.16572189331054688, 0.14473214745521545, 0.3574991524219513, 0.13142140209674835, 0.02631128765642643, 0.05013962462544441, 0.02328496426343918, 0.10088962316513062], [0.045243531465530396, 0.05725930258631706, 0.36333057284355164, 0.30150994658470154, 0.1813155710697174, 0.036967381834983826, 0.004416142590343952, 0.009957571513950825], [0.06011296808719635, 0.037308696657419205, 0.06809471547603607, 0.1830615997314453, 0.6035786867141724, 0.010677668265998363, 0.013581711798906326, 0.023583970963954926], [0.006179565563797951, 0.009308858774602413, 0.004247236531227827, 0.1396450698375702, 0.6018304228782654, 0.19872133433818817, 0.03328479453921318, 0.006782755255699158], [0.025866147130727768, 0.12976132333278656, 0.03325628489255905, 0.11107727140188217, 0.2477692812681198, 0.34214821457862854, 0.06477630138397217, 0.04534519463777542]], [[0.2944414019584656, 0.12043313682079315, 0.1049625352025032, 0.06427738815546036, 0.017677975818514824, 0.028611479327082634, 0.049376167356967926, 0.3202199339866638], [0.20396488904953003, 0.09006418287754059, 0.26349493861198425, 0.0013965480029582977, 0.0077902995981276035, 0.009432910941541195, 0.11353492736816406, 0.31032121181488037], [0.06016646698117256, 0.07810968905687332, 0.4756298065185547, 0.000880576204508543, 0.017085876315832138, 0.030477168038487434, 0.24464838206768036, 0.09300197660923004], [0.18536897003650665, 0.009414714761078358, 0.05475729703903198, 0.5827261209487915, 0.005208679474890232, 0.0003222195664420724, 0.014348851516842842, 0.14785327017307281], [0.1468174159526825, 0.024268362671136856, 0.12243049591779709, 0.0020030385348945856, 0.14701059460639954, 0.16564393043518066, 0.09825652092695236, 0.2935696542263031], [0.07340137660503387, 0.0103318952023983, 0.11040651053190231, 0.0008042651461437345, 0.07792628556489944, 0.45247384905815125, 0.13573503494262695, 0.13892070949077606], [0.022932294756174088, 0.03460513427853584, 0.327567994594574, 0.00018025364261120558, 0.015258828178048134, 0.034715842455625534, 0.5012738704681396, 0.06346571445465088], [0.2888084352016449, 0.06703561544418335, 0.04293316230177879, 0.025609903037548065, 0.003765430301427841, 0.01475512608885765, 0.02784593030810356, 0.5292463898658752]], [[0.005540157202631235, 0.23551620543003082, 0.06865210086107254, 0.08288539946079254, 0.12119658291339874, 0.34472528100013733, 0.1382715255022049, 0.003212773008272052], [0.33665889501571655, 0.020924009382724762, 0.02990807220339775, 0.21727217733860016, 0.020784039050340652, 0.02253710851073265, 0.027989821508526802, 0.32392585277557373], [0.06505483388900757, 0.12191533297300339, 0.057798463851213455, 0.1383189558982849, 0.23060272634029388, 0.2813079059123993, 0.03360743820667267, 0.07139439880847931], [0.08229350298643112, 0.04644915089011192, 0.04309647157788277, 0.40880876779556274, 0.047914884984493256, 0.16315151751041412, 0.07993537187576294, 0.1283503919839859], [0.0012186170788481832, 0.03680991381406784, 0.007667690049856901, 0.017864061519503593, 0.02146954834461212, 0.7084171175956726, 0.20393376052379608, 0.002619296545162797], [0.05566458776593208, 0.11366035789251328, 0.03856432065367699, 0.25452643632888794, 0.06942124664783478, 0.128010556101799, 0.20612533390522003, 0.13402719795703888], [0.011099805124104023, 0.23745380342006683, 0.016048990190029144, 0.11420892179012299, 0.24069146811962128, 0.2948397696018219, 0.05583849176764488, 0.029818717390298843], [0.016719158738851547, 0.22131535410881042, 0.0581810288131237, 0.04843943193554878, 0.115562304854393, 0.32996702194213867, 0.18181835114955902, 0.02799731306731701]], [[0.004418801516294479, 0.49204882979393005, 0.12175299972295761, 0.0316588319838047, 0.05531591176986694, 0.14485901594161987, 0.14545586705207825, 0.0044897617772221565], [0.001037245150655508, 0.9312590956687927, 0.033206142485141754, 0.0012487235944718122, 0.0033502678852528334, 0.005144220311194658, 0.023074021562933922, 0.0016803195467218757], [0.0005756843602284789, 0.7636014819145203, 0.07612590491771698, 0.002431996865198016, 0.0293459203094244, 0.0587247759103775, 0.06836913526058197, 0.0008250875398516655], [0.0018852663924917579, 0.00017141978605650365, 0.00017228268552571535, 0.9952849745750427, 0.00011806152906501666, 0.0001357140572508797, 0.00010403523629065603, 0.0021282320376485586], [0.012711982242763042, 0.3684525489807129, 0.19830390810966492, 0.008477968163788319, 0.03103998489677906, 0.1813763827085495, 0.1785757690668106, 0.021061498671770096], [0.03525920957326889, 0.2492937445640564, 0.22757945954799652, 0.01764448545873165, 0.09736572206020355, 0.15246430039405823, 0.15086214244365692, 0.0695309266448021], [0.0007081276271492243, 0.8575396537780762, 0.04710372909903526, 0.005506986286491156, 0.013110104948282242, 0.03477916866540909, 0.040193963795900345, 0.0010583577677607536], [0.024747086688876152, 0.26281315088272095, 0.12516504526138306, 0.12058816105127335, 0.12085828185081482, 0.17575818300247192, 0.10834953933954239, 0.061720605939626694]], [[0.08540461212396622, 0.22869513928890228, 0.12358545511960983, 0.12277278304100037, 0.0508594810962677, 0.11476663500070572, 0.05555896833539009, 0.2183569371700287], [0.0731530413031578, 0.09682492911815643, 0.05948801711201668, 0.13853922486305237, 0.09283751994371414, 0.18245644867420197, 0.14822602272033691, 0.2084747552871704], [0.06575141847133636, 0.41313406825065613, 0.10022680461406708, 0.1946571171283722, 0.01933591067790985, 0.09464649856090546, 0.03796004131436348, 0.07428805530071259], [0.05257577449083328, 0.221371591091156, 0.19336310029029846, 0.1749972552061081, 0.11485724151134491, 0.1375114917755127, 0.030215123668313026, 0.07510849833488464], [0.07728669792413712, 0.11020643264055252, 0.3174936771392822, 0.3078068792819977, 0.07913948595523834, 0.05669695511460304, 0.022575339302420616, 0.0287944246083498], [0.03174232691526413, 0.05149037390947342, 0.07491245865821838, 0.5594574809074402, 0.20897176861763, 0.031764917075634, 0.02131214551627636, 0.020348509773612022], [0.010858678258955479, 0.02770947851240635, 0.035005755722522736, 0.7071236371994019, 0.09898411482572556, 0.08013971894979477, 0.03364228084683418, 0.006536257453262806], [0.09519338607788086, 0.027063589543104172, 0.026319220662117004, 0.08343532681465149, 0.06016642227768898, 0.035133231431245804, 0.030333204194903374, 0.6423556208610535]], [[0.03377588838338852, 0.07656247168779373, 0.03884968161582947, 0.016547827050089836, 0.1683366447687149, 0.3044978082180023, 0.16261737048625946, 0.19881227612495422], [0.16663634777069092, 0.022858256474137306, 0.29388052225112915, 0.015242285095155239, 0.07365129888057709, 0.015526601113379002, 0.2193242609500885, 0.19288039207458496], [0.03399905562400818, 0.007180633023381233, 0.006412400398403406, 0.06217607483267784, 0.5044311285018921, 0.169499009847641, 0.10195253789424896, 0.1143491342663765], [0.02659071795642376, 0.03402939811348915, 0.0032649836502969265, 0.022981595247983932, 0.11784010380506516, 0.3170454502105713, 0.25205621123313904, 0.22619149088859558], [0.003602796932682395, 0.03446755185723305, 0.0009260997176170349, 0.00412345165386796, 0.03349756449460983, 0.6410001516342163, 0.24537962675094604, 0.037002697587013245], [0.06344737857580185, 0.14668899774551392, 0.018969057127833366, 0.025594592094421387, 0.1812521517276764, 0.051527734845876694, 0.14852586388587952, 0.3639942705631256], [0.05012904480099678, 0.04809364676475525, 0.008038152009248734, 0.05038299039006233, 0.19932685792446136, 0.17274226248264313, 0.09491075575351715, 0.37637630105018616], [0.05433942750096321, 0.2607540488243103, 0.04627671837806702, 0.019603600725531578, 0.0461399108171463, 0.17670191824436188, 0.04861545190215111, 0.34756895899772644]], [[0.11356167495250702, 0.29413896799087524, 0.2875443994998932, 0.030390413478016853, 0.007801880594342947, 0.06622134149074554, 0.03523219749331474, 0.1651090830564499], [0.010752828791737556, 0.2567373812198639, 0.018908420577645302, 0.01241355761885643, 0.026080474257469177, 0.2609117329120636, 0.2823876738548279, 0.13180790841579437], [0.009661098942160606, 0.8636161684989929, 0.08038786053657532, 0.0009730058372952044, 0.00036927207838743925, 0.032708872109651566, 0.0037497871089726686, 0.008533808402717113], [0.058355215936899185, 0.0756358951330185, 0.8124807476997375, 0.021001772955060005, 0.0022263561841100454, 0.0019814034458249807, 0.0020861532539129257, 0.026232488453388214], [0.0005086236051283777, 0.0012342599220573902, 0.004535661078989506, 0.7951494455337524, 0.19606898725032806, 0.0014901191461831331, 0.0009613792062737048, 5.153496385901235e-05], [0.0007776544080115855, 0.0013552603777498007, 0.0003124791255686432, 0.029406016692519188, 0.9085383415222168, 0.04562513530254364, 0.013312685303390026, 0.0006723135593347251], [0.00016710326599422842, 0.0007557927165180445, 3.5939476219937205e-05, 0.0016581336967647076, 0.06236455962061882, 0.8133818507194519, 0.12089437991380692, 0.0007421532645821571], [0.01874902844429016, 0.04321305826306343, 0.006358711514621973, 0.02624124102294445, 0.03953760489821434, 0.3624638319015503, 0.301817923784256, 0.20161859691143036]], [[0.032296814024448395, 0.13157127797603607, 0.041637636721134186, 0.7148693799972534, 0.06889423727989197, 0.004171581938862801, 0.0005791148287244141, 0.005979996174573898], [0.029022643342614174, 0.014692993834614754, 0.8426464796066284, 0.10709580034017563, 0.0011013447074219584, 0.0018106764182448387, 0.0008460271637886763, 0.0027840686962008476], [0.001396654755808413, 0.011889319866895676, 0.04422468692064285, 0.9389023184776306, 0.0031451985705643892, 0.00038424236117862165, 7.080473096721107e-06, 5.048437014920637e-05], [0.0001258471456822008, 0.0029132855124771595, 9.102580952458084e-05, 0.0171547532081604, 0.8915376663208008, 0.08562961965799332, 0.0022367406636476517, 0.0003110042307525873], [6.905619898134319e-07, 0.00011849752627313137, 7.498890113311063e-07, 8.348147093784064e-05, 0.012972760014235973, 0.9646432399749756, 0.02216348797082901, 1.7096572264563292e-05], [0.00011826483387267217, 0.007237663026899099, 0.00034454319393262267, 6.638347258558497e-05, 0.00014392162847798318, 0.01529153622686863, 0.9719372987747192, 0.004860411398112774], [0.001191813382320106, 0.21367771923542023, 0.0018962904578074813, 0.001504570827819407, 0.0022447872906923294, 0.03803892806172371, 0.5152241587638855, 0.22622166574001312], [0.1286720335483551, 0.3221377432346344, 0.03219599276781082, 0.035287924110889435, 0.002302520675584674, 0.005495885387063026, 0.015781128779053688, 0.4581267535686493]], [[0.11264563351869583, 0.11671500653028488, 0.061811793595552444, 0.22836606204509735, 0.10766790807247162, 0.161875382065773, 0.049227192997932434, 0.16169099509716034], [0.24348483979701996, 0.359942764043808, 0.12916631996631622, 0.0019557378254830837, 0.013136697001755238, 0.017741603776812553, 0.11460842192173004, 0.11996352672576904], [0.1471714824438095, 0.06725161522626877, 0.1782573163509369, 0.012397593818604946, 0.03927789255976677, 0.09725786000490189, 0.28428351879119873, 0.17410270869731903], [0.038281723856925964, 0.003679729765281081, 0.000604435452260077, 0.9286342859268188, 0.001532050664536655, 0.0007477657054550946, 0.00035452150041237473, 0.026165593415498734], [0.14310628175735474, 0.07338354736566544, 0.035191573202610016, 0.00942931231111288, 0.40013742446899414, 0.20395469665527344, 0.009295908734202385, 0.12550123035907745], [0.3000721037387848, 0.13550911843776703, 0.07911781966686249, 0.002575357910245657, 0.06022408977150917, 0.21756693720817566, 0.028083624318242073, 0.17685097455978394], [0.08768288046121597, 0.08168072998523712, 0.439998984336853, 0.002460643881931901, 0.02806478552520275, 0.04766959697008133, 0.2541303336620331, 0.05831199139356613], [0.2046714425086975, 0.09204822778701782, 0.03694169595837593, 0.1266297996044159, 0.07791823893785477, 0.1056075170636177, 0.016419807448983192, 0.3397633135318756]], [[0.1582898050546646, 0.3585202097892761, 0.1403975784778595, 0.032232485711574554, 0.1123252734541893, 0.07289401441812515, 0.06781435012817383, 0.05752627179026604], [0.23926207423210144, 0.03178771957755089, 0.16990086436271667, 0.13058415055274963, 0.04546235129237175, 0.057054292410612106, 0.0697939395904541, 0.2561546564102173], [0.24378208816051483, 0.2479889988899231, 0.07004241645336151, 0.11559262126684189, 0.07699379324913025, 0.03806982561945915, 0.027776647359132767, 0.17975354194641113], [0.07512403279542923, 0.46966660022735596, 0.08813213557004929, 0.0374809093773365, 0.13499538600444794, 0.0716761127114296, 0.05489153414964676, 0.06803323328495026], [0.21726779639720917, 0.20271354913711548, 0.04388028010725975, 0.23960450291633606, 0.00643636891618371, 0.01618300937116146, 0.013957010582089424, 0.2599574327468872], [0.19877305626869202, 0.07553234696388245, 0.0463767871260643, 0.4147583246231079, 0.018383292481303215, 0.011215257458388805, 0.014747466892004013, 0.22021344304084778], [0.1984350085258484, 0.17038564383983612, 0.04949295520782471, 0.23386240005493164, 0.08533739298582077, 0.04499391093850136, 0.018852774053812027, 0.1986398547887802], [0.12033459544181824, 0.2235412299633026, 0.07806126773357391, 0.08119028806686401, 0.10393443703651428, 0.11251991987228394, 0.05854170396924019, 0.2218765914440155]]], [[[0.2043260633945465, 0.043870534747838974, 0.2794721722602844, 0.0040762764401733875, 0.010107503272593021, 0.04536843299865723, 0.16591301560401917, 0.24686592817306519], [9.85085207503289e-05, 0.9600915908813477, 0.004993712063878775, 2.7630836484604515e-05, 8.658814294904005e-06, 0.0003508017398416996, 0.033829692751169205, 0.0005994191742502153], [0.014872814528644085, 0.08542417734861374, 0.5151582360267639, 0.00015068652282934636, 6.468733045039698e-05, 0.0009737834334373474, 0.3632051348686218, 0.020150456577539444], [0.0010863152565434575, 0.00020020849478896707, 5.3570573072647676e-05, 0.9917933344841003, 0.0002081821148749441, 3.777902020374313e-05, 0.0002893066266551614, 0.006331144366413355], [0.04233432561159134, 0.0017647736240178347, 0.0029895047191530466, 0.005343771073967218, 0.7282799482345581, 0.020229032263159752, 0.018329128623008728, 0.18072953820228577], [0.13490024209022522, 0.05035225301980972, 0.050431616604328156, 0.0010404756758362055, 0.013397706672549248, 0.30050262808799744, 0.13178212940692902, 0.317592978477478], [0.006053442135453224, 0.10521318018436432, 0.2701455056667328, 8.24957387521863e-05, 0.000259000196820125, 0.0030575182754546404, 0.6026332974433899, 0.012555446475744247], [0.05516520142555237, 0.13705728948116302, 0.1450430452823639, 0.0034178863279521465, 0.01148904673755169, 0.057180240750312805, 0.23127955198287964, 0.3593677580356598]], [[0.037427954375743866, 0.15603119134902954, 0.1792135238647461, 0.019320959225296974, 0.2860032021999359, 0.1658961921930313, 0.11430923640727997, 0.04179776832461357], [0.02875540591776371, 0.13683196902275085, 0.1090770736336708, 0.022532863542437553, 0.18013572692871094, 0.3271981179714203, 0.15850673615932465, 0.03696215897798538], [0.012304296717047691, 0.1306062638759613, 0.1588543802499771, 0.02348983660340309, 0.16581737995147705, 0.3383369743824005, 0.15783081948757172, 0.012759963050484657], [0.07002676278352737, 0.11159715056419373, 0.17571857571601868, 0.13089586794376373, 0.09580650925636292, 0.23530510067939758, 0.11217847466468811, 0.06847162544727325], [0.019814372062683105, 0.13314932584762573, 0.11989092081785202, 0.0281293373554945, 0.2662719786167145, 0.26188594102859497, 0.1464393585920334, 0.024418823421001434], [0.015888020396232605, 0.13962408900260925, 0.09310650825500488, 0.014510580338537693, 0.21147330105304718, 0.26886698603630066, 0.21291117370128632, 0.0436193086206913], [0.0069291600957512856, 0.1372879445552826, 0.15190953016281128, 0.020948713645339012, 0.11309841275215149, 0.338620126247406, 0.22021642327308655, 0.01098976656794548], [0.0343654565513134, 0.11515792459249496, 0.1871117353439331, 0.03381054103374481, 0.2473667711019516, 0.2242121398448944, 0.11007627844810486, 0.04789916053414345]], [[0.008421572856605053, 0.625160813331604, 0.04406754672527313, 0.0010110643925145268, 0.07184062898159027, 0.1612587720155716, 0.07484016567468643, 0.013399441726505756], [0.000685805338434875, 0.6406195759773254, 0.18111756443977356, 0.004741256590932608, 0.008661342784762383, 0.017352381721138954, 0.1462441235780716, 0.0005780035862699151], [0.00046108252718113363, 0.7250652313232422, 0.1288011223077774, 0.008900419808924198, 0.011324876919388771, 0.024025358259677887, 0.10082381218671799, 0.0005981939029879868], [0.0024783089756965637, 0.08264552801847458, 0.043869856745004654, 0.8227325081825256, 0.013242825865745544, 0.016259822994470596, 0.01634211279451847, 0.0024289884604513645], [0.002235997235402465, 0.3197489082813263, 0.18201342225074768, 0.010443826206028461, 0.3238263726234436, 0.1310001164674759, 0.02866915799677372, 0.002062272746115923], [0.0017855750629678369, 0.4542039930820465, 0.20192590355873108, 0.0034098695032298565, 0.16443826258182526, 0.07124900817871094, 0.10132640600204468, 0.0016611230093985796], [0.0002904457796830684, 0.5409369468688965, 0.10552603751420975, 0.022662363946437836, 0.06173253059387207, 0.13643625378608704, 0.1320473849773407, 0.0003680941299535334], [0.0026034044567495584, 0.40733635425567627, 0.027482828125357628, 0.0034106390085071325, 0.10848212987184525, 0.35398992896080017, 0.09344687312841415, 0.0032478347420692444]], [[0.19731669127941132, 0.22012649476528168, 0.15829037129878998, 0.06321924179792404, 0.07708251476287842, 0.039577558636665344, 0.06382578611373901, 0.18056142330169678], [0.10788702964782715, 0.2704716920852661, 0.07455609738826752, 0.09237246960401535, 0.063085176050663, 0.09634646028280258, 0.05148933082818985, 0.24379165470600128], [0.09210322797298431, 0.32641980051994324, 0.13594509661197662, 0.19599778950214386, 0.03819818049669266, 0.04970436915755272, 0.0657668188214302, 0.09586483240127563], [0.0027866812888532877, 0.005803244654089212, 0.005627952516078949, 0.9736284017562866, 0.003511475631967187, 0.0018524588085711002, 0.00244503584690392, 0.004344765562564135], [0.09957140684127808, 0.34510505199432373, 0.151844322681427, 0.03779307007789612, 0.030766239389777184, 0.06672541797161102, 0.07630328088998795, 0.19189134240150452], [0.030847206711769104, 0.5281378030776978, 0.10845354199409485, 0.035464849323034286, 0.02576093003153801, 0.052138280123472214, 0.08951952308416367, 0.12967775762081146], [0.06673461198806763, 0.2993946969509125, 0.13525904715061188, 0.15524472296237946, 0.05093613639473915, 0.08124536275863647, 0.07233627140522003, 0.13884907960891724], [0.10519028455018997, 0.3541548252105713, 0.06608971953392029, 0.12181626260280609, 0.05591971427202225, 0.050054244697093964, 0.03528163954615593, 0.2114933580160141]], [[0.0009614003938622773, 0.08767946064472198, 0.022321626543998718, 0.8102265000343323, 0.018301313742995262, 0.027235042303800583, 0.032139044255018234, 0.0011356058530509472], [0.004875978454947472, 0.20662187039852142, 0.17307980358600616, 0.4104118347167969, 0.03061072528362274, 0.05232882872223854, 0.11498374491930008, 0.007087219972163439], [0.00035618440597318113, 0.01637466438114643, 0.017109233886003494, 0.9147974848747253, 0.015401730313897133, 0.010693851858377457, 0.024631302803754807, 0.0006355341174639761], [0.0017554665682837367, 0.11214108020067215, 0.006970969960093498, 0.1989917904138565, 0.03328230604529381, 0.25364795327186584, 0.37115591764450073, 0.022054515779018402], [0.0021244545932859182, 0.04644396901130676, 0.006562519818544388, 0.12331469357013702, 0.03954973444342613, 0.24495209753513336, 0.5125319361686707, 0.024520650506019592], [0.014793524518609047, 0.22384242713451385, 0.041050661355257034, 0.29246339201927185, 0.028537070378661156, 0.11073138564825058, 0.21943938732147217, 0.06914220005273819], [0.0029732687398791313, 0.186567485332489, 0.031218096613883972, 0.5755664110183716, 0.009940178133547306, 0.03865950182080269, 0.13943906128406525, 0.01563606597483158], [0.0017125322483479977, 0.17363616824150085, 0.01669619232416153, 0.7516675591468811, 0.008535902947187424, 0.02183602564036846, 0.023341646417975426, 0.0025739187840372324]], [[0.010900459252297878, 0.368886262178421, 0.02778387814760208, 0.08910106122493744, 0.03497937321662903, 0.3167905807495117, 0.11306482553482056, 0.03849349543452263], [0.012552384287118912, 0.5112596154212952, 0.12460686266422272, 0.02473616972565651, 0.03288771212100983, 0.13575522601604462, 0.14146511256694794, 0.016736840829253197], [0.008382695727050304, 0.5907214879989624, 0.12712259590625763, 0.014709868468344212, 0.024087944999337196, 0.10601101815700531, 0.11799383163452148, 0.010970520786941051], [0.05555586889386177, 0.4340965151786804, 0.2820195257663727, 0.03992411121726036, 0.033181332051754, 0.08016634732484818, 0.0470159612596035, 0.028040243312716484], [0.02930949069559574, 0.32279297709465027, 0.3310302197933197, 0.03846947103738785, 0.12180032581090927, 0.12368327379226685, 0.02567697875201702, 0.007237226702272892], [0.017570339143276215, 0.4298768937587738, 0.22163645923137665, 0.06068306043744087, 0.11745647341012955, 0.10168613493442535, 0.04611098766326904, 0.004979751538485289], [0.006744390819221735, 0.28578418493270874, 0.11875998973846436, 0.10035238415002823, 0.22552849352359772, 0.17200787365436554, 0.08750355988740921, 0.003319075331091881], [0.004758745431900024, 0.25615987181663513, 0.024386731907725334, 0.12295886129140854, 0.0810524970293045, 0.4129532277584076, 0.08462925255298615, 0.013100847601890564]], [[0.004984861705452204, 0.45649009943008423, 0.1630174070596695, 0.18885576725006104, 0.02469579502940178, 0.07224797457456589, 0.08752311021089554, 0.0021849849727004766], [0.06963381171226501, 0.08339005708694458, 0.4827594757080078, 0.06447228044271469, 0.022000432014465332, 0.04479926824569702, 0.15977606177330017, 0.07316865026950836], [0.010397050529718399, 0.09392101317644119, 0.3306725323200226, 0.44288599491119385, 0.01758420839905739, 0.03928787633776665, 0.060698412358760834, 0.004552852362394333], [0.005090733524411917, 0.029497845098376274, 0.008345112204551697, 0.00596599979326129, 0.3045894205570221, 0.5103963613510132, 0.11683270335197449, 0.01928190514445305], [0.00021951631060801446, 0.0019855189602822065, 0.0003595152229536325, 0.0013186720898374915, 0.05904261767864227, 0.8754586577415466, 0.05927104875445366, 0.0023444320540875196], [0.004497367423027754, 0.04414306953549385, 0.008195140399038792, 0.004009098280221224, 0.004243379924446344, 0.16247104108333588, 0.7337926030158997, 0.03864827752113342], [0.01346533838659525, 0.14145879447460175, 0.05186934769153595, 0.02201225236058235, 0.015933096408843994, 0.1483645737171173, 0.5160571336746216, 0.09083948284387589], [0.010052414610981941, 0.4741777181625366, 0.04167039319872856, 0.029610510915517807, 0.0097732562571764, 0.2086332142353058, 0.19613824784755707, 0.02994423918426037]], [[0.005807966459542513, 0.28560107946395874, 0.05982685461640358, 0.04425966367125511, 0.24002036452293396, 0.20352481305599213, 0.15312987565994263, 0.00782934483140707], [0.002526284893974662, 0.3888636529445648, 0.30704551935195923, 0.011534495279192924, 0.028594225645065308, 0.030485980212688446, 0.22899718582630157, 0.0019525899551808834], [0.0010398339945822954, 0.4950900077819824, 0.10981139540672302, 0.10801911354064941, 0.04271124675869942, 0.03752532973885536, 0.20307303965091705, 0.002730040345340967], [0.005044565070420504, 0.32003864645957947, 0.056232549250125885, 0.2613711357116699, 0.05584973841905594, 0.05206572636961937, 0.21176594495773315, 0.03763172775506973], [0.004096448887139559, 0.4491733908653259, 0.047782737761735916, 0.016358479857444763, 0.10520435869693756, 0.11765492707490921, 0.23079705238342285, 0.02893257327377796], [0.0021371834445744753, 0.6610411405563354, 0.07761310040950775, 0.026181379333138466, 0.018374523147940636, 0.06126048043370247, 0.14738565683364868, 0.006006444804370403], [0.0006811431958340108, 0.7618387937545776, 0.05882370471954346, 0.028161434456706047, 0.004921139683574438, 0.02878129482269287, 0.11475814878940582, 0.0020342268981039524], [0.001904003438539803, 0.7591724991798401, 0.05737127736210823, 0.043994639068841934, 0.021425634622573853, 0.0570775642991066, 0.05670001357793808, 0.0023544132709503174]], [[0.0005522239371202886, 0.75010085105896, 0.00791284628212452, 0.022917715832591057, 0.00015692593296989799, 0.059812676161527634, 0.14276441931724548, 0.01578235626220703], [0.01621120609343052, 0.06738217920064926, 0.01006142608821392, 0.031218675896525383, 0.015205280855298042, 0.3629496991634369, 0.3268091082572937, 0.17016245424747467], [0.0007154293707571924, 0.8721755743026733, 0.037811294198036194, 0.0010213139466941357, 0.00023254353436641395, 0.0347532294690609, 0.05071468651294708, 0.002575980732217431], [0.06630247086286545, 0.058100633323192596, 0.8594430685043335, 0.005220802966505289, 0.0019839047454297543, 0.0014227123465389013, 0.0014464149717241526, 0.006080027669668198], [0.0006293403566814959, 0.07426398247480392, 0.017608845606446266, 0.5201663970947266, 0.34442776441574097, 0.038786981254816055, 0.0035427436232566833, 0.0005739786429330707], [0.00011084169091191143, 0.05086492747068405, 0.003180908504873514, 0.08107716590166092, 0.5747102499008179, 0.2709493637084961, 0.018367286771535873, 0.0007392286788672209], [4.224676013109274e-05, 0.009273777715861797, 0.00015861092833802104, 0.0024075291585177183, 0.0036073043011128902, 0.9249136447906494, 0.05882302299141884, 0.0007738639833405614], [5.4292020649882033e-05, 0.24118280410766602, 0.0007501796935684979, 0.02090318314731121, 0.0006767443264834583, 0.4096704125404358, 0.320011705160141, 0.006750765256583691]], [[0.044997867196798325, 0.09071057289838791, 0.09696545451879501, 0.18615350127220154, 0.28851285576820374, 0.17207249999046326, 0.0764823630452156, 0.04410477355122566], [0.05943986028432846, 0.1648261398077011, 0.09755630046129227, 0.16661353409290314, 0.08060801774263382, 0.21730786561965942, 0.10865210741758347, 0.10499609261751175], [0.015313610434532166, 0.1320830136537552, 0.06275565922260284, 0.17521797120571136, 0.1899973452091217, 0.2459590882062912, 0.14993742108345032, 0.02873585931956768], [0.04685104265809059, 0.09397617727518082, 0.03206643462181091, 0.2806328237056732, 0.06254494935274124, 0.16485542058944702, 0.18780136108398438, 0.13127176463603973], [0.06050354614853859, 0.049133747816085815, 0.03326043486595154, 0.0548408105969429, 0.21902774274349213, 0.14099888503551483, 0.1705048829317093, 0.2717299163341522], [0.050370387732982635, 0.07113885134458542, 0.10148487240076065, 0.036495186388492584, 0.24840538203716278, 0.16466538608074188, 0.13118286430835724, 0.19625705480575562], [0.0326082669198513, 0.1572088748216629, 0.09420650452375412, 0.07506942749023438, 0.1423799842596054, 0.22045432031154633, 0.1679389625787735, 0.1101335883140564], [0.0543740838766098, 0.11689066141843796, 0.114128477871418, 0.38633424043655396, 0.13390211760997772, 0.1102602556347847, 0.047554150223731995, 0.03655601292848587]], [[0.0009381136624142528, 0.8428494334220886, 0.01395291369408369, 0.00678520742803812, 0.0022549827117472887, 0.09297402203083038, 0.028281530365347862, 0.011963829398155212], [0.0014141658321022987, 0.7485761642456055, 0.04233546182513237, 0.023796020075678825, 0.01373087428510189, 0.06753572821617126, 0.09111452102661133, 0.011497125029563904], [0.0005973165389150381, 0.9440196752548218, 0.020098445937037468, 0.002258127322420478, 0.0014939522370696068, 0.019042078405618668, 0.009073298424482346, 0.003416989929974079], [0.0160576980561018, 0.24703188240528107, 0.5554786324501038, 0.019674906507134438, 0.06818752735853195, 0.0675843358039856, 0.014450322836637497, 0.011534684337675571], [0.0011021964019164443, 0.4242764115333557, 0.02921225130558014, 0.37560105323791504, 0.07796191424131393, 0.07052682340145111, 0.01642797514796257, 0.00489148311316967], [0.0011293755378574133, 0.3642755150794983, 0.006589744705706835, 0.1974111646413803, 0.21564485132694244, 0.15383614599704742, 0.04633261263370514, 0.014780675992369652], [0.0005218256264925003, 0.2678837478160858, 0.005134322680532932, 0.07079479098320007, 0.07946816086769104, 0.4687318503856659, 0.09757902473211288, 0.009886257350444794], [0.0002384261169936508, 0.4651075303554535, 0.0015461576404049993, 0.012757442891597748, 0.0058724544942379, 0.32827332615852356, 0.1689172238111496, 0.017287440598011017]], [[0.012522553093731403, 0.23916009068489075, 0.03655993193387985, 0.0008424747502431273, 0.10614066570997238, 0.5169376730918884, 0.05030248314142227, 0.03753407672047615], [0.006559597793966532, 0.20027931034564972, 0.12186158448457718, 0.00288115325383842, 0.04493841156363487, 0.4962187111377716, 0.10977599024772644, 0.017485277727246284], [0.005776034202426672, 0.3289974331855774, 0.13825052976608276, 0.0009027545456774533, 0.040593404322862625, 0.36087292432785034, 0.1157204881310463, 0.008886405266821384], [0.05170891806483269, 0.17306344211101532, 0.1490243822336197, 0.025806870311498642, 0.14582842588424683, 0.19925440847873688, 0.17609508335590363, 0.07921857386827469], [0.015186798758804798, 0.1123381182551384, 0.1652667224407196, 0.0004855591687373817, 0.13831879198551178, 0.4907431900501251, 0.06246645748615265, 0.015194379724562168], [0.00832256581634283, 0.06497923284769058, 0.1799437403678894, 0.001872093416750431, 0.2018146812915802, 0.43377673625946045, 0.10106706619262695, 0.008223764598369598], [0.0024990399833768606, 0.14686310291290283, 0.09022654592990875, 0.0015537402359768748, 0.08703286200761795, 0.5877919793128967, 0.07964057475328445, 0.004392107017338276], [0.005027380306273699, 0.3575447201728821, 0.018137037754058838, 0.003361766692250967, 0.09899549186229706, 0.448180228471756, 0.034846238791942596, 0.033907223492860794]]], [[[5.88795192015823e-05, 0.007379208225756884, 0.0007603410631418228, 0.9898680448532104, 0.000367699540220201, 0.0008774503949098289, 0.0006608708063140512, 2.7442378268460743e-05], [0.0009252883028239012, 0.012623531743884087, 0.004039640072733164, 0.9735202789306641, 0.0028500177431851625, 0.0028325191233307123, 0.0027646117378026247, 0.00044417500612325966], [0.00038580954424105585, 0.013913517817854881, 0.00286171305924654, 0.97679203748703, 0.0015614980366081, 0.002350317779928446, 0.0019720573909580708, 0.00016302074072882533], [0.0017463361145928502, 0.026128558441996574, 0.005883733741939068, 0.9494104385375977, 0.004162055905908346, 0.0055825309827923775, 0.00625511072576046, 0.0008312296122312546], [0.00024252232105936855, 0.005251955706626177, 0.0011162406299263239, 0.9901575446128845, 0.0007108701975084841, 0.0011491839541122317, 0.0012549447128549218, 0.00011672069376800209], [0.000306810368783772, 0.007314222864806652, 0.0018770105671137571, 0.9837853908538818, 0.0016582240350544453, 0.0022891031112521887, 0.0025743155274540186, 0.00019485490338411182], [0.00015116817667149007, 0.006999715697020292, 0.0011240204330533743, 0.9881231188774109, 0.0008015820058062673, 0.0015211186837404966, 0.0012185655068606138, 6.079799641156569e-05], [4.1240007703891024e-05, 0.004824817646294832, 0.00047027351683937013, 0.9923921227455139, 0.0003761235566344112, 0.0012949089286848903, 0.000578280829358846, 2.2233507479541004e-05]], [[0.02790418639779091, 0.28926846385002136, 0.1198134571313858, 0.1538480818271637, 0.10589999705553055, 0.11390068382024765, 0.1696539968252182, 0.019711114466190338], [0.11223170906305313, 0.1894255131483078, 0.19811424612998962, 0.14401136338710785, 0.12648577988147736, 0.07973537594079971, 0.11040444672107697, 0.03959154710173607], [0.0468226857483387, 0.20333349704742432, 0.14093798398971558, 0.18042218685150146, 0.13443271815776825, 0.14018602669239044, 0.13129474222660065, 0.022570159286260605], [0.09545956552028656, 0.11850067228078842, 0.1319413185119629, 0.16074883937835693, 0.1330292820930481, 0.17707407474517822, 0.12659986317157745, 0.05664637312293053], [0.08455085754394531, 0.14826053380966187, 0.18159301578998566, 0.1287834793329239, 0.12191881239414215, 0.18768377602100372, 0.11890322715044022, 0.02830633521080017], [0.07172654569149017, 0.12404190003871918, 0.15686453878879547, 0.1831585168838501, 0.08482426404953003, 0.20657238364219666, 0.14119292795658112, 0.031618837267160416], [0.03631541505455971, 0.20155936479568481, 0.15512396395206451, 0.15970155596733093, 0.10127504914999008, 0.17273539304733276, 0.16091297566890717, 0.01237632054835558], [0.013986943289637566, 0.228408545255661, 0.0864604040980339, 0.30967193841934204, 0.07285728305578232, 0.15889722108840942, 0.1216285228729248, 0.008089106529951096]], [[0.009425907395780087, 0.5277581214904785, 0.2808416783809662, 0.09324675053358078, 0.006970786489546299, 0.017530610784888268, 0.05761812999844551, 0.006608086638152599], [0.034865666180849075, 0.14312316477298737, 0.7847540974617004, 0.00577192660421133, 0.0011390092549845576, 0.0016615643398836255, 0.018425801768898964, 0.010258781723678112], [0.00943141058087349, 0.2779046893119812, 0.5686995387077332, 0.06862269341945648, 0.006655559409409761, 0.009527585469186306, 0.05110389366745949, 0.008054598234593868], [0.0057036434300243855, 0.20527546107769012, 0.1447337120771408, 0.015928711742162704, 0.1583603024482727, 0.10982407629489899, 0.33750617504119873, 0.02266795001924038], [0.0009261250961571932, 0.0577777624130249, 0.025018546730279922, 0.010416101664304733, 0.025779642164707184, 0.2894198000431061, 0.5813658833503723, 0.009296129457652569], [0.00968738179653883, 0.1709979921579361, 0.10550153255462646, 0.009871277026832104, 0.0069312434643507, 0.049527570605278015, 0.5983930230140686, 0.049090009182691574], [0.03207367658615112, 0.37669309973716736, 0.394784539937973, 0.016850067302584648, 0.004332433454692364, 0.009737332351505756, 0.10427874326705933, 0.06125003844499588], [0.010752412490546703, 0.7174721360206604, 0.16809949278831482, 0.015564671717584133, 0.0015396354719996452, 0.007169830147176981, 0.0646425187587738, 0.014759337529540062]], [[0.001267151441425085, 0.3579751253128052, 0.051634788513183594, 0.021019069477915764, 0.02380487322807312, 0.19304515421390533, 0.3476438522338867, 0.003609978361055255], [0.0035351444967091084, 0.3062352240085602, 0.0647195428609848, 0.008964965119957924, 0.05059489980340004, 0.28521105647087097, 0.27289527654647827, 0.007844017818570137], [0.0013218334643170238, 0.3237901031970978, 0.09395860135555267, 0.009033910930156708, 0.04182176664471626, 0.21900878846645355, 0.3092379868030548, 0.0018270235741510987], [0.002649834379553795, 0.41818392276763916, 0.09977269917726517, 0.00793857779353857, 0.030727243050932884, 0.1935916692018509, 0.24383381009101868, 0.003302294295281172], [0.0015963052865117788, 0.1703265756368637, 0.09301941096782684, 0.013446426019072533, 0.044524919241666794, 0.42434388399124146, 0.2489769011735916, 0.003765610745176673], [0.003923519980162382, 0.18729431927204132, 0.07147179543972015, 0.0181699451059103, 0.12089401483535767, 0.29129859805107117, 0.29585033655166626, 0.011097477748990059], [0.001404016511514783, 0.2573532462120056, 0.10211199522018433, 0.003045335179194808, 0.05287310108542442, 0.2898092567920685, 0.29146093130111694, 0.0019420612370595336], [0.0009632257861085236, 0.336372047662735, 0.052415452897548676, 0.008743580430746078, 0.019828319549560547, 0.2663958668708801, 0.3129498064517975, 0.0023317746818065643]], [[0.000978425843641162, 0.7458084225654602, 0.04625275358557701, 0.07554216682910919, 0.0019205468706786633, 0.055682554841041565, 0.07199215888977051, 0.0018229922279715538], [0.007732245605438948, 0.4239504039287567, 0.1742626428604126, 0.12412595748901367, 0.014681173488497734, 0.09933192282915115, 0.14900797605514526, 0.006907687988132238], [0.0029816001188009977, 0.4690883159637451, 0.08424659818410873, 0.2794186770915985, 0.003606097074225545, 0.055516332387924194, 0.10312682390213013, 0.002015609061345458], [0.005748901516199112, 0.4929424226284027, 0.3014489412307739, 0.051793359220027924, 0.007419006433337927, 0.03881869837641716, 0.09199435263872147, 0.009834352880716324], [0.001592949265614152, 0.3990585505962372, 0.05025423318147659, 0.4235426187515259, 0.003790296381339431, 0.03763643652200699, 0.08156238496303558, 0.002562546404078603], [0.007034344132989645, 0.3633005619049072, 0.06122468039393425, 0.3234921991825104, 0.02988213673233986, 0.07572869956493378, 0.12940075993537903, 0.009936686605215073], [0.0036746282130479813, 0.36744287610054016, 0.046010084450244904, 0.2985045313835144, 0.01580691896378994, 0.13075877726078033, 0.1337219625711441, 0.004080104175955057], [0.0009256224147975445, 0.6555811166763306, 0.022227898240089417, 0.17713043093681335, 0.002536712447181344, 0.05376172065734863, 0.08586429059505463, 0.001972207799553871]], [[0.030324671417474747, 0.43904080986976624, 0.19614681601524353, 0.03861849755048752, 0.027173178270459175, 0.06486987322568893, 0.179896280169487, 0.02392987161874771], [0.000439027207903564, 0.9006403088569641, 0.038121964782476425, 0.0011705075157806277, 0.00020304448844399303, 0.002028438728302717, 0.056353721767663956, 0.0010430768597871065], [0.0037794304080307484, 0.41395309567451477, 0.3913574516773224, 0.011775973252952099, 0.0008825580007396638, 0.004974419716745615, 0.16831159591674805, 0.004965482745319605], [0.0029333624988794327, 0.026422126218676567, 0.01061045378446579, 0.940638542175293, 0.0005982857546769083, 0.0026293888222426176, 0.010320302098989487, 0.005847468040883541], [0.0018628062680363655, 0.00973010528832674, 0.010667088441550732, 0.0006919155712239444, 0.5031436681747437, 0.42381712794303894, 0.04663444682955742, 0.0034528651740401983], [0.0015151721891015768, 0.06891322135925293, 0.030775371938943863, 0.0011676591821014881, 0.14550495147705078, 0.6055426001548767, 0.14360009133815765, 0.002981009893119335], [0.0004975224146619439, 0.3077434301376343, 0.17097525298595428, 0.0015573203563690186, 0.004458545707166195, 0.022496776655316353, 0.4905921220779419, 0.0016790220979601145], [0.0037380775902420282, 0.5952109694480896, 0.10298000276088715, 0.004094358999282122, 0.017723629251122475, 0.04587043449282646, 0.22463423013687134, 0.005748217459768057]], [[0.1864355206489563, 0.08434133976697922, 0.40687644481658936, 0.06704044342041016, 0.019598327577114105, 0.028962280601263046, 0.12479685992002487, 0.08194878697395325], [0.04208996519446373, 0.39119771122932434, 0.13049347698688507, 0.14052194356918335, 0.00802389346063137, 0.043623071163892746, 0.1828797459602356, 0.061170145869255066], [0.08820269256830215, 0.09409049898386002, 0.4806511402130127, 0.11548364907503128, 0.014830002561211586, 0.028330249711871147, 0.1161322221159935, 0.062279582023620605], [0.15313401818275452, 0.09337721019983292, 0.16056306660175323, 0.18991902470588684, 0.11872527003288269, 0.05328468233346939, 0.16140468418598175, 0.0695919618010521], [0.0837445855140686, 0.10327202826738358, 0.03287111595273018, 0.16280855238437653, 0.36175987124443054, 0.0846603736281395, 0.08489255607128143, 0.08599100261926651], [0.059960417449474335, 0.130484476685524, 0.04390202835202217, 0.15049907565116882, 0.0519937127828598, 0.20046336948871613, 0.18689967691898346, 0.1757972091436386], [0.04393398389220238, 0.24136723577976227, 0.09879595786333084, 0.12329603731632233, 0.03307538479566574, 0.12081290781497955, 0.25109508633613586, 0.08762345463037491], [0.10863935947418213, 0.11633483320474625, 0.16700752079486847, 0.11740868538618088, 0.0953332781791687, 0.13514702022075653, 0.16212864220142365, 0.09800069034099579]], [[0.019091138616204262, 0.16900783777236938, 0.12485898286104202, 0.2063550502061844, 0.10338599234819412, 0.13962601125240326, 0.2074039727449417, 0.030270973220467567], [0.03243716433644295, 0.10367967188358307, 0.16686157882213593, 0.16209933161735535, 0.16585507988929749, 0.11703715473413467, 0.19941005110740662, 0.05261998251080513], [0.04884108901023865, 0.05910405144095421, 0.17598332464694977, 0.23490594327449799, 0.14246003329753876, 0.08737947046756744, 0.19299708306789398, 0.058329030871391296], [0.10302206128835678, 0.05164572596549988, 0.12136603891849518, 0.225076824426651, 0.14406658709049225, 0.0717863067984581, 0.15356813371181488, 0.12946829199790955], [0.03127763792872429, 0.07451357692480087, 0.14956164360046387, 0.08839619904756546, 0.20429064333438873, 0.16866850852966309, 0.22907030582427979, 0.05422138795256615], [0.03086024522781372, 0.0842084214091301, 0.1659587174654007, 0.11967097967863083, 0.1369953602552414, 0.15486671030521393, 0.263641357421875, 0.043798163533210754], [0.027970049530267715, 0.0844772607088089, 0.15992310643196106, 0.12534618377685547, 0.14657893776893616, 0.14386919140815735, 0.27400824427604675, 0.037827011197805405], [0.010289612226188183, 0.1888853907585144, 0.09967488795518875, 0.18256071209907532, 0.090428426861763, 0.1830396205186844, 0.23255573213100433, 0.012565646320581436]], [[0.002787940204143524, 0.5181727409362793, 0.08099797368049622, 0.27508309483528137, 0.034924812614917755, 0.015736453235149384, 0.07091492414474487, 0.001382063957862556], [0.011189829558134079, 0.2921106517314911, 0.17000333964824677, 0.2531542479991913, 0.06564958393573761, 0.03905444219708443, 0.15765850245952606, 0.011179295368492603], [0.004204551223665476, 0.2137012630701065, 0.09584631025791168, 0.3175714910030365, 0.1025397852063179, 0.060067810118198395, 0.20084339380264282, 0.005225415341556072], [0.02038242481648922, 0.5164024829864502, 0.12094774842262268, 0.0832250788807869, 0.046021513640880585, 0.04349931329488754, 0.1518508642911911, 0.017670540139079094], [0.0027860067784786224, 0.5254090428352356, 0.04832589998841286, 0.11829930543899536, 0.030241183936595917, 0.05774474889039993, 0.21266640722751617, 0.004527374170720577], [0.011918012984097004, 0.43379518389701843, 0.10873124748468399, 0.14455047249794006, 0.06511802226305008, 0.041026439517736435, 0.18165531754493713, 0.013205323368310928], [0.006682520266622305, 0.4683452844619751, 0.11580932885408401, 0.16581669449806213, 0.038704708218574524, 0.0300978384912014, 0.1689654290676117, 0.005578202195465565], [0.004367010667920113, 0.6783655285835266, 0.06310465186834335, 0.1840658336877823, 0.014683987945318222, 0.009155021980404854, 0.043672919273376465, 0.002584984293207526]], [[0.006120564416050911, 0.6684261560440063, 0.08678439259529114, 0.04712793603539467, 0.013382496312260628, 0.05985603481531143, 0.1104559525847435, 0.00784637127071619], [0.01655694842338562, 0.5398333668708801, 0.19223099946975708, 0.022381702437996864, 0.017723772674798965, 0.06806690990924835, 0.12497144192457199, 0.018234794959425926], [0.02005402185022831, 0.5383425354957581, 0.1480831652879715, 0.030326837673783302, 0.017734816297888756, 0.09941521286964417, 0.1305951029062271, 0.01544828899204731], [0.07821375131607056, 0.4681454300880432, 0.18802006542682648, 0.04468577727675438, 0.025225991383194923, 0.04891510680317879, 0.09442787617444992, 0.05236601084470749], [0.03013988584280014, 0.408437579870224, 0.24941718578338623, 0.026786692440509796, 0.01994185335934162, 0.1240658164024353, 0.12198997288942337, 0.01922098733484745], [0.016585994511842728, 0.41787272691726685, 0.1739387959241867, 0.021578524261713028, 0.04243113845586777, 0.15506722033023834, 0.16098465025424957, 0.011540938168764114], [0.012334802187979221, 0.3647679090499878, 0.2581341564655304, 0.03127456456422806, 0.042360369116067886, 0.12931615114212036, 0.15451499819755554, 0.007296985946595669], [0.0030075996182858944, 0.4031435549259186, 0.055903319269418716, 0.13249115645885468, 0.045138806104660034, 0.18554526567459106, 0.17093215882778168, 0.003838120959699154]], [[0.010780292563140392, 0.3919141888618469, 0.13689792156219482, 0.04943875968456268, 0.03910920023918152, 0.10697858035564423, 0.24748428165912628, 0.01739681325852871], [0.04281991347670555, 0.21946920454502106, 0.19382110238075256, 0.040978897362947464, 0.09281595796346664, 0.12298973649740219, 0.24183039367198944, 0.04527479037642479], [0.040724147111177444, 0.2976994216442108, 0.32404738664627075, 0.025324925780296326, 0.036372870206832886, 0.08955464512109756, 0.17265179753303528, 0.013624733313918114], [0.056780215352773666, 0.1731848269701004, 0.4457501769065857, 0.015138109214603901, 0.08602188527584076, 0.08262686431407928, 0.12293963134288788, 0.01755833998322487], [0.015163399279117584, 0.10648909211158752, 0.501767635345459, 0.06403045356273651, 0.15915179252624512, 0.08549545705318451, 0.06532187014818192, 0.0025803116150200367], [0.01218075305223465, 0.1075310930609703, 0.20792634785175323, 0.08939179033041, 0.34324488043785095, 0.14158083498477936, 0.09396625310182571, 0.004178142175078392], [0.012052178382873535, 0.11946482211351395, 0.19100485742092133, 0.0919918417930603, 0.3083083927631378, 0.16876031458377838, 0.10461771488189697, 0.0037998256739228964], [0.003623373107984662, 0.21661224961280823, 0.08962198346853256, 0.10058290511369705, 0.0946590006351471, 0.20674382150173187, 0.2807648181915283, 0.007391896098852158]], [[0.01878041960299015, 0.1158781498670578, 0.14744971692562103, 0.2023780196905136, 0.29867061972618103, 0.1379188448190689, 0.06579560786485672, 0.013128494843840599], [0.049754608422517776, 0.10235338658094406, 0.1977427899837494, 0.15657749772071838, 0.17895466089248657, 0.15466658771038055, 0.12129805237054825, 0.03865242376923561], [0.009825104847550392, 0.05723225325345993, 0.11131197959184647, 0.07972892373800278, 0.3813859224319458, 0.2160576730966568, 0.1316623091697693, 0.012795799411833286], [0.04119083285331726, 0.12196680158376694, 0.10565153509378433, 0.12188085168600082, 0.1866576075553894, 0.18699903786182404, 0.17164628207683563, 0.06400712579488754], [0.016682200133800507, 0.06696362048387527, 0.05468582734465599, 0.07115533202886581, 0.14089225232601166, 0.224049910902977, 0.38136279582977295, 0.04420802742242813], [0.030455857515335083, 0.0991642102599144, 0.07953805476427078, 0.09055594354867935, 0.13261348009109497, 0.19129601120948792, 0.3196966350078583, 0.056679874658584595], [0.027887847274541855, 0.12234976142644882, 0.12661035358905792, 0.12017568200826645, 0.17116869986057281, 0.1959102302789688, 0.20111815631389618, 0.03477933257818222], [0.03537941351532936, 0.23222680389881134, 0.15070277452468872, 0.23210690915584564, 0.1487005054950714, 0.10535015910863876, 0.07365421950817108, 0.021879179403185844]]], [[[0.04795191064476967, 0.4211066663265228, 0.20605625212192535, 0.04511100798845291, 0.021181762218475342, 0.038593072444200516, 0.16319413483142853, 0.056805118918418884], [0.008996053598821163, 0.8566842675209045, 0.07307830452919006, 0.004007827956229448, 0.0008276154985651374, 0.0026540826074779034, 0.045848947018384933, 0.007902771234512329], [0.026831800118088722, 0.39414793252944946, 0.3089258074760437, 0.05399496853351593, 0.016473952680826187, 0.015661055222153664, 0.15538284182548523, 0.028581688180565834], [0.026910966262221336, 0.352448970079422, 0.18758881092071533, 0.2363334745168686, 0.013023367151618004, 0.024120274931192398, 0.12297842651605606, 0.03659572824835777], [0.030565816909074783, 0.21023643016815186, 0.24155375361442566, 0.010491650551557541, 0.06810832023620605, 0.19694605469703674, 0.1912543922662735, 0.050843581557273865], [0.034639667719602585, 0.24948661029338837, 0.24668514728546143, 0.011259774677455425, 0.06003035977482796, 0.13734667003154755, 0.20838449895381927, 0.052167221903800964], [0.021366920322179794, 0.5302726626396179, 0.2512076795101166, 0.011312578804790974, 0.00874092523008585, 0.013489882461726665, 0.13978539407253265, 0.023823942989110947], [0.05780654028058052, 0.4898693561553955, 0.19272126257419586, 0.022894959896802902, 0.01231276523321867, 0.03149585425853729, 0.11860979348421097, 0.07428937405347824]], [[0.11033067852258682, 0.3615352511405945, 0.1341266930103302, 0.06602654606103897, 0.05877857282757759, 0.11334032565355301, 0.09250020235776901, 0.0633617639541626], [0.11019520461559296, 0.2841300964355469, 0.16972365975379944, 0.07036248594522476, 0.05179924517869949, 0.1010378822684288, 0.15295594930648804, 0.05979553237557411], [0.09350679069757462, 0.3018133044242859, 0.14527921378612518, 0.11690469086170197, 0.06204746663570404, 0.11889377981424332, 0.10696570575237274, 0.054588962346315384], [0.07797940075397491, 0.24344713985919952, 0.145686075091362, 0.08201980590820312, 0.0850968211889267, 0.16999371349811554, 0.12091482430696487, 0.07486224174499512], [0.144298255443573, 0.15717202425003052, 0.1156858280301094, 0.16126790642738342, 0.08080732077360153, 0.12669143080711365, 0.10540517419576645, 0.1086721196770668], [0.12355189025402069, 0.18218795955181122, 0.11368418484926224, 0.16320167481899261, 0.08392968773841858, 0.12443096935749054, 0.1143060252070427, 0.09470760077238083], [0.12034279108047485, 0.2642575800418854, 0.12078893184661865, 0.10640788823366165, 0.08321735262870789, 0.14125297963619232, 0.09351501613855362, 0.07021749764680862], [0.13727357983589172, 0.2867727279663086, 0.10914604365825653, 0.10569502413272858, 0.06648027896881104, 0.12174317985773087, 0.08925856649875641, 0.08363062143325806]], [[0.03279488906264305, 0.22209259867668152, 0.07056573778390884, 0.3998791575431824, 0.053682196885347366, 0.09569890797138214, 0.09166174381971359, 0.033624712377786636], [0.04560462012887001, 0.2720406651496887, 0.1077067106962204, 0.11130891740322113, 0.08083608001470566, 0.13148751854896545, 0.18003353476524353, 0.07098198682069778], [0.030361196026206017, 0.3083750009536743, 0.10166243463754654, 0.11449983716011047, 0.08161605149507523, 0.1472979485988617, 0.1741209179162979, 0.042066656053066254], [0.03956332802772522, 0.12683147192001343, 0.09094978123903275, 0.406335711479187, 0.0529659241437912, 0.10945715010166168, 0.11505638808012009, 0.05884028971195221], [0.032136350870132446, 0.2152116596698761, 0.09264104813337326, 0.3153262138366699, 0.05733110383152962, 0.09162930399179459, 0.1577303409576416, 0.037994034588336945], [0.04449749365448952, 0.21539171040058136, 0.11084846407175064, 0.21684320271015167, 0.0769648626446724, 0.1067068949341774, 0.17822620272636414, 0.05052122846245766], [0.03222905099391937, 0.2561529576778412, 0.10705415904521942, 0.1679692566394806, 0.07317394018173218, 0.12472379207611084, 0.20030003786087036, 0.03839684650301933], [0.03190399706363678, 0.19860060513019562, 0.09468395262956619, 0.47024208307266235, 0.0370870865881443, 0.06570605933666229, 0.07772839069366455, 0.024047931656241417]], [[0.005043832119554281, 0.7376813888549805, 0.16563114523887634, 0.019003935158252716, 0.0010786183411255479, 0.01533920131623745, 0.05347748100757599, 0.002744379686191678], [0.003242073580622673, 0.7832396030426025, 0.12659786641597748, 0.007739846128970385, 0.0016504129162058234, 0.02014031633734703, 0.0540275014936924, 0.003362386953085661], [0.004227422643452883, 0.6608908772468567, 0.24953120946884155, 0.02535916678607464, 0.0007762469467706978, 0.012080582790076733, 0.04423556476831436, 0.002898900071159005], [0.0158662311732769, 0.5436719059944153, 0.13994190096855164, 0.161050483584404, 0.0047978805378079414, 0.040920697152614594, 0.07964575290679932, 0.014105177484452724], [0.009742096066474915, 0.42475688457489014, 0.07778072357177734, 0.12467052787542343, 0.0363217331469059, 0.22143366932868958, 0.09271444380283356, 0.012579837813973427], [0.006725260056555271, 0.675683856010437, 0.08418485522270203, 0.04984145238995552, 0.006580502260476351, 0.09529591351747513, 0.07249592989683151, 0.009192191064357758], [0.005608686245977879, 0.6755355000495911, 0.12110333144664764, 0.044298455119132996, 0.004413624759763479, 0.055255480110645294, 0.0866248682141304, 0.007160031236708164], [0.004328109323978424, 0.7892269492149353, 0.10560766607522964, 0.02436288632452488, 0.0013395396526902914, 0.01714319735765457, 0.05449816584587097, 0.003493516705930233]], [[0.02804459072649479, 0.14134329557418823, 0.0901423990726471, 0.18038176000118256, 0.17140404880046844, 0.2651415467262268, 0.10332061350345612, 0.020221799612045288], [0.06123318150639534, 0.12142631411552429, 0.10476356744766235, 0.20078998804092407, 0.18219594657421112, 0.1663527935743332, 0.11470452696084976, 0.04853377491235733], [0.041539955884218216, 0.12396133691072464, 0.08449432253837585, 0.2509377598762512, 0.14457175135612488, 0.23744797706604004, 0.09004765748977661, 0.026999276131391525], [0.05719687417149544, 0.15610121190547943, 0.10386724770069122, 0.15169550478458405, 0.2018212378025055, 0.1675063669681549, 0.10547927021980286, 0.056332193315029144], [0.02355794794857502, 0.11055468022823334, 0.07065888494253159, 0.11397312581539154, 0.2638469636440277, 0.30923253297805786, 0.09093494713306427, 0.01724100112915039], [0.03638549521565437, 0.12030600011348724, 0.07657202333211899, 0.18185289204120636, 0.17935557663440704, 0.30799877643585205, 0.07520562410354614, 0.022323518991470337], [0.035894375294446945, 0.10647768527269363, 0.06804388761520386, 0.20056654512882233, 0.19573400914669037, 0.2993236780166626, 0.07301908731460571, 0.020940721035003662], [0.021985534578561783, 0.13566575944423676, 0.07705311477184296, 0.1691989302635193, 0.1868930459022522, 0.3068544268608093, 0.08380241692066193, 0.01854681968688965]], [[0.04042252525687218, 0.024948488920927048, 0.01672709546983242, 0.7701460123062134, 0.0193442702293396, 0.02376391924917698, 0.018833404406905174, 0.08581426739692688], [0.04037826508283615, 0.18253877758979797, 0.12658841907978058, 0.3497426509857178, 0.08575405180454254, 0.0583646185696125, 0.10480598360300064, 0.051827285438776016], [0.04792587459087372, 0.17784370481967926, 0.10674911737442017, 0.37827420234680176, 0.06712190806865692, 0.05925379693508148, 0.09142906963825226, 0.07140231877565384], [0.0009559370810166001, 0.00034750025952234864, 0.0004991249297745526, 0.9947347640991211, 0.0008509564795531332, 0.0004075019678566605, 0.0004334052209742367, 0.0017709071980789304], [0.05396096780896187, 0.09610860049724579, 0.06524767726659775, 0.3670860230922699, 0.13786806166172028, 0.11187145859003067, 0.07875093072652817, 0.08910626918077469], [0.047963760793209076, 0.08610309660434723, 0.07417682558298111, 0.3917948603630066, 0.10895668715238571, 0.13489581644535065, 0.07355406880378723, 0.08255482465028763], [0.04914803430438042, 0.1718800961971283, 0.10807521641254425, 0.3501322269439697, 0.08429833501577377, 0.06274186819791794, 0.0944989025592804, 0.07922538369894028], [0.03724655508995056, 0.024900469928979874, 0.018094036728143692, 0.7613639831542969, 0.02733662910759449, 0.026785925030708313, 0.01916174590587616, 0.08511056005954742]], [[0.03188353404402733, 0.511184573173523, 0.1597106009721756, 0.022143688052892685, 0.043185509741306305, 0.06234342232346535, 0.14102767407894135, 0.028521062806248665], [0.0017615663819015026, 0.8981658816337585, 0.04109039157629013, 0.0005018776282668114, 0.0012048630742356181, 0.0032116109505295753, 0.052281565964221954, 0.0017821298679336905], [0.009091267362236977, 0.6442596316337585, 0.13651461899280548, 0.004001195542514324, 0.007784279063344002, 0.016960792243480682, 0.1709865927696228, 0.01040148176252842], [0.03212040290236473, 0.14748117327690125, 0.06874439865350723, 0.6455654501914978, 0.005228075198829174, 0.008751554414629936, 0.06446496397256851, 0.027643924579024315], [0.052914660423994064, 0.19895592331886292, 0.18615847826004028, 0.015498636290431023, 0.095477394759655, 0.22269578278064728, 0.1955156922340393, 0.03278351202607155], [0.030748700723052025, 0.29215359687805176, 0.16445837914943695, 0.00992680061608553, 0.07339145988225937, 0.22818081080913544, 0.18619036674499512, 0.014949933625757694], [0.01353136170655489, 0.5584908723831177, 0.17426088452339172, 0.003455230500549078, 0.010983716696500778, 0.026480959728360176, 0.19961120188236237, 0.013185703195631504], [0.03081732615828514, 0.5714689493179321, 0.1301819384098053, 0.01647958531975746, 0.0377778634428978, 0.06376637518405914, 0.12145023792982101, 0.028057821094989777]], [[0.019646216183900833, 0.20684820413589478, 0.07473023235797882, 0.2412721812725067, 0.14333799481391907, 0.22959831357002258, 0.06406190991401672, 0.020505035296082497], [0.06639131158590317, 0.23506216704845428, 0.13474394381046295, 0.10041003674268723, 0.10588838905096054, 0.1656784564256668, 0.10221553593873978, 0.08961009979248047], [0.02053840085864067, 0.1881178766489029, 0.08608412742614746, 0.12258540838956833, 0.17520900070667267, 0.259155809879303, 0.112428218126297, 0.035881198942661285], [0.028311092406511307, 0.19442391395568848, 0.07986999303102493, 0.11764989048242569, 0.14986839890480042, 0.263098806142807, 0.11470767110586166, 0.05207020789384842], [0.01136672031134367, 0.09479974210262299, 0.02935594506561756, 0.07482220232486725, 0.1610030084848404, 0.44363489747047424, 0.14058227837085724, 0.04443517327308655], [0.020944150164723396, 0.10006022453308105, 0.04376474395394325, 0.06118186563253403, 0.19007307291030884, 0.3874695897102356, 0.1314706802368164, 0.06503564864397049], [0.03610507398843765, 0.1389520764350891, 0.07623682916164398, 0.10129818320274353, 0.1432119458913803, 0.2837756872177124, 0.1355055570602417, 0.08491464704275131], [0.02259771339595318, 0.2595677971839905, 0.07865019142627716, 0.22116607427597046, 0.09167177230119705, 0.21388311684131622, 0.08313499391078949, 0.02932828664779663]], [[0.12284955382347107, 0.16421517729759216, 0.19535671174526215, 0.14562438428401947, 0.042630333453416824, 0.08295127004384995, 0.10436484217643738, 0.1420077383518219], [0.12935657799243927, 0.10141196846961975, 0.13172167539596558, 0.22774234414100647, 0.04611003026366234, 0.11776071786880493, 0.09330712258815765, 0.1525895744562149], [0.09039470553398132, 0.13499605655670166, 0.10170593112707138, 0.3448450267314911, 0.04849496856331825, 0.10709087550640106, 0.0629495158791542, 0.10952282696962357], [0.11639437824487686, 0.26442089676856995, 0.2816488444805145, 0.004214864689856768, 0.040247078984975815, 0.11625227332115173, 0.10828915238380432, 0.06853238493204117], [0.16494056582450867, 0.0985172837972641, 0.1469876915216446, 0.32494020462036133, 0.016435731202363968, 0.021154936403036118, 0.05223306268453598, 0.17479059100151062], [0.16603010892868042, 0.14040160179138184, 0.160994753241539, 0.26029831171035767, 0.022563621401786804, 0.02273542992770672, 0.06726158410310745, 0.15971457958221436], [0.1307903677225113, 0.1535664051771164, 0.11802860349416733, 0.27495330572128296, 0.04322778433561325, 0.08201650530099869, 0.05854329839348793, 0.13887366652488708], [0.15639232099056244, 0.2179294377565384, 0.1904129832983017, 0.09454604983329773, 0.03467670828104019, 0.06911864876747131, 0.08968275040388107, 0.14724108576774597]], [[0.004398063290864229, 0.5496929287910461, 0.1057557463645935, 0.021077489480376244, 0.05874355137348175, 0.11590525507926941, 0.14055801928043365, 0.00386891164816916], [0.01943165250122547, 0.44512563943862915, 0.16796310245990753, 0.021162962540984154, 0.07289423048496246, 0.09725835919380188, 0.1582595556974411, 0.017904605716466904], [0.007886803708970547, 0.544357419013977, 0.148586243391037, 0.012238672003149986, 0.050222139805555344, 0.09186360239982605, 0.13973882794380188, 0.005106181371957064], [0.032555822283029556, 0.40608200430870056, 0.2268708348274231, 0.01956729032099247, 0.0695853978395462, 0.09933874011039734, 0.12583181262016296, 0.020168039947748184], [0.014479600824415684, 0.3776332139968872, 0.23388484120368958, 0.02249825745820999, 0.06932634860277176, 0.13157862424850464, 0.1417698860168457, 0.00882936455309391], [0.021108942106366158, 0.32981613278388977, 0.23442040383815765, 0.02387557178735733, 0.09494113177061081, 0.11330848187208176, 0.17020545899868011, 0.012323872186243534], [0.008982602506875992, 0.4037751853466034, 0.18688705563545227, 0.015665875747799873, 0.09597354382276535, 0.11953261494636536, 0.16416500508785248, 0.005018157418817282], [0.003797098994255066, 0.49311599135398865, 0.14419670403003693, 0.038054078817367554, 0.05872008576989174, 0.12955962121486664, 0.13039018213748932, 0.0021661727223545313]], [[0.006705335807055235, 0.5573375821113586, 0.08946319669485092, 0.0776490718126297, 0.02652028203010559, 0.08760607242584229, 0.14953118562698364, 0.0051873852498829365], [0.03175860643386841, 0.27040815353393555, 0.15241217613220215, 0.09430947154760361, 0.07945224642753601, 0.11659041047096252, 0.23186424374580383, 0.023204706609249115], [0.016694672405719757, 0.38812971115112305, 0.1268596202135086, 0.06491867452859879, 0.04842737689614296, 0.10786229372024536, 0.23540392518043518, 0.011703629978001118], [0.029861250892281532, 0.36493977904319763, 0.1526937186717987, 0.09861487150192261, 0.05586576089262962, 0.10076569765806198, 0.17302967607975006, 0.024229202419519424], [0.008855830878019333, 0.4364308714866638, 0.1195569634437561, 0.047575801610946655, 0.029980067163705826, 0.11734341084957123, 0.2305312305688858, 0.009725905023515224], [0.014983692206442356, 0.3337787091732025, 0.107808917760849, 0.04971713945269585, 0.055686552077531815, 0.11669441312551498, 0.30541443824768066, 0.015916114673018456], [0.01805647648870945, 0.30054405331611633, 0.13735614717006683, 0.0808245986700058, 0.05783633515238762, 0.14085249602794647, 0.2533363103866577, 0.011193529702723026], [0.006326618138700724, 0.5259522199630737, 0.08274267613887787, 0.12043632566928864, 0.029097318649291992, 0.09845460206270218, 0.13262471556663513, 0.004365514498203993]], [[0.06279348582029343, 0.3317365348339081, 0.5366539359092712, 0.049229998141527176, 0.0001085040858015418, 0.00041024666279554367, 0.00942041166126728, 0.009646927937865257], [0.03489125892519951, 0.6853089928627014, 0.1907998025417328, 0.04265640303492546, 0.0007039212505333126, 0.0024555225390940905, 0.02583310380578041, 0.01735106110572815], [0.06585424393415451, 0.26289722323417664, 0.6287809610366821, 0.02737409807741642, 0.00012369586329441518, 0.0002873605117201805, 0.007308755069971085, 0.007373598869889975], [0.11475756764411926, 0.331272691488266, 0.2401401549577713, 0.2219802588224411, 0.004016598220914602, 0.006947598420083523, 0.031263403594493866, 0.04962160065770149], [0.013845114968717098, 0.3182391822338104, 0.11471080034971237, 0.3383345901966095, 0.04985252767801285, 0.03723425418138504, 0.10652396082878113, 0.021259557455778122], [0.011346105486154556, 0.33257097005844116, 0.061067886650562286, 0.1380329132080078, 0.030519874766469002, 0.1961301565170288, 0.2019553780555725, 0.028376728296279907], [0.024843739345669746, 0.47930625081062317, 0.21843421459197998, 0.08369679003953934, 0.0039995512925088406, 0.01898593083024025, 0.14053651690483093, 0.03019709512591362], [0.04184970259666443, 0.4843900501728058, 0.27898138761520386, 0.11413271725177765, 0.0011100583942607045, 0.004593041259795427, 0.044316522777080536, 0.030626511201262474]]], [[[0.03426762670278549, 0.3609254062175751, 0.10506373643875122, 0.10354841500520706, 0.045268718153238297, 0.21800023317337036, 0.10496368259191513, 0.027962232008576393], [0.03273973986506462, 0.4409143030643463, 0.1361485868692398, 0.06301937252283096, 0.03611334040760994, 0.14770419895648956, 0.11947467178106308, 0.02388571947813034], [0.03592599555850029, 0.3650032877922058, 0.12455830723047256, 0.11590855568647385, 0.0415470227599144, 0.19526664912700653, 0.09885907173156738, 0.022931018844246864], [0.05441131070256233, 0.30222272872924805, 0.11749175935983658, 0.1314891278743744, 0.06393995881080627, 0.18080376088619232, 0.10780493170022964, 0.04183638095855713], [0.016533875837922096, 0.34486812353134155, 0.07166611403226852, 0.09890951216220856, 0.03205233812332153, 0.3218047022819519, 0.09374715387821198, 0.02041819877922535], [0.023374361917376518, 0.2265123575925827, 0.07186409831047058, 0.12342788279056549, 0.05636276677250862, 0.3499513566493988, 0.11939697712659836, 0.029110193252563477], [0.03249906003475189, 0.3167441189289093, 0.08308162540197372, 0.10535992681980133, 0.04351316764950752, 0.297801673412323, 0.09715867042541504, 0.023841673508286476], [0.034278836101293564, 0.32624608278274536, 0.08880322426557541, 0.11927737295627594, 0.04629398137331009, 0.26630398631095886, 0.08899593353271484, 0.0298005361109972]], [[0.04716506227850914, 0.19862526655197144, 0.20843759179115295, 0.09680280834436417, 0.07551208138465881, 0.06858915835618973, 0.23899783194065094, 0.06587020307779312], [0.04879755526781082, 0.18488606810569763, 0.1928447186946869, 0.11073794960975647, 0.07349734753370285, 0.07306954264640808, 0.2493879646062851, 0.06677881628274918], [0.04248003661632538, 0.19574086368083954, 0.1961679756641388, 0.09396225959062576, 0.08185150474309921, 0.07966373860836029, 0.2528407871723175, 0.05729277804493904], [0.054460328072309494, 0.18769137561321259, 0.22430674731731415, 0.0481792688369751, 0.06763637065887451, 0.06380756944417953, 0.2838839888572693, 0.07003430277109146], [0.046981748193502426, 0.18919633328914642, 0.20094266533851624, 0.11650735139846802, 0.05365181714296341, 0.06923634558916092, 0.26608729362487793, 0.05739644542336464], [0.038864973932504654, 0.16612502932548523, 0.2030518501996994, 0.09007281064987183, 0.05826938897371292, 0.08176817744970322, 0.3154829740524292, 0.04636470973491669], [0.02769208326935768, 0.1843372881412506, 0.1880602240562439, 0.09926370531320572, 0.06742329895496368, 0.08726188540458679, 0.3116860091686249, 0.034275513142347336], [0.03643285483121872, 0.21742874383926392, 0.2142854779958725, 0.11341474950313568, 0.07035595923662186, 0.06599429994821548, 0.2345048189163208, 0.04758313298225403]], [[0.10144291818141937, 0.16593487560749054, 0.13333503901958466, 0.07736601680517197, 0.08319930732250214, 0.15534205734729767, 0.13062822818756104, 0.15275157988071442], [0.09190130978822708, 0.2065442055463791, 0.126150444149971, 0.04712488129734993, 0.08179733157157898, 0.12108947336673737, 0.16854767501354218, 0.1568446010351181], [0.09089992195367813, 0.16954724490642548, 0.14368152618408203, 0.07109662145376205, 0.09611689299345016, 0.14868614077568054, 0.1532938927412033, 0.1266777366399765], [0.08151523768901825, 0.1366434246301651, 0.13536234200000763, 0.05516352131962776, 0.10737966001033783, 0.19376826286315918, 0.16842488944530487, 0.12174271047115326], [0.07452107965946198, 0.13087338209152222, 0.11788050830364227, 0.043056637048721313, 0.09959544986486435, 0.238068088889122, 0.1796264350414276, 0.11637847125530243], [0.07040219008922577, 0.13382895290851593, 0.11615510284900665, 0.053289301693439484, 0.11104410886764526, 0.21795164048671722, 0.17936968803405762, 0.11795900017023087], [0.08798304945230484, 0.14724858105182648, 0.11914103478193283, 0.0389716736972332, 0.10211865603923798, 0.20055119693279266, 0.17702654004096985, 0.12695930898189545], [0.1075773537158966, 0.14533931016921997, 0.11410298198461533, 0.07030296325683594, 0.07670577615499496, 0.17580269277095795, 0.12730132043361664, 0.18286757171154022]], [[0.195155069231987, 0.1187509074807167, 0.1948373019695282, 0.09288527071475983, 0.058479759842157364, 0.055574022233486176, 0.12075384706258774, 0.1635637879371643], [0.12000962346792221, 0.13630671799182892, 0.2404385805130005, 0.057819999754428864, 0.08656689524650574, 0.06485246866941452, 0.19823509454727173, 0.09577056020498276], [0.1251610964536667, 0.11554493010044098, 0.23652803897857666, 0.05155028775334358, 0.09623227268457413, 0.07184945791959763, 0.20588292181491852, 0.09725095331668854], [0.16682791709899902, 0.10862334072589874, 0.18719805777072906, 0.1177777647972107, 0.09057316929101944, 0.06806445866823196, 0.12104668468236923, 0.13988859951496124], [0.13866664469242096, 0.10453826189041138, 0.21552373468875885, 0.06146574392914772, 0.11417536437511444, 0.0706004723906517, 0.1826392263174057, 0.11239047348499298], [0.10669784992933273, 0.13733728229999542, 0.21667581796646118, 0.06663558632135391, 0.10607344657182693, 0.07442565262317657, 0.1946437656879425, 0.09751062095165253], [0.10930659621953964, 0.10405059158802032, 0.2377491295337677, 0.049476027488708496, 0.10616450756788254, 0.07363700121641159, 0.23291118443012238, 0.08670505881309509], [0.16296371817588806, 0.13800613582134247, 0.20308999717235565, 0.09586956351995468, 0.06273923814296722, 0.06396222114562988, 0.1320079118013382, 0.14136123657226562]], [[0.15560707449913025, 0.21281129121780396, 0.11924853175878525, 0.22104595601558685, 0.02859402820467949, 0.06535732746124268, 0.07902299612760544, 0.11831280589103699], [0.1582924872636795, 0.2616695165634155, 0.13266217708587646, 0.14536184072494507, 0.02065753936767578, 0.058523163199424744, 0.09539755433797836, 0.12743568420410156], [0.1607280969619751, 0.1409023255109787, 0.13063688576221466, 0.26436465978622437, 0.030585987493395805, 0.06653432548046112, 0.0823194682598114, 0.12392832338809967], [0.12704181671142578, 0.14723774790763855, 0.08565595746040344, 0.38602587580680847, 0.027184853330254555, 0.06612322479486465, 0.06425934284925461, 0.09647113084793091], [0.12745454907417297, 0.0921587347984314, 0.0834379568696022, 0.22309339046478271, 0.07228954881429672, 0.210936039686203, 0.08430146425962448, 0.10632821917533875], [0.16329911351203918, 0.10771370679140091, 0.0854518786072731, 0.20240052044391632, 0.04873846471309662, 0.17088298499584198, 0.08668091148138046, 0.1348324418067932], [0.15384306013584137, 0.1663200557231903, 0.10902450233697891, 0.21316930651664734, 0.03299287334084511, 0.10679883509874344, 0.09586820751428604, 0.12198316305875778], [0.12363787740468979, 0.26088473200798035, 0.11113155633211136, 0.221024751663208, 0.02485981583595276, 0.07751499116420746, 0.07933720201253891, 0.10160911083221436]], [[0.08189762383699417, 0.045624811202287674, 0.08060748130083084, 0.1155969649553299, 0.14173245429992676, 0.3262786269187927, 0.11454109847545624, 0.09372100234031677], [0.0815298855304718, 0.06534897536039352, 0.08804725110530853, 0.11711528897285461, 0.1507803499698639, 0.2784218490123749, 0.12471987307071686, 0.09403650462627411], [0.07721471041440964, 0.05527224391698837, 0.08214680850505829, 0.1431189775466919, 0.14924822747707367, 0.2992072105407715, 0.11396265774965286, 0.079829141497612], [0.08400632441043854, 0.05320684239268303, 0.08192962408065796, 0.12060703337192535, 0.15823304653167725, 0.2780155539512634, 0.10352802276611328, 0.12047352641820908], [0.05388465151190758, 0.03915076702833176, 0.06955637782812119, 0.10391746461391449, 0.1585777848958969, 0.38995885848999023, 0.12151845544576645, 0.06343569606542587], [0.06661809235811234, 0.040653154253959656, 0.06510281562805176, 0.08437220752239227, 0.15248247981071472, 0.39106103777885437, 0.12454180419445038, 0.0751684159040451], [0.06483283638954163, 0.05245688185095787, 0.06978869438171387, 0.0993552953004837, 0.1609317809343338, 0.3489384055137634, 0.12992985546588898, 0.07376620918512344], [0.07577367126941681, 0.04821208119392395, 0.07378263771533966, 0.13122932612895966, 0.13428598642349243, 0.3334631621837616, 0.10911588370800018, 0.0941372960805893]], [[0.08310914039611816, 0.2064969539642334, 0.10811816900968552, 0.345400869846344, 0.015729263424873352, 0.03931385651230812, 0.08960969001054764, 0.11222200840711594], [0.09036678820848465, 0.3763680160045624, 0.11451045423746109, 0.18868906795978546, 0.008352654986083508, 0.02796957455575466, 0.08904243260622025, 0.10470102727413177], [0.0902029499411583, 0.21373283863067627, 0.12876924872398376, 0.33438509702682495, 0.012014967389404774, 0.029788685962557793, 0.07652676105499268, 0.1145794466137886], [0.03736543655395508, 0.07996700704097748, 0.05409551411867142, 0.7100082635879517, 0.01280169002711773, 0.02456521987915039, 0.037549495697021484, 0.04364737123250961], [0.06877334415912628, 0.14591531455516815, 0.09642527997493744, 0.3804735243320465, 0.03619282320141792, 0.08197008073329926, 0.10706651955842972, 0.08318313956260681], [0.07187484949827194, 0.1654009371995926, 0.09427924454212189, 0.3251737654209137, 0.03404957428574562, 0.0898762196302414, 0.11797990649938583, 0.10136548429727554], [0.09981223195791245, 0.22280745208263397, 0.13358429074287415, 0.22392280399799347, 0.017354842275381088, 0.04494938254356384, 0.12145242094993591, 0.13611648976802826], [0.07719621062278748, 0.23019425570964813, 0.11091252416372299, 0.3174605965614319, 0.014535000547766685, 0.04102879390120506, 0.09745429456233978, 0.11121831834316254]], [[0.09919381141662598, 0.14323556423187256, 0.10249660164117813, 0.4024888873100281, 0.022957293316721916, 0.05305824056267738, 0.11495794355869293, 0.06161164864897728], [0.1175188347697258, 0.16705861687660217, 0.12178725004196167, 0.2862214744091034, 0.026617513969540596, 0.06665550917387009, 0.12741023302078247, 0.08673063665628433], [0.10615575313568115, 0.12439107894897461, 0.09245048463344574, 0.4506777226924896, 0.01990559883415699, 0.04966563358902931, 0.08537683635950089, 0.07137680053710938], [0.10553780943155289, 0.12135501950979233, 0.144041508436203, 0.29912981390953064, 0.030980076640844345, 0.06441245228052139, 0.14975719153881073, 0.08478618413209915], [0.11717642098665237, 0.15532752871513367, 0.13334257900714874, 0.27015435695648193, 0.02766721323132515, 0.08047929406166077, 0.1384533941745758, 0.07739924639463425], [0.11936930567026138, 0.1429489403963089, 0.10529310256242752, 0.31779393553733826, 0.0315108597278595, 0.08073148131370544, 0.12157193571329117, 0.0807805061340332], [0.12131260335445404, 0.14573736488819122, 0.0943417176604271, 0.33574414253234863, 0.026459213346242905, 0.07565423846244812, 0.1149248406291008, 0.08582579344511032], [0.12583573162555695, 0.16157983243465424, 0.10014414042234421, 0.34513798356056213, 0.021776288747787476, 0.059207331389188766, 0.11286615580320358, 0.07345248758792877]], [[0.08898507058620453, 0.14400404691696167, 0.08883011341094971, 0.10340580344200134, 0.09562723338603973, 0.19303838908672333, 0.13947491347789764, 0.14663442969322205], [0.13672220706939697, 0.16350699961185455, 0.10508527606725693, 0.05416061356663704, 0.09013549983501434, 0.15470543503761292, 0.14497487246990204, 0.15070906281471252], [0.08672735840082169, 0.1734497994184494, 0.10669359564781189, 0.07171116769313812, 0.08854474872350693, 0.2002781331539154, 0.1534363329410553, 0.11915881186723709], [0.10271009802818298, 0.13223986327648163, 0.13395826518535614, 0.05574493855237961, 0.08385204523801804, 0.19538408517837524, 0.13946501910686493, 0.15664564073085785], [0.06595612317323685, 0.11150970309972763, 0.08468039333820343, 0.11340169608592987, 0.16367262601852417, 0.2074728161096573, 0.15692228078842163, 0.09638440608978271], [0.057196516543626785, 0.09050609916448593, 0.07493606954813004, 0.0953080952167511, 0.2232586294412613, 0.22159765660762787, 0.16592782735824585, 0.07126914709806442], [0.0668707937002182, 0.12312636524438858, 0.0737847089767456, 0.08301954716444016, 0.1483539640903473, 0.25382858514785767, 0.1644795536994934, 0.08653648942708969], [0.07481459528207779, 0.11704977601766586, 0.0807509645819664, 0.13288196921348572, 0.13997802138328552, 0.21774521470069885, 0.1305825114250183, 0.10619697719812393]], [[0.12145582586526871, 0.14392729103565216, 0.09153082221746445, 0.4081767201423645, 0.04731970280408859, 0.08023729175329208, 0.0400669202208519, 0.06728539615869522], [0.12814243137836456, 0.12152670323848724, 0.08660624921321869, 0.3838147819042206, 0.05875036492943764, 0.07942808419466019, 0.05858435109257698, 0.08314710855484009], [0.09573391079902649, 0.12468650192022324, 0.11173815280199051, 0.44330790638923645, 0.05795197933912277, 0.0722302794456482, 0.04804682359099388, 0.046304427087306976], [0.15819735825061798, 0.13865776360034943, 0.091505266726017, 0.22477655112743378, 0.0919458419084549, 0.12068609148263931, 0.06505435705184937, 0.10917677730321884], [0.06403770297765732, 0.14337997138500214, 0.08809852600097656, 0.3558674156665802, 0.08619733899831772, 0.1410144418478012, 0.07941524684429169, 0.04198942333459854], [0.09099990129470825, 0.13743816316127777, 0.07394960522651672, 0.31229168176651, 0.10793932527303696, 0.13948757946491241, 0.0751783549785614, 0.06271538138389587], [0.08893391489982605, 0.12401826679706573, 0.0675341784954071, 0.42319566011428833, 0.07738140225410461, 0.10369537770748138, 0.05688313767313957, 0.05835812911391258], [0.125366672873497, 0.14926332235336304, 0.0687413364648819, 0.41511303186416626, 0.0334291085600853, 0.07849569618701935, 0.03490610048174858, 0.09468485414981842]], [[0.08594363927841187, 0.62678462266922, 0.13342221081256866, 0.005623314529657364, 0.004025512840598822, 0.015094200149178505, 0.0787883922457695, 0.050318095833063126], [0.2254253327846527, 0.28911086916923523, 0.14496034383773804, 0.022338800132274628, 0.030325839295983315, 0.052361685782670975, 0.10268275439739227, 0.13279442489147186], [0.09024985134601593, 0.5884751677513123, 0.15940850973129272, 0.00842446181923151, 0.0053010741248726845, 0.01383327879011631, 0.07721952348947525, 0.05708809569478035], [0.1943131983280182, 0.21107973158359528, 0.23784376680850983, 0.024885255843400955, 0.026015540584921837, 0.04114844277501106, 0.16115736961364746, 0.10355664044618607], [0.28220877051353455, 0.08039260655641556, 0.13411660492420197, 0.08468952029943466, 0.13839319348335266, 0.07206800580024719, 0.08303432911634445, 0.12509691715240479], [0.15541860461235046, 0.0675390437245369, 0.061793118715286255, 0.023744968697428703, 0.38596343994140625, 0.1443185806274414, 0.07254449278116226, 0.08867783844470978], [0.1860445737838745, 0.181143119931221, 0.09279599040746689, 0.014290728606283665, 0.09259878098964691, 0.1822599321603775, 0.12755030393600464, 0.12331660091876984], [0.14795175194740295, 0.33865588903427124, 0.13960033655166626, 0.009903770871460438, 0.0186313409358263, 0.07392636686563492, 0.16369052231311798, 0.10764006525278091]], [[0.28592604398727417, 0.09219077229499817, 0.0589396134018898, 0.1262226700782776, 0.010075229220092297, 0.06643742322921753, 0.10486944764852524, 0.2553389072418213], [0.15574796497821808, 0.20912158489227295, 0.044726260006427765, 0.12461375445127487, 0.020742978900671005, 0.12121348083019257, 0.13198450207710266, 0.19184942543506622], [0.29996925592422485, 0.0990082174539566, 0.1119697317481041, 0.12983238697052002, 0.014567526057362556, 0.05506220832467079, 0.09249041229486465, 0.19710031151771545], [0.13147269189357758, 0.1588916927576065, 0.03577204793691635, 0.3068106770515442, 0.023024076595902443, 0.07207753509283066, 0.08364766836166382, 0.18830358982086182], [0.15644219517707825, 0.1519242525100708, 0.036126285791397095, 0.20249874889850616, 0.05528121441602707, 0.07575556635856628, 0.09856913238763809, 0.22340258955955505], [0.17669931054115295, 0.16919760406017303, 0.031626299023628235, 0.15330344438552856, 0.013377699069678783, 0.11663349717855453, 0.11088955402374268, 0.22827260196208954], [0.20365504920482635, 0.13692225515842438, 0.04070938006043434, 0.13302290439605713, 0.015745429322123528, 0.08330196887254715, 0.11961980164051056, 0.2670232057571411], [0.1730627715587616, 0.1079743430018425, 0.03469352051615715, 0.15740558505058289, 0.010606450960040092, 0.07400575280189514, 0.1117076724767685, 0.3305439352989197]]], [[[0.05349460244178772, 0.23432688415050507, 0.08758119493722916, 0.2862832844257355, 0.04909219220280647, 0.1372660994529724, 0.10713421553373337, 0.0448216013610363], [0.04783779755234718, 0.16285477578639984, 0.07758304476737976, 0.40861955285072327, 0.052410952746868134, 0.12000018358230591, 0.08567038923501968, 0.04502321034669876], [0.04231387749314308, 0.17895451188087463, 0.0917109027504921, 0.37498512864112854, 0.04848581179976463, 0.12839071452617645, 0.1003912165760994, 0.034767862409353256], [0.04520465061068535, 0.1559031456708908, 0.09879180043935776, 0.34674975275993347, 0.08300796896219254, 0.12282924354076385, 0.10727865248918533, 0.04023483023047447], [0.0477164201438427, 0.10245352238416672, 0.08199296146631241, 0.4383280873298645, 0.05779264494776726, 0.14024969935417175, 0.08993393182754517, 0.04153275489807129], [0.0368320606648922, 0.06134317070245743, 0.05285774916410446, 0.4946787655353546, 0.08045978099107742, 0.1563265025615692, 0.0813109502196312, 0.03619103133678436], [0.04425473511219025, 0.10208287835121155, 0.061187271028757095, 0.41594240069389343, 0.06412878632545471, 0.17186783254146576, 0.09738536179065704, 0.04315074160695076], [0.06346685439348221, 0.17459118366241455, 0.08268082141876221, 0.33186638355255127, 0.049671925604343414, 0.13133582472801208, 0.10845733433961868, 0.05792964622378349]], [[0.1085900291800499, 0.06949174404144287, 0.06499605625867844, 0.38803526759147644, 0.05851783603429794, 0.1725226193666458, 0.08230150490999222, 0.05554485693573952], [0.09447014331817627, 0.061679407954216, 0.05505414679646492, 0.4493672549724579, 0.05185406655073166, 0.16800829768180847, 0.07517028599977493, 0.044396523386240005], [0.08197043091058731, 0.05002541467547417, 0.05646947771310806, 0.5100733637809753, 0.04945895075798035, 0.15114516019821167, 0.06492889672517776, 0.0359283871948719], [0.08006798475980759, 0.08071127533912659, 0.08358649909496307, 0.31193166971206665, 0.09769747406244278, 0.20599745213985443, 0.10018815845251083, 0.03981953114271164], [0.0722971111536026, 0.049417827278375626, 0.04828150197863579, 0.43025314807891846, 0.06757325679063797, 0.2298734188079834, 0.07046174257993698, 0.03184201195836067], [0.07390623539686203, 0.052635207772254944, 0.053179118782281876, 0.4162839651107788, 0.0730128139257431, 0.21432805061340332, 0.0836726501584053, 0.03298189118504524], [0.07775610685348511, 0.05235714837908745, 0.05292671546339989, 0.39815014600753784, 0.06452859193086624, 0.23675405979156494, 0.08101437240839005, 0.036512862890958786], [0.10665368288755417, 0.06509708613157272, 0.052196573466062546, 0.41745156049728394, 0.05421581491827965, 0.17858318984508514, 0.07020877301692963, 0.05559339001774788]], [[0.07389350235462189, 0.1464490443468094, 0.08156369626522064, 0.287210613489151, 0.12160862237215042, 0.11656744033098221, 0.08225175738334656, 0.09045534580945969], [0.04317088797688484, 0.15493996441364288, 0.060154542326927185, 0.3030705749988556, 0.12082604318857193, 0.15472497045993805, 0.0946202278137207, 0.0684928372502327], [0.051482126116752625, 0.13689763844013214, 0.09139205515384674, 0.28414326906204224, 0.1182384267449379, 0.13893988728523254, 0.10730329155921936, 0.07160338759422302], [0.025450449436903, 0.11085972934961319, 0.04963657259941101, 0.4319857954978943, 0.1510837972164154, 0.11692622303962708, 0.0752529501914978, 0.03880437836050987], [0.023513613268733025, 0.08378750085830688, 0.0421743169426918, 0.24215173721313477, 0.25812453031539917, 0.20168143510818481, 0.09841176867485046, 0.05015503242611885], [0.020896263420581818, 0.0861954540014267, 0.03781726583838463, 0.23174403607845306, 0.20753847062587738, 0.2816217839717865, 0.09592830389738083, 0.03825841844081879], [0.039138052612543106, 0.11104514449834824, 0.05675230175256729, 0.24577440321445465, 0.15319368243217468, 0.19563370943069458, 0.12452609091997147, 0.07393655925989151], [0.06278889626264572, 0.1358722299337387, 0.06265171617269516, 0.30490127205848694, 0.13050773739814758, 0.12044712156057358, 0.09132444858551025, 0.09150650352239609]], [[0.08789828419685364, 0.23395267128944397, 0.28270477056503296, 0.0517769381403923, 0.06137397885322571, 0.04483773931860924, 0.18767613172531128, 0.049779485911130905], [0.1218479573726654, 0.21299542486667633, 0.2698858678340912, 0.03735247999429703, 0.06177063658833504, 0.053968675434589386, 0.18100722134113312, 0.0611717626452446], [0.1263820379972458, 0.1765994131565094, 0.23708751797676086, 0.07818275690078735, 0.09599490463733673, 0.06839410215616226, 0.16020098328590393, 0.05715825781226158], [0.0971202403306961, 0.17843472957611084, 0.1815534234046936, 0.06447593867778778, 0.1394529640674591, 0.10812480002641678, 0.1663718968629837, 0.06446593999862671], [0.09842786937952042, 0.1556258350610733, 0.1649882197380066, 0.029853539541363716, 0.12187758833169937, 0.17873819172382355, 0.20045161247253418, 0.050037067383527756], [0.10172472149133682, 0.1640080064535141, 0.24156786501407623, 0.03823839873075485, 0.06376133114099503, 0.07926969230175018, 0.25058722496032715, 0.06084273010492325], [0.1253448873758316, 0.20676130056381226, 0.23724880814552307, 0.039259422570466995, 0.058645084500312805, 0.0615517757833004, 0.19845479726791382, 0.07273397594690323], [0.09763961285352707, 0.256966233253479, 0.27242138981819153, 0.0391061045229435, 0.04019232839345932, 0.043167054653167725, 0.18477314710617065, 0.06573402881622314]], [[0.033541396260261536, 0.13989323377609253, 0.13378708064556122, 0.3076303005218506, 0.0959501639008522, 0.10996823012828827, 0.14668209850788116, 0.03254753351211548], [0.023068180307745934, 0.15644000470638275, 0.11171267181634903, 0.3043764531612396, 0.10370612889528275, 0.1125083789229393, 0.1605040729045868, 0.02768409438431263], [0.027519121766090393, 0.13886640965938568, 0.1771087646484375, 0.28688767552375793, 0.1009853258728981, 0.09194675832986832, 0.149155393242836, 0.027530480176210403], [0.027483468875288963, 0.19253534078598022, 0.15368063747882843, 0.2518371045589447, 0.08595483750104904, 0.09535495191812515, 0.16487246751785278, 0.028281139209866524], [0.01074009295552969, 0.15975321829319, 0.08135779947042465, 0.160913348197937, 0.16783837974071503, 0.21016860008239746, 0.19517457485198975, 0.014054030179977417], [0.009349294938147068, 0.1479533612728119, 0.06928082555532455, 0.16623468697071075, 0.13697916269302368, 0.257636159658432, 0.19957824051380157, 0.01298827026039362], [0.019830351695418358, 0.135671004652977, 0.09377221763134003, 0.21752962470054626, 0.1280042827129364, 0.18139903247356415, 0.1946789175271988, 0.0291146207600832], [0.034694720059633255, 0.13839322328567505, 0.10725095123052597, 0.26848241686820984, 0.0982103943824768, 0.14586852490901947, 0.16445577144622803, 0.042643990367650986]], [[0.10876116901636124, 0.3508974015712738, 0.14925111830234528, 0.04847785457968712, 0.04998702183365822, 0.08778753131628036, 0.11587844789028168, 0.0889594703912735], [0.14764545857906342, 0.2631308138370514, 0.11920288950204849, 0.07153124362230301, 0.05696236342191696, 0.10967010259628296, 0.10661245137453079, 0.1252446174621582], [0.14416739344596863, 0.2504686415195465, 0.1555507481098175, 0.06125583127140999, 0.05905859172344208, 0.09872161597013474, 0.11441957205533981, 0.11635755747556686], [0.10087605565786362, 0.2886306345462799, 0.14108052849769592, 0.11357688903808594, 0.06580965965986252, 0.11015526950359344, 0.10419429838657379, 0.07567667216062546], [0.09397110342979431, 0.21449637413024902, 0.10778644680976868, 0.0626814216375351, 0.11496585607528687, 0.18333886563777924, 0.11934437602758408, 0.1034155786037445], [0.1015104129910469, 0.21259059011936188, 0.10175509750843048, 0.06590358912944794, 0.11221754550933838, 0.16821934282779694, 0.1265418380498886, 0.11126153916120529], [0.13139598071575165, 0.2146017849445343, 0.1054026260972023, 0.05083521455526352, 0.07634809613227844, 0.15145255625247955, 0.12842608988285065, 0.14153766632080078], [0.11985461413860321, 0.3239474296569824, 0.12808556854724884, 0.04859394580125809, 0.04854604974389076, 0.09668254107236862, 0.11796724796295166, 0.1163226068019867]], [[0.05714668333530426, 0.11879236251115799, 0.07482501119375229, 0.4969445466995239, 0.07367319613695145, 0.07363204658031464, 0.0634431540966034, 0.041542988270521164], [0.04508474841713905, 0.0852588564157486, 0.06332319229841232, 0.572177529335022, 0.06994706392288208, 0.07355602085590363, 0.05993327125906944, 0.03071925789117813], [0.04677018150687218, 0.08160492777824402, 0.05975799635052681, 0.5867187976837158, 0.06617673486471176, 0.07206274569034576, 0.05389920249581337, 0.0330093689262867], [0.06285970658063889, 0.13497290015220642, 0.09076055139303207, 0.3955126404762268, 0.10346294194459915, 0.08124924451112747, 0.08360415697097778, 0.0475778691470623], [0.03888898715376854, 0.0808725357055664, 0.05912565812468529, 0.5895435214042664, 0.07199631631374359, 0.07739022374153137, 0.055209361016750336, 0.026973377913236618], [0.03541518375277519, 0.08351625502109528, 0.0586438924074173, 0.586990237236023, 0.071787528693676, 0.08404096961021423, 0.0561375617980957, 0.023468444123864174], [0.03976915031671524, 0.08237343281507492, 0.05735073238611221, 0.6044779419898987, 0.06148610636591911, 0.07456286251544952, 0.05263235419988632, 0.02734750136733055], [0.04945666715502739, 0.10245927423238754, 0.06171282008290291, 0.5654742121696472, 0.0666460171341896, 0.0647834837436676, 0.05088219419121742, 0.0385853573679924]], [[0.10814550518989563, 0.10348573327064514, 0.0874449834227562, 0.28174248337745667, 0.12852142751216888, 0.16021117568016052, 0.08251026272773743, 0.04793844372034073], [0.11748369038105011, 0.11572835594415665, 0.09577750414609909, 0.2633477449417114, 0.12465527653694153, 0.14359046518802643, 0.08367659896612167, 0.0557403564453125], [0.08635684102773666, 0.07751479744911194, 0.08927229791879654, 0.34118449687957764, 0.13604077696800232, 0.1472228318452835, 0.08418352901935577, 0.038224346935749054], [0.08849244564771652, 0.11747375875711441, 0.10138596594333649, 0.2671962380409241, 0.12490953505039215, 0.15195637941360474, 0.10456594824790955, 0.04401973634958267], [0.09310343116521835, 0.06936004757881165, 0.08310133218765259, 0.2710627317428589, 0.12196628004312515, 0.20338697731494904, 0.1070621982216835, 0.05095698684453964], [0.08756713569164276, 0.06558839231729507, 0.07012858241796494, 0.31773361563682556, 0.11335696280002594, 0.1990598738193512, 0.097493976354599, 0.04907144606113434], [0.09707747399806976, 0.07733990252017975, 0.07375265657901764, 0.3246960937976837, 0.12402964383363724, 0.17424027621746063, 0.08446396887302399, 0.04439994692802429], [0.1192106083035469, 0.1083100438117981, 0.08138519525527954, 0.29442527890205383, 0.10737982392311096, 0.15239524841308594, 0.08020796626806259, 0.0566859245300293]], [[0.031005986034870148, 0.4225994646549225, 0.1640343964099884, 0.28620344400405884, 0.007685725577175617, 0.00933805014938116, 0.05982373654842377, 0.019309239462018013], [0.02888953685760498, 0.35727477073669434, 0.11913508921861649, 0.3553890883922577, 0.016070956364274025, 0.023668935522437096, 0.07305245101451874, 0.026519140228629112], [0.032170671969652176, 0.32496047019958496, 0.18767663836479187, 0.33552244305610657, 0.012448729947209358, 0.014161476865410805, 0.06997861713171005, 0.023080887272953987], [0.02227817289531231, 0.3033653497695923, 0.13379503786563873, 0.4085903763771057, 0.01953786425292492, 0.018549472093582153, 0.07549160718917847, 0.018392177298665047], [0.02186499536037445, 0.35430923104286194, 0.11478770524263382, 0.3461724817752838, 0.0332551933825016, 0.02444607764482498, 0.08360900729894638, 0.02155538648366928], [0.020798668265342712, 0.3539201319217682, 0.0991702675819397, 0.35631856322288513, 0.024232374504208565, 0.03790852054953575, 0.08480978012084961, 0.02284156158566475], [0.031542614102363586, 0.3228851854801178, 0.12180335819721222, 0.3268889784812927, 0.02033403143286705, 0.029941486194729805, 0.10968828201293945, 0.03691612929105759], [0.033930689096450806, 0.3947891592979431, 0.14219893515110016, 0.29746896028518677, 0.010077862069010735, 0.014836267568171024, 0.0774361863732338, 0.029261913150548935]], [[0.032306451350450516, 0.20464761555194855, 0.08478016406297684, 0.10361956059932709, 0.18009746074676514, 0.1956920474767685, 0.14881348609924316, 0.05004327371716499], [0.025505444034934044, 0.2311238944530487, 0.06841669976711273, 0.06498654931783676, 0.14598475396633148, 0.24301192164421082, 0.17600224912166595, 0.04496859014034271], [0.03382550925016403, 0.23373129963874817, 0.12004819512367249, 0.08636429905891418, 0.14375701546669006, 0.16812363266944885, 0.17024216055870056, 0.043907828629016876], [0.026529861614108086, 0.20799219608306885, 0.10471194237470627, 0.1561383754014969, 0.13295628130435944, 0.13776902854442596, 0.18293575942516327, 0.050966545939445496], [0.015414432622492313, 0.1914796680212021, 0.05279803276062012, 0.088340625166893, 0.22836577892303467, 0.24547220766544342, 0.14861121773719788, 0.029517997056245804], [0.012183740735054016, 0.185941681265831, 0.04148538038134575, 0.07732777297496796, 0.16474345326423645, 0.3319142162799835, 0.15759144723415375, 0.028812328353524208], [0.025147734209895134, 0.1847483217716217, 0.05978511646389961, 0.07058598101139069, 0.17261090874671936, 0.2510823607444763, 0.18584704399108887, 0.05019257962703705], [0.027082577347755432, 0.16588644683361053, 0.06008356064558029, 0.10412980616092682, 0.19370682537555695, 0.22964008152484894, 0.1599176675081253, 0.0595531091094017]], [[0.06739259511232376, 0.06330467760562897, 0.05532163381576538, 0.3030819892883301, 0.13710425794124603, 0.22944389283657074, 0.07005001604557037, 0.07430095225572586], [0.06254876405000687, 0.07368268072605133, 0.0652068704366684, 0.2759099304676056, 0.13352620601654053, 0.23855435848236084, 0.0842118188738823, 0.06635940074920654], [0.056920863687992096, 0.06059170886874199, 0.05996338650584221, 0.35954442620277405, 0.11852873116731644, 0.21859921514987946, 0.0712510272860527, 0.0546005517244339], [0.051544301211833954, 0.08504311740398407, 0.07756883651018143, 0.3100140392780304, 0.11659946292638779, 0.2081439346075058, 0.09348370134830475, 0.057602524757385254], [0.046376168727874756, 0.043447546660900116, 0.04968918114900589, 0.3315899968147278, 0.13683873414993286, 0.273655503988266, 0.0724235326051712, 0.04597936570644379], [0.04561315104365349, 0.04728630185127258, 0.05192489176988602, 0.3031880855560303, 0.15244147181510925, 0.2817031443119049, 0.07493411004543304, 0.042908925563097], [0.047353629022836685, 0.056299228221178055, 0.05491316318511963, 0.34497949481010437, 0.12501220405101776, 0.24716641008853912, 0.07791925221681595, 0.046356622129678726], [0.06550955772399902, 0.060707882046699524, 0.05576092749834061, 0.2663382887840271, 0.1406879872083664, 0.25879967212677, 0.07668536901473999, 0.07551024854183197]], [[0.18791192770004272, 0.112158864736557, 0.08652457594871521, 0.12724556028842926, 0.10612893104553223, 0.07287946343421936, 0.08942244946956635, 0.21772827208042145], [0.18278783559799194, 0.10008221119642258, 0.09350220859050751, 0.18150389194488525, 0.09463697671890259, 0.0698758065700531, 0.07643935829401016, 0.20117172598838806], [0.1801522672176361, 0.10464107245206833, 0.10163824260234833, 0.15557748079299927, 0.09127798676490784, 0.08142044395208359, 0.08996018767356873, 0.195332333445549], [0.16419267654418945, 0.08919641375541687, 0.09658674150705338, 0.1537119746208191, 0.1404758244752884, 0.08302141726016998, 0.08987192809581757, 0.18294310569763184], [0.16421014070510864, 0.0786062628030777, 0.09706971049308777, 0.14673399925231934, 0.14087863266468048, 0.09767595678567886, 0.10856389254331589, 0.16626140475273132], [0.17606474459171295, 0.07169995456933975, 0.08287202566862106, 0.14610524475574493, 0.12857170403003693, 0.10516500473022461, 0.098016656935215, 0.1915045827627182], [0.17871171236038208, 0.08481885492801666, 0.09178272634744644, 0.1373990923166275, 0.11462898552417755, 0.10145603120326996, 0.09705958515405655, 0.19414302706718445], [0.17991682887077332, 0.1021185964345932, 0.08690938353538513, 0.12555772066116333, 0.10813439637422562, 0.07802413403987885, 0.09442495554685593, 0.22491393983364105]]], [[[0.14765127003192902, 0.1729981154203415, 0.13893473148345947, 0.07806555926799774, 0.07079720497131348, 0.08519481122493744, 0.14515729248523712, 0.1612011194229126], [0.13470599055290222, 0.2010210007429123, 0.14525362849235535, 0.08302074670791626, 0.062176190316677094, 0.07277113199234009, 0.1459241360425949, 0.15512718260288239], [0.13484130799770355, 0.18138380348682404, 0.15533025562763214, 0.07451312988996506, 0.06656529754400253, 0.07506826519966125, 0.1560770869255066, 0.15622082352638245], [0.13506442308425903, 0.17263473570346832, 0.12682375311851501, 0.12016943097114563, 0.07423555850982666, 0.08486735820770264, 0.13709598779678345, 0.14910879731178284], [0.12977758049964905, 0.1454659402370453, 0.13436807692050934, 0.0921262875199318, 0.09491653740406036, 0.10045475512742996, 0.1549641340970993, 0.14792665839195251], [0.12616556882858276, 0.14981791377067566, 0.1319536417722702, 0.08880523592233658, 0.08406154066324234, 0.11033991724252701, 0.16106517612934113, 0.14779099822044373], [0.13075444102287292, 0.16783343255519867, 0.14415033161640167, 0.07662850618362427, 0.07378444075584412, 0.08922011405229568, 0.16740459203720093, 0.1502242088317871], [0.13550542294979095, 0.1866665631532669, 0.139237642288208, 0.08414933830499649, 0.06879127770662308, 0.08468161523342133, 0.14739994704723358, 0.15356816351413727]], [[0.1557617038488388, 0.083870068192482, 0.08498059958219528, 0.2702607810497284, 0.13593178987503052, 0.08102022111415863, 0.07277385145425797, 0.11540097743272781], [0.14998874068260193, 0.0796135887503624, 0.08484280109405518, 0.2871536910533905, 0.12677893042564392, 0.07764387875795364, 0.0739360824227333, 0.12004223465919495], [0.15831394493579865, 0.07826350629329681, 0.08788017928600311, 0.26847565174102783, 0.13417628407478333, 0.07760452479124069, 0.07349403202533722, 0.12179183959960938], [0.13856229186058044, 0.09032708406448364, 0.09971882402896881, 0.2148166000843048, 0.1654496043920517, 0.0957690104842186, 0.0887000635266304, 0.10665655136108398], [0.15241651237010956, 0.07667983323335648, 0.0884632095694542, 0.2826920747756958, 0.13248269259929657, 0.07240651547908783, 0.07483518123626709, 0.12002391368150711], [0.14641664922237396, 0.08139602839946747, 0.08652271330356598, 0.2834565341472626, 0.13357779383659363, 0.07411199808120728, 0.0767693743109703, 0.11774890124797821], [0.15248261392116547, 0.07739678025245667, 0.087284155189991, 0.2639102339744568, 0.13749657571315765, 0.07696948945522308, 0.07867911458015442, 0.1257810890674591], [0.1528920978307724, 0.08457671105861664, 0.08543576300144196, 0.27141907811164856, 0.13388508558273315, 0.0817452147603035, 0.07445129752159119, 0.11559474468231201]], [[0.11691349744796753, 0.16365483403205872, 0.11116020381450653, 0.16807526350021362, 0.11237173527479172, 0.11684827506542206, 0.11298152804374695, 0.09799470007419586], [0.11362285912036896, 0.15767569839954376, 0.11157677322626114, 0.17179961502552032, 0.11792952567338943, 0.11938019841909409, 0.1160908043384552, 0.09192459285259247], [0.10674459487199783, 0.15651679039001465, 0.11046042293310165, 0.17837488651275635, 0.1120700016617775, 0.1207624301314354, 0.11929401755332947, 0.09577679634094238], [0.11044818162918091, 0.16395385563373566, 0.11851874738931656, 0.1630069762468338, 0.1122123971581459, 0.11277309060096741, 0.11636973917484283, 0.10271704196929932], [0.09539520740509033, 0.1504540741443634, 0.11270425468683243, 0.15871822834014893, 0.12590472400188446, 0.14376108348369598, 0.12859274446964264, 0.0844697430729866], [0.097108855843544, 0.13671638071537018, 0.11291517317295074, 0.17163126170635223, 0.12264145165681839, 0.14649099111557007, 0.12740293145179749, 0.08509290218353271], [0.10345329344272614, 0.14580582082271576, 0.11207176744937897, 0.17115706205368042, 0.11617127060890198, 0.135049968957901, 0.12522627413272858, 0.09106453508138657], [0.1125655472278595, 0.16185475885868073, 0.11331045627593994, 0.17565438151359558, 0.11084169149398804, 0.12148828059434891, 0.11208757013082504, 0.0921972468495369]], [[0.11627086997032166, 0.10357195883989334, 0.1182553693652153, 0.206752210855484, 0.10307998955249786, 0.11074919998645782, 0.12573902308940887, 0.11558143049478531], [0.12180547416210175, 0.08701153844594955, 0.11238481104373932, 0.2009260654449463, 0.11631966382265091, 0.12082874774932861, 0.11539139598608017, 0.125332310795784], [0.11253435909748077, 0.09565272182226181, 0.12181741744279861, 0.20864225924015045, 0.10816159099340439, 0.11397549510002136, 0.12404417991638184, 0.11517201364040375], [0.10274505615234375, 0.09899266809225082, 0.12270420789718628, 0.21690164506435394, 0.1157941073179245, 0.12339179962873459, 0.1229722648859024, 0.09649823606014252], [0.11223602294921875, 0.09438890218734741, 0.11591484397649765, 0.22334915399551392, 0.10786189138889313, 0.11935997009277344, 0.1248529925942421, 0.10203619301319122], [0.11595120280981064, 0.08857125043869019, 0.10763679444789886, 0.19553126394748688, 0.12332005053758621, 0.12697522342205048, 0.12494106590747833, 0.1170731633901596], [0.11747501790523529, 0.0861140638589859, 0.10856019705533981, 0.19598692655563354, 0.11603689193725586, 0.12285798043012619, 0.12883150577545166, 0.12413744628429413], [0.12262382358312607, 0.09617375582456589, 0.10839995741844177, 0.2089957594871521, 0.10985374450683594, 0.11670757085084915, 0.11751259118318558, 0.1197327971458435]], [[0.11697527021169662, 0.08940301835536957, 0.08612596243619919, 0.21301257610321045, 0.15440116822719574, 0.15288226306438446, 0.08109777420759201, 0.10610204190015793], [0.12081660330295563, 0.09125962853431702, 0.08904637396335602, 0.19802606105804443, 0.15647797286510468, 0.15251615643501282, 0.08681043982505798, 0.10504677891731262], [0.11367350816726685, 0.09076845645904541, 0.08639290183782578, 0.2087131291627884, 0.15897388756275177, 0.15960457921028137, 0.08225219696760178, 0.09962138533592224], [0.10917121917009354, 0.10732153803110123, 0.10540172457695007, 0.15464021265506744, 0.1668548732995987, 0.1587863266468048, 0.10179825127124786, 0.09602584689855576], [0.11103951185941696, 0.09637224674224854, 0.09065832197666168, 0.22943414747714996, 0.14077822864055634, 0.1439405232667923, 0.08873523026704788, 0.09904176741838455], [0.11236842721700668, 0.09629523009061813, 0.09568101167678833, 0.21399171650409698, 0.14531230926513672, 0.1450766623020172, 0.09387248009443283, 0.0974021777510643], [0.11280852556228638, 0.08825770765542984, 0.08257374167442322, 0.20353519916534424, 0.15803056955337524, 0.16455520689487457, 0.08596391975879669, 0.10427512228488922], [0.12078502774238586, 0.09641139209270477, 0.0840679332613945, 0.21758010983467102, 0.14506971836090088, 0.15058007836341858, 0.07873664796352386, 0.1067691370844841]], [[0.17151270806789398, 0.11048643290996552, 0.11168738454580307, 0.16302883625030518, 0.08641646057367325, 0.11478372663259506, 0.09505670517683029, 0.14702776074409485], [0.1755535900592804, 0.10155036300420761, 0.1110457107424736, 0.15398269891738892, 0.08453918248414993, 0.11578509211540222, 0.0985700786113739, 0.1589733362197876], [0.16280889511108398, 0.10170624405145645, 0.11446242779493332, 0.16719108819961548, 0.09223431348800659, 0.12067827582359314, 0.09848229587078094, 0.1424364447593689], [0.172735333442688, 0.11083744466304779, 0.12401722371578217, 0.1258680671453476, 0.07859200239181519, 0.12157180905342102, 0.11478223651647568, 0.1515958309173584], [0.1509542018175125, 0.10348309576511383, 0.11815870553255081, 0.16197986900806427, 0.09267054498195648, 0.13231608271598816, 0.10829492658376694, 0.13214269280433655], [0.1511511504650116, 0.10233662277460098, 0.11662408709526062, 0.16411422193050385, 0.09187204390764236, 0.13302189111709595, 0.10783404111862183, 0.133045956492424], [0.15723060071468353, 0.09931698441505432, 0.11113601177930832, 0.16573667526245117, 0.09389142692089081, 0.12970298528671265, 0.10150204598903656, 0.14148329198360443], [0.17114651203155518, 0.11324353516101837, 0.11165452003479004, 0.16751618683338165, 0.08163876086473465, 0.11461744457483292, 0.09271079301834106, 0.1474723070859909]], [[0.09050595760345459, 0.13387101888656616, 0.10752575099468231, 0.18480299413204193, 0.13159513473510742, 0.13009482622146606, 0.12473548948764801, 0.09686876833438873], [0.09941509366035461, 0.12671181559562683, 0.11319639533758163, 0.160554900765419, 0.1364489644765854, 0.13400593400001526, 0.1226431205868721, 0.10702382773160934], [0.09312327206134796, 0.13461065292358398, 0.11592744290828705, 0.17694547772407532, 0.13161274790763855, 0.127400204539299, 0.1268741637468338, 0.09350604563951492], [0.10596457868814468, 0.11397244781255722, 0.12300296127796173, 0.16103780269622803, 0.14059387147426605, 0.133737251162529, 0.12223518639802933, 0.09945592284202576], [0.08117131888866425, 0.10622382164001465, 0.10210729390382767, 0.1929839551448822, 0.1557159572839737, 0.14592714607715607, 0.12549489736557007, 0.0903756394982338], [0.08096471428871155, 0.09916216135025024, 0.09373418241739273, 0.18391944468021393, 0.16924037039279938, 0.15270628035068512, 0.12715604901313782, 0.09311670809984207], [0.08483024686574936, 0.10703414678573608, 0.09551151096820831, 0.17638590931892395, 0.1569787710905075, 0.16000047326087952, 0.12660259008407593, 0.09265635162591934], [0.08514091372489929, 0.12451668828725815, 0.10576102882623672, 0.19515615701675415, 0.13787759840488434, 0.13299794495105743, 0.12540026009082794, 0.0931493416428566]], [[0.1331709325313568, 0.10455644875764847, 0.09671011567115784, 0.26411235332489014, 0.12175469845533371, 0.08878215402364731, 0.0895441323518753, 0.10136909037828445], [0.13089142739772797, 0.11055076122283936, 0.10234378278255463, 0.2404269576072693, 0.12778514623641968, 0.0895819291472435, 0.09647300839424133, 0.10194697976112366], [0.14115475118160248, 0.10570980608463287, 0.10506192594766617, 0.23304902017116547, 0.12475282698869705, 0.0909273624420166, 0.09245972335338593, 0.10688455402851105], [0.11085078120231628, 0.11886981874704361, 0.11671572923660278, 0.2553308308124542, 0.12028267234563828, 0.09361934661865234, 0.1019868329167366, 0.08234413713216782], [0.10997549444437027, 0.10372541844844818, 0.10200779885053635, 0.28379738330841064, 0.1394905298948288, 0.09440754354000092, 0.09076369553804398, 0.07583216577768326], [0.10782335698604584, 0.1057082861661911, 0.09833820909261703, 0.2861342430114746, 0.13197515904903412, 0.09753220528364182, 0.09523911029100418, 0.07724940031766891], [0.1270771324634552, 0.10525607317686081, 0.1023826003074646, 0.23889397084712982, 0.13269072771072388, 0.09301026165485382, 0.09975146502256393, 0.10093773156404495], [0.1321869194507599, 0.10776427388191223, 0.09572823345661163, 0.2628342807292938, 0.11886779963970184, 0.08788324147462845, 0.09120187908411026, 0.10353339463472366]], [[0.152226984500885, 0.07659852504730225, 0.09634356200695038, 0.2114056795835495, 0.09854159504175186, 0.13447515666484833, 0.10894480347633362, 0.12146361917257309], [0.15416023135185242, 0.08190521597862244, 0.10444319248199463, 0.20595131814479828, 0.09643083065748215, 0.12574930489063263, 0.11050862818956375, 0.12085141986608505], [0.15170630812644958, 0.07852079719305038, 0.10612496733665466, 0.2048519104719162, 0.09572210907936096, 0.12971673905849457, 0.11342332512140274, 0.1199338436126709], [0.13963855803012848, 0.08896750956773758, 0.10815007984638214, 0.1991361379623413, 0.10748953372240067, 0.13742735981941223, 0.11452293395996094, 0.10466798394918442], [0.1452454924583435, 0.07477346062660217, 0.10069269686937332, 0.20066867768764496, 0.10519175976514816, 0.14460879564285278, 0.11581192910671234, 0.11300715804100037], [0.14257419109344482, 0.07494168728590012, 0.09801621735095978, 0.20824797451496124, 0.10521818697452545, 0.14407381415367126, 0.11434251815080643, 0.11258550733327866], [0.14902019500732422, 0.0762874186038971, 0.10009914636611938, 0.19655247032642365, 0.09961709380149841, 0.14076852798461914, 0.1174912303686142, 0.12016390264034271], [0.15190164744853973, 0.07845546305179596, 0.09388219565153122, 0.20720964670181274, 0.09878873825073242, 0.13749246299266815, 0.10889127850532532, 0.12337865680456161]], [[0.09174534678459167, 0.11871457099914551, 0.14215226471424103, 0.1773129403591156, 0.1700657457113266, 0.08835586905479431, 0.12692126631736755, 0.0847320482134819], [0.06379564106464386, 0.13198667764663696, 0.12841293215751648, 0.1878277063369751, 0.17367660999298096, 0.10496105253696442, 0.1461603194475174, 0.06317910552024841], [0.07476479560136795, 0.1214110478758812, 0.15235982835292816, 0.1689281314611435, 0.17754754424095154, 0.09173456579446793, 0.14355453848838806, 0.06969954818487167], [0.057910822331905365, 0.13472670316696167, 0.12769097089767456, 0.2279202938079834, 0.1757369190454483, 0.09432312101125717, 0.12823331356048584, 0.05345791578292847], [0.05671658739447594, 0.12742866575717926, 0.11689111590385437, 0.18646812438964844, 0.20615093410015106, 0.10481779277324677, 0.1444731503725052, 0.05705365166068077], [0.05754055827856064, 0.1310359388589859, 0.11359166353940964, 0.18121084570884705, 0.1827259212732315, 0.1208142563700676, 0.15319231152534485, 0.059888485819101334], [0.06919889152050018, 0.12134845554828644, 0.12445991486310959, 0.16041681170463562, 0.18723279237747192, 0.10448132455348969, 0.15975631773471832, 0.07310545444488525], [0.08498194813728333, 0.12134964764118195, 0.12802809476852417, 0.17859795689582825, 0.1732262223958969, 0.09180086851119995, 0.1352369636297226, 0.08677823841571808]], [[0.11593789607286453, 0.13809257745742798, 0.17485184967517853, 0.1688036322593689, 0.09005867689847946, 0.0889289528131485, 0.11224712431430817, 0.11107926070690155], [0.08674240112304688, 0.15728136897087097, 0.15060265362262726, 0.17329993844032288, 0.10039263218641281, 0.11159761995077133, 0.12350882589817047, 0.09657446295022964], [0.1049908921122551, 0.13837021589279175, 0.1945771872997284, 0.16268715262413025, 0.08812809735536575, 0.08851692080497742, 0.119816355407238, 0.10291309654712677], [0.06697086244821548, 0.149217888712883, 0.1505841612815857, 0.21639688313007355, 0.11223457753658295, 0.10740263015031815, 0.11999907344579697, 0.07719386368989944], [0.0734594464302063, 0.14354896545410156, 0.14134356379508972, 0.1739949733018875, 0.1338171660900116, 0.11677058041095734, 0.13373978435993195, 0.08332556486129761], [0.06900294870138168, 0.14758533239364624, 0.13705842196941376, 0.1708582490682602, 0.1191447526216507, 0.12978310883045197, 0.1416921466588974, 0.08487504720687866], [0.0887460857629776, 0.14014965295791626, 0.151304692029953, 0.16453032195568085, 0.10384967178106308, 0.10683216154575348, 0.13898241519927979, 0.10560494661331177], [0.10747011005878448, 0.1393033266067505, 0.15094642341136932, 0.177481546998024, 0.09255629032850266, 0.09273391216993332, 0.1174754649400711, 0.12203289568424225]], [[0.09562269598245621, 0.17284660041332245, 0.12809942662715912, 0.1952120065689087, 0.09678730368614197, 0.10633417218923569, 0.1198219507932663, 0.08527582883834839], [0.07421379536390305, 0.1846453994512558, 0.12866580486297607, 0.17844948172569275, 0.10377208888530731, 0.11138154566287994, 0.14070352911949158, 0.07816838473081589], [0.08719205856323242, 0.16768303513526917, 0.1512463539838791, 0.1614820957183838, 0.0998566523194313, 0.10761784762144089, 0.14064791798591614, 0.08427412062883377], [0.059632692486047745, 0.14939121901988983, 0.10776282846927643, 0.2682371437549591, 0.11982548981904984, 0.11580368131399155, 0.11993393301963806, 0.059413064271211624], [0.06225200742483139, 0.13784320652484894, 0.10019470006227493, 0.21010056138038635, 0.15825916826725006, 0.1424935907125473, 0.12609076499938965, 0.06276597827672958], [0.06285886466503143, 0.16152773797512054, 0.10631170868873596, 0.17590729892253876, 0.12539246678352356, 0.16059942543506622, 0.14309871196746826, 0.06430386751890182], [0.07738108932971954, 0.16198302805423737, 0.1262775957584381, 0.16197876632213593, 0.10978410392999649, 0.12143239378929138, 0.15577465295791626, 0.08538837730884552], [0.09195058047771454, 0.17314037680625916, 0.12201124429702759, 0.19762559235095978, 0.09518565237522125, 0.10268326103687286, 0.12476425617933273, 0.09263911098241806]]]], \"left_text\": [\"[CLS]\", \"transfer\", \"learning\", \"bert\", \"self\", \"supervised\", \"learning\", \"[SEP]\"], \"right_text\": [\"[CLS]\", \"transfer\", \"learning\", \"bert\", \"self\", \"supervised\", \"learning\", \"[SEP]\"]}}, \"default_filter\": \"all\", \"root_div_id\": \"bertviz-a492ca45f33b492b8b9f5bdbcc1f9407\", \"layer\": null, \"heads\": null}; // HACK: {\"attention\": {\"all\": {\"attn\": [[[[0.021471688523888588, 0.11818783730268478, 0.1273571401834488, 0.2520386576652527, 0.10933373868465424, 0.1178814098238945, 0.15705224871635437, 0.09667724370956421], [0.10270272940397263, 0.017381325364112854, 0.05789373070001602, 0.08408740162849426, 0.08054445683956146, 0.2913025915622711, 0.04208483546972275, 0.32400283217430115], [0.3185310661792755, 0.11833782494068146, 0.0042231157422065735, 0.12728507816791534, 0.22116777300834656, 0.05979571491479874, 0.002291534561663866, 0.14836783707141876], [0.040530070662498474, 0.07783496379852295, 0.06516934186220169, 0.03245235234498978, 0.10647381842136383, 0.3262057900428772, 0.06160903349518776, 0.28972455859184265], [0.13867415487766266, 0.12491236627101898, 0.08309179544448853, 0.13896462321281433, 0.0130592817440629, 0.2026725560426712, 0.0763663649559021, 0.2222588211297989], [0.10300623625516891, 0.08243090659379959, 0.017215300351381302, 0.2749914228916168, 0.0827358216047287, 0.006487335078418255, 0.014078550040721893, 0.41905441880226135], [0.2649904787540436, 0.11882265657186508, 0.0036927477922290564, 0.1314265877008438, 0.24017192423343658, 0.056132424622774124, 0.0024685722310096025, 0.18229462206363678], [0.17776252329349518, 0.06566043943166733, 0.07044108211994171, 0.07944270968437195, 0.05321170389652252, 0.10840796679258347, 0.10247717052698135, 0.34259647130966187]], [[0.0407116524875164, 0.007977649569511414, 0.010935850441455841, 0.02050274983048439, 0.019624413922429085, 0.029081294313073158, 0.010466326028108597, 0.8607001304626465], [0.11282382905483246, 0.3458743691444397, 0.0814504474401474, 0.07759799063205719, 0.08560600131750107, 0.11402241140604019, 0.10046899318695068, 0.08215600252151489], [0.04868807643651962, 0.02670900523662567, 0.09160330891609192, 0.02968820556998253, 0.025803573429584503, 0.5686190128326416, 0.11745785921812057, 0.09143085032701492], [0.03175055980682373, 0.027990145608782768, 0.013317928649485111, 0.8325313925743103, 0.011151199229061604, 0.050997789949178696, 0.018496999517083168, 0.013763919472694397], [0.08689813315868378, 0.1538286954164505, 0.07249999046325684, 0.08512748777866364, 0.2715543508529663, 0.18654409050941467, 0.08051747828722, 0.06302981823682785], [0.07168255001306534, 0.02218780294060707, 0.031140003353357315, 0.04638856649398804, 0.022614674642682076, 0.6478307843208313, 0.029250305145978928, 0.12890535593032837], [0.05020177736878395, 0.027533795684576035, 0.0849190503358841, 0.034008607268333435, 0.028074482455849648, 0.6080073714256287, 0.07085362076759338, 0.09640135616064072], [0.10163801163434982, 0.08469211310148239, 0.030895262956619263, 0.1586379110813141, 0.054850462824106216, 0.07821355015039444, 0.022920724004507065, 0.46815189719200134]], [[0.1206345409154892, 0.07879675924777985, 0.05775400623679161, 0.14818106591701508, 0.05476881563663483, 0.09271449595689774, 0.07811647653579712, 0.3690338134765625], [0.11172175407409668, 0.7367271184921265, 0.005667654797434807, 0.015947047621011734, 0.04044328257441521, 0.017992829903960228, 0.010149202309548855, 0.06135107949376106], [0.0032172424253076315, 0.003084961324930191, 0.13508717715740204, 0.004572948440909386, 0.009971353225409985, 0.013347161002457142, 0.8187121152877808, 0.012007026933133602], [0.02940969541668892, 0.008233967237174511, 0.00320526584982872, 0.9084973931312561, 0.0014565306482836604, 0.0068294997327029705, 0.005420546513050795, 0.03694705665111542], [0.17426200211048126, 0.06351236253976822, 0.016434859484434128, 0.0067700534127652645, 0.4286414682865143, 0.03621549531817436, 0.0158087071031332, 0.2583550810813904], [0.08640388399362564, 0.00787245575338602, 0.019306622445583344, 0.018896859139204025, 0.008439583703875542, 0.7756121158599854, 0.011928964406251907, 0.07153958827257156], [0.004353116732090712, 0.007265493739396334, 0.7428044080734253, 0.012583031319081783, 0.007947330363094807, 0.0059435004368424416, 0.21394632756710052, 0.0051568238995969296], [0.4254843592643738, 0.10188346356153488, 0.039558738470077515, 0.1489831954240799, 0.03327791020274162, 0.07676193863153458, 0.013236467726528645, 0.16081389784812927]], [[0.7577022910118103, 0.015325352549552917, 0.0422976054251194, 0.023204103112220764, 0.016970431432127953, 0.016413597390055656, 0.035216331481933594, 0.09287011623382568], [0.010225605219602585, 0.07772418111562729, 0.14943188428878784, 0.07621122151613235, 0.18733562529087067, 0.23837481439113617, 0.16144797205924988, 0.09924869984388351], [0.10490033030509949, 0.04999538138508797, 0.028924409300088882, 0.056648775935173035, 0.04736774414777756, 0.12121973186731339, 0.03720111772418022, 0.553742527961731], [0.00395099027082324, 0.12540781497955322, 0.09602333605289459, 0.18643417954444885, 0.1690593808889389, 0.2335607409477234, 0.13733385503292084, 0.0482296496629715], [0.012024850584566593, 0.1668165922164917, 0.21052157878875732, 0.040826354175806046, 0.030015740543603897, 0.1534535437822342, 0.26806625723838806, 0.11827510595321655], [0.019895637407898903, 0.08929508924484253, 0.1458849161863327, 0.07957526296377182, 0.1356533318758011, 0.25124791264533997, 0.13983815908432007, 0.1386096328496933], [0.09570496529340744, 0.06420950591564178, 0.03970567509531975, 0.07052619755268097, 0.06202278658747673, 0.1358882635831833, 0.04344959929585457, 0.4884929955005646], [0.20170989632606506, 0.07049639523029327, 0.05832545831799507, 0.2050817459821701, 0.12242201715707779, 0.09737671911716461, 0.05922793224453926, 0.1853599101305008]], [[0.47134721279144287, 0.035104990005493164, 0.10972526669502258, 0.12242025136947632, 0.02998363971710205, 0.038672126829624176, 0.12249429523944855, 0.0702522024512291], [0.006798149552196264, 0.06942520290613174, 0.10122837871313095, 0.30507564544677734, 0.27176058292388916, 0.04662668704986572, 0.12209724634885788, 0.07698805630207062], [0.014498528093099594, 0.18418624997138977, 0.029602419584989548, 0.13087604939937592, 0.37408387660980225, 0.1890348345041275, 0.03676261752843857, 0.040955401957035065], [0.029406065121293068, 0.0718308538198471, 0.08112069964408875, 0.15324810147285461, 0.046834975481033325, 0.07996471226215363, 0.10982675105333328, 0.427767813205719], [0.007055839989334345, 0.23295801877975464, 0.08575888723134995, 0.23656678199768066, 0.08220486342906952, 0.2052188217639923, 0.09232737869024277, 0.05790933594107628], [0.017934957519173622, 0.2567504048347473, 0.11829658597707748, 0.09023672342300415, 0.2426222562789917, 0.06258274614810944, 0.14532645046710968, 0.06624992936849594], [0.009883584454655647, 0.2157512754201889, 0.025735918432474136, 0.13362380862236023, 0.3439098298549652, 0.20434099435806274, 0.030224692076444626, 0.03652988746762276], [0.18744561076164246, 0.057522594928741455, 0.03516869992017746, 0.1374415010213852, 0.03618650138378143, 0.0462883822619915, 0.04344644024968147, 0.45650023221969604]], [[0.8942770957946777, 0.009896082803606987, 0.005542676895856857, 0.0060235895216465, 0.02905900403857231, 0.010259916074573994, 0.004390742629766464, 0.04055095836520195], [0.020996950566768646, 0.06554192304611206, 0.14937041699886322, 0.06135530397295952, 0.3539215922355652, 0.07966604828834534, 0.126323401927948, 0.14282436668872833], [0.04967644438147545, 0.1887095719575882, 0.006725625600665808, 0.04451966658234596, 0.6060479879379272, 0.021812520921230316, 0.004949432332068682, 0.07755867391824722], [0.003219911828637123, 0.06664253026247025, 0.014448627829551697, 0.6837857365608215, 0.08562610298395157, 0.02917187660932541, 0.016713358461856842, 0.10039182752370834], [0.008593816310167313, 0.2810300588607788, 0.168934166431427, 0.11092272400856018, 0.06207966431975365, 0.03391663357615471, 0.1772753894329071, 0.1572476178407669], [0.002828266005963087, 0.025432495400309563, 0.0037990594282746315, 0.06518229842185974, 0.8416959047317505, 0.011276080273091793, 0.004874010570347309, 0.04491191729903221], [0.01543775387108326, 0.06494764983654022, 0.003198701422661543, 0.03384480997920036, 0.776537299156189, 0.026477152481675148, 0.004008834715932608, 0.07554765790700912], [0.035026777535676956, 0.15370765328407288, 0.008801005780696869, 0.2045493870973587, 0.4395006000995636, 0.06852395832538605, 0.010022198781371117, 0.07986850291490555]], [[0.42171287536621094, 0.03875601664185524, 0.043698500841856, 0.048433735966682434, 0.05885818973183632, 0.050756994634866714, 0.02628549560904503, 0.31149807572364807], [0.009404572658240795, 0.006425682455301285, 0.7700634002685547, 0.031769219785928726, 0.06801306456327438, 0.016837850213050842, 0.08076851069927216, 0.01671769469976425], [0.029085621237754822, 0.09933630377054214, 0.03618260845541954, 0.2512584328651428, 0.4865887463092804, 0.05260034278035164, 0.002963659120723605, 0.04198431223630905], [0.03440961614251137, 0.020100656896829605, 0.061726443469524384, 0.028047440573573112, 0.4599679112434387, 0.093656525015831, 0.1348918229341507, 0.16719965636730194], [0.0015403962461277843, 0.016711724922060966, 0.03553806245326996, 0.03070434369146824, 0.0859232097864151, 0.17160223424434662, 0.5519510507583618, 0.10602903366088867], [0.04711703583598137, 0.011188512668013573, 0.021322311833500862, 0.0023892875760793686, 0.027110321447253227, 0.012749813497066498, 0.6764894723892212, 0.2016332596540451], [0.011231622658669949, 0.019534384831786156, 0.0010225425940006971, 0.01836572028696537, 0.040591537952423096, 0.03431578725576401, 0.012959958985447884, 0.8619784712791443], [0.49713870882987976, 0.016321802511811256, 0.01081320084631443, 0.050838567316532135, 0.09228529036045074, 0.036229733377695084, 0.07743167132139206, 0.2189410775899887]], [[0.05272819101810455, 0.015783900395035744, 0.013865047134459019, 0.020464003086090088, 0.04532293230295181, 0.009132209233939648, 0.017565516754984856, 0.8251381516456604], [0.002139737131074071, 0.021385686472058296, 0.3235270380973816, 0.16609223186969757, 0.01425822265446186, 0.09160368144512177, 0.36745885014533997, 0.013534566387534142], [0.020569035783410072, 0.00600788090378046, 0.008501380681991577, 0.011467373929917812, 0.05493544042110443, 0.8546163439750671, 0.009534620679914951, 0.03436795249581337], [0.09872465580701828, 0.11508657038211823, 0.0741937980055809, 0.27946558594703674, 0.09253279864788055, 0.16041086614131927, 0.0786796510219574, 0.1009061336517334], [0.250691294670105, 0.05414477735757828, 0.05867752060294151, 0.03350270912051201, 0.21528807282447815, 0.27873659133911133, 0.0634666457772255, 0.04549238458275795], [0.09854541718959808, 0.026735765859484673, 0.06250122934579849, 0.14600180089473724, 0.26033011078834534, 0.21321840584278107, 0.06532472372055054, 0.1273425817489624], [0.018337642773985863, 0.00654919957742095, 0.008287215605378151, 0.013893510214984417, 0.05237918347120285, 0.8565787076950073, 0.008766092360019684, 0.03520835563540459], [0.05268581211566925, 0.08788977563381195, 0.013114131055772305, 0.3294703960418701, 0.08630944788455963, 0.04505159333348274, 0.018023407086730003, 0.36745545268058777]], [[0.29260575771331787, 0.09154874086380005, 0.03734234720468521, 0.19319400191307068, 0.05860329046845436, 0.04112362861633301, 0.029504599049687386, 0.25607767701148987], [0.05278302729129791, 0.09393826872110367, 0.08308645337820053, 0.07856923341751099, 0.17054963111877441, 0.3805864751338959, 0.13058936595916748, 0.009897500276565552], [0.01404661126434803, 0.15685653686523438, 0.015334276482462883, 0.014604093506932259, 0.30936142802238464, 0.44330039620399475, 0.024755528196692467, 0.021741211414337158], [0.659001886844635, 0.03429969772696495, 0.031217919662594795, 0.047064509242773056, 0.059166163206100464, 0.009948941878974438, 0.035038892179727554, 0.12426184117794037], [0.10737919807434082, 0.28597667813301086, 0.08430129289627075, 0.037537019699811935, 0.18300585448741913, 0.151278555393219, 0.10382933169603348, 0.046692006289958954], [0.022930895909667015, 0.33493754267692566, 0.10541751235723495, 0.011582932434976101, 0.1803947538137436, 0.10405189543962479, 0.15825387835502625, 0.08243061602115631], [0.016123933717608452, 0.19749979674816132, 0.016267213970422745, 0.01842876337468624, 0.24961325526237488, 0.45316293835639954, 0.02468664012849331, 0.024217549711465836], [0.2647956609725952, 0.05159040167927742, 0.028540244325995445, 0.17157228291034698, 0.0710943192243576, 0.027542050927877426, 0.031389180570840836, 0.3534758388996124]], [[0.31483194231987, 0.052349258214235306, 0.14906077086925507, 0.1213754341006279, 0.03193305432796478, 0.096764475107193, 0.16199181973934174, 0.07169324904680252], [0.04752199724316597, 0.2554153501987457, 0.08893968164920807, 0.05758949741721153, 0.17264984548091888, 0.2653430700302124, 0.08177944272756577, 0.030761076137423515], [0.00505095673725009, 0.30400949716567993, 0.030699923634529114, 0.0861530676484108, 0.07715601474046707, 0.44403406977653503, 0.03867726027965546, 0.014219232834875584], [0.44731709361076355, 0.1402100771665573, 0.019967304542660713, 0.14659519493579865, 0.0848962664604187, 0.03708021715283394, 0.019227491691708565, 0.10470626503229141], [0.019624121487140656, 0.17774663865566254, 0.13483655452728271, 0.10507044941186905, 0.18620792031288147, 0.17542269825935364, 0.16444887220859528, 0.03664278984069824], [0.10875245183706284, 0.16345961391925812, 0.03414337337017059, 0.1296858936548233, 0.37315136194229126, 0.06403370946645737, 0.036755286157131195, 0.0900183618068695], [0.00318325636908412, 0.35653212666511536, 0.02672324888408184, 0.0840984359383583, 0.08104889839887619, 0.4073435664176941, 0.03249230608344078, 0.008578204549849033], [0.8607511520385742, 0.024567101150751114, 0.0070968265645205975, 0.03966781497001648, 0.014702708460390568, 0.013121245428919792, 0.0063948906026780605, 0.03369820863008499]], [[0.9703182578086853, 0.0021002902649343014, 0.0018539230804890394, 0.00670267641544342, 0.006661528721451759, 0.004659128841012716, 0.0016359619330614805, 0.006068293005228043], [0.02706011012196541, 0.11130930483341217, 0.07061789184808731, 0.145772784948349, 0.17763298749923706, 0.21516115963459015, 0.0688634142279625, 0.1835823804140091], [0.00256175035610795, 0.08301801234483719, 0.01328063290566206, 0.26004815101623535, 0.023575423285365105, 0.5936261415481567, 0.016074631363153458, 0.007815255783498287], [0.4642695486545563, 0.046843044459819794, 0.0708102434873581, 0.020206548273563385, 0.016396356746554375, 0.061752721667289734, 0.09259387105703354, 0.22712768614292145], [0.03446163982152939, 0.1277792602777481, 0.07092101126909256, 0.2510322630405426, 0.10564415156841278, 0.21634332835674286, 0.0726432278752327, 0.12117503583431244], [0.06763479113578796, 0.1435547173023224, 0.09432581812143326, 0.21616363525390625, 0.15439167618751526, 0.17801471054553986, 0.0842912495136261, 0.06162343546748161], [0.0020440667867660522, 0.10513298213481903, 0.012893467210233212, 0.24563166499137878, 0.020653843879699707, 0.5921642780303955, 0.014499601908028126, 0.006980065256357193], [0.9370508790016174, 0.006072002463042736, 0.0014256502036005259, 0.010766706429421902, 0.009175198152661324, 0.01611444354057312, 0.0014679147861897945, 0.017927100881934166]], [[0.9433727264404297, 0.0020571460481733084, 0.003001623786985874, 0.006801769603043795, 0.006996781099587679, 0.001607094774954021, 0.0025984745007008314, 0.03356439620256424], [0.0474449098110199, 0.01151583343744278, 0.6942529082298279, 0.010227230377495289, 0.06550207734107971, 0.04148280620574951, 0.11841809749603271, 0.01115613803267479], [0.005398353096097708, 0.9290728569030762, 0.003448615549132228, 0.010666749440133572, 0.026407092809677124, 0.022784970700740814, 0.00036656323936767876, 0.0018547337967902422], [0.16396890580654144, 0.05180935189127922, 0.3693680763244629, 0.17079560458660126, 0.08731380850076675, 0.06638725101947784, 0.04838736727833748, 0.04196956008672714], [0.011876084841787815, 0.13767574727535248, 0.27895602583885193, 0.025973109528422356, 0.07745363563299179, 0.32983776926994324, 0.09953486919403076, 0.038692642003297806], [0.2168094366788864, 0.0071740229614079, 0.030327128246426582, 0.007211386691778898, 0.5666447877883911, 0.010117675177752972, 0.1118701696395874, 0.049845367670059204], [0.009053081274032593, 0.1500590741634369, 0.0002746123354882002, 0.01375899650156498, 0.13563573360443115, 0.6291595101356506, 0.009196602739393711, 0.052862342447042465], [0.9757063388824463, 5.398916619014926e-05, 8.936564699979499e-05, 0.0012246784754097462, 0.003424322698265314, 0.0021721746306866407, 0.0030006456654518843, 0.014328515157103539]]], [[[0.6463747024536133, 0.015984689816832542, 0.013849921524524689, 0.021047402173280716, 0.01964288204908371, 0.02096586488187313, 0.023477252572774887, 0.23865735530853271], [0.6503119468688965, 0.1523979753255844, 0.017982181161642075, 0.00995629746466875, 0.08424269407987595, 0.0061574699357151985, 0.02144056372344494, 0.0575108677148819], [0.018134133890271187, 0.010337969288229942, 0.12838980555534363, 0.0036229791585355997, 0.0026558039244264364, 0.004153591580688953, 0.8186590671539307, 0.01404664944857359], [0.48123449087142944, 0.012461498379707336, 0.038840699940919876, 0.37371042370796204, 0.01166674867272377, 0.006434858310967684, 0.052576251327991486, 0.023075062781572342], [0.2660391330718994, 0.06215012073516846, 0.01742531731724739, 0.00438943225890398, 0.48931992053985596, 0.11772681027650833, 0.01050359383225441, 0.03244568780064583], [0.10327248275279999, 0.00876823253929615, 0.007784364279359579, 0.004810729529708624, 0.017365949228405952, 0.8229702115058899, 0.006108491215854883, 0.02891954779624939], [0.05528882518410683, 0.020629918202757835, 0.652289628982544, 0.007362705189734697, 0.003696998581290245, 0.007419401314109564, 0.2394130676984787, 0.01389950793236494], [0.7424921989440918, 0.008563279174268246, 0.025619296357035637, 0.027382176369428635, 0.051012881100177765, 0.054540738463401794, 0.012546176090836525, 0.07784327864646912]], [[0.22654055058956146, 0.0963054895401001, 0.1730431765317917, 0.04842643439769745, 0.1443185955286026, 0.0711379200220108, 0.15479066967964172, 0.08543720841407776], [0.04746638983488083, 0.06877217441797256, 0.14928601682186127, 0.12896519899368286, 0.19716233015060425, 0.13579680025577545, 0.12017115205526352, 0.15238003432750702], [0.02888605371117592, 0.1560075879096985, 0.012637456879019737, 0.04547842592000961, 0.48954686522483826, 0.18005293607711792, 0.011390767060220242, 0.07599986344575882], [0.28194648027420044, 0.049538254737854004, 0.06262224167585373, 0.18321241438388824, 0.06748419255018234, 0.0408594086766243, 0.06437108665704727, 0.24996589124202728], [0.041627198457717896, 0.15454591810703278, 0.04136064276099205, 0.04874589294195175, 0.27811840176582336, 0.27706846594810486, 0.03421163558959961, 0.12432179600000381], [0.037660256028175354, 0.24833597242832184, 0.10310319066047668, 0.017617085948586464, 0.3764772415161133, 0.052805397659540176, 0.07788403332233429, 0.08611676841974258], [0.021535448729991913, 0.18237635493278503, 0.010878462344408035, 0.08700799942016602, 0.4022807776927948, 0.1912735551595688, 0.008005932904779911, 0.09664160758256912], [0.09130392968654633, 0.11782689392566681, 0.07085081189870834, 0.0751589983701706, 0.34618642926216125, 0.09958281368017197, 0.0632600486278534, 0.13583017885684967]], [[0.5115909576416016, 0.07468347996473312, 0.042368333786726, 0.07572736591100693, 0.1715310662984848, 0.04222807660698891, 0.02485048398375511, 0.05702020600438118], [0.2595946788787842, 0.07356332242488861, 0.28477099537849426, 0.02655605785548687, 0.1732032597064972, 0.10256747901439667, 0.00801482331007719, 0.07172936201095581], [0.03457588702440262, 0.10368933528661728, 0.004064579494297504, 0.021644694730639458, 0.8316331505775452, 0.0027678373735398054, 2.778341695375275e-05, 0.0015967590734362602], [0.852299690246582, 0.005905137397348881, 0.0071694375947117805, 0.05233130231499672, 0.03880264237523079, 0.01296300534158945, 0.0021456326358020306, 0.02838314324617386], [0.12494358420372009, 0.00875945296138525, 0.036229848861694336, 0.019153151661157608, 0.05839503929018974, 0.6138701438903809, 0.10511308908462524, 0.0335356742143631], [0.016652178019285202, 0.0011119056725874543, 0.000993717578239739, 0.0004838491149712354, 0.9386332035064697, 0.0009565797518007457, 0.028921877965331078, 0.01224667951464653], [0.03371454030275345, 0.02884453535079956, 8.040719694690779e-05, 0.0072661940939724445, 0.6611404418945312, 0.193736270070076, 0.002781073097139597, 0.0724366307258606], [0.3855246901512146, 0.05951862782239914, 0.007979311048984528, 0.016040757298469543, 0.09083730727434158, 0.05667491629719734, 0.07411535829305649, 0.3093090057373047]], [[0.061507824808359146, 0.004986283835023642, 0.009816857054829597, 0.07514869421720505, 0.014307225123047829, 0.009592472575604916, 0.008735141716897488, 0.8159054517745972], [0.6936283707618713, 0.0034856575075536966, 0.017981410026550293, 0.01926223747432232, 0.038159891963005066, 0.1278093010187149, 0.024989880621433258, 0.07468316704034805], [0.652849018573761, 0.028495971113443375, 0.0017546508461236954, 0.03165152296423912, 0.09031364321708679, 0.02440478280186653, 0.0024394532665610313, 0.16809092462062836], [0.6573171615600586, 0.01937190629541874, 0.030498238280415535, 0.003067685291171074, 0.12997685372829437, 0.06937044858932495, 0.03320953622460365, 0.0571882463991642], [0.5022286176681519, 0.02390853688120842, 0.047651257365942, 0.06722987443208694, 0.026876086369156837, 0.05948801711201668, 0.05216461420059204, 0.22045299410820007], [0.4551982283592224, 0.12741941213607788, 0.009735074825584888, 0.04626713693141937, 0.17061921954154968, 0.011488097719848156, 0.011208719573915005, 0.16806408762931824], [0.6686170101165771, 0.0323091484606266, 0.002050392096862197, 0.031197700649499893, 0.07351170480251312, 0.023515067994594574, 0.002725988393649459, 0.16607296466827393], [0.027827898040413857, 0.006076654884964228, 0.02478516846895218, 0.05346723645925522, 0.04188399016857147, 0.013200240209698677, 0.025900790467858315, 0.8068580031394958]], [[0.37314048409461975, 0.021659530699253082, 0.0068834396079182625, 0.012100204825401306, 0.015690261498093605, 0.0117213549092412, 0.006088954862207174, 0.5527158379554749], [0.17211830615997314, 0.10364583134651184, 0.1301177591085434, 0.018486587330698967, 0.16217869520187378, 0.2301998883485794, 0.11315572261810303, 0.0700971931219101], [0.127826526761055, 0.22351288795471191, 0.011492833495140076, 0.02002270705997944, 0.27154844999313354, 0.2418150007724762, 0.014552944339811802, 0.08922874927520752], [0.06043564900755882, 0.2236536145210266, 0.014078116975724697, 0.4781205654144287, 0.147333562374115, 0.03151123970746994, 0.02375037595629692, 0.021116793155670166], [0.30136212706565857, 0.23937353491783142, 0.026709187775850296, 0.009023210033774376, 0.1032920554280281, 0.08444643765687943, 0.019722646102309227, 0.21607083082199097], [0.3582819402217865, 0.23183543980121613, 0.016988638788461685, 0.009715518914163113, 0.18971988558769226, 0.061987318098545074, 0.016949601471424103, 0.11452160775661469], [0.17772692441940308, 0.29963552951812744, 0.009281638078391552, 0.024924851953983307, 0.2214791178703308, 0.16478899121284485, 0.007413079962134361, 0.09474991261959076], [0.4654928147792816, 0.008104012347757816, 0.004996109288185835, 0.005109735298901796, 0.0022489074617624283, 0.005616891197860241, 0.005293205380439758, 0.5031382441520691]], [[0.32516294717788696, 0.05195345729589462, 0.05868571251630783, 0.09858476370573044, 0.018880117684602737, 0.035638418048620224, 0.06707505136728287, 0.34401947259902954], [0.34796974062919617, 0.0205382090061903, 0.03472105413675308, 0.01129847951233387, 0.2005143165588379, 0.0325164794921875, 0.041761964559555054, 0.31067976355552673], [0.4990384578704834, 0.052962224930524826, 0.01959570124745369, 0.006823993753641844, 0.13235898315906525, 0.058755598962306976, 0.02537553198635578, 0.20508944988250732], [0.16853070259094238, 0.07116549462080002, 0.010323697701096535, 0.641282320022583, 0.04777121916413307, 0.018559755757451057, 0.017880234867334366, 0.024486495181918144], [0.32847610116004944, 0.13795273005962372, 0.0429055280983448, 0.017877832055091858, 0.020245159044861794, 0.06881272047758102, 0.03249341994524002, 0.3512364625930786], [0.6089703440666199, 0.08981002867221832, 0.06743787974119186, 0.021137459203600883, 0.06924913823604584, 0.013632402755320072, 0.046718910336494446, 0.08304383605718613], [0.5474951267242432, 0.0640471950173378, 0.02393644116818905, 0.012628615833818913, 0.15073655545711517, 0.04183092340826988, 0.014984801411628723, 0.144340381026268], [0.22702613472938538, 0.1166316568851471, 0.12158145755529404, 0.059729959815740585, 0.07013487070798874, 0.06855633854866028, 0.08453648537397385, 0.25180312991142273]], [[0.23177692294120789, 0.07106755673885345, 0.09083788841962814, 0.052608612924814224, 0.11866630613803864, 0.08092959970235825, 0.10823573917150497, 0.2458774298429489], [0.05008746311068535, 0.9071791768074036, 0.011075121350586414, 0.0033851657062768936, 0.0013047298416495323, 0.0023669209331274033, 0.00799394492059946, 0.0166074950248003], [0.011280752718448639, 0.012810920365154743, 0.6478146314620972, 0.0001252702932106331, 0.0005299689364619553, 0.0030737051274627447, 0.320393443107605, 0.00397133082151413], [0.013934544287621975, 0.0008706855587661266, 2.196325294789858e-05, 0.9825156927108765, 0.00019722621073015034, 0.00025616338825784624, 1.3778138054476585e-05, 0.0021899191197007895], [0.04946361854672432, 0.012715776450932026, 0.004179408773779869, 0.0020629235077649355, 0.9165554642677307, 0.004639063961803913, 0.0010368094081059098, 0.009347072802484035], [0.024397682398557663, 0.016373269259929657, 0.021411115303635597, 0.006017624866217375, 0.013227240182459354, 0.9061394929885864, 0.005666240584105253, 0.0067673493176698685], [0.004556960891932249, 0.007396268658339977, 0.8303858041763306, 7.510435534641147e-05, 0.00040022245957516134, 0.002635061042383313, 0.15173038840293884, 0.0028200848028063774], [0.15955699980258942, 0.164989173412323, 0.18811315298080444, 0.06665091961622238, 0.11844762414693832, 0.06048513948917389, 0.0741359293460846, 0.16762112081050873]], [[0.23096993565559387, 0.022094199433922768, 0.006907739210873842, 0.03260308876633644, 0.07543440908193588, 0.02995281293988228, 0.008113711141049862, 0.5939241051673889], [0.014215970411896706, 0.09941413998603821, 0.3274126648902893, 0.05224282294511795, 0.12152573466300964, 0.21468064188957214, 0.16576091945171356, 0.004747138824313879], [0.01653105393052101, 0.1571933478116989, 0.00286175892688334, 0.016035500913858414, 0.18120470643043518, 0.6183955669403076, 0.0031689018942415714, 0.004609070252627134], [0.06494282931089401, 0.013422232121229172, 0.004351973067969084, 0.8438374996185303, 0.0021331198513507843, 0.01371854729950428, 0.0028363356832414865, 0.054757505655288696], [0.015980403870344162, 0.39125362038612366, 0.029664665460586548, 0.029971089214086533, 0.3427659869194031, 0.15237721800804138, 0.019196579232811928, 0.018790477886795998], [0.006722535938024521, 0.010192631743848324, 0.0025560923386365175, 0.0029197814874351025, 0.9604284763336182, 0.007977462373673916, 0.0025294520892202854, 0.006673522759228945], [0.016234813258051872, 0.0708569884300232, 0.0022277962416410446, 0.023645849898457527, 0.13088080286979675, 0.7500472068786621, 0.0024812319315969944, 0.0036254313308745623], [0.04695603996515274, 0.02222830429673195, 0.002104147570207715, 0.007211680058389902, 0.02083907090127468, 0.0069567118771374226, 0.0024497213307768106, 0.8912543654441833]], [[0.37432634830474854, 0.12012062966823578, 0.11431621760129929, 0.26436567306518555, 0.05188949406147003, 0.02554706484079361, 0.024243298918008804, 0.02519121952354908], [0.4708598256111145, 0.3073054552078247, 0.019229386001825333, 0.0013174260966479778, 0.0019605588167905807, 0.0097580561414361, 0.0612870454788208, 0.12828221917152405], [0.08721638470888138, 0.8477073311805725, 0.0060676634311676025, 0.026804091408848763, 0.0022430988028645515, 0.0007727952906861901, 4.2524316086201e-06, 0.02918442338705063], [0.5687860250473022, 0.03031921572983265, 0.18561358749866486, 0.21049439907073975, 0.000536516250576824, 2.0967812815797515e-05, 0.0001274324458790943, 0.004101915750652552], [0.4388923943042755, 0.0056887720711529255, 0.021345390006899834, 0.43549060821533203, 0.09328281879425049, 0.0050484295934438705, 3.957430453738198e-05, 0.00021211974672041833], [4.44415672973264e-05, 2.5544872528371343e-07, 1.8009177438216284e-07, 3.42858511430677e-05, 0.999894380569458, 2.436284012219403e-05, 1.754192908265395e-06, 3.0385115223907633e-07], [0.0023087160661816597, 2.7358006263966672e-05, 3.23849569383583e-09, 0.00010809687955770642, 0.08591807633638382, 0.9109966158866882, 0.0001854546571848914, 0.00045567337656393647], [0.06220272555947304, 0.012949603609740734, 4.074903699802235e-05, 0.0007212741766124964, 0.0021399555262178183, 0.08636347204446793, 0.7385498881340027, 0.097032330930233]], [[0.5705273747444153, 0.09941532462835312, 0.026664312928915024, 0.07433290034532547, 0.05465018004179001, 0.032215919345617294, 0.023897111415863037, 0.11829690635204315], [0.18915246427059174, 0.14583230018615723, 0.060214024037122726, 0.055503640323877335, 0.207358255982399, 0.17269711196422577, 0.06488457322120667, 0.10435760021209717], [0.2948305010795593, 0.37612441182136536, 0.04532751813530922, 0.07229488343000412, 0.0670148953795433, 0.04879501089453697, 0.01161283627152443, 0.08400004357099533], [0.7285773158073425, 0.12414674460887909, 0.02443859912455082, 0.0292475838214159, 0.05259259045124054, 0.014122744090855122, 0.008368856273591518, 0.01850569248199463], [0.03883694112300873, 0.3613016903400421, 0.282673716545105, 0.08470508456230164, 0.08593498915433884, 0.07198580354452133, 0.03749614208936691, 0.037065643817186356], [0.0626014992594719, 0.24943587183952332, 0.10349496454000473, 0.14208057522773743, 0.3482964336872101, 0.03714170679450035, 0.013220871798694134, 0.04372808709740639], [0.04197202995419502, 0.11452856659889221, 0.03591115027666092, 0.1490740329027176, 0.4492402672767639, 0.1696920543909073, 0.013575269840657711, 0.02600664086639881], [0.104124516248703, 0.11107372492551804, 0.034636568278074265, 0.09604281932115555, 0.2707063555717468, 0.25232425332069397, 0.0767633393406868, 0.05432842671871185]], [[0.49281075596809387, 0.06777603179216385, 0.0320909209549427, 0.12199041247367859, 0.08602488040924072, 0.08306851983070374, 0.0380973182618618, 0.07814112305641174], [0.5045677423477173, 0.0019958235789090395, 0.008274255320429802, 0.047509972006082535, 0.15707597136497498, 0.019866054877638817, 0.010953059419989586, 0.24975717067718506], [0.34259089827537537, 0.010424750857055187, 0.005044217687100172, 0.06250599026679993, 0.10652288794517517, 0.041327252984046936, 0.005944816395640373, 0.42563921213150024], [0.46543341875076294, 0.014330855570733547, 0.046955760568380356, 0.002964757615700364, 0.12457997351884842, 0.1701129823923111, 0.062043461948633194, 0.11357877403497696], [0.3824474513530731, 0.16160273551940918, 0.07174894213676453, 0.046838246285915375, 0.004863458685576916, 0.04397314041852951, 0.07420314848423004, 0.21432289481163025], [0.27989956736564636, 0.04224467650055885, 0.006375844124704599, 0.3161732256412506, 0.05011150613427162, 0.0013874198775738478, 0.0052262842655181885, 0.29858145117759705], [0.3836717903614044, 0.010954215191304684, 0.0037486751098185778, 0.09446178376674652, 0.16251733899116516, 0.035259347409009933, 0.0045150709338486195, 0.30487173795700073], [0.25542524456977844, 0.07928185909986496, 0.06753561645746231, 0.23199768364429474, 0.06726896017789841, 0.09417888522148132, 0.06296490132808685, 0.14134684205055237]], [[0.5101070404052734, 0.04607206955552101, 0.008715823292732239, 0.018747428432106972, 0.06038355827331543, 0.023051660507917404, 0.008998927660286427, 0.32392340898513794], [0.05794176086783409, 0.06309250742197037, 0.01299362163990736, 0.017333222553133965, 0.6477261781692505, 0.14451074600219727, 0.020874924957752228, 0.03552701324224472], [0.0178472138941288, 0.1535504311323166, 0.0006408945773728192, 0.0031119436025619507, 0.7169285416603088, 0.09466126561164856, 0.0010667629539966583, 0.01219285186380148], [0.3327995240688324, 0.1992001235485077, 0.028376717120409012, 0.09949552267789841, 0.06920640170574188, 0.1076567992568016, 0.027799559757113457, 0.13546539843082428], [0.050820473581552505, 0.08555430918931961, 0.0038811052218079567, 0.008250550366938114, 0.6641672849655151, 0.061256103217601776, 0.007462869863957167, 0.1186072900891304], [0.0445331409573555, 0.06386175006628036, 0.0013895010342821479, 0.0012612753780558705, 0.8568770885467529, 0.006407692097127438, 0.002574256854131818, 0.02309529297053814], [0.01671077311038971, 0.1453532725572586, 0.0004975610645487905, 0.002941465936601162, 0.7179335951805115, 0.09635534882545471, 0.0008506744052283466, 0.019357332959771156], [0.39538097381591797, 0.03193436935544014, 0.00903250277042389, 0.010311814025044441, 0.10750748217105865, 0.024123361334204674, 0.012732558883726597, 0.4089770019054413]]], [[[0.5196425318717957, 0.01138569787144661, 0.003245145082473755, 0.02928265929222107, 0.005563313607126474, 0.00434377184137702, 0.0029544986318796873, 0.42358237504959106], [0.203314870595932, 0.6233835220336914, 0.02318795584142208, 0.004530611913651228, 0.013668619096279144, 0.028320422396063805, 0.011793406680226326, 0.09180064499378204], [0.011698299087584019, 0.9470238089561462, 0.006001747213304043, 0.004693630151450634, 0.004846682772040367, 0.016546104103326797, 0.0033589990343898535, 0.0058306059800088406], [0.40242820978164673, 0.1157413199543953, 0.031200749799609184, 0.20765237510204315, 0.0035143315326422453, 0.025653427466750145, 0.02148706465959549, 0.19232256710529327], [0.4345463514328003, 0.20750391483306885, 0.022308005020022392, 0.0017538758693262935, 0.03291594609618187, 0.047833409160375595, 0.013241465203464031, 0.23989702761173248], [0.3750551640987396, 0.13136176764965057, 0.023505035787820816, 0.0009256611228920519, 0.03285611793398857, 0.02935982495546341, 0.022045068442821503, 0.3848913311958313], [0.005207605194300413, 0.9607976675033569, 0.00593813881278038, 0.002331298543140292, 0.0039303782396018505, 0.014877952635288239, 0.0034472665283828974, 0.0034696648363023996], [0.5324410796165466, 0.006187204271554947, 0.004935906268656254, 0.016793305054306984, 0.0044795856811106205, 0.004639124032109976, 0.0034595488104969263, 0.4270643889904022]], [[0.3494865596294403, 0.04159921035170555, 0.040438879281282425, 0.05315172299742699, 0.0825556293129921, 0.036677684634923935, 0.041582562029361725, 0.3545078933238983], [0.16878536343574524, 0.07989595830440521, 0.11918269842863083, 0.0015622383216395974, 0.43921199440956116, 0.04291420802474022, 0.07624074816703796, 0.0722067579627037], [0.23556040227413177, 0.07412397116422653, 0.05673488974571228, 0.009733881801366806, 0.4511459171772003, 0.04229385033249855, 0.049257613718509674, 0.08114947378635406], [0.2850003242492676, 0.060983553528785706, 0.08015524595975876, 0.08638075739145279, 0.07489130645990372, 0.013675021938979626, 0.07393232733011246, 0.3249814510345459], [0.2413238286972046, 0.1047351062297821, 0.09992577880620956, 0.0023500046227127314, 0.3550298511981964, 0.03516245633363724, 0.06756436824798584, 0.09390858560800552], [0.5291825532913208, 0.02519182115793228, 0.024668028578162193, 0.007743256166577339, 0.14212723076343536, 0.03516913950443268, 0.01693633571267128, 0.2189815491437912], [0.21679532527923584, 0.05152006074786186, 0.0411435030400753, 0.009675621055066586, 0.4933089315891266, 0.051493365317583084, 0.044806741178035736, 0.09125638753175735], [0.7164539098739624, 0.026473060250282288, 0.01779986172914505, 0.026522299274802208, 0.03836076334118843, 0.05046295374631882, 0.018555762246251106, 0.10537140816450119]], [[0.2560795843601227, 0.09779997169971466, 0.08347774296998978, 0.04442361369729042, 0.1362779438495636, 0.06054935231804848, 0.07553161680698395, 0.24586012959480286], [0.23759257793426514, 0.000580218737013638, 0.0012038463028147817, 5.0108217692468315e-05, 0.0031317383982241154, 0.0012855062959715724, 0.0015591956907883286, 0.7545968294143677], [0.2669764459133148, 0.008842840790748596, 0.00457348907366395, 0.0015042121522128582, 0.024521201848983765, 0.00845293514430523, 0.00521265110000968, 0.679916262626648], [0.3593103885650635, 0.00023839778441470116, 0.0002929760084953159, 0.0005105437594465911, 0.001451803371310234, 0.0011992614017799497, 0.0006853505037724972, 0.6363112926483154], [0.22500811517238617, 0.003045446937903762, 0.0036691511049866676, 0.00028488290263339877, 0.008593457750976086, 0.003370349993929267, 0.0026306514628231525, 0.7533978819847107], [0.2690473794937134, 0.0006262868409976363, 0.00046101651969365776, 4.8805606638779864e-05, 0.002965083345770836, 0.0007183088455349207, 0.0004571162280626595, 0.7256759405136108], [0.347226619720459, 0.006903868168592453, 0.003493234049528837, 0.001331438310444355, 0.018428610637784004, 0.008616299368441105, 0.00258346414193511, 0.6114164590835571], [0.3682744801044464, 0.04437039792537689, 0.07374053448438644, 0.04669110104441643, 0.13634629547595978, 0.030375750735402107, 0.049248456954956055, 0.25095292925834656]], [[0.10355254262685776, 0.12388528138399124, 0.10961143672466278, 0.1265053153038025, 0.20479044318199158, 0.10564877837896347, 0.07099638134241104, 0.15500982105731964], [0.1912764310836792, 0.12796908617019653, 0.13806062936782837, 0.08882609754800797, 0.1465805321931839, 0.09980557858943939, 0.10303863883018494, 0.10444293916225433], [0.11942638456821442, 0.2193172723054886, 0.08375659584999084, 0.23122601211071014, 0.12991541624069214, 0.07538841664791107, 0.08960402011871338, 0.05136581510305405], [0.07830522954463959, 0.045927807688713074, 0.09736242890357971, 0.2761763334274292, 0.17341436445713043, 0.1709659844636917, 0.08440594375133514, 0.0734419897198677], [0.0642535611987114, 0.1536492556333542, 0.15784962475299835, 0.2434677630662918, 0.07275507599115372, 0.12476792186498642, 0.14667168259620667, 0.03658512979745865], [0.0873662680387497, 0.18265801668167114, 0.16615046560764313, 0.15363696217536926, 0.1537259966135025, 0.08244524896144867, 0.13540111482143402, 0.038615912199020386], [0.10562475025653839, 0.14184676110744476, 0.08366267383098602, 0.342235803604126, 0.1165543794631958, 0.06708376854658127, 0.09426809102296829, 0.04872376099228859], [0.19978567957878113, 0.10382338613271713, 0.09856998175382614, 0.06089109182357788, 0.13884961605072021, 0.12586206197738647, 0.05005091056227684, 0.22216717898845673]], [[0.29180169105529785, 0.0591089092195034, 0.025485491380095482, 0.07145343720912933, 0.026209216564893723, 0.07782501727342606, 0.04143137112259865, 0.40668490529060364], [0.11158925294876099, 0.6429012417793274, 0.008890517055988312, 0.0013016427401453257, 0.0006347691523842514, 0.007795777637511492, 0.00694163516163826, 0.21994519233703613], [0.029129520058631897, 0.006361203733831644, 0.17398834228515625, 0.0006594877340830863, 0.0010487991385161877, 0.00295412284322083, 0.7501970529556274, 0.03566153347492218], [0.008640546351671219, 4.74070075142663e-05, 2.66766164713772e-05, 0.9786419868469238, 6.703981489408761e-05, 0.00033242374774999917, 2.6797351893037558e-05, 0.012217086739838123], [0.2662560045719147, 0.0014371915021911263, 0.001877296599559486, 0.003031244035810232, 0.3673425614833832, 0.027847111225128174, 0.0009084941702894866, 0.33130013942718506], [0.1901874542236328, 0.005040443502366543, 0.0033200986217707396, 0.004717221483588219, 0.017999177798628807, 0.5889667868614197, 0.0012773032067343593, 0.18849146366119385], [0.03709268942475319, 0.011007944121956825, 0.8450267910957336, 0.0010429957183077931, 0.0009145983494818211, 0.001971675083041191, 0.08795955777168274, 0.014983708038926125], [0.4064842760562897, 0.04132836312055588, 0.026201331987977028, 0.0641905814409256, 0.02021893300116062, 0.04889436066150665, 0.013169857673346996, 0.3795122504234314]], [[0.050620388239622116, 0.11911308020353317, 0.12330275774002075, 0.22043251991271973, 0.1287059634923935, 0.12507426738739014, 0.1428094208240509, 0.08994166553020477], [0.021595457568764687, 0.6676000356674194, 0.09079601615667343, 0.04573917016386986, 0.021805107593536377, 0.03152820095419884, 0.09013108909130096, 0.030804935842752457], [0.00033206024090759456, 0.002448219573125243, 0.320136159658432, 4.8422993131680414e-05, 0.0027510218787938356, 0.010195239447057247, 0.6633445024490356, 0.0007444250513799489], [0.001045730896294117, 0.0006539783789776266, 2.5031424229382537e-05, 0.9949718713760376, 1.2653193152800668e-05, 4.498447378864512e-05, 2.583549212431535e-05, 0.0032199095003306866], [0.006817441899329424, 0.0037793279625475407, 0.03802042454481125, 0.0007317200652323663, 0.8240209221839905, 0.06226484104990959, 0.0509178563952446, 0.013447563163936138], [0.003175186924636364, 0.0067818863317370415, 0.06607306748628616, 0.0013993018073961139, 0.05187925323843956, 0.7497026920318604, 0.1171937882900238, 0.0037947942037135363], [0.000356605916749686, 0.00292345997877419, 0.4265701472759247, 5.944446456851438e-05, 0.0028959098272025585, 0.013940851204097271, 0.5525378584861755, 0.0007157087093219161], [0.08361717313528061, 0.16605955362319946, 0.11804387718439102, 0.21081297099590302, 0.07463439553976059, 0.09056703746318817, 0.13192136585712433, 0.12434370815753937]], [[0.26628196239471436, 0.11264508962631226, 0.06975775212049484, 0.07298874109983444, 0.1774655133485794, 0.09463614225387573, 0.07368424534797668, 0.13254055380821228], [0.2147480696439743, 0.10667271912097931, 0.274047315120697, 0.012847548350691795, 0.09800393879413605, 0.08140179514884949, 0.167030930519104, 0.04524771496653557], [0.2534951865673065, 0.08841413259506226, 0.03794461861252785, 0.05564458295702934, 0.3036384582519531, 0.09028732776641846, 0.03274466097354889, 0.13783100247383118], [0.6473450064659119, 0.020831244066357613, 0.009059889242053032, 0.12418235838413239, 0.02713010460138321, 0.014765151776373386, 0.022237028926610947, 0.13444925844669342], [0.07942035049200058, 0.09416671842336655, 0.03843800351023674, 0.00199121399782598, 0.04561898112297058, 0.43377581238746643, 0.28018948435783386, 0.026399459689855576], [0.14524485170841217, 0.2324141561985016, 0.07769623398780823, 0.003657365683466196, 0.07677823305130005, 0.08413361012935638, 0.34140047430992126, 0.03867499902844429], [0.3094787299633026, 0.06525856256484985, 0.013340619392693043, 0.039336416870355606, 0.14791470766067505, 0.11296460032463074, 0.06663388758897781, 0.24507245421409607], [0.2155054658651352, 0.10222671180963516, 0.08376257121562958, 0.0826445147395134, 0.18846452236175537, 0.05776534602046013, 0.09956230968236923, 0.17006856203079224]], [[0.2226928472518921, 0.12133507430553436, 0.06570715457201004, 0.3576356768608093, 0.03725689649581909, 0.027359597384929657, 0.06351664662361145, 0.1044960469007492], [0.19675306975841522, 0.2645280063152313, 0.11124969273805618, 0.05952325835824013, 0.11188884824514389, 0.10376156121492386, 0.06417158991098404, 0.08812404423952103], [0.09769613295793533, 0.6783900856971741, 0.019683316349983215, 0.01996757462620735, 0.06249760463833809, 0.0375230610370636, 0.01085041556507349, 0.07339189946651459], [0.000997378840111196, 1.2709959264611825e-05, 1.2241048352734651e-05, 0.9973466396331787, 3.41159466188401e-05, 3.8847396353958175e-05, 3.283859768998809e-05, 0.0015251269796863198], [0.29806241393089294, 0.0950760766863823, 0.01787104271352291, 0.0381411537528038, 0.271556556224823, 0.14041677117347717, 0.015661990270018578, 0.12321391701698303], [0.2769582271575928, 0.07864725589752197, 0.06758362054824829, 0.029800016433000565, 0.18363872170448303, 0.15559260547161102, 0.05781567469239235, 0.149963840842247], [0.11495951563119888, 0.5572694540023804, 0.03356575965881348, 0.025764191523194313, 0.08688468486070633, 0.0651988834142685, 0.02537304162979126, 0.0909845381975174], [0.23288846015930176, 0.044576022773981094, 0.016984563320875168, 0.5635581016540527, 0.010411752387881279, 0.010220111347734928, 0.01796325109899044, 0.10339774191379547]], [[0.3317427635192871, 0.07053609192371368, 0.04861629754304886, 0.11069820076227188, 0.0741690918803215, 0.10263148695230484, 0.05787433311343193, 0.2037317454814911], [0.4211222231388092, 0.010286745615303516, 0.03275614604353905, 0.03483392670750618, 0.13295559585094452, 0.13907895982265472, 0.033565811812877655, 0.1954006552696228], [0.45389923453330994, 0.0202352162450552, 0.0017944795545190573, 0.20991204679012299, 0.0717584639787674, 0.050260331481695175, 0.002101341262459755, 0.19003888964653015], [0.3036538362503052, 0.01774531602859497, 0.07321341335773468, 0.14325478672981262, 0.09055747091770172, 0.1620083749294281, 0.12069421261548996, 0.08887264132499695], [0.34592682123184204, 0.21887823939323425, 0.0468854196369648, 0.2159809172153473, 0.01076820120215416, 0.031304143369197845, 0.04159217327833176, 0.08866407722234726], [0.44147995114326477, 0.1277870237827301, 0.03913760185241699, 0.1965000480413437, 0.03174512833356857, 0.030047236010432243, 0.0395045131444931, 0.09379841387271881], [0.44428926706314087, 0.024074940010905266, 0.0018828004831448197, 0.3357801139354706, 0.08223600685596466, 0.04151713475584984, 0.0019489011028781533, 0.06827079504728317], [0.2619381248950958, 0.08662679046392441, 0.07271482795476913, 0.046930864453315735, 0.06032596901059151, 0.10792206972837448, 0.07936929911375046, 0.28417202830314636]], [[0.17036905884742737, 0.09374919533729553, 0.056285008788108826, 0.07880574464797974, 0.11792739480733871, 0.03320392221212387, 0.04921203479170799, 0.40044766664505005], [0.23079784214496613, 0.10086973011493683, 0.045393045991659164, 0.07953751087188721, 0.20811469852924347, 0.12353647500276566, 0.0502031072974205, 0.16154757142066956], [0.11766994744539261, 0.14583642780780792, 0.027642441913485527, 0.15445421636104584, 0.29655829071998596, 0.09770254790782928, 0.03711467608809471, 0.1230214312672615], [0.4688645601272583, 0.019385332241654396, 0.009252750314772129, 0.009190435521304607, 0.08619748800992966, 0.0785895586013794, 0.017971647903323174, 0.31054824590682983], [0.23604696989059448, 0.12220938503742218, 0.05268334597349167, 0.1532713621854782, 0.10156470537185669, 0.0655030757188797, 0.04173590987920761, 0.22698521614074707], [0.35775813460350037, 0.11568240076303482, 0.03710141032934189, 0.11355770379304886, 0.08414788544178009, 0.032787907868623734, 0.05120260268449783, 0.2077620029449463], [0.14463065564632416, 0.09246806055307388, 0.025685016065835953, 0.1874459981918335, 0.2766963839530945, 0.10948389768600464, 0.04394901916384697, 0.11964094638824463], [0.18020395934581757, 0.06629716604948044, 0.06115063279867172, 0.1312057077884674, 0.1254177838563919, 0.031851641833782196, 0.06378261744976044, 0.34009048342704773]], [[0.336747407913208, 0.06747261434793472, 0.04586166515946388, 0.04922793433070183, 0.15118440985679626, 0.10690439492464066, 0.03903232514858246, 0.20356929302215576], [0.010306148789823055, 0.7482750415802002, 0.062351495027542114, 0.0009479798609390855, 0.08355914801359177, 0.04582035541534424, 0.04491924121975899, 0.0038206465542316437], [0.033293526619672775, 0.6218602657318115, 0.031211521476507187, 0.0013937478652223945, 0.040449436753988266, 0.22143429517745972, 0.031995147466659546, 0.01836211048066616], [0.03938399627804756, 0.005099129863083363, 0.0007541029481217265, 0.9117987751960754, 0.0009483787580393255, 0.0026104592252522707, 0.0006884734611958265, 0.038716740906238556], [0.011509529314935207, 0.3493000566959381, 0.08537448197603226, 9.623405640013516e-05, 0.2656245231628418, 0.2514829635620117, 0.03090091235935688, 0.0057112304493784904], [0.028588294982910156, 0.4989347457885742, 0.08468275517225266, 0.0013154929038137197, 0.09597647935152054, 0.22805990278720856, 0.03937738016247749, 0.023065052926540375], [0.03964404761791229, 0.5695553421974182, 0.04802042990922928, 0.0018340471433475614, 0.05632602795958519, 0.2408268302679062, 0.02512924000620842, 0.018664121627807617], [0.43051114678382874, 0.04699878767132759, 0.04876933619379997, 0.08530368655920029, 0.08169656246900558, 0.08239924907684326, 0.035054389387369156, 0.18926678597927094]], [[0.10542326420545578, 0.1266256868839264, 0.10753358155488968, 0.19754943251609802, 0.08219078183174133, 0.15605735778808594, 0.142562136054039, 0.08205784112215042], [0.2635948657989502, 0.008173267357051373, 0.016553740948438644, 0.38369637727737427, 0.012388985604047775, 0.03136269375681877, 0.016881359741091728, 0.26734867691993713], [0.27557966113090515, 0.00711330771446228, 0.002657907083630562, 0.1606028825044632, 0.003814391791820526, 0.010721978731453419, 0.0031245690770447254, 0.5363853573799133], [0.19746020436286926, 0.09129729866981506, 0.06482209265232086, 0.2942626476287842, 0.03547756373882294, 0.06706167757511139, 0.07449784129858017, 0.17512069642543793], [0.2839234173297882, 0.06356432288885117, 0.030923238024115562, 0.22195695340633392, 0.0019394410774111748, 0.009605353698134422, 0.02105684205889702, 0.36703041195869446], [0.24098718166351318, 0.03124634176492691, 0.031069030985236168, 0.44642144441604614, 0.007903465069830418, 0.01133026834577322, 0.032777152955532074, 0.19826513528823853], [0.310398668050766, 0.007495925296097994, 0.0038398189935833216, 0.21262258291244507, 0.004803483374416828, 0.011717344634234905, 0.003608495695516467, 0.4455137252807617], [0.13234823942184448, 0.1558704525232315, 0.17771215736865997, 0.04767831414937973, 0.08120401948690414, 0.05962223932147026, 0.12556971609592438, 0.21999485790729523]]], [[[0.2607910931110382, 0.11253522336483002, 0.03295978158712387, 0.06016317009925842, 0.1524016559123993, 0.07244621962308884, 0.06901108473539352, 0.239691823720932], [0.1305890679359436, 0.27400290966033936, 0.024025918915867805, 0.0035065393894910812, 0.11734426021575928, 0.23014967143535614, 0.08000858873128891, 0.14037299156188965], [0.188144713640213, 0.06785055249929428, 0.04144931957125664, 0.008938535116612911, 0.1337752342224121, 0.1475876420736313, 0.23084217309951782, 0.18141184747219086], [0.1223558858036995, 0.005512073636054993, 0.001385029754601419, 0.6714786291122437, 0.004063135478645563, 0.0015673001762479544, 0.0035549141466617584, 0.19008295238018036], [0.21316000819206238, 0.04453202337026596, 0.006904024630784988, 0.0032217861153185368, 0.19554318487644196, 0.18842177093029022, 0.028555843979120255, 0.31966134905815125], [0.21943530440330505, 0.02099754847586155, 0.005595266353338957, 0.0005614268011413515, 0.04761456325650215, 0.54474937915802, 0.012526767328381538, 0.14851976931095123], [0.45414969325065613, 0.09039794653654099, 0.09972301870584488, 0.009511352516710758, 0.050941601395606995, 0.07905787974596024, 0.07380447536706924, 0.14241407811641693], [0.4113128185272217, 0.055123377591371536, 0.02839682623744011, 0.06644763797521591, 0.07164153456687927, 0.024901648983359337, 0.0304561760276556, 0.31171995401382446]], [[0.210384339094162, 0.08349688351154327, 0.07173537462949753, 0.09056375920772552, 0.11939135193824768, 0.11203742772340775, 0.07977215200662613, 0.23261870443820953], [0.2682461142539978, 0.014613986946642399, 0.04203887656331062, 0.17002445459365845, 0.058123212307691574, 0.03195761889219284, 0.05099283903837204, 0.36400288343429565], [0.21336399018764496, 0.04411306232213974, 0.019366556778550148, 0.2098989635705948, 0.027295252308249474, 0.024415483698248863, 0.024161214008927345, 0.4373854100704193], [0.12654051184654236, 0.1312001645565033, 0.14568130671977997, 0.003294913098216057, 0.0913986787199974, 0.11153916269540787, 0.19452278316020966, 0.19582241773605347], [0.3154485523700714, 0.0636277049779892, 0.03410904109477997, 0.15760596096515656, 0.006914426106959581, 0.03459079936146736, 0.04164468124508858, 0.3460588753223419], [0.4265236556529999, 0.0347447395324707, 0.02168351598083973, 0.12114595621824265, 0.025233326479792595, 0.012647328898310661, 0.02799171581864357, 0.33002978563308716], [0.21771982312202454, 0.04609312489628792, 0.024650869891047478, 0.22517254948616028, 0.02431756630539894, 0.02638200856745243, 0.027331173419952393, 0.408332884311676], [0.32788723707199097, 0.08594750612974167, 0.04430527985095978, 0.1426215022802353, 0.054855480790138245, 0.07305730134248734, 0.04659874364733696, 0.22472697496414185]], [[0.24588434398174286, 0.04422673583030701, 0.10402728617191315, 0.029708851128816605, 0.02296934276819229, 0.02573159709572792, 0.07679854333400726, 0.45065322518348694], [0.2341950535774231, 0.046753913164138794, 0.19183349609375, 0.0006317236693575978, 0.014484052546322346, 0.0030511810909956694, 0.13376404345035553, 0.3752865195274353], [0.2514256536960602, 0.023531002923846245, 0.15062165260314941, 0.004275746643543243, 0.011633104644715786, 0.002903283340856433, 0.14864760637283325, 0.4069618880748749], [0.2306247353553772, 0.006558806169778109, 0.13858290016651154, 0.11227235943078995, 0.010019679553806782, 0.0021023526787757874, 0.06795936822891235, 0.43187984824180603], [0.2697533667087555, 0.12316031754016876, 0.12561923265457153, 0.005833446979522705, 0.022329622879624367, 0.016733920201659203, 0.08837908506393433, 0.3481910526752472], [0.36249667406082153, 0.07295301556587219, 0.10807780921459198, 0.0009629730484448373, 0.03713027760386467, 0.015773873776197433, 0.0871211439371109, 0.31548425555229187], [0.26444029808044434, 0.021552717313170433, 0.12648014724254608, 0.004021698608994484, 0.008905965834856033, 0.0027608140371739864, 0.14228416979312897, 0.42955413460731506], [0.36420923471450806, 0.051437851041555405, 0.04941776022315025, 0.02817424014210701, 0.043167080730199814, 0.023825090378522873, 0.052755147218704224, 0.38701364398002625]], [[0.3765830099582672, 0.05816907063126564, 0.04181088134646416, 0.13221324980258942, 0.1562284678220749, 0.07744971662759781, 0.027178799733519554, 0.13036683201789856], [0.5193264484405518, 0.0025901063345372677, 0.015602825209498405, 0.352751761674881, 0.05048568174242973, 0.007324535399675369, 0.0009361962438561022, 0.0509825274348259], [0.2810536324977875, 0.003637624206021428, 0.005398365203291178, 0.5871676802635193, 0.08270519971847534, 0.010744161903858185, 0.0006440567085519433, 0.02864932082593441], [0.08746294677257538, 0.02183225005865097, 0.009354855865240097, 0.023380015045404434, 0.5625523328781128, 0.26649919152259827, 0.019179172813892365, 0.009739257395267487], [0.22373364865779877, 0.04708613455295563, 0.0025531246792525053, 0.17243728041648865, 0.007243013475090265, 0.058414045721292496, 0.1520300954580307, 0.33650264143943787], [0.40896275639533997, 0.09592314064502716, 0.004132031928747892, 0.10175859928131104, 0.0016413538251072168, 0.006692295894026756, 0.025378627702593803, 0.35551127791404724], [0.27546823024749756, 0.0118147237226367, 0.001176565419882536, 0.1880369931459427, 0.001570398802869022, 0.003222158644348383, 0.0037978491745889187, 0.514913022518158], [0.32509633898735046, 0.07714282721281052, 0.04903443902730942, 0.13073770701885223, 0.056081052869558334, 0.011741284281015396, 0.010914317332208157, 0.3392520844936371]], [[0.20000140368938446, 0.1259205937385559, 0.06354618817567825, 0.04487544298171997, 0.0620129220187664, 0.030467456206679344, 0.06144768372178078, 0.4117283523082733], [0.04916215315461159, 0.04093281552195549, 0.3425585627555847, 0.001917629037052393, 0.021389450877904892, 0.012085365131497383, 0.438119113445282, 0.09383495151996613], [0.10816267877817154, 0.1058226078748703, 0.25600650906562805, 0.019992409273982048, 0.011369571089744568, 0.005042532458901405, 0.3095996379852295, 0.1840040385723114], [0.05276937782764435, 0.004222098272293806, 0.03853599727153778, 0.7713826894760132, 0.004515719134360552, 0.0009263448882848024, 0.042119257152080536, 0.08552853018045425], [0.3518182039260864, 0.0953337550163269, 0.025921780616044998, 0.015006307512521744, 0.0060338713228702545, 0.022297142073512077, 0.03256881609559059, 0.45102012157440186], [0.2704657316207886, 0.21196411550045013, 0.0421563982963562, 0.0031917451415210962, 0.009127073921263218, 0.024406077340245247, 0.05640712007880211, 0.3822817802429199], [0.1394462287425995, 0.084314726293087, 0.22573480010032654, 0.021845774725079536, 0.007222507614642382, 0.0037611802108585835, 0.29528769850730896, 0.22238703072071075], [0.19335517287254333, 0.16168485581874847, 0.06462014466524124, 0.03257356956601143, 0.06398326903581619, 0.023481903597712517, 0.050320811569690704, 0.40998026728630066]], [[0.41572055220603943, 0.06225515529513359, 0.06848236918449402, 0.22336672246456146, 0.05358103662729263, 0.04357430711388588, 0.013918673619627953, 0.11910118907690048], [0.5653717517852783, 0.1414431929588318, 0.06710700690746307, 0.05179725959897041, 0.0018409707117825747, 0.0004805350035894662, 0.002481928328052163, 0.16947732865810394], [0.7516640424728394, 0.04753664880990982, 0.0019012719858437777, 0.12816035747528076, 0.0120718814432621, 0.0011632838286459446, 9.44253770285286e-05, 0.0574081726372242], [0.43521633744239807, 0.016656052321195602, 0.03959190100431442, 0.3231472373008728, 0.10280812531709671, 0.013543356209993362, 0.026583710685372353, 0.04245323687791824], [0.008282898925244808, 0.0012727356515824795, 0.0015312043251469731, 8.794408495305106e-05, 0.0025366079062223434, 0.7519065737724304, 0.23041792213916779, 0.003964135888963938], [0.005059296265244484, 0.003145357593894005, 0.00374247832223773, 1.5028510460979305e-05, 0.0009063688921742141, 0.002093956572934985, 0.9653088450431824, 0.01972869038581848], [0.06162463501095772, 0.1206449344754219, 0.00013940295320935547, 0.001860247110016644, 5.5792748753447086e-05, 0.0019794192630797625, 0.02579384297132492, 0.787901759147644], [0.15290385484695435, 0.12142058461904526, 0.02570776455104351, 0.16884924471378326, 0.005071927327662706, 0.005521093960851431, 0.0039937193505465984, 0.5165318250656128]], [[0.2359461486339569, 0.09183073788881302, 0.055439915508031845, 0.13411350548267365, 0.133743554353714, 0.02940532937645912, 0.046834517270326614, 0.272686243057251], [0.4061550498008728, 0.02137920819222927, 0.010076681151986122, 0.04384332150220871, 0.02251284569501877, 0.01219575572758913, 0.008043804205954075, 0.47579336166381836], [0.4271731674671173, 0.031572356820106506, 0.020235542207956314, 0.1375972181558609, 0.03367321193218231, 0.026196828112006187, 0.018641801550984383, 0.3049098253250122], [0.010807706043124199, 0.00029549820465035737, 0.0015287534333765507, 0.9767032265663147, 0.0002387637650826946, 0.00017978886899072677, 0.001960574882104993, 0.008285663090646267], [0.23933908343315125, 0.26204490661621094, 0.08059801161289215, 0.03583352640271187, 0.07917484641075134, 0.0702708289027214, 0.06505642831325531, 0.16768242418766022], [0.5095899105072021, 0.015039115212857723, 0.016085581853985786, 0.016470879316329956, 0.03422701358795166, 0.02692529745399952, 0.012831825762987137, 0.3688303232192993], [0.44571563601493835, 0.05376021936535835, 0.03473145514726639, 0.0756523534655571, 0.042157530784606934, 0.03972173109650612, 0.032450322061777115, 0.2758108079433441], [0.2222408652305603, 0.0854879766702652, 0.046315424144268036, 0.16284243762493134, 0.09421991556882858, 0.020068064332008362, 0.039220210164785385, 0.3296050429344177]], [[0.7653884887695312, 0.0002476693771313876, 0.001427812036126852, 0.22496995329856873, 0.007897387258708477, 5.31404430148541e-06, 3.4696259199051838e-09, 6.344463326968253e-05], [0.9050750732421875, 0.0018784564454108477, 0.0005228671943768859, 0.06869775056838989, 1.2077185918002442e-09, 1.2591701769801289e-12, 4.009449514069544e-16, 0.023825911805033684], [0.16034507751464844, 4.4700760781779536e-07, 4.144190768329281e-07, 0.8396499156951904, 4.231325419823406e-06, 2.465670246101781e-12, 1.3558816030935874e-21, 1.5323690760737918e-08], [0.017588108777999878, 6.85374885733836e-08, 1.5040714060887694e-05, 0.004445558413863182, 0.9779450297355652, 6.210652372828918e-06, 9.35906019350341e-10, 9.021579039369954e-09], [2.3237036828049895e-07, 9.29210527966795e-12, 3.0092383663041233e-13, 1.2206808008841108e-08, 0.0065815080888569355, 0.9820541143417358, 0.011364128440618515, 7.279229302659118e-11], [6.296686505535831e-10, 1.367711774946656e-07, 2.715023674361005e-14, 8.463227948313223e-15, 3.6514384181216e-13, 1.8271750377607532e-05, 0.9999731779098511, 8.49930802360177e-06], [1.0040717562942447e-10, 3.590165533751133e-06, 5.4274835507207496e-18, 5.266124005879377e-16, 9.299995665901525e-21, 2.202216631275178e-09, 0.00013920722994953394, 0.9998571872711182], [0.0007677633548155427, 0.0013133574975654483, 3.6069550333195366e-06, 1.6285343008348718e-05, 1.4751775376329462e-13, 7.514660314638603e-15, 5.324632878708768e-13, 0.9978989362716675]], [[0.18096919357776642, 0.08129599690437317, 0.06780652701854706, 0.07214730978012085, 0.1359674483537674, 0.11514142900705338, 0.07940949499607086, 0.26726260781288147], [0.2147289514541626, 0.05798080563545227, 0.08645470440387726, 0.1755412220954895, 0.12715867161750793, 0.0899081900715828, 0.05754261836409569, 0.19068488478660583], [0.08930803090333939, 0.061899833381175995, 0.010830068960785866, 0.7029405832290649, 0.0349845364689827, 0.029939426109194756, 0.00840546190738678, 0.06169210374355316], [0.09495075792074203, 0.040676601231098175, 0.3794444799423218, 0.02090083621442318, 0.0756727084517479, 0.07743324339389801, 0.2739194631576538, 0.03700196370482445], [0.2441413849592209, 0.21158915758132935, 0.05164855346083641, 0.062156375497579575, 0.010451214388012886, 0.029203565791249275, 0.04155586659908295, 0.3492538630962372], [0.24364443123340607, 0.09760606288909912, 0.05546291917562485, 0.12623441219329834, 0.0477822981774807, 0.03658442199230194, 0.04006637632846832, 0.3526190221309662], [0.1365480273962021, 0.059156548231840134, 0.01572345197200775, 0.6064568161964417, 0.03895163908600807, 0.03857862204313278, 0.012181572616100311, 0.09240332245826721], [0.14161129295825958, 0.1350780576467514, 0.08876180648803711, 0.05430717393755913, 0.10909415036439896, 0.08329477906227112, 0.08743195235729218, 0.3004208207130432]], [[0.030945684760808945, 0.18244707584381104, 0.21322934329509735, 0.08741999417543411, 0.053719863295555115, 0.11705092340707779, 0.27923616766929626, 0.03595094755291939], [0.09899003803730011, 0.22642964124679565, 0.16276727616786957, 0.05086229741573334, 0.07572664320468903, 0.11532565206289291, 0.19350722432136536, 0.07639122754335403], [0.07106183469295502, 0.21016444265842438, 0.12169443070888519, 0.19023096561431885, 0.06333206593990326, 0.11100748926401138, 0.15420976281166077, 0.07829893380403519], [0.06751108914613724, 0.10873254388570786, 0.18462178111076355, 0.24403907358646393, 0.04444591701030731, 0.05624838545918465, 0.26804155111312866, 0.026359694078564644], [0.1668316274881363, 0.17802618443965912, 0.09248121827840805, 0.06726525723934174, 0.03633077070116997, 0.11957530677318573, 0.11004837602376938, 0.2294413298368454], [0.24002671241760254, 0.10520337522029877, 0.05831097438931465, 0.036742471158504486, 0.04768611863255501, 0.08340735733509064, 0.0645671933889389, 0.3640557825565338], [0.09211453050374985, 0.17457059025764465, 0.12312821298837662, 0.18329863250255585, 0.05786637216806412, 0.1126120314002037, 0.15759815275669098, 0.09881146252155304], [0.1014765202999115, 0.12303707003593445, 0.18224085867404938, 0.15192674100399017, 0.054172106087207794, 0.09278729557991028, 0.2177136242389679, 0.07664574682712555]], [[0.341095894575119, 0.18426182866096497, 0.04858534410595894, 0.09763657301664352, 0.06497520953416824, 0.07307857275009155, 0.029075508937239647, 0.1612910032272339], [0.3606833219528198, 0.03136357292532921, 0.038888413459062576, 0.2599553167819977, 0.05004216730594635, 0.05624738335609436, 0.024221356958150864, 0.17859847843647003], [0.32320350408554077, 0.14249911904335022, 0.015364065766334534, 0.3122791349887848, 0.03393986448645592, 0.03236379101872444, 0.002162575488910079, 0.138187974691391], [0.2810293734073639, 0.18602105975151062, 0.18395841121673584, 0.013098851777613163, 0.1335042417049408, 0.08724334090948105, 0.033488187938928604, 0.08165651559829712], [0.28024494647979736, 0.054811473935842514, 0.029411816969513893, 0.5854120254516602, 0.008401565253734589, 0.005640995688736439, 0.0019147831480950117, 0.03416236490011215], [0.2670026421546936, 0.023840446025133133, 0.011162334121763706, 0.653820812702179, 0.01053899247199297, 0.003046796889975667, 0.006168863736093044, 0.024419071152806282], [0.1543482542037964, 0.03961915522813797, 0.004135345574468374, 0.4159132242202759, 0.1746961772441864, 0.13605698943138123, 0.017626255750656128, 0.05760453641414642], [0.24831372499465942, 0.09684286266565323, 0.02048049308359623, 0.08247985690832138, 0.08095674961805344, 0.0850282832980156, 0.06866797059774399, 0.3172300457954407]], [[0.1769888550043106, 0.136417955160141, 0.05657796189188957, 0.0939934104681015, 0.10469626635313034, 0.14240217208862305, 0.06872893124818802, 0.22019433975219727], [0.0012225902173668146, 0.9472531676292419, 0.02074575610458851, 2.6207264454569668e-05, 0.0006061098538339138, 0.0016455799341201782, 0.02734130248427391, 0.0011591026559472084], [0.04704184830188751, 0.5312251448631287, 0.10925206542015076, 0.024679914116859436, 0.007291178219020367, 0.015584016218781471, 0.18688081204891205, 0.07804502546787262], [0.005890951491892338, 0.00013536078040488064, 8.25075912871398e-05, 0.9894569516181946, 7.665869634365663e-05, 0.00016866964870132506, 9.595468873158097e-05, 0.004092842806130648], [0.21910855174064636, 0.13574784994125366, 0.03902416303753853, 0.0015554085839539766, 0.17124436795711517, 0.17013922333717346, 0.03872792795300484, 0.22445248067378998], [0.07156576216220856, 0.16234742105007172, 0.07644550502300262, 0.0006049371440894902, 0.08249501883983612, 0.4884229302406311, 0.053234197199344635, 0.06488431990146637], [0.062010910362005234, 0.5138973593711853, 0.23017601668834686, 0.027819477021694183, 0.008695931173861027, 0.013493238016963005, 0.08972575515508652, 0.0541813038289547], [0.25321000814437866, 0.18637700378894806, 0.10884464532136917, 0.06967616826295853, 0.11867894232273102, 0.06718339025974274, 0.07625110447406769, 0.11977875232696533]]], [[[0.0910516306757927, 0.4632015526294708, 0.11567742377519608, 0.019032513722777367, 0.03110060840845108, 0.03691175952553749, 0.06256958097219467, 0.18045499920845032], [0.10526259988546371, 0.39302581548690796, 0.05547574535012245, 0.07494177669286728, 0.07932444661855698, 0.05361679196357727, 0.13297481834888458, 0.10537805408239365], [0.05812210962176323, 0.7115265130996704, 0.11033540219068527, 0.04566943645477295, 0.005813707131892443, 0.006600131280720234, 0.018507543951272964, 0.04342515394091606], [0.27909713983535767, 0.22986428439617157, 0.28808724880218506, 0.0942310094833374, 0.01830575056374073, 0.003588563296943903, 0.006630613002926111, 0.08019544929265976], [0.2367941439151764, 0.17108489573001862, 0.34892213344573975, 0.10126549750566483, 0.13197778165340424, 0.002197759225964546, 0.0008633109391666949, 0.0068944282829761505], [0.11655902862548828, 0.02828548662364483, 0.05835608392953873, 0.08666850626468658, 0.6916383504867554, 0.009334330447018147, 0.005079299211502075, 0.0040788957849144936], [0.012572060339152813, 0.03498844429850578, 0.0066841100342571735, 0.12433237582445145, 0.7527581453323364, 0.03792796656489372, 0.027291525155305862, 0.0034453128464519978], [0.022632600739598274, 0.08677412569522858, 0.0031278375536203384, 0.02552880346775055, 0.24819475412368774, 0.27991271018981934, 0.2165304273366928, 0.11729878932237625]], [[0.3895530104637146, 0.5281021595001221, 0.06302981823682785, 2.0792687791981734e-05, 1.416282424671067e-09, 1.5121749408208984e-09, 5.518652557157111e-08, 0.019294140860438347], [0.00010231895430479199, 0.07902266085147858, 1.5318873920477927e-06, 2.614020777613746e-09, 4.255244601125696e-09, 0.00048203623737208545, 0.011222144588828087, 0.9091693162918091], [0.009340476244688034, 0.9839829206466675, 0.0010366386268287897, 2.7889146991810776e-08, 1.0341716420603372e-15, 3.6711278006244796e-13, 4.969094580253852e-12, 0.0056398408487439156], [0.022257519885897636, 0.0005032291519455612, 0.9766378402709961, 0.0006015017279423773, 8.38476754694284e-09, 6.88370843684419e-15, 5.62766837271185e-16, 2.6376460127153223e-08], [4.6644660756101075e-07, 2.7513234746034954e-11, 5.79425829982938e-07, 0.9974159002304077, 0.0025830527301877737, 4.8751255717896166e-14, 4.6906161718074866e-18, 2.0976143935848433e-17], [1.4257413609095049e-12, 2.522841744539983e-12, 8.62462075905011e-15, 3.0289928787397e-08, 0.9999274015426636, 7.20660318620503e-05, 5.309353241500503e-07, 1.6836010142035106e-15], [3.489238141464007e-16, 4.89900817395722e-13, 2.262400973488794e-21, 9.490640966256653e-14, 2.080758713418618e-05, 0.9893724322319031, 0.010606816969811916, 1.8186311831480673e-11], [1.6712524419926211e-10, 1.673823135206476e-05, 6.556578468087243e-14, 5.6135507687008444e-15, 5.55139538938737e-13, 9.606235107639804e-05, 0.9508981704711914, 0.04898902028799057]], [[0.43585631251335144, 0.09773663431406021, 0.3459720313549042, 0.07772380113601685, 0.03373454883694649, 0.0029208031482994556, 0.00025275861844420433, 0.005803184118121862], [0.1670154184103012, 0.010161112993955612, 0.7701616883277893, 0.00400434248149395, 0.0002768632839433849, 2.554633465479128e-05, 0.00048215477727353573, 0.0478728786110878], [0.15971586108207703, 0.01670781522989273, 0.20985135436058044, 0.6007914543151855, 0.012470551766455173, 0.0001570811145938933, 8.162307494785637e-06, 0.00029775401344522834], [0.0954175740480423, 0.0017901529790833592, 0.0058808522298932076, 0.20756061375141144, 0.6513143181800842, 0.036422163248062134, 0.0005551770445890725, 0.0010591750033199787], [0.002706035040318966, 0.004433713853359222, 4.0552586142439395e-05, 0.0026749668177217245, 0.11168529838323593, 0.7392945289611816, 0.13767310976982117, 0.0014918301021680236], [0.003931410610675812, 0.007982534356415272, 7.048398401821032e-05, 7.101149094523862e-06, 4.9969807150773704e-05, 0.028219768777489662, 0.6692856550216675, 0.29045310616493225], [0.000246861221967265, 0.008754933252930641, 8.331037679454312e-05, 1.002797762339469e-05, 1.6758415313233854e-06, 0.0030002493876963854, 0.846676230430603, 0.14122673869132996], [0.06461326032876968, 0.20530498027801514, 0.062162596732378006, 0.0008333955192938447, 1.0791081876959652e-05, 0.00030445627635344863, 0.007475459948182106, 0.6592950820922852]], [[0.16196636855602264, 2.1306852431735024e-05, 0.004778294824063778, 0.7906972765922546, 0.04253640025854111, 2.988810265946995e-08, 3.702349191114784e-12, 4.213581803469424e-07], [0.23583459854125977, 0.0007028084364719689, 0.7211873531341553, 0.04056259244680405, 2.2762488782746004e-08, 2.0521494226155568e-11, 1.0114273134298468e-11, 0.0017127543687820435], [0.0004921791260130703, 8.540225593378636e-08, 0.00013938159099780023, 0.9993525147438049, 1.5873634765739553e-05, 2.4237587323050524e-15, 8.77931758009368e-22, 1.279929667027252e-13], [6.645640269198339e-07, 2.1207584577354055e-09, 1.4586738927846454e-08, 0.0003817728138528764, 0.9996174573898315, 1.4834692763088242e-07, 8.104600974709331e-13, 9.061426332586733e-14], [2.511877695860615e-13, 3.875517406992657e-10, 1.4320144147073115e-16, 7.035610982697449e-11, 0.02279338613152504, 0.9739527106285095, 0.003253970993682742, 3.3826823720578547e-12], [5.0823162681384176e-14, 9.703654058057509e-08, 1.4238451260381786e-15, 1.5562769273963755e-16, 1.2103398625950678e-14, 2.739409865171183e-06, 0.9999598264694214, 3.7275574868544936e-05], [4.904049388798626e-12, 7.423512670357013e-06, 3.3247296788493225e-14, 1.784887281742269e-16, 2.239592542463088e-19, 1.9868516554222282e-10, 0.001111079822294414, 0.9988815188407898], [0.00011137629917357117, 0.003138691885396838, 1.6242403944488615e-05, 1.789517369843452e-07, 9.92325143971541e-16, 2.6784616665993626e-14, 4.336210834843257e-10, 0.996733546257019]], [[0.7871800065040588, 0.00020065985154360533, 0.0014235450653359294, 0.21111389994621277, 8.194654947146773e-05, 3.4611077892598985e-10, 8.423499392581565e-14, 2.6239352024504115e-08], [0.34938374161720276, 0.03366946429014206, 0.5068279504776001, 0.10839176923036575, 3.6670273484418203e-09, 6.573084437855314e-11, 1.960077586349307e-11, 0.0017270909156650305], [0.00017093669157475233, 4.359893353012012e-07, 4.8774596507428214e-05, 0.9997796416282654, 1.7948201502804295e-07, 5.73604147375271e-16, 1.7343250889513057e-22, 1.5487733166265338e-14], [5.641516054311069e-07, 2.9809921198165057e-09, 2.1854720699820973e-08, 0.0009941670577973127, 0.9990052580833435, 4.947445475522727e-08, 1.5992975173351187e-12, 4.946496229112085e-14], [7.218464920851625e-14, 6.045831890677533e-11, 8.156549260518976e-18, 4.840491202307007e-11, 0.023021627217531204, 0.9767410755157471, 0.0002373339084442705, 1.376625999608902e-13], [2.39082232201919e-14, 1.2635547363970545e-06, 1.1477582308915468e-16, 1.0335564182079447e-16, 2.165660805254852e-15, 3.4601598599692807e-05, 0.9999480247497559, 1.6095656974357553e-05], [8.861113232061513e-12, 0.006232377141714096, 3.0569466500252745e-14, 2.5370534124068145e-15, 1.699393066900413e-19, 7.725957118509541e-08, 0.013958403840661049, 0.9798091650009155], [5.586729821516201e-05, 0.11279561370611191, 1.084951600205386e-05, 8.628356340523169e-07, 3.262832785933384e-17, 3.851136515128873e-15, 1.6343677800012557e-10, 0.8871368169784546]], [[0.10001979023218155, 0.27790290117263794, 0.07114851474761963, 0.05579604580998421, 0.16762813925743103, 0.11318083852529526, 0.0913872942328453, 0.12293644994497299], [0.0893436074256897, 0.41653555631637573, 0.08589829504489899, 0.022549964487552643, 0.11973101645708084, 0.05887266620993614, 0.06149233877658844, 0.14557655155658722], [0.05561423301696777, 0.3359445631504059, 0.0490383580327034, 0.024569228291511536, 0.2686634361743927, 0.11582434922456741, 0.09092943370342255, 0.05941629782319069], [0.12124787271022797, 0.07392995059490204, 0.02823050320148468, 0.04258725047111511, 0.025009755045175552, 0.04690803214907646, 0.1714293509721756, 0.4906572997570038], [0.060948148369789124, 0.09020094573497772, 0.006339069921523333, 0.00637396052479744, 0.021819626912474632, 0.10373088717460632, 0.14179831743240356, 0.5687890648841858], [0.15959130227565765, 0.040810707956552505, 0.004591250326484442, 0.0020516528747975826, 0.003324134275317192, 0.010976884514093399, 0.019837021827697754, 0.7588170766830444], [0.10306438058614731, 0.27474379539489746, 0.02059229090809822, 0.019709352403879166, 0.012706205248832703, 0.03922940418124199, 0.07870732992887497, 0.4512472152709961], [0.19023792445659637, 0.2199219912290573, 0.03792127966880798, 0.042776621878147125, 0.03566695377230644, 0.027122285217046738, 0.031661488115787506, 0.4146915674209595]], [[0.26680800318717957, 0.3502981662750244, 0.0839574933052063, 0.027183162048459053, 0.022327203303575516, 0.007528252899646759, 0.022886965423822403, 0.21901074051856995], [0.18013180792331696, 0.5354639291763306, 0.07804358005523682, 0.008112381212413311, 0.013646368868649006, 0.04526336118578911, 0.020522451028227806, 0.11881618946790695], [0.13298888504505157, 0.6527820229530334, 0.06558211892843246, 0.0031326720491051674, 0.006537036504596472, 0.028548656031489372, 0.01783139444887638, 0.09259724617004395], [0.4005940556526184, 0.0974222719669342, 0.12835471332073212, 0.16208122670650482, 0.005551867187023163, 0.004390219692140818, 0.037026744335889816, 0.16457892954349518], [0.3950866758823395, 0.33328351378440857, 0.14526993036270142, 0.0038934682961553335, 0.004713136702775955, 0.005140128079801798, 0.007828197441995144, 0.10478518903255463], [0.6984498500823975, 0.07622870057821274, 0.07904984056949615, 0.0011729164980351925, 0.02908395789563656, 0.004705227445811033, 0.0056847394444048405, 0.10562480986118317], [0.182861328125, 0.5923111438751221, 0.1100698858499527, 0.004976707510650158, 0.009780565276741982, 0.026021376252174377, 0.015333608724176884, 0.058645375072956085], [0.3037327229976654, 0.2614564597606659, 0.08855953067541122, 0.06266964226961136, 0.06519058346748352, 0.014600242488086224, 0.02165828086435795, 0.18213261663913727]], [[0.19154919683933258, 0.12590764462947845, 0.18112905323505402, 0.020864006131887436, 0.06341731548309326, 0.08300026506185532, 0.1452329009771347, 0.18889960646629333], [0.3694984018802643, 0.023178575560450554, 0.04001415893435478, 0.012510129250586033, 0.008883300237357616, 0.010757431387901306, 0.03525878116488457, 0.4998992383480072], [0.36948758363723755, 0.04102712124586105, 0.025082848966121674, 0.0529695488512516, 0.010367967188358307, 0.009419210255146027, 0.01934802532196045, 0.4722977578639984], [0.18516507744789124, 0.05538897216320038, 0.23466691374778748, 0.026955699548125267, 0.042505718767642975, 0.055654555559158325, 0.15064682066440582, 0.24901624023914337], [0.44020986557006836, 0.017747165635228157, 0.026356294751167297, 0.02642083540558815, 0.0034138390328735113, 0.007623161654919386, 0.017886152490973473, 0.4603427052497864], [0.3619130551815033, 0.056823693215847015, 0.037794362753629684, 0.026558207347989082, 0.010519815608859062, 0.005796060897409916, 0.04635517671704292, 0.4542396366596222], [0.38394418358802795, 0.03176378831267357, 0.021203912794589996, 0.06371065974235535, 0.005226301494985819, 0.00711321085691452, 0.02052921988070011, 0.466508686542511], [0.18403436243534088, 0.17029941082000732, 0.14085230231285095, 0.013067692518234253, 0.043853674083948135, 0.06831210851669312, 0.0977354571223259, 0.2818450331687927]], [[0.3581104874610901, 0.059809934347867966, 0.027710827067494392, 0.031308986246585846, 0.03413717448711395, 0.04160166531801224, 0.035292938351631165, 0.4120279848575592], [0.012196873314678669, 0.9532812237739563, 0.0071846419014036655, 3.1654899430577643e-06, 4.7887016989989206e-05, 0.001647528144530952, 0.013626736588776112, 0.01201201044023037], [0.025674551725387573, 0.04145900160074234, 0.16231591999530792, 6.970225967961596e-06, 0.0004403212515171617, 0.011670802719891071, 0.7273749113082886, 0.031057532876729965], [0.1250072717666626, 0.000303753768093884, 0.0001324167533311993, 0.705817461013794, 0.00033210328547284007, 7.079037459334359e-05, 0.00013635550567414612, 0.1681998074054718], [0.1783047467470169, 0.005475573241710663, 0.004744979087263346, 0.00013174189371056855, 0.43326982855796814, 0.2490815669298172, 0.004491770640015602, 0.12449987977743149], [0.004168849904090166, 0.002901218831539154, 0.0015117917209863663, 8.746044954932586e-07, 0.0014686881331726909, 0.9857876300811768, 0.001626443350687623, 0.002534545725211501], [0.031188592314720154, 0.04861430078744888, 0.5844625234603882, 1.1191273188160267e-05, 0.00044209210318513215, 0.014653411693871021, 0.3051620125770569, 0.015465903095901012], [0.4030090570449829, 0.05161435902118683, 0.08338254690170288, 0.03718319162726402, 0.07376335561275482, 0.0720037892460823, 0.04293663799762726, 0.23610706627368927]], [[0.10375820845365524, 0.11890233308076859, 0.15872108936309814, 0.14251495897769928, 0.2091522216796875, 0.07152559608221054, 0.10111312568187714, 0.09431242197751999], [0.117201067507267, 0.2820527255535126, 0.10680832713842392, 0.027575267478823662, 0.03810693323612213, 0.11332244426012039, 0.11322294920682907, 0.20171023905277252], [0.10674567520618439, 0.3247331380844116, 0.03637063875794411, 0.23748116195201874, 0.05274573341012001, 0.08382489532232285, 0.03384731337428093, 0.12425144016742706], [0.23910817503929138, 0.022788096219301224, 0.09506868571043015, 0.12841707468032837, 0.15777133405208588, 0.04783749207854271, 0.08106625825166702, 0.22794286906719208], [0.1985820084810257, 0.0961528941988945, 0.05629570409655571, 0.3547166585922241, 0.0038313069380819798, 0.015546254813671112, 0.040994223207235336, 0.23388086259365082], [0.21105152368545532, 0.15220877528190613, 0.15000145137310028, 0.10304753482341766, 0.031869422644376755, 0.031634166836738586, 0.10062553733587265, 0.21956151723861694], [0.10553687810897827, 0.38160163164138794, 0.035881269723176956, 0.16978086531162262, 0.04404201731085777, 0.10195491462945938, 0.031601615250110626, 0.12960083782672882], [0.19687288999557495, 0.07144366949796677, 0.07948148995637894, 0.22888927161693573, 0.1045374646782875, 0.0500967800617218, 0.07271556556224823, 0.1959628313779831]], [[0.1111888438463211, 0.7454237937927246, 0.0802520364522934, 0.0018707362469285727, 0.00258454866707325, 0.0021256855688989162, 0.0016627046279609203, 0.054891735315322876], [0.00533426133915782, 0.5308873653411865, 0.019650300964713097, 4.350872040959075e-05, 7.696286957070697e-06, 0.004111583810299635, 0.2724979817867279, 0.16746728122234344], [0.021532202139496803, 0.9259887337684631, 0.018241295590996742, 5.534469164558686e-05, 1.90853870662977e-06, 8.058835373958573e-05, 0.00012295031046960503, 0.033977117389440536], [0.4988496005535126, 0.07032321393489838, 0.2889705002307892, 0.13373717665672302, 0.00033767276909202337, 8.70611984282732e-06, 2.117768417519983e-05, 0.007752018049359322], [0.24700278043746948, 0.0084513695910573, 0.020263101905584335, 0.6375101804733276, 0.08507528156042099, 0.001192031311802566, 0.0001228152250405401, 0.0003825179301202297], [0.008467171341180801, 0.005216025281697512, 0.0004399277677293867, 0.003765217261388898, 0.48330166935920715, 0.2667921781539917, 0.23033659160137177, 0.0016813096590340137], [4.968719440512359e-05, 0.001065259100869298, 9.933908131642966e-07, 1.993185833271127e-06, 0.003441739594563842, 0.5340927243232727, 0.4602266252040863, 0.0011209864169359207], [0.0006832886137999594, 0.030164213851094246, 5.0586779252626e-05, 3.517286586429691e-06, 0.00020528992172330618, 0.04899916052818298, 0.7780929803848267, 0.14180095493793488]], [[0.4080628752708435, 0.029739536345005035, 0.11355732381343842, 0.04149629548192024, 0.045784059911966324, 0.027273651212453842, 0.09315191209316254, 0.24093441665172577], [0.07222606241703033, 0.1266864687204361, 0.4511316418647766, 0.0016790522495284677, 0.0030657658353447914, 0.004054979886859655, 0.27416130900382996, 0.06699463725090027], [0.24166205525398254, 0.1272450089454651, 0.32114994525909424, 0.007817746140062809, 0.002215092536062002, 0.0019651881884783506, 0.15812425315380096, 0.13982068002223969], [0.3924476206302643, 0.0017452602041885257, 0.007685292046517134, 0.03402285277843475, 0.0018544795457273722, 0.0017225575866177678, 0.004602658562362194, 0.555919349193573], [0.5680015683174133, 0.019160864874720573, 0.07049258053302765, 0.0012178609613329172, 0.008444895967841148, 0.0027508779894560575, 0.017432577908039093, 0.3124987483024597], [0.40462422370910645, 0.07834932208061218, 0.14850863814353943, 0.0023164080921560526, 0.03841467946767807, 0.012739893049001694, 0.07675588876008987, 0.23829098045825958], [0.1848762184381485, 0.12345333397388458, 0.2951796054840088, 0.0020063072443008423, 0.001877856208011508, 0.001715292688459158, 0.23800213634967804, 0.15288935601711273], [0.31166312098503113, 0.01060927752405405, 0.05589474365115166, 0.02701600268483162, 0.024848725646734238, 0.017851779237389565, 0.050467733293771744, 0.5016486644744873]]], [[[0.052998919039964676, 0.4397948682308197, 0.06499941647052765, 0.04580384120345116, 0.061764564365148544, 0.1675010770559311, 0.0885365903377533, 0.07860065251588821], [0.06484977155923843, 0.19646629691123962, 0.10174163430929184, 0.05539156123995781, 0.0978829637169838, 0.2624107003211975, 0.03622544929385185, 0.18503159284591675], [0.021684857085347176, 0.39586055278778076, 0.11177030950784683, 0.09032004326581955, 0.07251322269439697, 0.20124739408493042, 0.06623166799545288, 0.040372055023908615], [0.015301906503736973, 0.13350537419319153, 0.009314199909567833, 0.025926116853952408, 0.09152437001466751, 0.2467760145664215, 0.3820853531360626, 0.09556666761636734], [0.0021900921128690243, 0.017343180254101753, 0.0013934227172285318, 0.0009252942400053144, 0.028400490060448647, 0.48664095997810364, 0.4207550287246704, 0.04235156998038292], [0.00916450098156929, 0.09375707805156708, 0.00908058974891901, 0.0023403766099363565, 0.021015644073486328, 0.29824182391166687, 0.40716180205345154, 0.15923820436000824], [0.0025627596769481897, 0.37484997510910034, 0.00853599701076746, 0.007583754602819681, 0.00999650452286005, 0.16411393880844116, 0.38067150115966797, 0.0516856387257576], [0.0468912273645401, 0.34614938497543335, 0.03629970923066139, 0.010155804455280304, 0.014946979470551014, 0.15231212973594666, 0.05603204295039177, 0.3372127413749695]], [[0.0965178832411766, 0.07243242114782333, 0.05712062120437622, 0.03545853868126869, 0.13930337131023407, 0.09174004942178726, 0.04283735528588295, 0.46458983421325684], [0.321464866399765, 0.04354073479771614, 0.07936442643404007, 0.053003694862127304, 0.07245628535747528, 0.12565813958644867, 0.09292570501565933, 0.21158599853515625], [0.08392056077718735, 0.09528584778308868, 0.06077560782432556, 0.016023047268390656, 0.1792328804731369, 0.29387181997299194, 0.1542094647884369, 0.1166808158159256], [0.15850062668323517, 0.056094612926244736, 0.0900413915514946, 0.14655421674251556, 0.09551408141851425, 0.08454472571611404, 0.09866408258676529, 0.2700863182544708], [0.12263462692499161, 0.06184415519237518, 0.06528639048337936, 0.05787867680191994, 0.1233246773481369, 0.13046680390834808, 0.15039941668510437, 0.28816521167755127], [0.16497556865215302, 0.04806344583630562, 0.07345806807279587, 0.05534652993083, 0.10812392085790634, 0.07843280583620071, 0.20198194682598114, 0.2696177661418915], [0.08643722534179688, 0.1308385729789734, 0.12375813722610474, 0.06796643882989883, 0.048370130360126495, 0.23030473291873932, 0.24073821306228638, 0.07158656418323517], [0.07919955998659134, 0.06341835856437683, 0.05490593612194061, 0.044042911380529404, 0.06792138516902924, 0.08918434381484985, 0.04737399145960808, 0.5539535284042358]], [[0.032411590218544006, 0.28774434328079224, 0.12053120136260986, 0.08945135772228241, 0.05347709357738495, 0.2910681664943695, 0.0739024356007576, 0.051413822919130325], [0.13098493218421936, 0.13463972508907318, 0.10900600254535675, 0.06755314767360687, 0.09899245947599411, 0.08663683384656906, 0.19355766475200653, 0.17862918972969055], [0.0600866936147213, 0.282356858253479, 0.0953342616558075, 0.2200823277235031, 0.06503170728683472, 0.19780783355236053, 0.03827856108546257, 0.041021928191185], [0.16572189331054688, 0.14473214745521545, 0.3574991524219513, 0.13142140209674835, 0.02631128765642643, 0.05013962462544441, 0.02328496426343918, 0.10088962316513062], [0.045243531465530396, 0.05725930258631706, 0.36333057284355164, 0.30150994658470154, 0.1813155710697174, 0.036967381834983826, 0.004416142590343952, 0.009957571513950825], [0.06011296808719635, 0.037308696657419205, 0.06809471547603607, 0.1830615997314453, 0.6035786867141724, 0.010677668265998363, 0.013581711798906326, 0.023583970963954926], [0.006179565563797951, 0.009308858774602413, 0.004247236531227827, 0.1396450698375702, 0.6018304228782654, 0.19872133433818817, 0.03328479453921318, 0.006782755255699158], [0.025866147130727768, 0.12976132333278656, 0.03325628489255905, 0.11107727140188217, 0.2477692812681198, 0.34214821457862854, 0.06477630138397217, 0.04534519463777542]], [[0.2944414019584656, 0.12043313682079315, 0.1049625352025032, 0.06427738815546036, 0.017677975818514824, 0.028611479327082634, 0.049376167356967926, 0.3202199339866638], [0.20396488904953003, 0.09006418287754059, 0.26349493861198425, 0.0013965480029582977, 0.0077902995981276035, 0.009432910941541195, 0.11353492736816406, 0.31032121181488037], [0.06016646698117256, 0.07810968905687332, 0.4756298065185547, 0.000880576204508543, 0.017085876315832138, 0.030477168038487434, 0.24464838206768036, 0.09300197660923004], [0.18536897003650665, 0.009414714761078358, 0.05475729703903198, 0.5827261209487915, 0.005208679474890232, 0.0003222195664420724, 0.014348851516842842, 0.14785327017307281], [0.1468174159526825, 0.024268362671136856, 0.12243049591779709, 0.0020030385348945856, 0.14701059460639954, 0.16564393043518066, 0.09825652092695236, 0.2935696542263031], [0.07340137660503387, 0.0103318952023983, 0.11040651053190231, 0.0008042651461437345, 0.07792628556489944, 0.45247384905815125, 0.13573503494262695, 0.13892070949077606], [0.022932294756174088, 0.03460513427853584, 0.327567994594574, 0.00018025364261120558, 0.015258828178048134, 0.034715842455625534, 0.5012738704681396, 0.06346571445465088], [0.2888084352016449, 0.06703561544418335, 0.04293316230177879, 0.025609903037548065, 0.003765430301427841, 0.01475512608885765, 0.02784593030810356, 0.5292463898658752]], [[0.005540157202631235, 0.23551620543003082, 0.06865210086107254, 0.08288539946079254, 0.12119658291339874, 0.34472528100013733, 0.1382715255022049, 0.003212773008272052], [0.33665889501571655, 0.020924009382724762, 0.02990807220339775, 0.21727217733860016, 0.020784039050340652, 0.02253710851073265, 0.027989821508526802, 0.32392585277557373], [0.06505483388900757, 0.12191533297300339, 0.057798463851213455, 0.1383189558982849, 0.23060272634029388, 0.2813079059123993, 0.03360743820667267, 0.07139439880847931], [0.08229350298643112, 0.04644915089011192, 0.04309647157788277, 0.40880876779556274, 0.047914884984493256, 0.16315151751041412, 0.07993537187576294, 0.1283503919839859], [0.0012186170788481832, 0.03680991381406784, 0.007667690049856901, 0.017864061519503593, 0.02146954834461212, 0.7084171175956726, 0.20393376052379608, 0.002619296545162797], [0.05566458776593208, 0.11366035789251328, 0.03856432065367699, 0.25452643632888794, 0.06942124664783478, 0.128010556101799, 0.20612533390522003, 0.13402719795703888], [0.011099805124104023, 0.23745380342006683, 0.016048990190029144, 0.11420892179012299, 0.24069146811962128, 0.2948397696018219, 0.05583849176764488, 0.029818717390298843], [0.016719158738851547, 0.22131535410881042, 0.0581810288131237, 0.04843943193554878, 0.115562304854393, 0.32996702194213867, 0.18181835114955902, 0.02799731306731701]], [[0.004418801516294479, 0.49204882979393005, 0.12175299972295761, 0.0316588319838047, 0.05531591176986694, 0.14485901594161987, 0.14545586705207825, 0.0044897617772221565], [0.001037245150655508, 0.9312590956687927, 0.033206142485141754, 0.0012487235944718122, 0.0033502678852528334, 0.005144220311194658, 0.023074021562933922, 0.0016803195467218757], [0.0005756843602284789, 0.7636014819145203, 0.07612590491771698, 0.002431996865198016, 0.0293459203094244, 0.0587247759103775, 0.06836913526058197, 0.0008250875398516655], [0.0018852663924917579, 0.00017141978605650365, 0.00017228268552571535, 0.9952849745750427, 0.00011806152906501666, 0.0001357140572508797, 0.00010403523629065603, 0.0021282320376485586], [0.012711982242763042, 0.3684525489807129, 0.19830390810966492, 0.008477968163788319, 0.03103998489677906, 0.1813763827085495, 0.1785757690668106, 0.021061498671770096], [0.03525920957326889, 0.2492937445640564, 0.22757945954799652, 0.01764448545873165, 0.09736572206020355, 0.15246430039405823, 0.15086214244365692, 0.0695309266448021], [0.0007081276271492243, 0.8575396537780762, 0.04710372909903526, 0.005506986286491156, 0.013110104948282242, 0.03477916866540909, 0.040193963795900345, 0.0010583577677607536], [0.024747086688876152, 0.26281315088272095, 0.12516504526138306, 0.12058816105127335, 0.12085828185081482, 0.17575818300247192, 0.10834953933954239, 0.061720605939626694]], [[0.08540461212396622, 0.22869513928890228, 0.12358545511960983, 0.12277278304100037, 0.0508594810962677, 0.11476663500070572, 0.05555896833539009, 0.2183569371700287], [0.0731530413031578, 0.09682492911815643, 0.05948801711201668, 0.13853922486305237, 0.09283751994371414, 0.18245644867420197, 0.14822602272033691, 0.2084747552871704], [0.06575141847133636, 0.41313406825065613, 0.10022680461406708, 0.1946571171283722, 0.01933591067790985, 0.09464649856090546, 0.03796004131436348, 0.07428805530071259], [0.05257577449083328, 0.221371591091156, 0.19336310029029846, 0.1749972552061081, 0.11485724151134491, 0.1375114917755127, 0.030215123668313026, 0.07510849833488464], [0.07728669792413712, 0.11020643264055252, 0.3174936771392822, 0.3078068792819977, 0.07913948595523834, 0.05669695511460304, 0.022575339302420616, 0.0287944246083498], [0.03174232691526413, 0.05149037390947342, 0.07491245865821838, 0.5594574809074402, 0.20897176861763, 0.031764917075634, 0.02131214551627636, 0.020348509773612022], [0.010858678258955479, 0.02770947851240635, 0.035005755722522736, 0.7071236371994019, 0.09898411482572556, 0.08013971894979477, 0.03364228084683418, 0.006536257453262806], [0.09519338607788086, 0.027063589543104172, 0.026319220662117004, 0.08343532681465149, 0.06016642227768898, 0.035133231431245804, 0.030333204194903374, 0.6423556208610535]], [[0.03377588838338852, 0.07656247168779373, 0.03884968161582947, 0.016547827050089836, 0.1683366447687149, 0.3044978082180023, 0.16261737048625946, 0.19881227612495422], [0.16663634777069092, 0.022858256474137306, 0.29388052225112915, 0.015242285095155239, 0.07365129888057709, 0.015526601113379002, 0.2193242609500885, 0.19288039207458496], [0.03399905562400818, 0.007180633023381233, 0.006412400398403406, 0.06217607483267784, 0.5044311285018921, 0.169499009847641, 0.10195253789424896, 0.1143491342663765], [0.02659071795642376, 0.03402939811348915, 0.0032649836502969265, 0.022981595247983932, 0.11784010380506516, 0.3170454502105713, 0.25205621123313904, 0.22619149088859558], [0.003602796932682395, 0.03446755185723305, 0.0009260997176170349, 0.00412345165386796, 0.03349756449460983, 0.6410001516342163, 0.24537962675094604, 0.037002697587013245], [0.06344737857580185, 0.14668899774551392, 0.018969057127833366, 0.025594592094421387, 0.1812521517276764, 0.051527734845876694, 0.14852586388587952, 0.3639942705631256], [0.05012904480099678, 0.04809364676475525, 0.008038152009248734, 0.05038299039006233, 0.19932685792446136, 0.17274226248264313, 0.09491075575351715, 0.37637630105018616], [0.05433942750096321, 0.2607540488243103, 0.04627671837806702, 0.019603600725531578, 0.0461399108171463, 0.17670191824436188, 0.04861545190215111, 0.34756895899772644]], [[0.11356167495250702, 0.29413896799087524, 0.2875443994998932, 0.030390413478016853, 0.007801880594342947, 0.06622134149074554, 0.03523219749331474, 0.1651090830564499], [0.010752828791737556, 0.2567373812198639, 0.018908420577645302, 0.01241355761885643, 0.026080474257469177, 0.2609117329120636, 0.2823876738548279, 0.13180790841579437], [0.009661098942160606, 0.8636161684989929, 0.08038786053657532, 0.0009730058372952044, 0.00036927207838743925, 0.032708872109651566, 0.0037497871089726686, 0.008533808402717113], [0.058355215936899185, 0.0756358951330185, 0.8124807476997375, 0.021001772955060005, 0.0022263561841100454, 0.0019814034458249807, 0.0020861532539129257, 0.026232488453388214], [0.0005086236051283777, 0.0012342599220573902, 0.004535661078989506, 0.7951494455337524, 0.19606898725032806, 0.0014901191461831331, 0.0009613792062737048, 5.153496385901235e-05], [0.0007776544080115855, 0.0013552603777498007, 0.0003124791255686432, 0.029406016692519188, 0.9085383415222168, 0.04562513530254364, 0.013312685303390026, 0.0006723135593347251], [0.00016710326599422842, 0.0007557927165180445, 3.5939476219937205e-05, 0.0016581336967647076, 0.06236455962061882, 0.8133818507194519, 0.12089437991380692, 0.0007421532645821571], [0.01874902844429016, 0.04321305826306343, 0.006358711514621973, 0.02624124102294445, 0.03953760489821434, 0.3624638319015503, 0.301817923784256, 0.20161859691143036]], [[0.032296814024448395, 0.13157127797603607, 0.041637636721134186, 0.7148693799972534, 0.06889423727989197, 0.004171581938862801, 0.0005791148287244141, 0.005979996174573898], [0.029022643342614174, 0.014692993834614754, 0.8426464796066284, 0.10709580034017563, 0.0011013447074219584, 0.0018106764182448387, 0.0008460271637886763, 0.0027840686962008476], [0.001396654755808413, 0.011889319866895676, 0.04422468692064285, 0.9389023184776306, 0.0031451985705643892, 0.00038424236117862165, 7.080473096721107e-06, 5.048437014920637e-05], [0.0001258471456822008, 0.0029132855124771595, 9.102580952458084e-05, 0.0171547532081604, 0.8915376663208008, 0.08562961965799332, 0.0022367406636476517, 0.0003110042307525873], [6.905619898134319e-07, 0.00011849752627313137, 7.498890113311063e-07, 8.348147093784064e-05, 0.012972760014235973, 0.9646432399749756, 0.02216348797082901, 1.7096572264563292e-05], [0.00011826483387267217, 0.007237663026899099, 0.00034454319393262267, 6.638347258558497e-05, 0.00014392162847798318, 0.01529153622686863, 0.9719372987747192, 0.004860411398112774], [0.001191813382320106, 0.21367771923542023, 0.0018962904578074813, 0.001504570827819407, 0.0022447872906923294, 0.03803892806172371, 0.5152241587638855, 0.22622166574001312], [0.1286720335483551, 0.3221377432346344, 0.03219599276781082, 0.035287924110889435, 0.002302520675584674, 0.005495885387063026, 0.015781128779053688, 0.4581267535686493]], [[0.11264563351869583, 0.11671500653028488, 0.061811793595552444, 0.22836606204509735, 0.10766790807247162, 0.161875382065773, 0.049227192997932434, 0.16169099509716034], [0.24348483979701996, 0.359942764043808, 0.12916631996631622, 0.0019557378254830837, 0.013136697001755238, 0.017741603776812553, 0.11460842192173004, 0.11996352672576904], [0.1471714824438095, 0.06725161522626877, 0.1782573163509369, 0.012397593818604946, 0.03927789255976677, 0.09725786000490189, 0.28428351879119873, 0.17410270869731903], [0.038281723856925964, 0.003679729765281081, 0.000604435452260077, 0.9286342859268188, 0.001532050664536655, 0.0007477657054550946, 0.00035452150041237473, 0.026165593415498734], [0.14310628175735474, 0.07338354736566544, 0.035191573202610016, 0.00942931231111288, 0.40013742446899414, 0.20395469665527344, 0.009295908734202385, 0.12550123035907745], [0.3000721037387848, 0.13550911843776703, 0.07911781966686249, 0.002575357910245657, 0.06022408977150917, 0.21756693720817566, 0.028083624318242073, 0.17685097455978394], [0.08768288046121597, 0.08168072998523712, 0.439998984336853, 0.002460643881931901, 0.02806478552520275, 0.04766959697008133, 0.2541303336620331, 0.05831199139356613], [0.2046714425086975, 0.09204822778701782, 0.03694169595837593, 0.1266297996044159, 0.07791823893785477, 0.1056075170636177, 0.016419807448983192, 0.3397633135318756]], [[0.1582898050546646, 0.3585202097892761, 0.1403975784778595, 0.032232485711574554, 0.1123252734541893, 0.07289401441812515, 0.06781435012817383, 0.05752627179026604], [0.23926207423210144, 0.03178771957755089, 0.16990086436271667, 0.13058415055274963, 0.04546235129237175, 0.057054292410612106, 0.0697939395904541, 0.2561546564102173], [0.24378208816051483, 0.2479889988899231, 0.07004241645336151, 0.11559262126684189, 0.07699379324913025, 0.03806982561945915, 0.027776647359132767, 0.17975354194641113], [0.07512403279542923, 0.46966660022735596, 0.08813213557004929, 0.0374809093773365, 0.13499538600444794, 0.0716761127114296, 0.05489153414964676, 0.06803323328495026], [0.21726779639720917, 0.20271354913711548, 0.04388028010725975, 0.23960450291633606, 0.00643636891618371, 0.01618300937116146, 0.013957010582089424, 0.2599574327468872], [0.19877305626869202, 0.07553234696388245, 0.0463767871260643, 0.4147583246231079, 0.018383292481303215, 0.011215257458388805, 0.014747466892004013, 0.22021344304084778], [0.1984350085258484, 0.17038564383983612, 0.04949295520782471, 0.23386240005493164, 0.08533739298582077, 0.04499391093850136, 0.018852774053812027, 0.1986398547887802], [0.12033459544181824, 0.2235412299633026, 0.07806126773357391, 0.08119028806686401, 0.10393443703651428, 0.11251991987228394, 0.05854170396924019, 0.2218765914440155]]], [[[0.2043260633945465, 0.043870534747838974, 0.2794721722602844, 0.0040762764401733875, 0.010107503272593021, 0.04536843299865723, 0.16591301560401917, 0.24686592817306519], [9.85085207503289e-05, 0.9600915908813477, 0.004993712063878775, 2.7630836484604515e-05, 8.658814294904005e-06, 0.0003508017398416996, 0.033829692751169205, 0.0005994191742502153], [0.014872814528644085, 0.08542417734861374, 0.5151582360267639, 0.00015068652282934636, 6.468733045039698e-05, 0.0009737834334373474, 0.3632051348686218, 0.020150456577539444], [0.0010863152565434575, 0.00020020849478896707, 5.3570573072647676e-05, 0.9917933344841003, 0.0002081821148749441, 3.777902020374313e-05, 0.0002893066266551614, 0.006331144366413355], [0.04233432561159134, 0.0017647736240178347, 0.0029895047191530466, 0.005343771073967218, 0.7282799482345581, 0.020229032263159752, 0.018329128623008728, 0.18072953820228577], [0.13490024209022522, 0.05035225301980972, 0.050431616604328156, 0.0010404756758362055, 0.013397706672549248, 0.30050262808799744, 0.13178212940692902, 0.317592978477478], [0.006053442135453224, 0.10521318018436432, 0.2701455056667328, 8.24957387521863e-05, 0.000259000196820125, 0.0030575182754546404, 0.6026332974433899, 0.012555446475744247], [0.05516520142555237, 0.13705728948116302, 0.1450430452823639, 0.0034178863279521465, 0.01148904673755169, 0.057180240750312805, 0.23127955198287964, 0.3593677580356598]], [[0.037427954375743866, 0.15603119134902954, 0.1792135238647461, 0.019320959225296974, 0.2860032021999359, 0.1658961921930313, 0.11430923640727997, 0.04179776832461357], [0.02875540591776371, 0.13683196902275085, 0.1090770736336708, 0.022532863542437553, 0.18013572692871094, 0.3271981179714203, 0.15850673615932465, 0.03696215897798538], [0.012304296717047691, 0.1306062638759613, 0.1588543802499771, 0.02348983660340309, 0.16581737995147705, 0.3383369743824005, 0.15783081948757172, 0.012759963050484657], [0.07002676278352737, 0.11159715056419373, 0.17571857571601868, 0.13089586794376373, 0.09580650925636292, 0.23530510067939758, 0.11217847466468811, 0.06847162544727325], [0.019814372062683105, 0.13314932584762573, 0.11989092081785202, 0.0281293373554945, 0.2662719786167145, 0.26188594102859497, 0.1464393585920334, 0.024418823421001434], [0.015888020396232605, 0.13962408900260925, 0.09310650825500488, 0.014510580338537693, 0.21147330105304718, 0.26886698603630066, 0.21291117370128632, 0.0436193086206913], [0.0069291600957512856, 0.1372879445552826, 0.15190953016281128, 0.020948713645339012, 0.11309841275215149, 0.338620126247406, 0.22021642327308655, 0.01098976656794548], [0.0343654565513134, 0.11515792459249496, 0.1871117353439331, 0.03381054103374481, 0.2473667711019516, 0.2242121398448944, 0.11007627844810486, 0.04789916053414345]], [[0.008421572856605053, 0.625160813331604, 0.04406754672527313, 0.0010110643925145268, 0.07184062898159027, 0.1612587720155716, 0.07484016567468643, 0.013399441726505756], [0.000685805338434875, 0.6406195759773254, 0.18111756443977356, 0.004741256590932608, 0.008661342784762383, 0.017352381721138954, 0.1462441235780716, 0.0005780035862699151], [0.00046108252718113363, 0.7250652313232422, 0.1288011223077774, 0.008900419808924198, 0.011324876919388771, 0.024025358259677887, 0.10082381218671799, 0.0005981939029879868], [0.0024783089756965637, 0.08264552801847458, 0.043869856745004654, 0.8227325081825256, 0.013242825865745544, 0.016259822994470596, 0.01634211279451847, 0.0024289884604513645], [0.002235997235402465, 0.3197489082813263, 0.18201342225074768, 0.010443826206028461, 0.3238263726234436, 0.1310001164674759, 0.02866915799677372, 0.002062272746115923], [0.0017855750629678369, 0.4542039930820465, 0.20192590355873108, 0.0034098695032298565, 0.16443826258182526, 0.07124900817871094, 0.10132640600204468, 0.0016611230093985796], [0.0002904457796830684, 0.5409369468688965, 0.10552603751420975, 0.022662363946437836, 0.06173253059387207, 0.13643625378608704, 0.1320473849773407, 0.0003680941299535334], [0.0026034044567495584, 0.40733635425567627, 0.027482828125357628, 0.0034106390085071325, 0.10848212987184525, 0.35398992896080017, 0.09344687312841415, 0.0032478347420692444]], [[0.19731669127941132, 0.22012649476528168, 0.15829037129878998, 0.06321924179792404, 0.07708251476287842, 0.039577558636665344, 0.06382578611373901, 0.18056142330169678], [0.10788702964782715, 0.2704716920852661, 0.07455609738826752, 0.09237246960401535, 0.063085176050663, 0.09634646028280258, 0.05148933082818985, 0.24379165470600128], [0.09210322797298431, 0.32641980051994324, 0.13594509661197662, 0.19599778950214386, 0.03819818049669266, 0.04970436915755272, 0.0657668188214302, 0.09586483240127563], [0.0027866812888532877, 0.005803244654089212, 0.005627952516078949, 0.9736284017562866, 0.003511475631967187, 0.0018524588085711002, 0.00244503584690392, 0.004344765562564135], [0.09957140684127808, 0.34510505199432373, 0.151844322681427, 0.03779307007789612, 0.030766239389777184, 0.06672541797161102, 0.07630328088998795, 0.19189134240150452], [0.030847206711769104, 0.5281378030776978, 0.10845354199409485, 0.035464849323034286, 0.02576093003153801, 0.052138280123472214, 0.08951952308416367, 0.12967775762081146], [0.06673461198806763, 0.2993946969509125, 0.13525904715061188, 0.15524472296237946, 0.05093613639473915, 0.08124536275863647, 0.07233627140522003, 0.13884907960891724], [0.10519028455018997, 0.3541548252105713, 0.06608971953392029, 0.12181626260280609, 0.05591971427202225, 0.050054244697093964, 0.03528163954615593, 0.2114933580160141]], [[0.0009614003938622773, 0.08767946064472198, 0.022321626543998718, 0.8102265000343323, 0.018301313742995262, 0.027235042303800583, 0.032139044255018234, 0.0011356058530509472], [0.004875978454947472, 0.20662187039852142, 0.17307980358600616, 0.4104118347167969, 0.03061072528362274, 0.05232882872223854, 0.11498374491930008, 0.007087219972163439], [0.00035618440597318113, 0.01637466438114643, 0.017109233886003494, 0.9147974848747253, 0.015401730313897133, 0.010693851858377457, 0.024631302803754807, 0.0006355341174639761], [0.0017554665682837367, 0.11214108020067215, 0.006970969960093498, 0.1989917904138565, 0.03328230604529381, 0.25364795327186584, 0.37115591764450073, 0.022054515779018402], [0.0021244545932859182, 0.04644396901130676, 0.006562519818544388, 0.12331469357013702, 0.03954973444342613, 0.24495209753513336, 0.5125319361686707, 0.024520650506019592], [0.014793524518609047, 0.22384242713451385, 0.041050661355257034, 0.29246339201927185, 0.028537070378661156, 0.11073138564825058, 0.21943938732147217, 0.06914220005273819], [0.0029732687398791313, 0.186567485332489, 0.031218096613883972, 0.5755664110183716, 0.009940178133547306, 0.03865950182080269, 0.13943906128406525, 0.01563606597483158], [0.0017125322483479977, 0.17363616824150085, 0.01669619232416153, 0.7516675591468811, 0.008535902947187424, 0.02183602564036846, 0.023341646417975426, 0.0025739187840372324]], [[0.010900459252297878, 0.368886262178421, 0.02778387814760208, 0.08910106122493744, 0.03497937321662903, 0.3167905807495117, 0.11306482553482056, 0.03849349543452263], [0.012552384287118912, 0.5112596154212952, 0.12460686266422272, 0.02473616972565651, 0.03288771212100983, 0.13575522601604462, 0.14146511256694794, 0.016736840829253197], [0.008382695727050304, 0.5907214879989624, 0.12712259590625763, 0.014709868468344212, 0.024087944999337196, 0.10601101815700531, 0.11799383163452148, 0.010970520786941051], [0.05555586889386177, 0.4340965151786804, 0.2820195257663727, 0.03992411121726036, 0.033181332051754, 0.08016634732484818, 0.0470159612596035, 0.028040243312716484], [0.02930949069559574, 0.32279297709465027, 0.3310302197933197, 0.03846947103738785, 0.12180032581090927, 0.12368327379226685, 0.02567697875201702, 0.007237226702272892], [0.017570339143276215, 0.4298768937587738, 0.22163645923137665, 0.06068306043744087, 0.11745647341012955, 0.10168613493442535, 0.04611098766326904, 0.004979751538485289], [0.006744390819221735, 0.28578418493270874, 0.11875998973846436, 0.10035238415002823, 0.22552849352359772, 0.17200787365436554, 0.08750355988740921, 0.003319075331091881], [0.004758745431900024, 0.25615987181663513, 0.024386731907725334, 0.12295886129140854, 0.0810524970293045, 0.4129532277584076, 0.08462925255298615, 0.013100847601890564]], [[0.004984861705452204, 0.45649009943008423, 0.1630174070596695, 0.18885576725006104, 0.02469579502940178, 0.07224797457456589, 0.08752311021089554, 0.0021849849727004766], [0.06963381171226501, 0.08339005708694458, 0.4827594757080078, 0.06447228044271469, 0.022000432014465332, 0.04479926824569702, 0.15977606177330017, 0.07316865026950836], [0.010397050529718399, 0.09392101317644119, 0.3306725323200226, 0.44288599491119385, 0.01758420839905739, 0.03928787633776665, 0.060698412358760834, 0.004552852362394333], [0.005090733524411917, 0.029497845098376274, 0.008345112204551697, 0.00596599979326129, 0.3045894205570221, 0.5103963613510132, 0.11683270335197449, 0.01928190514445305], [0.00021951631060801446, 0.0019855189602822065, 0.0003595152229536325, 0.0013186720898374915, 0.05904261767864227, 0.8754586577415466, 0.05927104875445366, 0.0023444320540875196], [0.004497367423027754, 0.04414306953549385, 0.008195140399038792, 0.004009098280221224, 0.004243379924446344, 0.16247104108333588, 0.7337926030158997, 0.03864827752113342], [0.01346533838659525, 0.14145879447460175, 0.05186934769153595, 0.02201225236058235, 0.015933096408843994, 0.1483645737171173, 0.5160571336746216, 0.09083948284387589], [0.010052414610981941, 0.4741777181625366, 0.04167039319872856, 0.029610510915517807, 0.0097732562571764, 0.2086332142353058, 0.19613824784755707, 0.02994423918426037]], [[0.005807966459542513, 0.28560107946395874, 0.05982685461640358, 0.04425966367125511, 0.24002036452293396, 0.20352481305599213, 0.15312987565994263, 0.00782934483140707], [0.002526284893974662, 0.3888636529445648, 0.30704551935195923, 0.011534495279192924, 0.028594225645065308, 0.030485980212688446, 0.22899718582630157, 0.0019525899551808834], [0.0010398339945822954, 0.4950900077819824, 0.10981139540672302, 0.10801911354064941, 0.04271124675869942, 0.03752532973885536, 0.20307303965091705, 0.002730040345340967], [0.005044565070420504, 0.32003864645957947, 0.056232549250125885, 0.2613711357116699, 0.05584973841905594, 0.05206572636961937, 0.21176594495773315, 0.03763172775506973], [0.004096448887139559, 0.4491733908653259, 0.047782737761735916, 0.016358479857444763, 0.10520435869693756, 0.11765492707490921, 0.23079705238342285, 0.02893257327377796], [0.0021371834445744753, 0.6610411405563354, 0.07761310040950775, 0.026181379333138466, 0.018374523147940636, 0.06126048043370247, 0.14738565683364868, 0.006006444804370403], [0.0006811431958340108, 0.7618387937545776, 0.05882370471954346, 0.028161434456706047, 0.004921139683574438, 0.02878129482269287, 0.11475814878940582, 0.0020342268981039524], [0.001904003438539803, 0.7591724991798401, 0.05737127736210823, 0.043994639068841934, 0.021425634622573853, 0.0570775642991066, 0.05670001357793808, 0.0023544132709503174]], [[0.0005522239371202886, 0.75010085105896, 0.00791284628212452, 0.022917715832591057, 0.00015692593296989799, 0.059812676161527634, 0.14276441931724548, 0.01578235626220703], [0.01621120609343052, 0.06738217920064926, 0.01006142608821392, 0.031218675896525383, 0.015205280855298042, 0.3629496991634369, 0.3268091082572937, 0.17016245424747467], [0.0007154293707571924, 0.8721755743026733, 0.037811294198036194, 0.0010213139466941357, 0.00023254353436641395, 0.0347532294690609, 0.05071468651294708, 0.002575980732217431], [0.06630247086286545, 0.058100633323192596, 0.8594430685043335, 0.005220802966505289, 0.0019839047454297543, 0.0014227123465389013, 0.0014464149717241526, 0.006080027669668198], [0.0006293403566814959, 0.07426398247480392, 0.017608845606446266, 0.5201663970947266, 0.34442776441574097, 0.038786981254816055, 0.0035427436232566833, 0.0005739786429330707], [0.00011084169091191143, 0.05086492747068405, 0.003180908504873514, 0.08107716590166092, 0.5747102499008179, 0.2709493637084961, 0.018367286771535873, 0.0007392286788672209], [4.224676013109274e-05, 0.009273777715861797, 0.00015861092833802104, 0.0024075291585177183, 0.0036073043011128902, 0.9249136447906494, 0.05882302299141884, 0.0007738639833405614], [5.4292020649882033e-05, 0.24118280410766602, 0.0007501796935684979, 0.02090318314731121, 0.0006767443264834583, 0.4096704125404358, 0.320011705160141, 0.006750765256583691]], [[0.044997867196798325, 0.09071057289838791, 0.09696545451879501, 0.18615350127220154, 0.28851285576820374, 0.17207249999046326, 0.0764823630452156, 0.04410477355122566], [0.05943986028432846, 0.1648261398077011, 0.09755630046129227, 0.16661353409290314, 0.08060801774263382, 0.21730786561965942, 0.10865210741758347, 0.10499609261751175], [0.015313610434532166, 0.1320830136537552, 0.06275565922260284, 0.17521797120571136, 0.1899973452091217, 0.2459590882062912, 0.14993742108345032, 0.02873585931956768], [0.04685104265809059, 0.09397617727518082, 0.03206643462181091, 0.2806328237056732, 0.06254494935274124, 0.16485542058944702, 0.18780136108398438, 0.13127176463603973], [0.06050354614853859, 0.049133747816085815, 0.03326043486595154, 0.0548408105969429, 0.21902774274349213, 0.14099888503551483, 0.1705048829317093, 0.2717299163341522], [0.050370387732982635, 0.07113885134458542, 0.10148487240076065, 0.036495186388492584, 0.24840538203716278, 0.16466538608074188, 0.13118286430835724, 0.19625705480575562], [0.0326082669198513, 0.1572088748216629, 0.09420650452375412, 0.07506942749023438, 0.1423799842596054, 0.22045432031154633, 0.1679389625787735, 0.1101335883140564], [0.0543740838766098, 0.11689066141843796, 0.114128477871418, 0.38633424043655396, 0.13390211760997772, 0.1102602556347847, 0.047554150223731995, 0.03655601292848587]], [[0.0009381136624142528, 0.8428494334220886, 0.01395291369408369, 0.00678520742803812, 0.0022549827117472887, 0.09297402203083038, 0.028281530365347862, 0.011963829398155212], [0.0014141658321022987, 0.7485761642456055, 0.04233546182513237, 0.023796020075678825, 0.01373087428510189, 0.06753572821617126, 0.09111452102661133, 0.011497125029563904], [0.0005973165389150381, 0.9440196752548218, 0.020098445937037468, 0.002258127322420478, 0.0014939522370696068, 0.019042078405618668, 0.009073298424482346, 0.003416989929974079], [0.0160576980561018, 0.24703188240528107, 0.5554786324501038, 0.019674906507134438, 0.06818752735853195, 0.0675843358039856, 0.014450322836637497, 0.011534684337675571], [0.0011021964019164443, 0.4242764115333557, 0.02921225130558014, 0.37560105323791504, 0.07796191424131393, 0.07052682340145111, 0.01642797514796257, 0.00489148311316967], [0.0011293755378574133, 0.3642755150794983, 0.006589744705706835, 0.1974111646413803, 0.21564485132694244, 0.15383614599704742, 0.04633261263370514, 0.014780675992369652], [0.0005218256264925003, 0.2678837478160858, 0.005134322680532932, 0.07079479098320007, 0.07946816086769104, 0.4687318503856659, 0.09757902473211288, 0.009886257350444794], [0.0002384261169936508, 0.4651075303554535, 0.0015461576404049993, 0.012757442891597748, 0.0058724544942379, 0.32827332615852356, 0.1689172238111496, 0.017287440598011017]], [[0.012522553093731403, 0.23916009068489075, 0.03655993193387985, 0.0008424747502431273, 0.10614066570997238, 0.5169376730918884, 0.05030248314142227, 0.03753407672047615], [0.006559597793966532, 0.20027931034564972, 0.12186158448457718, 0.00288115325383842, 0.04493841156363487, 0.4962187111377716, 0.10977599024772644, 0.017485277727246284], [0.005776034202426672, 0.3289974331855774, 0.13825052976608276, 0.0009027545456774533, 0.040593404322862625, 0.36087292432785034, 0.1157204881310463, 0.008886405266821384], [0.05170891806483269, 0.17306344211101532, 0.1490243822336197, 0.025806870311498642, 0.14582842588424683, 0.19925440847873688, 0.17609508335590363, 0.07921857386827469], [0.015186798758804798, 0.1123381182551384, 0.1652667224407196, 0.0004855591687373817, 0.13831879198551178, 0.4907431900501251, 0.06246645748615265, 0.015194379724562168], [0.00832256581634283, 0.06497923284769058, 0.1799437403678894, 0.001872093416750431, 0.2018146812915802, 0.43377673625946045, 0.10106706619262695, 0.008223764598369598], [0.0024990399833768606, 0.14686310291290283, 0.09022654592990875, 0.0015537402359768748, 0.08703286200761795, 0.5877919793128967, 0.07964057475328445, 0.004392107017338276], [0.005027380306273699, 0.3575447201728821, 0.018137037754058838, 0.003361766692250967, 0.09899549186229706, 0.448180228471756, 0.034846238791942596, 0.033907223492860794]]], [[[5.88795192015823e-05, 0.007379208225756884, 0.0007603410631418228, 0.9898680448532104, 0.000367699540220201, 0.0008774503949098289, 0.0006608708063140512, 2.7442378268460743e-05], [0.0009252883028239012, 0.012623531743884087, 0.004039640072733164, 0.9735202789306641, 0.0028500177431851625, 0.0028325191233307123, 0.0027646117378026247, 0.00044417500612325966], [0.00038580954424105585, 0.013913517817854881, 0.00286171305924654, 0.97679203748703, 0.0015614980366081, 0.002350317779928446, 0.0019720573909580708, 0.00016302074072882533], [0.0017463361145928502, 0.026128558441996574, 0.005883733741939068, 0.9494104385375977, 0.004162055905908346, 0.0055825309827923775, 0.00625511072576046, 0.0008312296122312546], [0.00024252232105936855, 0.005251955706626177, 0.0011162406299263239, 0.9901575446128845, 0.0007108701975084841, 0.0011491839541122317, 0.0012549447128549218, 0.00011672069376800209], [0.000306810368783772, 0.007314222864806652, 0.0018770105671137571, 0.9837853908538818, 0.0016582240350544453, 0.0022891031112521887, 0.0025743155274540186, 0.00019485490338411182], [0.00015116817667149007, 0.006999715697020292, 0.0011240204330533743, 0.9881231188774109, 0.0008015820058062673, 0.0015211186837404966, 0.0012185655068606138, 6.079799641156569e-05], [4.1240007703891024e-05, 0.004824817646294832, 0.00047027351683937013, 0.9923921227455139, 0.0003761235566344112, 0.0012949089286848903, 0.000578280829358846, 2.2233507479541004e-05]], [[0.02790418639779091, 0.28926846385002136, 0.1198134571313858, 0.1538480818271637, 0.10589999705553055, 0.11390068382024765, 0.1696539968252182, 0.019711114466190338], [0.11223170906305313, 0.1894255131483078, 0.19811424612998962, 0.14401136338710785, 0.12648577988147736, 0.07973537594079971, 0.11040444672107697, 0.03959154710173607], [0.0468226857483387, 0.20333349704742432, 0.14093798398971558, 0.18042218685150146, 0.13443271815776825, 0.14018602669239044, 0.13129474222660065, 0.022570159286260605], [0.09545956552028656, 0.11850067228078842, 0.1319413185119629, 0.16074883937835693, 0.1330292820930481, 0.17707407474517822, 0.12659986317157745, 0.05664637312293053], [0.08455085754394531, 0.14826053380966187, 0.18159301578998566, 0.1287834793329239, 0.12191881239414215, 0.18768377602100372, 0.11890322715044022, 0.02830633521080017], [0.07172654569149017, 0.12404190003871918, 0.15686453878879547, 0.1831585168838501, 0.08482426404953003, 0.20657238364219666, 0.14119292795658112, 0.031618837267160416], [0.03631541505455971, 0.20155936479568481, 0.15512396395206451, 0.15970155596733093, 0.10127504914999008, 0.17273539304733276, 0.16091297566890717, 0.01237632054835558], [0.013986943289637566, 0.228408545255661, 0.0864604040980339, 0.30967193841934204, 0.07285728305578232, 0.15889722108840942, 0.1216285228729248, 0.008089106529951096]], [[0.009425907395780087, 0.5277581214904785, 0.2808416783809662, 0.09324675053358078, 0.006970786489546299, 0.017530610784888268, 0.05761812999844551, 0.006608086638152599], [0.034865666180849075, 0.14312316477298737, 0.7847540974617004, 0.00577192660421133, 0.0011390092549845576, 0.0016615643398836255, 0.018425801768898964, 0.010258781723678112], [0.00943141058087349, 0.2779046893119812, 0.5686995387077332, 0.06862269341945648, 0.006655559409409761, 0.009527585469186306, 0.05110389366745949, 0.008054598234593868], [0.0057036434300243855, 0.20527546107769012, 0.1447337120771408, 0.015928711742162704, 0.1583603024482727, 0.10982407629489899, 0.33750617504119873, 0.02266795001924038], [0.0009261250961571932, 0.0577777624130249, 0.025018546730279922, 0.010416101664304733, 0.025779642164707184, 0.2894198000431061, 0.5813658833503723, 0.009296129457652569], [0.00968738179653883, 0.1709979921579361, 0.10550153255462646, 0.009871277026832104, 0.0069312434643507, 0.049527570605278015, 0.5983930230140686, 0.049090009182691574], [0.03207367658615112, 0.37669309973716736, 0.394784539937973, 0.016850067302584648, 0.004332433454692364, 0.009737332351505756, 0.10427874326705933, 0.06125003844499588], [0.010752412490546703, 0.7174721360206604, 0.16809949278831482, 0.015564671717584133, 0.0015396354719996452, 0.007169830147176981, 0.0646425187587738, 0.014759337529540062]], [[0.001267151441425085, 0.3579751253128052, 0.051634788513183594, 0.021019069477915764, 0.02380487322807312, 0.19304515421390533, 0.3476438522338867, 0.003609978361055255], [0.0035351444967091084, 0.3062352240085602, 0.0647195428609848, 0.008964965119957924, 0.05059489980340004, 0.28521105647087097, 0.27289527654647827, 0.007844017818570137], [0.0013218334643170238, 0.3237901031970978, 0.09395860135555267, 0.009033910930156708, 0.04182176664471626, 0.21900878846645355, 0.3092379868030548, 0.0018270235741510987], [0.002649834379553795, 0.41818392276763916, 0.09977269917726517, 0.00793857779353857, 0.030727243050932884, 0.1935916692018509, 0.24383381009101868, 0.003302294295281172], [0.0015963052865117788, 0.1703265756368637, 0.09301941096782684, 0.013446426019072533, 0.044524919241666794, 0.42434388399124146, 0.2489769011735916, 0.003765610745176673], [0.003923519980162382, 0.18729431927204132, 0.07147179543972015, 0.0181699451059103, 0.12089401483535767, 0.29129859805107117, 0.29585033655166626, 0.011097477748990059], [0.001404016511514783, 0.2573532462120056, 0.10211199522018433, 0.003045335179194808, 0.05287310108542442, 0.2898092567920685, 0.29146093130111694, 0.0019420612370595336], [0.0009632257861085236, 0.336372047662735, 0.052415452897548676, 0.008743580430746078, 0.019828319549560547, 0.2663958668708801, 0.3129498064517975, 0.0023317746818065643]], [[0.000978425843641162, 0.7458084225654602, 0.04625275358557701, 0.07554216682910919, 0.0019205468706786633, 0.055682554841041565, 0.07199215888977051, 0.0018229922279715538], [0.007732245605438948, 0.4239504039287567, 0.1742626428604126, 0.12412595748901367, 0.014681173488497734, 0.09933192282915115, 0.14900797605514526, 0.006907687988132238], [0.0029816001188009977, 0.4690883159637451, 0.08424659818410873, 0.2794186770915985, 0.003606097074225545, 0.055516332387924194, 0.10312682390213013, 0.002015609061345458], [0.005748901516199112, 0.4929424226284027, 0.3014489412307739, 0.051793359220027924, 0.007419006433337927, 0.03881869837641716, 0.09199435263872147, 0.009834352880716324], [0.001592949265614152, 0.3990585505962372, 0.05025423318147659, 0.4235426187515259, 0.003790296381339431, 0.03763643652200699, 0.08156238496303558, 0.002562546404078603], [0.007034344132989645, 0.3633005619049072, 0.06122468039393425, 0.3234921991825104, 0.02988213673233986, 0.07572869956493378, 0.12940075993537903, 0.009936686605215073], [0.0036746282130479813, 0.36744287610054016, 0.046010084450244904, 0.2985045313835144, 0.01580691896378994, 0.13075877726078033, 0.1337219625711441, 0.004080104175955057], [0.0009256224147975445, 0.6555811166763306, 0.022227898240089417, 0.17713043093681335, 0.002536712447181344, 0.05376172065734863, 0.08586429059505463, 0.001972207799553871]], [[0.030324671417474747, 0.43904080986976624, 0.19614681601524353, 0.03861849755048752, 0.027173178270459175, 0.06486987322568893, 0.179896280169487, 0.02392987161874771], [0.000439027207903564, 0.9006403088569641, 0.038121964782476425, 0.0011705075157806277, 0.00020304448844399303, 0.002028438728302717, 0.056353721767663956, 0.0010430768597871065], [0.0037794304080307484, 0.41395309567451477, 0.3913574516773224, 0.011775973252952099, 0.0008825580007396638, 0.004974419716745615, 0.16831159591674805, 0.004965482745319605], [0.0029333624988794327, 0.026422126218676567, 0.01061045378446579, 0.940638542175293, 0.0005982857546769083, 0.0026293888222426176, 0.010320302098989487, 0.005847468040883541], [0.0018628062680363655, 0.00973010528832674, 0.010667088441550732, 0.0006919155712239444, 0.5031436681747437, 0.42381712794303894, 0.04663444682955742, 0.0034528651740401983], [0.0015151721891015768, 0.06891322135925293, 0.030775371938943863, 0.0011676591821014881, 0.14550495147705078, 0.6055426001548767, 0.14360009133815765, 0.002981009893119335], [0.0004975224146619439, 0.3077434301376343, 0.17097525298595428, 0.0015573203563690186, 0.004458545707166195, 0.022496776655316353, 0.4905921220779419, 0.0016790220979601145], [0.0037380775902420282, 0.5952109694480896, 0.10298000276088715, 0.004094358999282122, 0.017723629251122475, 0.04587043449282646, 0.22463423013687134, 0.005748217459768057]], [[0.1864355206489563, 0.08434133976697922, 0.40687644481658936, 0.06704044342041016, 0.019598327577114105, 0.028962280601263046, 0.12479685992002487, 0.08194878697395325], [0.04208996519446373, 0.39119771122932434, 0.13049347698688507, 0.14052194356918335, 0.00802389346063137, 0.043623071163892746, 0.1828797459602356, 0.061170145869255066], [0.08820269256830215, 0.09409049898386002, 0.4806511402130127, 0.11548364907503128, 0.014830002561211586, 0.028330249711871147, 0.1161322221159935, 0.062279582023620605], [0.15313401818275452, 0.09337721019983292, 0.16056306660175323, 0.18991902470588684, 0.11872527003288269, 0.05328468233346939, 0.16140468418598175, 0.0695919618010521], [0.0837445855140686, 0.10327202826738358, 0.03287111595273018, 0.16280855238437653, 0.36175987124443054, 0.0846603736281395, 0.08489255607128143, 0.08599100261926651], [0.059960417449474335, 0.130484476685524, 0.04390202835202217, 0.15049907565116882, 0.0519937127828598, 0.20046336948871613, 0.18689967691898346, 0.1757972091436386], [0.04393398389220238, 0.24136723577976227, 0.09879595786333084, 0.12329603731632233, 0.03307538479566574, 0.12081290781497955, 0.25109508633613586, 0.08762345463037491], [0.10863935947418213, 0.11633483320474625, 0.16700752079486847, 0.11740868538618088, 0.0953332781791687, 0.13514702022075653, 0.16212864220142365, 0.09800069034099579]], [[0.019091138616204262, 0.16900783777236938, 0.12485898286104202, 0.2063550502061844, 0.10338599234819412, 0.13962601125240326, 0.2074039727449417, 0.030270973220467567], [0.03243716433644295, 0.10367967188358307, 0.16686157882213593, 0.16209933161735535, 0.16585507988929749, 0.11703715473413467, 0.19941005110740662, 0.05261998251080513], [0.04884108901023865, 0.05910405144095421, 0.17598332464694977, 0.23490594327449799, 0.14246003329753876, 0.08737947046756744, 0.19299708306789398, 0.058329030871391296], [0.10302206128835678, 0.05164572596549988, 0.12136603891849518, 0.225076824426651, 0.14406658709049225, 0.0717863067984581, 0.15356813371181488, 0.12946829199790955], [0.03127763792872429, 0.07451357692480087, 0.14956164360046387, 0.08839619904756546, 0.20429064333438873, 0.16866850852966309, 0.22907030582427979, 0.05422138795256615], [0.03086024522781372, 0.0842084214091301, 0.1659587174654007, 0.11967097967863083, 0.1369953602552414, 0.15486671030521393, 0.263641357421875, 0.043798163533210754], [0.027970049530267715, 0.0844772607088089, 0.15992310643196106, 0.12534618377685547, 0.14657893776893616, 0.14386919140815735, 0.27400824427604675, 0.037827011197805405], [0.010289612226188183, 0.1888853907585144, 0.09967488795518875, 0.18256071209907532, 0.090428426861763, 0.1830396205186844, 0.23255573213100433, 0.012565646320581436]], [[0.002787940204143524, 0.5181727409362793, 0.08099797368049622, 0.27508309483528137, 0.034924812614917755, 0.015736453235149384, 0.07091492414474487, 0.001382063957862556], [0.011189829558134079, 0.2921106517314911, 0.17000333964824677, 0.2531542479991913, 0.06564958393573761, 0.03905444219708443, 0.15765850245952606, 0.011179295368492603], [0.004204551223665476, 0.2137012630701065, 0.09584631025791168, 0.3175714910030365, 0.1025397852063179, 0.060067810118198395, 0.20084339380264282, 0.005225415341556072], [0.02038242481648922, 0.5164024829864502, 0.12094774842262268, 0.0832250788807869, 0.046021513640880585, 0.04349931329488754, 0.1518508642911911, 0.017670540139079094], [0.0027860067784786224, 0.5254090428352356, 0.04832589998841286, 0.11829930543899536, 0.030241183936595917, 0.05774474889039993, 0.21266640722751617, 0.004527374170720577], [0.011918012984097004, 0.43379518389701843, 0.10873124748468399, 0.14455047249794006, 0.06511802226305008, 0.041026439517736435, 0.18165531754493713, 0.013205323368310928], [0.006682520266622305, 0.4683452844619751, 0.11580932885408401, 0.16581669449806213, 0.038704708218574524, 0.0300978384912014, 0.1689654290676117, 0.005578202195465565], [0.004367010667920113, 0.6783655285835266, 0.06310465186834335, 0.1840658336877823, 0.014683987945318222, 0.009155021980404854, 0.043672919273376465, 0.002584984293207526]], [[0.006120564416050911, 0.6684261560440063, 0.08678439259529114, 0.04712793603539467, 0.013382496312260628, 0.05985603481531143, 0.1104559525847435, 0.00784637127071619], [0.01655694842338562, 0.5398333668708801, 0.19223099946975708, 0.022381702437996864, 0.017723772674798965, 0.06806690990924835, 0.12497144192457199, 0.018234794959425926], [0.02005402185022831, 0.5383425354957581, 0.1480831652879715, 0.030326837673783302, 0.017734816297888756, 0.09941521286964417, 0.1305951029062271, 0.01544828899204731], [0.07821375131607056, 0.4681454300880432, 0.18802006542682648, 0.04468577727675438, 0.025225991383194923, 0.04891510680317879, 0.09442787617444992, 0.05236601084470749], [0.03013988584280014, 0.408437579870224, 0.24941718578338623, 0.026786692440509796, 0.01994185335934162, 0.1240658164024353, 0.12198997288942337, 0.01922098733484745], [0.016585994511842728, 0.41787272691726685, 0.1739387959241867, 0.021578524261713028, 0.04243113845586777, 0.15506722033023834, 0.16098465025424957, 0.011540938168764114], [0.012334802187979221, 0.3647679090499878, 0.2581341564655304, 0.03127456456422806, 0.042360369116067886, 0.12931615114212036, 0.15451499819755554, 0.007296985946595669], [0.0030075996182858944, 0.4031435549259186, 0.055903319269418716, 0.13249115645885468, 0.045138806104660034, 0.18554526567459106, 0.17093215882778168, 0.003838120959699154]], [[0.010780292563140392, 0.3919141888618469, 0.13689792156219482, 0.04943875968456268, 0.03910920023918152, 0.10697858035564423, 0.24748428165912628, 0.01739681325852871], [0.04281991347670555, 0.21946920454502106, 0.19382110238075256, 0.040978897362947464, 0.09281595796346664, 0.12298973649740219, 0.24183039367198944, 0.04527479037642479], [0.040724147111177444, 0.2976994216442108, 0.32404738664627075, 0.025324925780296326, 0.036372870206832886, 0.08955464512109756, 0.17265179753303528, 0.013624733313918114], [0.056780215352773666, 0.1731848269701004, 0.4457501769065857, 0.015138109214603901, 0.08602188527584076, 0.08262686431407928, 0.12293963134288788, 0.01755833998322487], [0.015163399279117584, 0.10648909211158752, 0.501767635345459, 0.06403045356273651, 0.15915179252624512, 0.08549545705318451, 0.06532187014818192, 0.0025803116150200367], [0.01218075305223465, 0.1075310930609703, 0.20792634785175323, 0.08939179033041, 0.34324488043785095, 0.14158083498477936, 0.09396625310182571, 0.004178142175078392], [0.012052178382873535, 0.11946482211351395, 0.19100485742092133, 0.0919918417930603, 0.3083083927631378, 0.16876031458377838, 0.10461771488189697, 0.0037998256739228964], [0.003623373107984662, 0.21661224961280823, 0.08962198346853256, 0.10058290511369705, 0.0946590006351471, 0.20674382150173187, 0.2807648181915283, 0.007391896098852158]], [[0.01878041960299015, 0.1158781498670578, 0.14744971692562103, 0.2023780196905136, 0.29867061972618103, 0.1379188448190689, 0.06579560786485672, 0.013128494843840599], [0.049754608422517776, 0.10235338658094406, 0.1977427899837494, 0.15657749772071838, 0.17895466089248657, 0.15466658771038055, 0.12129805237054825, 0.03865242376923561], [0.009825104847550392, 0.05723225325345993, 0.11131197959184647, 0.07972892373800278, 0.3813859224319458, 0.2160576730966568, 0.1316623091697693, 0.012795799411833286], [0.04119083285331726, 0.12196680158376694, 0.10565153509378433, 0.12188085168600082, 0.1866576075553894, 0.18699903786182404, 0.17164628207683563, 0.06400712579488754], [0.016682200133800507, 0.06696362048387527, 0.05468582734465599, 0.07115533202886581, 0.14089225232601166, 0.224049910902977, 0.38136279582977295, 0.04420802742242813], [0.030455857515335083, 0.0991642102599144, 0.07953805476427078, 0.09055594354867935, 0.13261348009109497, 0.19129601120948792, 0.3196966350078583, 0.056679874658584595], [0.027887847274541855, 0.12234976142644882, 0.12661035358905792, 0.12017568200826645, 0.17116869986057281, 0.1959102302789688, 0.20111815631389618, 0.03477933257818222], [0.03537941351532936, 0.23222680389881134, 0.15070277452468872, 0.23210690915584564, 0.1487005054950714, 0.10535015910863876, 0.07365421950817108, 0.021879179403185844]]], [[[0.04795191064476967, 0.4211066663265228, 0.20605625212192535, 0.04511100798845291, 0.021181762218475342, 0.038593072444200516, 0.16319413483142853, 0.056805118918418884], [0.008996053598821163, 0.8566842675209045, 0.07307830452919006, 0.004007827956229448, 0.0008276154985651374, 0.0026540826074779034, 0.045848947018384933, 0.007902771234512329], [0.026831800118088722, 0.39414793252944946, 0.3089258074760437, 0.05399496853351593, 0.016473952680826187, 0.015661055222153664, 0.15538284182548523, 0.028581688180565834], [0.026910966262221336, 0.352448970079422, 0.18758881092071533, 0.2363334745168686, 0.013023367151618004, 0.024120274931192398, 0.12297842651605606, 0.03659572824835777], [0.030565816909074783, 0.21023643016815186, 0.24155375361442566, 0.010491650551557541, 0.06810832023620605, 0.19694605469703674, 0.1912543922662735, 0.050843581557273865], [0.034639667719602585, 0.24948661029338837, 0.24668514728546143, 0.011259774677455425, 0.06003035977482796, 0.13734667003154755, 0.20838449895381927, 0.052167221903800964], [0.021366920322179794, 0.5302726626396179, 0.2512076795101166, 0.011312578804790974, 0.00874092523008585, 0.013489882461726665, 0.13978539407253265, 0.023823942989110947], [0.05780654028058052, 0.4898693561553955, 0.19272126257419586, 0.022894959896802902, 0.01231276523321867, 0.03149585425853729, 0.11860979348421097, 0.07428937405347824]], [[0.11033067852258682, 0.3615352511405945, 0.1341266930103302, 0.06602654606103897, 0.05877857282757759, 0.11334032565355301, 0.09250020235776901, 0.0633617639541626], [0.11019520461559296, 0.2841300964355469, 0.16972365975379944, 0.07036248594522476, 0.05179924517869949, 0.1010378822684288, 0.15295594930648804, 0.05979553237557411], [0.09350679069757462, 0.3018133044242859, 0.14527921378612518, 0.11690469086170197, 0.06204746663570404, 0.11889377981424332, 0.10696570575237274, 0.054588962346315384], [0.07797940075397491, 0.24344713985919952, 0.145686075091362, 0.08201980590820312, 0.0850968211889267, 0.16999371349811554, 0.12091482430696487, 0.07486224174499512], [0.144298255443573, 0.15717202425003052, 0.1156858280301094, 0.16126790642738342, 0.08080732077360153, 0.12669143080711365, 0.10540517419576645, 0.1086721196770668], [0.12355189025402069, 0.18218795955181122, 0.11368418484926224, 0.16320167481899261, 0.08392968773841858, 0.12443096935749054, 0.1143060252070427, 0.09470760077238083], [0.12034279108047485, 0.2642575800418854, 0.12078893184661865, 0.10640788823366165, 0.08321735262870789, 0.14125297963619232, 0.09351501613855362, 0.07021749764680862], [0.13727357983589172, 0.2867727279663086, 0.10914604365825653, 0.10569502413272858, 0.06648027896881104, 0.12174317985773087, 0.08925856649875641, 0.08363062143325806]], [[0.03279488906264305, 0.22209259867668152, 0.07056573778390884, 0.3998791575431824, 0.053682196885347366, 0.09569890797138214, 0.09166174381971359, 0.033624712377786636], [0.04560462012887001, 0.2720406651496887, 0.1077067106962204, 0.11130891740322113, 0.08083608001470566, 0.13148751854896545, 0.18003353476524353, 0.07098198682069778], [0.030361196026206017, 0.3083750009536743, 0.10166243463754654, 0.11449983716011047, 0.08161605149507523, 0.1472979485988617, 0.1741209179162979, 0.042066656053066254], [0.03956332802772522, 0.12683147192001343, 0.09094978123903275, 0.406335711479187, 0.0529659241437912, 0.10945715010166168, 0.11505638808012009, 0.05884028971195221], [0.032136350870132446, 0.2152116596698761, 0.09264104813337326, 0.3153262138366699, 0.05733110383152962, 0.09162930399179459, 0.1577303409576416, 0.037994034588336945], [0.04449749365448952, 0.21539171040058136, 0.11084846407175064, 0.21684320271015167, 0.0769648626446724, 0.1067068949341774, 0.17822620272636414, 0.05052122846245766], [0.03222905099391937, 0.2561529576778412, 0.10705415904521942, 0.1679692566394806, 0.07317394018173218, 0.12472379207611084, 0.20030003786087036, 0.03839684650301933], [0.03190399706363678, 0.19860060513019562, 0.09468395262956619, 0.47024208307266235, 0.0370870865881443, 0.06570605933666229, 0.07772839069366455, 0.024047931656241417]], [[0.005043832119554281, 0.7376813888549805, 0.16563114523887634, 0.019003935158252716, 0.0010786183411255479, 0.01533920131623745, 0.05347748100757599, 0.002744379686191678], [0.003242073580622673, 0.7832396030426025, 0.12659786641597748, 0.007739846128970385, 0.0016504129162058234, 0.02014031633734703, 0.0540275014936924, 0.003362386953085661], [0.004227422643452883, 0.6608908772468567, 0.24953120946884155, 0.02535916678607464, 0.0007762469467706978, 0.012080582790076733, 0.04423556476831436, 0.002898900071159005], [0.0158662311732769, 0.5436719059944153, 0.13994190096855164, 0.161050483584404, 0.0047978805378079414, 0.040920697152614594, 0.07964575290679932, 0.014105177484452724], [0.009742096066474915, 0.42475688457489014, 0.07778072357177734, 0.12467052787542343, 0.0363217331469059, 0.22143366932868958, 0.09271444380283356, 0.012579837813973427], [0.006725260056555271, 0.675683856010437, 0.08418485522270203, 0.04984145238995552, 0.006580502260476351, 0.09529591351747513, 0.07249592989683151, 0.009192191064357758], [0.005608686245977879, 0.6755355000495911, 0.12110333144664764, 0.044298455119132996, 0.004413624759763479, 0.055255480110645294, 0.0866248682141304, 0.007160031236708164], [0.004328109323978424, 0.7892269492149353, 0.10560766607522964, 0.02436288632452488, 0.0013395396526902914, 0.01714319735765457, 0.05449816584587097, 0.003493516705930233]], [[0.02804459072649479, 0.14134329557418823, 0.0901423990726471, 0.18038176000118256, 0.17140404880046844, 0.2651415467262268, 0.10332061350345612, 0.020221799612045288], [0.06123318150639534, 0.12142631411552429, 0.10476356744766235, 0.20078998804092407, 0.18219594657421112, 0.1663527935743332, 0.11470452696084976, 0.04853377491235733], [0.041539955884218216, 0.12396133691072464, 0.08449432253837585, 0.2509377598762512, 0.14457175135612488, 0.23744797706604004, 0.09004765748977661, 0.026999276131391525], [0.05719687417149544, 0.15610121190547943, 0.10386724770069122, 0.15169550478458405, 0.2018212378025055, 0.1675063669681549, 0.10547927021980286, 0.056332193315029144], [0.02355794794857502, 0.11055468022823334, 0.07065888494253159, 0.11397312581539154, 0.2638469636440277, 0.30923253297805786, 0.09093494713306427, 0.01724100112915039], [0.03638549521565437, 0.12030600011348724, 0.07657202333211899, 0.18185289204120636, 0.17935557663440704, 0.30799877643585205, 0.07520562410354614, 0.022323518991470337], [0.035894375294446945, 0.10647768527269363, 0.06804388761520386, 0.20056654512882233, 0.19573400914669037, 0.2993236780166626, 0.07301908731460571, 0.020940721035003662], [0.021985534578561783, 0.13566575944423676, 0.07705311477184296, 0.1691989302635193, 0.1868930459022522, 0.3068544268608093, 0.08380241692066193, 0.01854681968688965]], [[0.04042252525687218, 0.024948488920927048, 0.01672709546983242, 0.7701460123062134, 0.0193442702293396, 0.02376391924917698, 0.018833404406905174, 0.08581426739692688], [0.04037826508283615, 0.18253877758979797, 0.12658841907978058, 0.3497426509857178, 0.08575405180454254, 0.0583646185696125, 0.10480598360300064, 0.051827285438776016], [0.04792587459087372, 0.17784370481967926, 0.10674911737442017, 0.37827420234680176, 0.06712190806865692, 0.05925379693508148, 0.09142906963825226, 0.07140231877565384], [0.0009559370810166001, 0.00034750025952234864, 0.0004991249297745526, 0.9947347640991211, 0.0008509564795531332, 0.0004075019678566605, 0.0004334052209742367, 0.0017709071980789304], [0.05396096780896187, 0.09610860049724579, 0.06524767726659775, 0.3670860230922699, 0.13786806166172028, 0.11187145859003067, 0.07875093072652817, 0.08910626918077469], [0.047963760793209076, 0.08610309660434723, 0.07417682558298111, 0.3917948603630066, 0.10895668715238571, 0.13489581644535065, 0.07355406880378723, 0.08255482465028763], [0.04914803430438042, 0.1718800961971283, 0.10807521641254425, 0.3501322269439697, 0.08429833501577377, 0.06274186819791794, 0.0944989025592804, 0.07922538369894028], [0.03724655508995056, 0.024900469928979874, 0.018094036728143692, 0.7613639831542969, 0.02733662910759449, 0.026785925030708313, 0.01916174590587616, 0.08511056005954742]], [[0.03188353404402733, 0.511184573173523, 0.1597106009721756, 0.022143688052892685, 0.043185509741306305, 0.06234342232346535, 0.14102767407894135, 0.028521062806248665], [0.0017615663819015026, 0.8981658816337585, 0.04109039157629013, 0.0005018776282668114, 0.0012048630742356181, 0.0032116109505295753, 0.052281565964221954, 0.0017821298679336905], [0.009091267362236977, 0.6442596316337585, 0.13651461899280548, 0.004001195542514324, 0.007784279063344002, 0.016960792243480682, 0.1709865927696228, 0.01040148176252842], [0.03212040290236473, 0.14748117327690125, 0.06874439865350723, 0.6455654501914978, 0.005228075198829174, 0.008751554414629936, 0.06446496397256851, 0.027643924579024315], [0.052914660423994064, 0.19895592331886292, 0.18615847826004028, 0.015498636290431023, 0.095477394759655, 0.22269578278064728, 0.1955156922340393, 0.03278351202607155], [0.030748700723052025, 0.29215359687805176, 0.16445837914943695, 0.00992680061608553, 0.07339145988225937, 0.22818081080913544, 0.18619036674499512, 0.014949933625757694], [0.01353136170655489, 0.5584908723831177, 0.17426088452339172, 0.003455230500549078, 0.010983716696500778, 0.026480959728360176, 0.19961120188236237, 0.013185703195631504], [0.03081732615828514, 0.5714689493179321, 0.1301819384098053, 0.01647958531975746, 0.0377778634428978, 0.06376637518405914, 0.12145023792982101, 0.028057821094989777]], [[0.019646216183900833, 0.20684820413589478, 0.07473023235797882, 0.2412721812725067, 0.14333799481391907, 0.22959831357002258, 0.06406190991401672, 0.020505035296082497], [0.06639131158590317, 0.23506216704845428, 0.13474394381046295, 0.10041003674268723, 0.10588838905096054, 0.1656784564256668, 0.10221553593873978, 0.08961009979248047], [0.02053840085864067, 0.1881178766489029, 0.08608412742614746, 0.12258540838956833, 0.17520900070667267, 0.259155809879303, 0.112428218126297, 0.035881198942661285], [0.028311092406511307, 0.19442391395568848, 0.07986999303102493, 0.11764989048242569, 0.14986839890480042, 0.263098806142807, 0.11470767110586166, 0.05207020789384842], [0.01136672031134367, 0.09479974210262299, 0.02935594506561756, 0.07482220232486725, 0.1610030084848404, 0.44363489747047424, 0.14058227837085724, 0.04443517327308655], [0.020944150164723396, 0.10006022453308105, 0.04376474395394325, 0.06118186563253403, 0.19007307291030884, 0.3874695897102356, 0.1314706802368164, 0.06503564864397049], [0.03610507398843765, 0.1389520764350891, 0.07623682916164398, 0.10129818320274353, 0.1432119458913803, 0.2837756872177124, 0.1355055570602417, 0.08491464704275131], [0.02259771339595318, 0.2595677971839905, 0.07865019142627716, 0.22116607427597046, 0.09167177230119705, 0.21388311684131622, 0.08313499391078949, 0.02932828664779663]], [[0.12284955382347107, 0.16421517729759216, 0.19535671174526215, 0.14562438428401947, 0.042630333453416824, 0.08295127004384995, 0.10436484217643738, 0.1420077383518219], [0.12935657799243927, 0.10141196846961975, 0.13172167539596558, 0.22774234414100647, 0.04611003026366234, 0.11776071786880493, 0.09330712258815765, 0.1525895744562149], [0.09039470553398132, 0.13499605655670166, 0.10170593112707138, 0.3448450267314911, 0.04849496856331825, 0.10709087550640106, 0.0629495158791542, 0.10952282696962357], [0.11639437824487686, 0.26442089676856995, 0.2816488444805145, 0.004214864689856768, 0.040247078984975815, 0.11625227332115173, 0.10828915238380432, 0.06853238493204117], [0.16494056582450867, 0.0985172837972641, 0.1469876915216446, 0.32494020462036133, 0.016435731202363968, 0.021154936403036118, 0.05223306268453598, 0.17479059100151062], [0.16603010892868042, 0.14040160179138184, 0.160994753241539, 0.26029831171035767, 0.022563621401786804, 0.02273542992770672, 0.06726158410310745, 0.15971457958221436], [0.1307903677225113, 0.1535664051771164, 0.11802860349416733, 0.27495330572128296, 0.04322778433561325, 0.08201650530099869, 0.05854329839348793, 0.13887366652488708], [0.15639232099056244, 0.2179294377565384, 0.1904129832983017, 0.09454604983329773, 0.03467670828104019, 0.06911864876747131, 0.08968275040388107, 0.14724108576774597]], [[0.004398063290864229, 0.5496929287910461, 0.1057557463645935, 0.021077489480376244, 0.05874355137348175, 0.11590525507926941, 0.14055801928043365, 0.00386891164816916], [0.01943165250122547, 0.44512563943862915, 0.16796310245990753, 0.021162962540984154, 0.07289423048496246, 0.09725835919380188, 0.1582595556974411, 0.017904605716466904], [0.007886803708970547, 0.544357419013977, 0.148586243391037, 0.012238672003149986, 0.050222139805555344, 0.09186360239982605, 0.13973882794380188, 0.005106181371957064], [0.032555822283029556, 0.40608200430870056, 0.2268708348274231, 0.01956729032099247, 0.0695853978395462, 0.09933874011039734, 0.12583181262016296, 0.020168039947748184], [0.014479600824415684, 0.3776332139968872, 0.23388484120368958, 0.02249825745820999, 0.06932634860277176, 0.13157862424850464, 0.1417698860168457, 0.00882936455309391], [0.021108942106366158, 0.32981613278388977, 0.23442040383815765, 0.02387557178735733, 0.09494113177061081, 0.11330848187208176, 0.17020545899868011, 0.012323872186243534], [0.008982602506875992, 0.4037751853466034, 0.18688705563545227, 0.015665875747799873, 0.09597354382276535, 0.11953261494636536, 0.16416500508785248, 0.005018157418817282], [0.003797098994255066, 0.49311599135398865, 0.14419670403003693, 0.038054078817367554, 0.05872008576989174, 0.12955962121486664, 0.13039018213748932, 0.0021661727223545313]], [[0.006705335807055235, 0.5573375821113586, 0.08946319669485092, 0.0776490718126297, 0.02652028203010559, 0.08760607242584229, 0.14953118562698364, 0.0051873852498829365], [0.03175860643386841, 0.27040815353393555, 0.15241217613220215, 0.09430947154760361, 0.07945224642753601, 0.11659041047096252, 0.23186424374580383, 0.023204706609249115], [0.016694672405719757, 0.38812971115112305, 0.1268596202135086, 0.06491867452859879, 0.04842737689614296, 0.10786229372024536, 0.23540392518043518, 0.011703629978001118], [0.029861250892281532, 0.36493977904319763, 0.1526937186717987, 0.09861487150192261, 0.05586576089262962, 0.10076569765806198, 0.17302967607975006, 0.024229202419519424], [0.008855830878019333, 0.4364308714866638, 0.1195569634437561, 0.047575801610946655, 0.029980067163705826, 0.11734341084957123, 0.2305312305688858, 0.009725905023515224], [0.014983692206442356, 0.3337787091732025, 0.107808917760849, 0.04971713945269585, 0.055686552077531815, 0.11669441312551498, 0.30541443824768066, 0.015916114673018456], [0.01805647648870945, 0.30054405331611633, 0.13735614717006683, 0.0808245986700058, 0.05783633515238762, 0.14085249602794647, 0.2533363103866577, 0.011193529702723026], [0.006326618138700724, 0.5259522199630737, 0.08274267613887787, 0.12043632566928864, 0.029097318649291992, 0.09845460206270218, 0.13262471556663513, 0.004365514498203993]], [[0.06279348582029343, 0.3317365348339081, 0.5366539359092712, 0.049229998141527176, 0.0001085040858015418, 0.00041024666279554367, 0.00942041166126728, 0.009646927937865257], [0.03489125892519951, 0.6853089928627014, 0.1907998025417328, 0.04265640303492546, 0.0007039212505333126, 0.0024555225390940905, 0.02583310380578041, 0.01735106110572815], [0.06585424393415451, 0.26289722323417664, 0.6287809610366821, 0.02737409807741642, 0.00012369586329441518, 0.0002873605117201805, 0.007308755069971085, 0.007373598869889975], [0.11475756764411926, 0.331272691488266, 0.2401401549577713, 0.2219802588224411, 0.004016598220914602, 0.006947598420083523, 0.031263403594493866, 0.04962160065770149], [0.013845114968717098, 0.3182391822338104, 0.11471080034971237, 0.3383345901966095, 0.04985252767801285, 0.03723425418138504, 0.10652396082878113, 0.021259557455778122], [0.011346105486154556, 0.33257097005844116, 0.061067886650562286, 0.1380329132080078, 0.030519874766469002, 0.1961301565170288, 0.2019553780555725, 0.028376728296279907], [0.024843739345669746, 0.47930625081062317, 0.21843421459197998, 0.08369679003953934, 0.0039995512925088406, 0.01898593083024025, 0.14053651690483093, 0.03019709512591362], [0.04184970259666443, 0.4843900501728058, 0.27898138761520386, 0.11413271725177765, 0.0011100583942607045, 0.004593041259795427, 0.044316522777080536, 0.030626511201262474]]], [[[0.03426762670278549, 0.3609254062175751, 0.10506373643875122, 0.10354841500520706, 0.045268718153238297, 0.21800023317337036, 0.10496368259191513, 0.027962232008576393], [0.03273973986506462, 0.4409143030643463, 0.1361485868692398, 0.06301937252283096, 0.03611334040760994, 0.14770419895648956, 0.11947467178106308, 0.02388571947813034], [0.03592599555850029, 0.3650032877922058, 0.12455830723047256, 0.11590855568647385, 0.0415470227599144, 0.19526664912700653, 0.09885907173156738, 0.022931018844246864], [0.05441131070256233, 0.30222272872924805, 0.11749175935983658, 0.1314891278743744, 0.06393995881080627, 0.18080376088619232, 0.10780493170022964, 0.04183638095855713], [0.016533875837922096, 0.34486812353134155, 0.07166611403226852, 0.09890951216220856, 0.03205233812332153, 0.3218047022819519, 0.09374715387821198, 0.02041819877922535], [0.023374361917376518, 0.2265123575925827, 0.07186409831047058, 0.12342788279056549, 0.05636276677250862, 0.3499513566493988, 0.11939697712659836, 0.029110193252563477], [0.03249906003475189, 0.3167441189289093, 0.08308162540197372, 0.10535992681980133, 0.04351316764950752, 0.297801673412323, 0.09715867042541504, 0.023841673508286476], [0.034278836101293564, 0.32624608278274536, 0.08880322426557541, 0.11927737295627594, 0.04629398137331009, 0.26630398631095886, 0.08899593353271484, 0.0298005361109972]], [[0.04716506227850914, 0.19862526655197144, 0.20843759179115295, 0.09680280834436417, 0.07551208138465881, 0.06858915835618973, 0.23899783194065094, 0.06587020307779312], [0.04879755526781082, 0.18488606810569763, 0.1928447186946869, 0.11073794960975647, 0.07349734753370285, 0.07306954264640808, 0.2493879646062851, 0.06677881628274918], [0.04248003661632538, 0.19574086368083954, 0.1961679756641388, 0.09396225959062576, 0.08185150474309921, 0.07966373860836029, 0.2528407871723175, 0.05729277804493904], [0.054460328072309494, 0.18769137561321259, 0.22430674731731415, 0.0481792688369751, 0.06763637065887451, 0.06380756944417953, 0.2838839888572693, 0.07003430277109146], [0.046981748193502426, 0.18919633328914642, 0.20094266533851624, 0.11650735139846802, 0.05365181714296341, 0.06923634558916092, 0.26608729362487793, 0.05739644542336464], [0.038864973932504654, 0.16612502932548523, 0.2030518501996994, 0.09007281064987183, 0.05826938897371292, 0.08176817744970322, 0.3154829740524292, 0.04636470973491669], [0.02769208326935768, 0.1843372881412506, 0.1880602240562439, 0.09926370531320572, 0.06742329895496368, 0.08726188540458679, 0.3116860091686249, 0.034275513142347336], [0.03643285483121872, 0.21742874383926392, 0.2142854779958725, 0.11341474950313568, 0.07035595923662186, 0.06599429994821548, 0.2345048189163208, 0.04758313298225403]], [[0.10144291818141937, 0.16593487560749054, 0.13333503901958466, 0.07736601680517197, 0.08319930732250214, 0.15534205734729767, 0.13062822818756104, 0.15275157988071442], [0.09190130978822708, 0.2065442055463791, 0.126150444149971, 0.04712488129734993, 0.08179733157157898, 0.12108947336673737, 0.16854767501354218, 0.1568446010351181], [0.09089992195367813, 0.16954724490642548, 0.14368152618408203, 0.07109662145376205, 0.09611689299345016, 0.14868614077568054, 0.1532938927412033, 0.1266777366399765], [0.08151523768901825, 0.1366434246301651, 0.13536234200000763, 0.05516352131962776, 0.10737966001033783, 0.19376826286315918, 0.16842488944530487, 0.12174271047115326], [0.07452107965946198, 0.13087338209152222, 0.11788050830364227, 0.043056637048721313, 0.09959544986486435, 0.238068088889122, 0.1796264350414276, 0.11637847125530243], [0.07040219008922577, 0.13382895290851593, 0.11615510284900665, 0.053289301693439484, 0.11104410886764526, 0.21795164048671722, 0.17936968803405762, 0.11795900017023087], [0.08798304945230484, 0.14724858105182648, 0.11914103478193283, 0.0389716736972332, 0.10211865603923798, 0.20055119693279266, 0.17702654004096985, 0.12695930898189545], [0.1075773537158966, 0.14533931016921997, 0.11410298198461533, 0.07030296325683594, 0.07670577615499496, 0.17580269277095795, 0.12730132043361664, 0.18286757171154022]], [[0.195155069231987, 0.1187509074807167, 0.1948373019695282, 0.09288527071475983, 0.058479759842157364, 0.055574022233486176, 0.12075384706258774, 0.1635637879371643], [0.12000962346792221, 0.13630671799182892, 0.2404385805130005, 0.057819999754428864, 0.08656689524650574, 0.06485246866941452, 0.19823509454727173, 0.09577056020498276], [0.1251610964536667, 0.11554493010044098, 0.23652803897857666, 0.05155028775334358, 0.09623227268457413, 0.07184945791959763, 0.20588292181491852, 0.09725095331668854], [0.16682791709899902, 0.10862334072589874, 0.18719805777072906, 0.1177777647972107, 0.09057316929101944, 0.06806445866823196, 0.12104668468236923, 0.13988859951496124], [0.13866664469242096, 0.10453826189041138, 0.21552373468875885, 0.06146574392914772, 0.11417536437511444, 0.0706004723906517, 0.1826392263174057, 0.11239047348499298], [0.10669784992933273, 0.13733728229999542, 0.21667581796646118, 0.06663558632135391, 0.10607344657182693, 0.07442565262317657, 0.1946437656879425, 0.09751062095165253], [0.10930659621953964, 0.10405059158802032, 0.2377491295337677, 0.049476027488708496, 0.10616450756788254, 0.07363700121641159, 0.23291118443012238, 0.08670505881309509], [0.16296371817588806, 0.13800613582134247, 0.20308999717235565, 0.09586956351995468, 0.06273923814296722, 0.06396222114562988, 0.1320079118013382, 0.14136123657226562]], [[0.15560707449913025, 0.21281129121780396, 0.11924853175878525, 0.22104595601558685, 0.02859402820467949, 0.06535732746124268, 0.07902299612760544, 0.11831280589103699], [0.1582924872636795, 0.2616695165634155, 0.13266217708587646, 0.14536184072494507, 0.02065753936767578, 0.058523163199424744, 0.09539755433797836, 0.12743568420410156], [0.1607280969619751, 0.1409023255109787, 0.13063688576221466, 0.26436465978622437, 0.030585987493395805, 0.06653432548046112, 0.0823194682598114, 0.12392832338809967], [0.12704181671142578, 0.14723774790763855, 0.08565595746040344, 0.38602587580680847, 0.027184853330254555, 0.06612322479486465, 0.06425934284925461, 0.09647113084793091], [0.12745454907417297, 0.0921587347984314, 0.0834379568696022, 0.22309339046478271, 0.07228954881429672, 0.210936039686203, 0.08430146425962448, 0.10632821917533875], [0.16329911351203918, 0.10771370679140091, 0.0854518786072731, 0.20240052044391632, 0.04873846471309662, 0.17088298499584198, 0.08668091148138046, 0.1348324418067932], [0.15384306013584137, 0.1663200557231903, 0.10902450233697891, 0.21316930651664734, 0.03299287334084511, 0.10679883509874344, 0.09586820751428604, 0.12198316305875778], [0.12363787740468979, 0.26088473200798035, 0.11113155633211136, 0.221024751663208, 0.02485981583595276, 0.07751499116420746, 0.07933720201253891, 0.10160911083221436]], [[0.08189762383699417, 0.045624811202287674, 0.08060748130083084, 0.1155969649553299, 0.14173245429992676, 0.3262786269187927, 0.11454109847545624, 0.09372100234031677], [0.0815298855304718, 0.06534897536039352, 0.08804725110530853, 0.11711528897285461, 0.1507803499698639, 0.2784218490123749, 0.12471987307071686, 0.09403650462627411], [0.07721471041440964, 0.05527224391698837, 0.08214680850505829, 0.1431189775466919, 0.14924822747707367, 0.2992072105407715, 0.11396265774965286, 0.079829141497612], [0.08400632441043854, 0.05320684239268303, 0.08192962408065796, 0.12060703337192535, 0.15823304653167725, 0.2780155539512634, 0.10352802276611328, 0.12047352641820908], [0.05388465151190758, 0.03915076702833176, 0.06955637782812119, 0.10391746461391449, 0.1585777848958969, 0.38995885848999023, 0.12151845544576645, 0.06343569606542587], [0.06661809235811234, 0.040653154253959656, 0.06510281562805176, 0.08437220752239227, 0.15248247981071472, 0.39106103777885437, 0.12454180419445038, 0.0751684159040451], [0.06483283638954163, 0.05245688185095787, 0.06978869438171387, 0.0993552953004837, 0.1609317809343338, 0.3489384055137634, 0.12992985546588898, 0.07376620918512344], [0.07577367126941681, 0.04821208119392395, 0.07378263771533966, 0.13122932612895966, 0.13428598642349243, 0.3334631621837616, 0.10911588370800018, 0.0941372960805893]], [[0.08310914039611816, 0.2064969539642334, 0.10811816900968552, 0.345400869846344, 0.015729263424873352, 0.03931385651230812, 0.08960969001054764, 0.11222200840711594], [0.09036678820848465, 0.3763680160045624, 0.11451045423746109, 0.18868906795978546, 0.008352654986083508, 0.02796957455575466, 0.08904243260622025, 0.10470102727413177], [0.0902029499411583, 0.21373283863067627, 0.12876924872398376, 0.33438509702682495, 0.012014967389404774, 0.029788685962557793, 0.07652676105499268, 0.1145794466137886], [0.03736543655395508, 0.07996700704097748, 0.05409551411867142, 0.7100082635879517, 0.01280169002711773, 0.02456521987915039, 0.037549495697021484, 0.04364737123250961], [0.06877334415912628, 0.14591531455516815, 0.09642527997493744, 0.3804735243320465, 0.03619282320141792, 0.08197008073329926, 0.10706651955842972, 0.08318313956260681], [0.07187484949827194, 0.1654009371995926, 0.09427924454212189, 0.3251737654209137, 0.03404957428574562, 0.0898762196302414, 0.11797990649938583, 0.10136548429727554], [0.09981223195791245, 0.22280745208263397, 0.13358429074287415, 0.22392280399799347, 0.017354842275381088, 0.04494938254356384, 0.12145242094993591, 0.13611648976802826], [0.07719621062278748, 0.23019425570964813, 0.11091252416372299, 0.3174605965614319, 0.014535000547766685, 0.04102879390120506, 0.09745429456233978, 0.11121831834316254]], [[0.09919381141662598, 0.14323556423187256, 0.10249660164117813, 0.4024888873100281, 0.022957293316721916, 0.05305824056267738, 0.11495794355869293, 0.06161164864897728], [0.1175188347697258, 0.16705861687660217, 0.12178725004196167, 0.2862214744091034, 0.026617513969540596, 0.06665550917387009, 0.12741023302078247, 0.08673063665628433], [0.10615575313568115, 0.12439107894897461, 0.09245048463344574, 0.4506777226924896, 0.01990559883415699, 0.04966563358902931, 0.08537683635950089, 0.07137680053710938], [0.10553780943155289, 0.12135501950979233, 0.144041508436203, 0.29912981390953064, 0.030980076640844345, 0.06441245228052139, 0.14975719153881073, 0.08478618413209915], [0.11717642098665237, 0.15532752871513367, 0.13334257900714874, 0.27015435695648193, 0.02766721323132515, 0.08047929406166077, 0.1384533941745758, 0.07739924639463425], [0.11936930567026138, 0.1429489403963089, 0.10529310256242752, 0.31779393553733826, 0.0315108597278595, 0.08073148131370544, 0.12157193571329117, 0.0807805061340332], [0.12131260335445404, 0.14573736488819122, 0.0943417176604271, 0.33574414253234863, 0.026459213346242905, 0.07565423846244812, 0.1149248406291008, 0.08582579344511032], [0.12583573162555695, 0.16157983243465424, 0.10014414042234421, 0.34513798356056213, 0.021776288747787476, 0.059207331389188766, 0.11286615580320358, 0.07345248758792877]], [[0.08898507058620453, 0.14400404691696167, 0.08883011341094971, 0.10340580344200134, 0.09562723338603973, 0.19303838908672333, 0.13947491347789764, 0.14663442969322205], [0.13672220706939697, 0.16350699961185455, 0.10508527606725693, 0.05416061356663704, 0.09013549983501434, 0.15470543503761292, 0.14497487246990204, 0.15070906281471252], [0.08672735840082169, 0.1734497994184494, 0.10669359564781189, 0.07171116769313812, 0.08854474872350693, 0.2002781331539154, 0.1534363329410553, 0.11915881186723709], [0.10271009802818298, 0.13223986327648163, 0.13395826518535614, 0.05574493855237961, 0.08385204523801804, 0.19538408517837524, 0.13946501910686493, 0.15664564073085785], [0.06595612317323685, 0.11150970309972763, 0.08468039333820343, 0.11340169608592987, 0.16367262601852417, 0.2074728161096573, 0.15692228078842163, 0.09638440608978271], [0.057196516543626785, 0.09050609916448593, 0.07493606954813004, 0.0953080952167511, 0.2232586294412613, 0.22159765660762787, 0.16592782735824585, 0.07126914709806442], [0.0668707937002182, 0.12312636524438858, 0.0737847089767456, 0.08301954716444016, 0.1483539640903473, 0.25382858514785767, 0.1644795536994934, 0.08653648942708969], [0.07481459528207779, 0.11704977601766586, 0.0807509645819664, 0.13288196921348572, 0.13997802138328552, 0.21774521470069885, 0.1305825114250183, 0.10619697719812393]], [[0.12145582586526871, 0.14392729103565216, 0.09153082221746445, 0.4081767201423645, 0.04731970280408859, 0.08023729175329208, 0.0400669202208519, 0.06728539615869522], [0.12814243137836456, 0.12152670323848724, 0.08660624921321869, 0.3838147819042206, 0.05875036492943764, 0.07942808419466019, 0.05858435109257698, 0.08314710855484009], [0.09573391079902649, 0.12468650192022324, 0.11173815280199051, 0.44330790638923645, 0.05795197933912277, 0.0722302794456482, 0.04804682359099388, 0.046304427087306976], [0.15819735825061798, 0.13865776360034943, 0.091505266726017, 0.22477655112743378, 0.0919458419084549, 0.12068609148263931, 0.06505435705184937, 0.10917677730321884], [0.06403770297765732, 0.14337997138500214, 0.08809852600097656, 0.3558674156665802, 0.08619733899831772, 0.1410144418478012, 0.07941524684429169, 0.04198942333459854], [0.09099990129470825, 0.13743816316127777, 0.07394960522651672, 0.31229168176651, 0.10793932527303696, 0.13948757946491241, 0.0751783549785614, 0.06271538138389587], [0.08893391489982605, 0.12401826679706573, 0.0675341784954071, 0.42319566011428833, 0.07738140225410461, 0.10369537770748138, 0.05688313767313957, 0.05835812911391258], [0.125366672873497, 0.14926332235336304, 0.0687413364648819, 0.41511303186416626, 0.0334291085600853, 0.07849569618701935, 0.03490610048174858, 0.09468485414981842]], [[0.08594363927841187, 0.62678462266922, 0.13342221081256866, 0.005623314529657364, 0.004025512840598822, 0.015094200149178505, 0.0787883922457695, 0.050318095833063126], [0.2254253327846527, 0.28911086916923523, 0.14496034383773804, 0.022338800132274628, 0.030325839295983315, 0.052361685782670975, 0.10268275439739227, 0.13279442489147186], [0.09024985134601593, 0.5884751677513123, 0.15940850973129272, 0.00842446181923151, 0.0053010741248726845, 0.01383327879011631, 0.07721952348947525, 0.05708809569478035], [0.1943131983280182, 0.21107973158359528, 0.23784376680850983, 0.024885255843400955, 0.026015540584921837, 0.04114844277501106, 0.16115736961364746, 0.10355664044618607], [0.28220877051353455, 0.08039260655641556, 0.13411660492420197, 0.08468952029943466, 0.13839319348335266, 0.07206800580024719, 0.08303432911634445, 0.12509691715240479], [0.15541860461235046, 0.0675390437245369, 0.061793118715286255, 0.023744968697428703, 0.38596343994140625, 0.1443185806274414, 0.07254449278116226, 0.08867783844470978], [0.1860445737838745, 0.181143119931221, 0.09279599040746689, 0.014290728606283665, 0.09259878098964691, 0.1822599321603775, 0.12755030393600464, 0.12331660091876984], [0.14795175194740295, 0.33865588903427124, 0.13960033655166626, 0.009903770871460438, 0.0186313409358263, 0.07392636686563492, 0.16369052231311798, 0.10764006525278091]], [[0.28592604398727417, 0.09219077229499817, 0.0589396134018898, 0.1262226700782776, 0.010075229220092297, 0.06643742322921753, 0.10486944764852524, 0.2553389072418213], [0.15574796497821808, 0.20912158489227295, 0.044726260006427765, 0.12461375445127487, 0.020742978900671005, 0.12121348083019257, 0.13198450207710266, 0.19184942543506622], [0.29996925592422485, 0.0990082174539566, 0.1119697317481041, 0.12983238697052002, 0.014567526057362556, 0.05506220832467079, 0.09249041229486465, 0.19710031151771545], [0.13147269189357758, 0.1588916927576065, 0.03577204793691635, 0.3068106770515442, 0.023024076595902443, 0.07207753509283066, 0.08364766836166382, 0.18830358982086182], [0.15644219517707825, 0.1519242525100708, 0.036126285791397095, 0.20249874889850616, 0.05528121441602707, 0.07575556635856628, 0.09856913238763809, 0.22340258955955505], [0.17669931054115295, 0.16919760406017303, 0.031626299023628235, 0.15330344438552856, 0.013377699069678783, 0.11663349717855453, 0.11088955402374268, 0.22827260196208954], [0.20365504920482635, 0.13692225515842438, 0.04070938006043434, 0.13302290439605713, 0.015745429322123528, 0.08330196887254715, 0.11961980164051056, 0.2670232057571411], [0.1730627715587616, 0.1079743430018425, 0.03469352051615715, 0.15740558505058289, 0.010606450960040092, 0.07400575280189514, 0.1117076724767685, 0.3305439352989197]]], [[[0.05349460244178772, 0.23432688415050507, 0.08758119493722916, 0.2862832844257355, 0.04909219220280647, 0.1372660994529724, 0.10713421553373337, 0.0448216013610363], [0.04783779755234718, 0.16285477578639984, 0.07758304476737976, 0.40861955285072327, 0.052410952746868134, 0.12000018358230591, 0.08567038923501968, 0.04502321034669876], [0.04231387749314308, 0.17895451188087463, 0.0917109027504921, 0.37498512864112854, 0.04848581179976463, 0.12839071452617645, 0.1003912165760994, 0.034767862409353256], [0.04520465061068535, 0.1559031456708908, 0.09879180043935776, 0.34674975275993347, 0.08300796896219254, 0.12282924354076385, 0.10727865248918533, 0.04023483023047447], [0.0477164201438427, 0.10245352238416672, 0.08199296146631241, 0.4383280873298645, 0.05779264494776726, 0.14024969935417175, 0.08993393182754517, 0.04153275489807129], [0.0368320606648922, 0.06134317070245743, 0.05285774916410446, 0.4946787655353546, 0.08045978099107742, 0.1563265025615692, 0.0813109502196312, 0.03619103133678436], [0.04425473511219025, 0.10208287835121155, 0.061187271028757095, 0.41594240069389343, 0.06412878632545471, 0.17186783254146576, 0.09738536179065704, 0.04315074160695076], [0.06346685439348221, 0.17459118366241455, 0.08268082141876221, 0.33186638355255127, 0.049671925604343414, 0.13133582472801208, 0.10845733433961868, 0.05792964622378349]], [[0.1085900291800499, 0.06949174404144287, 0.06499605625867844, 0.38803526759147644, 0.05851783603429794, 0.1725226193666458, 0.08230150490999222, 0.05554485693573952], [0.09447014331817627, 0.061679407954216, 0.05505414679646492, 0.4493672549724579, 0.05185406655073166, 0.16800829768180847, 0.07517028599977493, 0.044396523386240005], [0.08197043091058731, 0.05002541467547417, 0.05646947771310806, 0.5100733637809753, 0.04945895075798035, 0.15114516019821167, 0.06492889672517776, 0.0359283871948719], [0.08006798475980759, 0.08071127533912659, 0.08358649909496307, 0.31193166971206665, 0.09769747406244278, 0.20599745213985443, 0.10018815845251083, 0.03981953114271164], [0.0722971111536026, 0.049417827278375626, 0.04828150197863579, 0.43025314807891846, 0.06757325679063797, 0.2298734188079834, 0.07046174257993698, 0.03184201195836067], [0.07390623539686203, 0.052635207772254944, 0.053179118782281876, 0.4162839651107788, 0.0730128139257431, 0.21432805061340332, 0.0836726501584053, 0.03298189118504524], [0.07775610685348511, 0.05235714837908745, 0.05292671546339989, 0.39815014600753784, 0.06452859193086624, 0.23675405979156494, 0.08101437240839005, 0.036512862890958786], [0.10665368288755417, 0.06509708613157272, 0.052196573466062546, 0.41745156049728394, 0.05421581491827965, 0.17858318984508514, 0.07020877301692963, 0.05559339001774788]], [[0.07389350235462189, 0.1464490443468094, 0.08156369626522064, 0.287210613489151, 0.12160862237215042, 0.11656744033098221, 0.08225175738334656, 0.09045534580945969], [0.04317088797688484, 0.15493996441364288, 0.060154542326927185, 0.3030705749988556, 0.12082604318857193, 0.15472497045993805, 0.0946202278137207, 0.0684928372502327], [0.051482126116752625, 0.13689763844013214, 0.09139205515384674, 0.28414326906204224, 0.1182384267449379, 0.13893988728523254, 0.10730329155921936, 0.07160338759422302], [0.025450449436903, 0.11085972934961319, 0.04963657259941101, 0.4319857954978943, 0.1510837972164154, 0.11692622303962708, 0.0752529501914978, 0.03880437836050987], [0.023513613268733025, 0.08378750085830688, 0.0421743169426918, 0.24215173721313477, 0.25812453031539917, 0.20168143510818481, 0.09841176867485046, 0.05015503242611885], [0.020896263420581818, 0.0861954540014267, 0.03781726583838463, 0.23174403607845306, 0.20753847062587738, 0.2816217839717865, 0.09592830389738083, 0.03825841844081879], [0.039138052612543106, 0.11104514449834824, 0.05675230175256729, 0.24577440321445465, 0.15319368243217468, 0.19563370943069458, 0.12452609091997147, 0.07393655925989151], [0.06278889626264572, 0.1358722299337387, 0.06265171617269516, 0.30490127205848694, 0.13050773739814758, 0.12044712156057358, 0.09132444858551025, 0.09150650352239609]], [[0.08789828419685364, 0.23395267128944397, 0.28270477056503296, 0.0517769381403923, 0.06137397885322571, 0.04483773931860924, 0.18767613172531128, 0.049779485911130905], [0.1218479573726654, 0.21299542486667633, 0.2698858678340912, 0.03735247999429703, 0.06177063658833504, 0.053968675434589386, 0.18100722134113312, 0.0611717626452446], [0.1263820379972458, 0.1765994131565094, 0.23708751797676086, 0.07818275690078735, 0.09599490463733673, 0.06839410215616226, 0.16020098328590393, 0.05715825781226158], [0.0971202403306961, 0.17843472957611084, 0.1815534234046936, 0.06447593867778778, 0.1394529640674591, 0.10812480002641678, 0.1663718968629837, 0.06446593999862671], [0.09842786937952042, 0.1556258350610733, 0.1649882197380066, 0.029853539541363716, 0.12187758833169937, 0.17873819172382355, 0.20045161247253418, 0.050037067383527756], [0.10172472149133682, 0.1640080064535141, 0.24156786501407623, 0.03823839873075485, 0.06376133114099503, 0.07926969230175018, 0.25058722496032715, 0.06084273010492325], [0.1253448873758316, 0.20676130056381226, 0.23724880814552307, 0.039259422570466995, 0.058645084500312805, 0.0615517757833004, 0.19845479726791382, 0.07273397594690323], [0.09763961285352707, 0.256966233253479, 0.27242138981819153, 0.0391061045229435, 0.04019232839345932, 0.043167054653167725, 0.18477314710617065, 0.06573402881622314]], [[0.033541396260261536, 0.13989323377609253, 0.13378708064556122, 0.3076303005218506, 0.0959501639008522, 0.10996823012828827, 0.14668209850788116, 0.03254753351211548], [0.023068180307745934, 0.15644000470638275, 0.11171267181634903, 0.3043764531612396, 0.10370612889528275, 0.1125083789229393, 0.1605040729045868, 0.02768409438431263], [0.027519121766090393, 0.13886640965938568, 0.1771087646484375, 0.28688767552375793, 0.1009853258728981, 0.09194675832986832, 0.149155393242836, 0.027530480176210403], [0.027483468875288963, 0.19253534078598022, 0.15368063747882843, 0.2518371045589447, 0.08595483750104904, 0.09535495191812515, 0.16487246751785278, 0.028281139209866524], [0.01074009295552969, 0.15975321829319, 0.08135779947042465, 0.160913348197937, 0.16783837974071503, 0.21016860008239746, 0.19517457485198975, 0.014054030179977417], [0.009349294938147068, 0.1479533612728119, 0.06928082555532455, 0.16623468697071075, 0.13697916269302368, 0.257636159658432, 0.19957824051380157, 0.01298827026039362], [0.019830351695418358, 0.135671004652977, 0.09377221763134003, 0.21752962470054626, 0.1280042827129364, 0.18139903247356415, 0.1946789175271988, 0.0291146207600832], [0.034694720059633255, 0.13839322328567505, 0.10725095123052597, 0.26848241686820984, 0.0982103943824768, 0.14586852490901947, 0.16445577144622803, 0.042643990367650986]], [[0.10876116901636124, 0.3508974015712738, 0.14925111830234528, 0.04847785457968712, 0.04998702183365822, 0.08778753131628036, 0.11587844789028168, 0.0889594703912735], [0.14764545857906342, 0.2631308138370514, 0.11920288950204849, 0.07153124362230301, 0.05696236342191696, 0.10967010259628296, 0.10661245137453079, 0.1252446174621582], [0.14416739344596863, 0.2504686415195465, 0.1555507481098175, 0.06125583127140999, 0.05905859172344208, 0.09872161597013474, 0.11441957205533981, 0.11635755747556686], [0.10087605565786362, 0.2886306345462799, 0.14108052849769592, 0.11357688903808594, 0.06580965965986252, 0.11015526950359344, 0.10419429838657379, 0.07567667216062546], [0.09397110342979431, 0.21449637413024902, 0.10778644680976868, 0.0626814216375351, 0.11496585607528687, 0.18333886563777924, 0.11934437602758408, 0.1034155786037445], [0.1015104129910469, 0.21259059011936188, 0.10175509750843048, 0.06590358912944794, 0.11221754550933838, 0.16821934282779694, 0.1265418380498886, 0.11126153916120529], [0.13139598071575165, 0.2146017849445343, 0.1054026260972023, 0.05083521455526352, 0.07634809613227844, 0.15145255625247955, 0.12842608988285065, 0.14153766632080078], [0.11985461413860321, 0.3239474296569824, 0.12808556854724884, 0.04859394580125809, 0.04854604974389076, 0.09668254107236862, 0.11796724796295166, 0.1163226068019867]], [[0.05714668333530426, 0.11879236251115799, 0.07482501119375229, 0.4969445466995239, 0.07367319613695145, 0.07363204658031464, 0.0634431540966034, 0.041542988270521164], [0.04508474841713905, 0.0852588564157486, 0.06332319229841232, 0.572177529335022, 0.06994706392288208, 0.07355602085590363, 0.05993327125906944, 0.03071925789117813], [0.04677018150687218, 0.08160492777824402, 0.05975799635052681, 0.5867187976837158, 0.06617673486471176, 0.07206274569034576, 0.05389920249581337, 0.0330093689262867], [0.06285970658063889, 0.13497290015220642, 0.09076055139303207, 0.3955126404762268, 0.10346294194459915, 0.08124924451112747, 0.08360415697097778, 0.0475778691470623], [0.03888898715376854, 0.0808725357055664, 0.05912565812468529, 0.5895435214042664, 0.07199631631374359, 0.07739022374153137, 0.055209361016750336, 0.026973377913236618], [0.03541518375277519, 0.08351625502109528, 0.0586438924074173, 0.586990237236023, 0.071787528693676, 0.08404096961021423, 0.0561375617980957, 0.023468444123864174], [0.03976915031671524, 0.08237343281507492, 0.05735073238611221, 0.6044779419898987, 0.06148610636591911, 0.07456286251544952, 0.05263235419988632, 0.02734750136733055], [0.04945666715502739, 0.10245927423238754, 0.06171282008290291, 0.5654742121696472, 0.0666460171341896, 0.0647834837436676, 0.05088219419121742, 0.0385853573679924]], [[0.10814550518989563, 0.10348573327064514, 0.0874449834227562, 0.28174248337745667, 0.12852142751216888, 0.16021117568016052, 0.08251026272773743, 0.04793844372034073], [0.11748369038105011, 0.11572835594415665, 0.09577750414609909, 0.2633477449417114, 0.12465527653694153, 0.14359046518802643, 0.08367659896612167, 0.0557403564453125], [0.08635684102773666, 0.07751479744911194, 0.08927229791879654, 0.34118449687957764, 0.13604077696800232, 0.1472228318452835, 0.08418352901935577, 0.038224346935749054], [0.08849244564771652, 0.11747375875711441, 0.10138596594333649, 0.2671962380409241, 0.12490953505039215, 0.15195637941360474, 0.10456594824790955, 0.04401973634958267], [0.09310343116521835, 0.06936004757881165, 0.08310133218765259, 0.2710627317428589, 0.12196628004312515, 0.20338697731494904, 0.1070621982216835, 0.05095698684453964], [0.08756713569164276, 0.06558839231729507, 0.07012858241796494, 0.31773361563682556, 0.11335696280002594, 0.1990598738193512, 0.097493976354599, 0.04907144606113434], [0.09707747399806976, 0.07733990252017975, 0.07375265657901764, 0.3246960937976837, 0.12402964383363724, 0.17424027621746063, 0.08446396887302399, 0.04439994692802429], [0.1192106083035469, 0.1083100438117981, 0.08138519525527954, 0.29442527890205383, 0.10737982392311096, 0.15239524841308594, 0.08020796626806259, 0.0566859245300293]], [[0.031005986034870148, 0.4225994646549225, 0.1640343964099884, 0.28620344400405884, 0.007685725577175617, 0.00933805014938116, 0.05982373654842377, 0.019309239462018013], [0.02888953685760498, 0.35727477073669434, 0.11913508921861649, 0.3553890883922577, 0.016070956364274025, 0.023668935522437096, 0.07305245101451874, 0.026519140228629112], [0.032170671969652176, 0.32496047019958496, 0.18767663836479187, 0.33552244305610657, 0.012448729947209358, 0.014161476865410805, 0.06997861713171005, 0.023080887272953987], [0.02227817289531231, 0.3033653497695923, 0.13379503786563873, 0.4085903763771057, 0.01953786425292492, 0.018549472093582153, 0.07549160718917847, 0.018392177298665047], [0.02186499536037445, 0.35430923104286194, 0.11478770524263382, 0.3461724817752838, 0.0332551933825016, 0.02444607764482498, 0.08360900729894638, 0.02155538648366928], [0.020798668265342712, 0.3539201319217682, 0.0991702675819397, 0.35631856322288513, 0.024232374504208565, 0.03790852054953575, 0.08480978012084961, 0.02284156158566475], [0.031542614102363586, 0.3228851854801178, 0.12180335819721222, 0.3268889784812927, 0.02033403143286705, 0.029941486194729805, 0.10968828201293945, 0.03691612929105759], [0.033930689096450806, 0.3947891592979431, 0.14219893515110016, 0.29746896028518677, 0.010077862069010735, 0.014836267568171024, 0.0774361863732338, 0.029261913150548935]], [[0.032306451350450516, 0.20464761555194855, 0.08478016406297684, 0.10361956059932709, 0.18009746074676514, 0.1956920474767685, 0.14881348609924316, 0.05004327371716499], [0.025505444034934044, 0.2311238944530487, 0.06841669976711273, 0.06498654931783676, 0.14598475396633148, 0.24301192164421082, 0.17600224912166595, 0.04496859014034271], [0.03382550925016403, 0.23373129963874817, 0.12004819512367249, 0.08636429905891418, 0.14375701546669006, 0.16812363266944885, 0.17024216055870056, 0.043907828629016876], [0.026529861614108086, 0.20799219608306885, 0.10471194237470627, 0.1561383754014969, 0.13295628130435944, 0.13776902854442596, 0.18293575942516327, 0.050966545939445496], [0.015414432622492313, 0.1914796680212021, 0.05279803276062012, 0.088340625166893, 0.22836577892303467, 0.24547220766544342, 0.14861121773719788, 0.029517997056245804], [0.012183740735054016, 0.185941681265831, 0.04148538038134575, 0.07732777297496796, 0.16474345326423645, 0.3319142162799835, 0.15759144723415375, 0.028812328353524208], [0.025147734209895134, 0.1847483217716217, 0.05978511646389961, 0.07058598101139069, 0.17261090874671936, 0.2510823607444763, 0.18584704399108887, 0.05019257962703705], [0.027082577347755432, 0.16588644683361053, 0.06008356064558029, 0.10412980616092682, 0.19370682537555695, 0.22964008152484894, 0.1599176675081253, 0.0595531091094017]], [[0.06739259511232376, 0.06330467760562897, 0.05532163381576538, 0.3030819892883301, 0.13710425794124603, 0.22944389283657074, 0.07005001604557037, 0.07430095225572586], [0.06254876405000687, 0.07368268072605133, 0.0652068704366684, 0.2759099304676056, 0.13352620601654053, 0.23855435848236084, 0.0842118188738823, 0.06635940074920654], [0.056920863687992096, 0.06059170886874199, 0.05996338650584221, 0.35954442620277405, 0.11852873116731644, 0.21859921514987946, 0.0712510272860527, 0.0546005517244339], [0.051544301211833954, 0.08504311740398407, 0.07756883651018143, 0.3100140392780304, 0.11659946292638779, 0.2081439346075058, 0.09348370134830475, 0.057602524757385254], [0.046376168727874756, 0.043447546660900116, 0.04968918114900589, 0.3315899968147278, 0.13683873414993286, 0.273655503988266, 0.0724235326051712, 0.04597936570644379], [0.04561315104365349, 0.04728630185127258, 0.05192489176988602, 0.3031880855560303, 0.15244147181510925, 0.2817031443119049, 0.07493411004543304, 0.042908925563097], [0.047353629022836685, 0.056299228221178055, 0.05491316318511963, 0.34497949481010437, 0.12501220405101776, 0.24716641008853912, 0.07791925221681595, 0.046356622129678726], [0.06550955772399902, 0.060707882046699524, 0.05576092749834061, 0.2663382887840271, 0.1406879872083664, 0.25879967212677, 0.07668536901473999, 0.07551024854183197]], [[0.18791192770004272, 0.112158864736557, 0.08652457594871521, 0.12724556028842926, 0.10612893104553223, 0.07287946343421936, 0.08942244946956635, 0.21772827208042145], [0.18278783559799194, 0.10008221119642258, 0.09350220859050751, 0.18150389194488525, 0.09463697671890259, 0.0698758065700531, 0.07643935829401016, 0.20117172598838806], [0.1801522672176361, 0.10464107245206833, 0.10163824260234833, 0.15557748079299927, 0.09127798676490784, 0.08142044395208359, 0.08996018767356873, 0.195332333445549], [0.16419267654418945, 0.08919641375541687, 0.09658674150705338, 0.1537119746208191, 0.1404758244752884, 0.08302141726016998, 0.08987192809581757, 0.18294310569763184], [0.16421014070510864, 0.0786062628030777, 0.09706971049308777, 0.14673399925231934, 0.14087863266468048, 0.09767595678567886, 0.10856389254331589, 0.16626140475273132], [0.17606474459171295, 0.07169995456933975, 0.08287202566862106, 0.14610524475574493, 0.12857170403003693, 0.10516500473022461, 0.098016656935215, 0.1915045827627182], [0.17871171236038208, 0.08481885492801666, 0.09178272634744644, 0.1373990923166275, 0.11462898552417755, 0.10145603120326996, 0.09705958515405655, 0.19414302706718445], [0.17991682887077332, 0.1021185964345932, 0.08690938353538513, 0.12555772066116333, 0.10813439637422562, 0.07802413403987885, 0.09442495554685593, 0.22491393983364105]]], [[[0.14765127003192902, 0.1729981154203415, 0.13893473148345947, 0.07806555926799774, 0.07079720497131348, 0.08519481122493744, 0.14515729248523712, 0.1612011194229126], [0.13470599055290222, 0.2010210007429123, 0.14525362849235535, 0.08302074670791626, 0.062176190316677094, 0.07277113199234009, 0.1459241360425949, 0.15512718260288239], [0.13484130799770355, 0.18138380348682404, 0.15533025562763214, 0.07451312988996506, 0.06656529754400253, 0.07506826519966125, 0.1560770869255066, 0.15622082352638245], [0.13506442308425903, 0.17263473570346832, 0.12682375311851501, 0.12016943097114563, 0.07423555850982666, 0.08486735820770264, 0.13709598779678345, 0.14910879731178284], [0.12977758049964905, 0.1454659402370453, 0.13436807692050934, 0.0921262875199318, 0.09491653740406036, 0.10045475512742996, 0.1549641340970993, 0.14792665839195251], [0.12616556882858276, 0.14981791377067566, 0.1319536417722702, 0.08880523592233658, 0.08406154066324234, 0.11033991724252701, 0.16106517612934113, 0.14779099822044373], [0.13075444102287292, 0.16783343255519867, 0.14415033161640167, 0.07662850618362427, 0.07378444075584412, 0.08922011405229568, 0.16740459203720093, 0.1502242088317871], [0.13550542294979095, 0.1866665631532669, 0.139237642288208, 0.08414933830499649, 0.06879127770662308, 0.08468161523342133, 0.14739994704723358, 0.15356816351413727]], [[0.1557617038488388, 0.083870068192482, 0.08498059958219528, 0.2702607810497284, 0.13593178987503052, 0.08102022111415863, 0.07277385145425797, 0.11540097743272781], [0.14998874068260193, 0.0796135887503624, 0.08484280109405518, 0.2871536910533905, 0.12677893042564392, 0.07764387875795364, 0.0739360824227333, 0.12004223465919495], [0.15831394493579865, 0.07826350629329681, 0.08788017928600311, 0.26847565174102783, 0.13417628407478333, 0.07760452479124069, 0.07349403202533722, 0.12179183959960938], [0.13856229186058044, 0.09032708406448364, 0.09971882402896881, 0.2148166000843048, 0.1654496043920517, 0.0957690104842186, 0.0887000635266304, 0.10665655136108398], [0.15241651237010956, 0.07667983323335648, 0.0884632095694542, 0.2826920747756958, 0.13248269259929657, 0.07240651547908783, 0.07483518123626709, 0.12002391368150711], [0.14641664922237396, 0.08139602839946747, 0.08652271330356598, 0.2834565341472626, 0.13357779383659363, 0.07411199808120728, 0.0767693743109703, 0.11774890124797821], [0.15248261392116547, 0.07739678025245667, 0.087284155189991, 0.2639102339744568, 0.13749657571315765, 0.07696948945522308, 0.07867911458015442, 0.1257810890674591], [0.1528920978307724, 0.08457671105861664, 0.08543576300144196, 0.27141907811164856, 0.13388508558273315, 0.0817452147603035, 0.07445129752159119, 0.11559474468231201]], [[0.11691349744796753, 0.16365483403205872, 0.11116020381450653, 0.16807526350021362, 0.11237173527479172, 0.11684827506542206, 0.11298152804374695, 0.09799470007419586], [0.11362285912036896, 0.15767569839954376, 0.11157677322626114, 0.17179961502552032, 0.11792952567338943, 0.11938019841909409, 0.1160908043384552, 0.09192459285259247], [0.10674459487199783, 0.15651679039001465, 0.11046042293310165, 0.17837488651275635, 0.1120700016617775, 0.1207624301314354, 0.11929401755332947, 0.09577679634094238], [0.11044818162918091, 0.16395385563373566, 0.11851874738931656, 0.1630069762468338, 0.1122123971581459, 0.11277309060096741, 0.11636973917484283, 0.10271704196929932], [0.09539520740509033, 0.1504540741443634, 0.11270425468683243, 0.15871822834014893, 0.12590472400188446, 0.14376108348369598, 0.12859274446964264, 0.0844697430729866], [0.097108855843544, 0.13671638071537018, 0.11291517317295074, 0.17163126170635223, 0.12264145165681839, 0.14649099111557007, 0.12740293145179749, 0.08509290218353271], [0.10345329344272614, 0.14580582082271576, 0.11207176744937897, 0.17115706205368042, 0.11617127060890198, 0.135049968957901, 0.12522627413272858, 0.09106453508138657], [0.1125655472278595, 0.16185475885868073, 0.11331045627593994, 0.17565438151359558, 0.11084169149398804, 0.12148828059434891, 0.11208757013082504, 0.0921972468495369]], [[0.11627086997032166, 0.10357195883989334, 0.1182553693652153, 0.206752210855484, 0.10307998955249786, 0.11074919998645782, 0.12573902308940887, 0.11558143049478531], [0.12180547416210175, 0.08701153844594955, 0.11238481104373932, 0.2009260654449463, 0.11631966382265091, 0.12082874774932861, 0.11539139598608017, 0.125332310795784], [0.11253435909748077, 0.09565272182226181, 0.12181741744279861, 0.20864225924015045, 0.10816159099340439, 0.11397549510002136, 0.12404417991638184, 0.11517201364040375], [0.10274505615234375, 0.09899266809225082, 0.12270420789718628, 0.21690164506435394, 0.1157941073179245, 0.12339179962873459, 0.1229722648859024, 0.09649823606014252], [0.11223602294921875, 0.09438890218734741, 0.11591484397649765, 0.22334915399551392, 0.10786189138889313, 0.11935997009277344, 0.1248529925942421, 0.10203619301319122], [0.11595120280981064, 0.08857125043869019, 0.10763679444789886, 0.19553126394748688, 0.12332005053758621, 0.12697522342205048, 0.12494106590747833, 0.1170731633901596], [0.11747501790523529, 0.0861140638589859, 0.10856019705533981, 0.19598692655563354, 0.11603689193725586, 0.12285798043012619, 0.12883150577545166, 0.12413744628429413], [0.12262382358312607, 0.09617375582456589, 0.10839995741844177, 0.2089957594871521, 0.10985374450683594, 0.11670757085084915, 0.11751259118318558, 0.1197327971458435]], [[0.11697527021169662, 0.08940301835536957, 0.08612596243619919, 0.21301257610321045, 0.15440116822719574, 0.15288226306438446, 0.08109777420759201, 0.10610204190015793], [0.12081660330295563, 0.09125962853431702, 0.08904637396335602, 0.19802606105804443, 0.15647797286510468, 0.15251615643501282, 0.08681043982505798, 0.10504677891731262], [0.11367350816726685, 0.09076845645904541, 0.08639290183782578, 0.2087131291627884, 0.15897388756275177, 0.15960457921028137, 0.08225219696760178, 0.09962138533592224], [0.10917121917009354, 0.10732153803110123, 0.10540172457695007, 0.15464021265506744, 0.1668548732995987, 0.1587863266468048, 0.10179825127124786, 0.09602584689855576], [0.11103951185941696, 0.09637224674224854, 0.09065832197666168, 0.22943414747714996, 0.14077822864055634, 0.1439405232667923, 0.08873523026704788, 0.09904176741838455], [0.11236842721700668, 0.09629523009061813, 0.09568101167678833, 0.21399171650409698, 0.14531230926513672, 0.1450766623020172, 0.09387248009443283, 0.0974021777510643], [0.11280852556228638, 0.08825770765542984, 0.08257374167442322, 0.20353519916534424, 0.15803056955337524, 0.16455520689487457, 0.08596391975879669, 0.10427512228488922], [0.12078502774238586, 0.09641139209270477, 0.0840679332613945, 0.21758010983467102, 0.14506971836090088, 0.15058007836341858, 0.07873664796352386, 0.1067691370844841]], [[0.17151270806789398, 0.11048643290996552, 0.11168738454580307, 0.16302883625030518, 0.08641646057367325, 0.11478372663259506, 0.09505670517683029, 0.14702776074409485], [0.1755535900592804, 0.10155036300420761, 0.1110457107424736, 0.15398269891738892, 0.08453918248414993, 0.11578509211540222, 0.0985700786113739, 0.1589733362197876], [0.16280889511108398, 0.10170624405145645, 0.11446242779493332, 0.16719108819961548, 0.09223431348800659, 0.12067827582359314, 0.09848229587078094, 0.1424364447593689], [0.172735333442688, 0.11083744466304779, 0.12401722371578217, 0.1258680671453476, 0.07859200239181519, 0.12157180905342102, 0.11478223651647568, 0.1515958309173584], [0.1509542018175125, 0.10348309576511383, 0.11815870553255081, 0.16197986900806427, 0.09267054498195648, 0.13231608271598816, 0.10829492658376694, 0.13214269280433655], [0.1511511504650116, 0.10233662277460098, 0.11662408709526062, 0.16411422193050385, 0.09187204390764236, 0.13302189111709595, 0.10783404111862183, 0.133045956492424], [0.15723060071468353, 0.09931698441505432, 0.11113601177930832, 0.16573667526245117, 0.09389142692089081, 0.12970298528671265, 0.10150204598903656, 0.14148329198360443], [0.17114651203155518, 0.11324353516101837, 0.11165452003479004, 0.16751618683338165, 0.08163876086473465, 0.11461744457483292, 0.09271079301834106, 0.1474723070859909]], [[0.09050595760345459, 0.13387101888656616, 0.10752575099468231, 0.18480299413204193, 0.13159513473510742, 0.13009482622146606, 0.12473548948764801, 0.09686876833438873], [0.09941509366035461, 0.12671181559562683, 0.11319639533758163, 0.160554900765419, 0.1364489644765854, 0.13400593400001526, 0.1226431205868721, 0.10702382773160934], [0.09312327206134796, 0.13461065292358398, 0.11592744290828705, 0.17694547772407532, 0.13161274790763855, 0.127400204539299, 0.1268741637468338, 0.09350604563951492], [0.10596457868814468, 0.11397244781255722, 0.12300296127796173, 0.16103780269622803, 0.14059387147426605, 0.133737251162529, 0.12223518639802933, 0.09945592284202576], [0.08117131888866425, 0.10622382164001465, 0.10210729390382767, 0.1929839551448822, 0.1557159572839737, 0.14592714607715607, 0.12549489736557007, 0.0903756394982338], [0.08096471428871155, 0.09916216135025024, 0.09373418241739273, 0.18391944468021393, 0.16924037039279938, 0.15270628035068512, 0.12715604901313782, 0.09311670809984207], [0.08483024686574936, 0.10703414678573608, 0.09551151096820831, 0.17638590931892395, 0.1569787710905075, 0.16000047326087952, 0.12660259008407593, 0.09265635162591934], [0.08514091372489929, 0.12451668828725815, 0.10576102882623672, 0.19515615701675415, 0.13787759840488434, 0.13299794495105743, 0.12540026009082794, 0.0931493416428566]], [[0.1331709325313568, 0.10455644875764847, 0.09671011567115784, 0.26411235332489014, 0.12175469845533371, 0.08878215402364731, 0.0895441323518753, 0.10136909037828445], [0.13089142739772797, 0.11055076122283936, 0.10234378278255463, 0.2404269576072693, 0.12778514623641968, 0.0895819291472435, 0.09647300839424133, 0.10194697976112366], [0.14115475118160248, 0.10570980608463287, 0.10506192594766617, 0.23304902017116547, 0.12475282698869705, 0.0909273624420166, 0.09245972335338593, 0.10688455402851105], [0.11085078120231628, 0.11886981874704361, 0.11671572923660278, 0.2553308308124542, 0.12028267234563828, 0.09361934661865234, 0.1019868329167366, 0.08234413713216782], [0.10997549444437027, 0.10372541844844818, 0.10200779885053635, 0.28379738330841064, 0.1394905298948288, 0.09440754354000092, 0.09076369553804398, 0.07583216577768326], [0.10782335698604584, 0.1057082861661911, 0.09833820909261703, 0.2861342430114746, 0.13197515904903412, 0.09753220528364182, 0.09523911029100418, 0.07724940031766891], [0.1270771324634552, 0.10525607317686081, 0.1023826003074646, 0.23889397084712982, 0.13269072771072388, 0.09301026165485382, 0.09975146502256393, 0.10093773156404495], [0.1321869194507599, 0.10776427388191223, 0.09572823345661163, 0.2628342807292938, 0.11886779963970184, 0.08788324147462845, 0.09120187908411026, 0.10353339463472366]], [[0.152226984500885, 0.07659852504730225, 0.09634356200695038, 0.2114056795835495, 0.09854159504175186, 0.13447515666484833, 0.10894480347633362, 0.12146361917257309], [0.15416023135185242, 0.08190521597862244, 0.10444319248199463, 0.20595131814479828, 0.09643083065748215, 0.12574930489063263, 0.11050862818956375, 0.12085141986608505], [0.15170630812644958, 0.07852079719305038, 0.10612496733665466, 0.2048519104719162, 0.09572210907936096, 0.12971673905849457, 0.11342332512140274, 0.1199338436126709], [0.13963855803012848, 0.08896750956773758, 0.10815007984638214, 0.1991361379623413, 0.10748953372240067, 0.13742735981941223, 0.11452293395996094, 0.10466798394918442], [0.1452454924583435, 0.07477346062660217, 0.10069269686937332, 0.20066867768764496, 0.10519175976514816, 0.14460879564285278, 0.11581192910671234, 0.11300715804100037], [0.14257419109344482, 0.07494168728590012, 0.09801621735095978, 0.20824797451496124, 0.10521818697452545, 0.14407381415367126, 0.11434251815080643, 0.11258550733327866], [0.14902019500732422, 0.0762874186038971, 0.10009914636611938, 0.19655247032642365, 0.09961709380149841, 0.14076852798461914, 0.1174912303686142, 0.12016390264034271], [0.15190164744853973, 0.07845546305179596, 0.09388219565153122, 0.20720964670181274, 0.09878873825073242, 0.13749246299266815, 0.10889127850532532, 0.12337865680456161]], [[0.09174534678459167, 0.11871457099914551, 0.14215226471424103, 0.1773129403591156, 0.1700657457113266, 0.08835586905479431, 0.12692126631736755, 0.0847320482134819], [0.06379564106464386, 0.13198667764663696, 0.12841293215751648, 0.1878277063369751, 0.17367660999298096, 0.10496105253696442, 0.1461603194475174, 0.06317910552024841], [0.07476479560136795, 0.1214110478758812, 0.15235982835292816, 0.1689281314611435, 0.17754754424095154, 0.09173456579446793, 0.14355453848838806, 0.06969954818487167], [0.057910822331905365, 0.13472670316696167, 0.12769097089767456, 0.2279202938079834, 0.1757369190454483, 0.09432312101125717, 0.12823331356048584, 0.05345791578292847], [0.05671658739447594, 0.12742866575717926, 0.11689111590385437, 0.18646812438964844, 0.20615093410015106, 0.10481779277324677, 0.1444731503725052, 0.05705365166068077], [0.05754055827856064, 0.1310359388589859, 0.11359166353940964, 0.18121084570884705, 0.1827259212732315, 0.1208142563700676, 0.15319231152534485, 0.059888485819101334], [0.06919889152050018, 0.12134845554828644, 0.12445991486310959, 0.16041681170463562, 0.18723279237747192, 0.10448132455348969, 0.15975631773471832, 0.07310545444488525], [0.08498194813728333, 0.12134964764118195, 0.12802809476852417, 0.17859795689582825, 0.1732262223958969, 0.09180086851119995, 0.1352369636297226, 0.08677823841571808]], [[0.11593789607286453, 0.13809257745742798, 0.17485184967517853, 0.1688036322593689, 0.09005867689847946, 0.0889289528131485, 0.11224712431430817, 0.11107926070690155], [0.08674240112304688, 0.15728136897087097, 0.15060265362262726, 0.17329993844032288, 0.10039263218641281, 0.11159761995077133, 0.12350882589817047, 0.09657446295022964], [0.1049908921122551, 0.13837021589279175, 0.1945771872997284, 0.16268715262413025, 0.08812809735536575, 0.08851692080497742, 0.119816355407238, 0.10291309654712677], [0.06697086244821548, 0.149217888712883, 0.1505841612815857, 0.21639688313007355, 0.11223457753658295, 0.10740263015031815, 0.11999907344579697, 0.07719386368989944], [0.0734594464302063, 0.14354896545410156, 0.14134356379508972, 0.1739949733018875, 0.1338171660900116, 0.11677058041095734, 0.13373978435993195, 0.08332556486129761], [0.06900294870138168, 0.14758533239364624, 0.13705842196941376, 0.1708582490682602, 0.1191447526216507, 0.12978310883045197, 0.1416921466588974, 0.08487504720687866], [0.0887460857629776, 0.14014965295791626, 0.151304692029953, 0.16453032195568085, 0.10384967178106308, 0.10683216154575348, 0.13898241519927979, 0.10560494661331177], [0.10747011005878448, 0.1393033266067505, 0.15094642341136932, 0.177481546998024, 0.09255629032850266, 0.09273391216993332, 0.1174754649400711, 0.12203289568424225]], [[0.09562269598245621, 0.17284660041332245, 0.12809942662715912, 0.1952120065689087, 0.09678730368614197, 0.10633417218923569, 0.1198219507932663, 0.08527582883834839], [0.07421379536390305, 0.1846453994512558, 0.12866580486297607, 0.17844948172569275, 0.10377208888530731, 0.11138154566287994, 0.14070352911949158, 0.07816838473081589], [0.08719205856323242, 0.16768303513526917, 0.1512463539838791, 0.1614820957183838, 0.0998566523194313, 0.10761784762144089, 0.14064791798591614, 0.08427412062883377], [0.059632692486047745, 0.14939121901988983, 0.10776282846927643, 0.2682371437549591, 0.11982548981904984, 0.11580368131399155, 0.11993393301963806, 0.059413064271211624], [0.06225200742483139, 0.13784320652484894, 0.10019470006227493, 0.21010056138038635, 0.15825916826725006, 0.1424935907125473, 0.12609076499938965, 0.06276597827672958], [0.06285886466503143, 0.16152773797512054, 0.10631170868873596, 0.17590729892253876, 0.12539246678352356, 0.16059942543506622, 0.14309871196746826, 0.06430386751890182], [0.07738108932971954, 0.16198302805423737, 0.1262775957584381, 0.16197876632213593, 0.10978410392999649, 0.12143239378929138, 0.15577465295791626, 0.08538837730884552], [0.09195058047771454, 0.17314037680625916, 0.12201124429702759, 0.19762559235095978, 0.09518565237522125, 0.10268326103687286, 0.12476425617933273, 0.09263911098241806]]]], \"left_text\": [\"[CLS]\", \"transfer\", \"learning\", \"bert\", \"self\", \"supervised\", \"learning\", \"[SEP]\"], \"right_text\": [\"[CLS]\", \"transfer\", \"learning\", \"bert\", \"self\", \"supervised\", \"learning\", \"[SEP]\"]}}, \"default_filter\": \"all\", \"root_div_id\": \"bertviz-a492ca45f33b492b8b9f5bdbcc1f9407\", \"layer\": null, \"heads\": null} is a template marker that is replaced by actual params.\n",
              "    const TEXT_SIZE = 15;\n",
              "    const BOXWIDTH = 110;\n",
              "    const BOXHEIGHT = 22.5;\n",
              "    const MATRIX_WIDTH = 115;\n",
              "    const CHECKBOX_SIZE = 20;\n",
              "    const TEXT_TOP = 30;\n",
              "\n",
              "    // var headColors;\n",
              "    console.log(\"d3 version\", d3.version)\n",
              "    let headColors;\n",
              "    try {\n",
              "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
              "    } catch (err) {\n",
              "        console.log('Older d3 version')\n",
              "        headColors = d3.scale.category10();\n",
              "    }\n",
              "    // let params = window.params;\n",
              "    let config = {};\n",
              "    initialize();\n",
              "    renderVis();\n",
              "\n",
              "    function initialize() {\n",
              "        config.attention = params['attention'];\n",
              "        config.filter = params['default_filter'];\n",
              "        config.rootDivId = params['root_div_id'];\n",
              "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
              "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
              "        if (params['heads']) {\n",
              "            config.headVis = new Array(config.nHeads).fill(false);\n",
              "            params['heads'].forEach(x => config.headVis[x] = true);\n",
              "        } else {\n",
              "            config.headVis = new Array(config.nHeads).fill(true);\n",
              "        }\n",
              "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
              "        config.layer = (params['layer'] == null ? 0 : params['layer'])\n",
              "\n",
              "\n",
              "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
              "        for (var i = 0; i < config.nLayers; i++) {\n",
              "            layerEl.append($(\"<option />\").val(i).text(i));\n",
              "        }\n",
              "        layerEl.val(config.layer).change();\n",
              "        layerEl.on('change', function (e) {\n",
              "            config.layer = +e.currentTarget.value;\n",
              "            renderVis();\n",
              "        });\n",
              "\n",
              "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
              "            config.filter = e.currentTarget.value;\n",
              "            renderVis();\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderVis() {\n",
              "\n",
              "        // Load parameters\n",
              "        const attnData = config.attention[config.filter];\n",
              "        const leftText = attnData.left_text;\n",
              "        const rightText = attnData.right_text;\n",
              "\n",
              "        // Select attention for given layer\n",
              "        const layerAttention = attnData.attn[config.layer];\n",
              "\n",
              "        // Clear vis\n",
              "        $(`#${config.rootDivId} #vis`).empty();\n",
              "\n",
              "        // Determine size of visualization\n",
              "        const height = config.initialTextLength * BOXHEIGHT + TEXT_TOP;\n",
              "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
              "            .append('svg')\n",
              "            .attr(\"width\", \"100%\")\n",
              "            .attr(\"height\", height + \"px\");\n",
              "\n",
              "        // Display tokens on left and right side of visualization\n",
              "        renderText(svg, leftText, true, layerAttention, 0);\n",
              "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
              "\n",
              "        // Render attention arcs\n",
              "        renderAttention(svg, layerAttention);\n",
              "\n",
              "        // Draw squares at top of visualization, one for each head\n",
              "        drawCheckboxes(0, svg, layerAttention);\n",
              "    }\n",
              "\n",
              "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
              "\n",
              "        const textContainer = svg.append(\"svg:g\")\n",
              "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
              "\n",
              "        // Add attention highlights superimposed over words\n",
              "        textContainer.append(\"g\")\n",
              "            .classed(\"attentionBoxes\", true)\n",
              "            .selectAll(\"g\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\"rect\")\n",
              "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"x\", function () {\n",
              "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                return leftPos + boxOffsets(headIndex);\n",
              "            })\n",
              "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "            .attr(\"height\", BOXHEIGHT)\n",
              "            .attr(\"fill\", function () {\n",
              "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
              "            })\n",
              "            .style(\"opacity\", 0.0);\n",
              "\n",
              "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
              "            .data(text)\n",
              "            .enter()\n",
              "            .append(\"g\");\n",
              "\n",
              "        // Add gray background that appears when hovering over text\n",
              "        tokenContainer.append(\"rect\")\n",
              "            .classed(\"background\", true)\n",
              "            .style(\"opacity\", 0.0)\n",
              "            .attr(\"fill\", \"lightgray\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH)\n",
              "            .attr(\"height\", BOXHEIGHT);\n",
              "\n",
              "        // Add token text\n",
              "        const textEl = tokenContainer.append(\"text\")\n",
              "            .text(d => d)\n",
              "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "            .style(\"cursor\", \"default\")\n",
              "            .style(\"-webkit-user-select\", \"none\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
              "\n",
              "        if (isLeft) {\n",
              "            textEl.style(\"text-anchor\", \"end\")\n",
              "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        } else {\n",
              "            textEl.style(\"text-anchor\", \"start\")\n",
              "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        }\n",
              "\n",
              "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
              "\n",
              "            // Show gray background for moused-over token\n",
              "            textContainer.selectAll(\".background\")\n",
              "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
              "\n",
              "            // Reset visibility attribute for any previously highlighted attention arcs\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null)\n",
              "\n",
              "            // Hide group containing attention arcs\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
              "\n",
              "            // Set to visible appropriate attention arcs to be highlighted\n",
              "            if (isLeft) {\n",
              "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            } else {\n",
              "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            }\n",
              "\n",
              "            // Update color boxes superimposed over tokens\n",
              "            const id = isLeft ? \"right\" : \"left\";\n",
              "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
              "            svg.select(\"#\" + id)\n",
              "                .selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .attr(\"head-index\", (d, i) => i)\n",
              "                .selectAll(\"rect\")\n",
              "                .attr(\"x\", function () {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    return leftPos + boxOffsets(headIndex);\n",
              "                })\n",
              "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "                .attr(\"height\", BOXHEIGHT)\n",
              "                .style(\"opacity\", function (d) {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    if (config.headVis[headIndex])\n",
              "                        if (d) {\n",
              "                            return d[index];\n",
              "                        } else {\n",
              "                            return 0.0;\n",
              "                        }\n",
              "                    else\n",
              "                        return 0.0;\n",
              "                });\n",
              "        });\n",
              "\n",
              "        textContainer.on(\"mouseleave\", function () {\n",
              "\n",
              "            // Unhighlight selected token\n",
              "            d3.select(this).selectAll(\".background\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "\n",
              "            // Reset visibility attributes for previously selected lines\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null) ;\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
              "\n",
              "            // Reset highlights superimposed over tokens\n",
              "            svg.selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .selectAll(\"rect\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderAttention(svg, attention) {\n",
              "\n",
              "        // Remove previous dom elements\n",
              "        svg.select(\"#attention\").remove();\n",
              "\n",
              "        // Add new elements\n",
              "        svg.append(\"g\")\n",
              "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
              "            .selectAll(\".headAttention\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\".tokenAttention\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
              "            .attr(\"left-token-index\", (d, i) => i)\n",
              "            .selectAll(\"line\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"line\")\n",
              "            .attr(\"x1\", BOXWIDTH)\n",
              "            .attr(\"y1\", function () {\n",
              "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
              "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
              "            })\n",
              "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
              "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
              "            .attr(\"stroke-width\", 2)\n",
              "            .attr(\"stroke\", function () {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                return headColors(headIndex)\n",
              "            })\n",
              "            .attr(\"left-token-index\", function () {\n",
              "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
              "            })\n",
              "            .attr(\"right-token-index\", (d, i) => i)\n",
              "        ;\n",
              "        updateAttention(svg)\n",
              "    }\n",
              "\n",
              "    function updateAttention(svg) {\n",
              "        svg.select(\"#attention\")\n",
              "            .selectAll(\"line\")\n",
              "            .attr(\"stroke-opacity\", function (d) {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                // If head is selected\n",
              "                if (config.headVis[headIndex]) {\n",
              "                    // Set opacity to attention weight divided by number of active heads\n",
              "                    return d / activeHeads()\n",
              "                } else {\n",
              "                    return 0.0;\n",
              "                }\n",
              "            })\n",
              "    }\n",
              "\n",
              "    function boxOffsets(i) {\n",
              "        const numHeadsAbove = config.headVis.reduce(\n",
              "            function (acc, val, cur) {\n",
              "                return val && cur < i ? acc + 1 : acc;\n",
              "            }, 0);\n",
              "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
              "    }\n",
              "\n",
              "    function activeHeads() {\n",
              "        return config.headVis.reduce(function (acc, val) {\n",
              "            return val ? acc + 1 : acc;\n",
              "        }, 0);\n",
              "    }\n",
              "\n",
              "    function drawCheckboxes(top, svg) {\n",
              "        const checkboxContainer = svg.append(\"g\");\n",
              "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
              "            .data(config.headVis)\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"fill\", (d, i) => headColors(i))\n",
              "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
              "            .attr(\"y\", top)\n",
              "            .attr(\"width\", CHECKBOX_SIZE)\n",
              "            .attr(\"height\", CHECKBOX_SIZE);\n",
              "\n",
              "        function updateCheckboxes() {\n",
              "            checkboxContainer.selectAll(\"rect\")\n",
              "                .data(config.headVis)\n",
              "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
              "        }\n",
              "\n",
              "        updateCheckboxes();\n",
              "\n",
              "        checkbox.on(\"click\", function (d, i) {\n",
              "            if (config.headVis[i] && activeHeads() === 1) return;\n",
              "            config.headVis[i] = !config.headVis[i];\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "\n",
              "        checkbox.on(\"dblclick\", function (d, i) {\n",
              "            // If we double click on the only active head then reset\n",
              "            if (config.headVis[i] && activeHeads() === 1) {\n",
              "                config.headVis = new Array(config.nHeads).fill(true);\n",
              "            } else {\n",
              "                config.headVis = new Array(config.nHeads).fill(false);\n",
              "                config.headVis[i] = true;\n",
              "            }\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function lighten(color) {\n",
              "        const c = d3.hsl(color);\n",
              "        const increment = (1 - c.l) * 0.6;\n",
              "        c.l += increment;\n",
              "        c.s -= increment;\n",
              "        return c;\n",
              "    }\n",
              "\n",
              "    function transpose(mat) {\n",
              "        return mat[0].map(function (col, i) {\n",
              "            return mat.map(function (row) {\n",
              "                return row[i];\n",
              "            });\n",
              "        });\n",
              "    }\n",
              "\n",
              "});"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBZ35y4tnB1h"
      },
      "source": [
        "## Tradeoffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oCp9vPrTUMx"
      },
      "source": [
        "We're going to go with the embeddings via CNN approach and optimize it because performance is quite similar to the contextualized embeddings via transformers approach but at much lower cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVzPrFK0Y0b-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e289eb-ab64-4dc1-fdf1-58fea0564ec5"
      },
      "source": [
        "# Performance\n",
        "with open(Path(\"cnn\", \"performance.json\"), \"r\") as fp:\n",
        "    cnn_performance = json.load(fp)\n",
        "with open(Path(\"transformers\", \"performance.json\"), \"r\") as fp:\n",
        "    transformers_performance = json.load(fp)\n",
        "print (f'CNN: f1 = {cnn_performance[\"overall\"][\"f1\"]}')\n",
        "print (f'Transformer: f1 = {transformers_performance[\"overall\"][\"f1\"]}')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN: f1 = 0.5994276061921316\n",
            "Transformer: f1 = 0.5868288723603842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok2jBSjGsxyL"
      },
      "source": [
        "This was just one run on one split so you'll want to experiment with k-fold cross validation to properly reach any conclusions about performance. Also make sure you take the time to tune these baselines since their training periods are quite fast (we can achieve f1 of 0.7 with just a bit of tuning for both CNN / Transformers). We'll cover hyperparameter tuning in a few lessons so you can replicate the process here on your own time. We should also benchmark on other important metrics as we iterate, not just precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSM_UOkrVV6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a001dbe5-21e1-4dbb-88e3-59b38102bedd"
      },
      "source": [
        "# Size\n",
        "print (f'CNN: {Path(\"cnn\", \"model.pt\").stat().st_size/1000000:.1f} MB')\n",
        "print (f'Transformer: {Path(\"transformers\", \"model.pt\").stat().st_size/1000000:.1f} MB')"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN: 4.3 MB\n",
            "Transformer: 439.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDcnWxoMup6W"
      },
      "source": [
        "> We'll consider other tradeoffs such as maintenance overhead, bias test passes, etc. as we develop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MILv2j74iUMQ"
      },
      "source": [
        "## Experiment tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t40bb7o2jyCP"
      },
      "source": [
        "So far, we've been training and evaluating our different baselines but haven't really been tracking these experiments. We'll fix this but defining a proper process for experiment tracking which we'll use for all future experiments (including hyperparameter optimization). There are many options for experiment tracking but we're going to use [MLFlow](https://mlflow.org/) (100% free and [open-source](https://github.com/mlflow/mlflow)) which is my personal preference since 2018 and has all the functionality we'll need (and [growing integration support](https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789)). There are also several \"[freemium](https://en.wikipedia.org/wiki/Freemium)\" options that you may want to consider ([Comet](https://www.comet.ml/site/), [Neptune](https://neptune.ai/), [Weights and Biases](https://www.wandb.com/), etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiU-_H58iVvV",
        "outputId": "6be2df41-6007-40f7-eaa6-02bda1bc5a67"
      },
      "source": [
        "!pip install mlflow pyngrok -q"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.2MB 254kB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 13.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 348kB 58.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 57.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 67.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 481kB 60.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 64.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 43.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 14.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 67.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjBl3l1cl4x6"
      },
      "source": [
        "from argparse import Namespace\n",
        "import mlflow\n",
        "from pathlib import Path"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwbBLh4xdFG"
      },
      "source": [
        "# Specify arguments\n",
        "args = Namespace(\n",
        "    char_level=True,\n",
        "    filter_sizes=list(range(1, 11)),\n",
        "    batch_size=64,\n",
        "    embedding_dim=128, \n",
        "    num_filters=128,\n",
        "    hidden_dim=128, \n",
        "    dropout_p=0.5,\n",
        "    lr=2e-4,\n",
        "    num_epochs=200,\n",
        "    patience=10,\n",
        ")"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIHrsmkN7rYi"
      },
      "source": [
        "> When we move to Python scripts, we'll use the [Typer](https://typer.tiangolo.com/) package instead of argparse for a better CLI experience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq5Zoy6YohM3"
      },
      "source": [
        "# Set tracking URI\n",
        "MODEL_REGISTRY = Path(\"experiments\")\n",
        "Path(MODEL_REGISTRY).mkdir(exist_ok=True) # create experiments dir\n",
        "mlflow.set_tracking_uri(\"file://\" + str(MODEL_REGISTRY.absolute()))"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DR1CvJeo48U",
        "outputId": "0e754f99-637b-4e45-9978-0143f259ab67"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bertviz_repo  cnn  experiments\trnn  sample_data  transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGvUEKbl9buj"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZgQlLyHHwEk"
      },
      "source": [
        "We're going to log the training epoch metrics within our `Trainer`'s `train` function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F16Qt7xSHqph"
      },
      "source": [
        "# Trainer (modified for experiment tracking)\n",
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, \n",
        "                 optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Tracking\n",
        "            mlflow.log_metrics(\n",
        "                {\"train_loss\": train_loss, \"val_loss\": val_loss}, step=epoch\n",
        "            )\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "\n",
        "        return best_model, best_val_loss"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mk5Dlcj_aJd"
      },
      "source": [
        "And to make things simple, we'll encapsulate all the components for training into one function which returns all the artifacts we want to be able to track from our experiment. The input argument `args`contains all the parameters needed and it's nice to have it all organized under one variable so we can easily log it and tweak it for different experiments (we'll see this when we do hyperparameter optimization)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWUtQYLIR9Nn"
      },
      "source": [
        "def train_cnn(args, df):\n",
        "    \"\"\"Train a CNN using specific arguments.\"\"\"\n",
        "\n",
        "    # Set seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # Get data splits\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "    X_test_raw = X_test\n",
        "    num_classes = len(label_encoder)\n",
        "\n",
        "    # Set device\n",
        "    cuda = True\n",
        "    device = torch.device('cuda' if (\n",
        "        torch.cuda.is_available() and cuda) else 'cpu')\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    if device.type == 'cuda':\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "    # Tokenize\n",
        "    tokenizer = Tokenizer(char_level=args.char_level)\n",
        "    tokenizer.fit_on_texts(texts=X_train)\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Convert texts to sequences of indices\n",
        "    X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "    X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "    X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "\n",
        "    # Class weights\n",
        "    counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CNNTextDataset(\n",
        "        X=X_train, y=y_train, max_filter_size=max(args.filter_sizes))\n",
        "    val_dataset = CNNTextDataset(\n",
        "        X=X_val, y=y_val, max_filter_size=max(args.filter_sizes))\n",
        "    test_dataset = CNNTextDataset(\n",
        "        X=X_test, y=y_test, max_filter_size=max(args.filter_sizes))\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = train_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    val_dataloader = val_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    test_dataloader = test_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(\n",
        "        embedding_dim=args.embedding_dim, vocab_size=vocab_size,\n",
        "        num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "        hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "        num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss\n",
        "    class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "    loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer & scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    # Trainer module\n",
        "    trainer = Trainer(\n",
        "        model=model, device=device, loss_fn=loss_fn, \n",
        "        optimizer=optimizer, scheduler=scheduler)\n",
        "\n",
        "    # Train\n",
        "    best_model, best_val_loss = trainer.train(\n",
        "        args.num_epochs, args.patience, train_dataloader, val_dataloader)\n",
        "\n",
        "    # Best threshold for f1\n",
        "    train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "    threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "\n",
        "    # Determine predictions using threshold\n",
        "    test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "    y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "\n",
        "    # Evaluate\n",
        "    performance = get_metrics(\n",
        "        y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "\n",
        "    return {\n",
        "        \"args\": args,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"label_encoder\": label_encoder,\n",
        "        \"model\": best_model,\n",
        "        \"performance\": performance,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "    }"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyqrdKxZ9gFi"
      },
      "source": [
        "### Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EyOAaaTLlil"
      },
      "source": [
        "With MLFlow we need to first initialize an experiment and then you can do runs under that experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5qLhfSJxSkp"
      },
      "source": [
        "import tempfile"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJHQ_SwwLjRY",
        "outputId": "2a6e2d86-e9df-4b4b-e385-44c0048a009f"
      },
      "source": [
        "# Set experiment\n",
        "mlflow.set_experiment(experiment_name=\"baselines\")"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: 'baselines' does not exist. Creating a new experiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCuqxD1V2dce"
      },
      "source": [
        "def save_dict(d, filepath):\n",
        "    \"\"\"Save dict to a json file.\"\"\"\n",
        "    with open(filepath, \"w\") as fp:\n",
        "        json.dump(d, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rWwqZPWo7Oo",
        "outputId": "3d9e079c-8876-42fe-d802-703282cb2765"
      },
      "source": [
        "# Tracking\n",
        "with mlflow.start_run(run_name=\"cnn\") as run:\n",
        "\n",
        "    # Train & evaluate\n",
        "    artifacts = train_cnn(args=args, df=df)    \n",
        "    \n",
        "    # Log key metrics\n",
        "    mlflow.log_metrics({\"precision\": artifacts[\"performance\"][\"overall\"][\"precision\"]})\n",
        "    mlflow.log_metrics({\"recall\": artifacts[\"performance\"][\"overall\"][\"recall\"]})\n",
        "    mlflow.log_metrics({\"f1\": artifacts[\"performance\"][\"overall\"][\"f1\"]})\n",
        "\n",
        "    # Log artifacts\n",
        "    with tempfile.TemporaryDirectory() as dp:\n",
        "        artifacts[\"tokenizer\"].save(Path(dp, \"tokenizer.json\"))\n",
        "        artifacts[\"label_encoder\"].save(Path(dp, \"label_encoder.json\"))\n",
        "        torch.save(artifacts[\"model\"].state_dict(), Path(dp, \"model.pt\"))\n",
        "        save_dict(artifacts[\"performance\"], Path(dp, \"performance.json\"))\n",
        "        mlflow.log_artifacts(dp)\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(vars(artifacts[\"args\"]))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00539, val_loss: 0.00301, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00393, val_loss: 0.00281, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00345, val_loss: 0.00264, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00324, val_loss: 0.00259, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00313, val_loss: 0.00255, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00295, val_loss: 0.00250, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00286, val_loss: 0.00243, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00273, val_loss: 0.00236, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00260, val_loss: 0.00230, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00254, val_loss: 0.00223, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00239, val_loss: 0.00215, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00227, val_loss: 0.00209, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00215, val_loss: 0.00200, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00210, val_loss: 0.00195, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00200, val_loss: 0.00190, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00191, val_loss: 0.00185, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00182, val_loss: 0.00179, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00175, val_loss: 0.00176, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00167, val_loss: 0.00171, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00159, val_loss: 0.00168, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00155, val_loss: 0.00166, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00147, val_loss: 0.00163, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00142, val_loss: 0.00160, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00139, val_loss: 0.00159, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00131, val_loss: 0.00157, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00124, val_loss: 0.00158, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 27 | train_loss: 0.00123, val_loss: 0.00154, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00116, val_loss: 0.00156, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00113, val_loss: 0.00154, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00109, val_loss: 0.00153, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00103, val_loss: 0.00151, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00103, val_loss: 0.00151, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00097, val_loss: 0.00154, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 34 | train_loss: 0.00094, val_loss: 0.00151, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 35 | train_loss: 0.00092, val_loss: 0.00149, lr: 2.00E-04, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00087, val_loss: 0.00152, lr: 2.00E-04, _patience: 9\n",
            "Epoch: 37 | train_loss: 0.00084, val_loss: 0.00150, lr: 2.00E-04, _patience: 8\n",
            "Epoch: 38 | train_loss: 0.00082, val_loss: 0.00150, lr: 2.00E-04, _patience: 7\n",
            "Epoch: 39 | train_loss: 0.00079, val_loss: 0.00150, lr: 2.00E-04, _patience: 6\n",
            "Epoch: 40 | train_loss: 0.00077, val_loss: 0.00153, lr: 2.00E-04, _patience: 5\n",
            "Epoch: 41 | train_loss: 0.00076, val_loss: 0.00158, lr: 2.00E-05, _patience: 4\n",
            "Epoch: 42 | train_loss: 0.00070, val_loss: 0.00150, lr: 2.00E-05, _patience: 3\n",
            "Epoch: 43 | train_loss: 0.00067, val_loss: 0.00153, lr: 2.00E-05, _patience: 2\n",
            "Epoch: 44 | train_loss: 0.00067, val_loss: 0.00150, lr: 2.00E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWgLPYgCBhi"
      },
      "source": [
        "### Viewing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9JkJ_7MCC4U"
      },
      "source": [
        "Let's view what we've tracked from our experiment. MLFlow serves a dashboard for us to view and explore our experiments on a localhost port but since we're inside a notebook, we're going to use public tunnel ([ngrok](https://ngrok.com/)) to view it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCco6Xa3436x"
      },
      "source": [
        "from pyngrok import ngrok"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR4xFBQI7Tqj"
      },
      "source": [
        "> You may need to rerun the cell below multiple times if the connection times out it is overloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gd8i4b941hL",
        "outputId": "38bde339-e3d2-4e34-a146-66b8f81a3381"
      },
      "source": [
        "# https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab\n",
        "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: https://9cfe1fdda032.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfUQpOIDej0z"
      },
      "source": [
        "MLFlow creates a main dashboard with all your experiments and their respective runs. We can sort runs by clicking on the column headers.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/applied-ml/experiment_tracking/dashboard.png\" width=\"1000\" alt=\"pivot\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhjsDJyeeGN"
      },
      "source": [
        "We can click on any of our experiments on the main dashboard to further explore it:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/applied-ml/experiment_tracking/plots.png\" width=\"1000\" alt=\"pivot\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVeCRid9hWs"
      },
      "source": [
        "### Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEbgvyFQfW_e"
      },
      "source": [
        "We need to be able to load our saved experiment artifacts for inference, retraining, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUdmwNiVy6Dy"
      },
      "source": [
        "def load_dict(filepath):\n",
        "    \"\"\"Load a dict from a json file.\"\"\"\n",
        "    with open(filepath, \"r\") as fp:\n",
        "        d = json.load(fp)\n",
        "    return d"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP_FfHn07943",
        "outputId": "3d0b0125-9612-48c4-c263-f09eed94ab91"
      },
      "source": [
        "# Load all runs from experiment\n",
        "experiment_id = mlflow.get_experiment_by_name(\"baselines\").experiment_id\n",
        "all_runs = mlflow.search_runs(experiment_ids=experiment_id, order_by=[\"metrics.best_val_loss ASC\"])\n",
        "print (all_runs)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             run_id  ... tags.mlflow.runName\n",
            "0  29aa31d151f94b089c6809d55c4c44e4  ...                 cnn\n",
            "\n",
            "[1 rows x 25 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHbhpuFq9QPA"
      },
      "source": [
        "# Best run\n",
        "device = torch.device(\"cpu\")\n",
        "best_run_id = all_runs.iloc[0].run_id\n",
        "best_run = mlflow.get_run(run_id=best_run_id)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "with tempfile.TemporaryDirectory() as dp:\n",
        "    client.download_artifacts(run_id=best_run_id, path=\"\", dst_path=dp)\n",
        "    tokenizer = Tokenizer.load(fp=Path(dp, \"tokenizer.json\"))\n",
        "    label_encoder = LabelEncoder.load(fp=Path(dp, \"label_encoder.json\"))\n",
        "    model_state = torch.load(Path(dp, \"model.pt\"), map_location=device)\n",
        "    performance = load_dict(filepath=Path(dp, \"performance.json\"))"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUAGjr5w8oxM",
        "outputId": "c7a16dfd-6fc8-454a-913a-69b3ec8abfe1"
      },
      "source": [
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8241269747992438,\n",
            "  \"recall\": 0.510039095141312,\n",
            "  \"f1\": 0.6024953438953675,\n",
            "  \"num_samples\": 480.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsMvF6K_8LIt",
        "outputId": "0e6548a2-008d-4aee-d133-3278191abf10"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "model = CNN(\n",
        "    embedding_dim=args.embedding_dim, vocab_size=len(tokenizer),\n",
        "    num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "    hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "    num_classes=len(label_encoder))\n",
        "model.load_state_dict(model_state)\n",
        "model.to(device)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(39, 128, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
              "    (3): Conv1d(128, 128, kernel_size=(4,), stride=(1,))\n",
              "    (4): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
              "    (5): Conv1d(128, 128, kernel_size=(6,), stride=(1,))\n",
              "    (6): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
              "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,))\n",
              "    (8): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
              "    (9): Conv1d(128, 128, kernel_size=(10,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=35, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2axMjbk9XgI"
      },
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcypz1sO9Xk1"
      },
      "source": [
        "# Dataloader\n",
        "text = \"Transfer learning with BERT for self-supervised learning\"\n",
        "X = np.array(tokenizer.texts_to_sequences([preprocess(text)]))\n",
        "y_filler = label_encoder.encode([np.array([label_encoder.classes[0]]*len(X))])\n",
        "dataset = CNNTextDataset(\n",
        "    X=X, y=y_filler, max_filter_size=max(filter_sizes))\n",
        "dataloader = dataset.create_dataloader(\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiQr5E6L9XrM",
        "outputId": "47ee445e-c689-4764-927c-66a638e3e9a2"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural-language-processing',\n",
              "  'self-supervised-learning',\n",
              "  'transfer-learning',\n",
              "  'transformers']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CzPlupuYPWT"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHM69_fPYXy_"
      },
      "source": [
        "Optimization is the process of fine-tuning the hyperparameters in our experiment to optimize towards a particular objective. It can be a computationally involved process depending on the number of parameters, search space and model architectures. Hyperparameters don't just include the model's parameters but they also include parameters (choices) from preprocessing, splitting, etc. When we look at all the different parameters that can be tuned, it quickly becomes a very large search space. However, just because something is a hyperparameter doesn't mean we need to tune it.\n",
        "\n",
        "- It's absolutely alright to fix some hyperparameters (ex. lower=True during preprocessing) and remove them from the current tuning subset. Just be sure to note which parameters you are fixing and your reasoning for doing so.\n",
        "- You can initially just tune a small, yet influential, subset of hyperparameters that you believe will yield best results.\n",
        "\n",
        "There are many options for hyperparameter tuning ([Optuna](https://github.com/optuna/optuna), [Ray tune](https://github.com/ray-project/ray/tree/master/python/ray/tune), [Hyperopt](https://github.com/hyperopt/hyperopt), etc.) but we'll be using Optuna for it's simplicity and efficiency. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFFkEgjSYR9v",
        "outputId": "00288988-b6f2-44a5-8784-a549579fa425"
      },
      "source": [
        "!pip install optuna numpyencoder -q"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 286kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 4.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 18.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 11.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25h  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLI2DvYihgH9"
      },
      "source": [
        "import optuna"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oxHC5gUZw6v"
      },
      "source": [
        "There are many factors to consider when performing hyperparameter optimization and luckily Optuna allows us to [implement](https://optuna.readthedocs.io/en/stable/reference/) them with ease. We'll be conducting a small study where we'll tune a set of arguments (we'll do a much more thorough [study](https://optuna.readthedocs.io/en/stable/reference/study.html) of the parameter space when we move our code to Python scripts). Here's the process for the study:\n",
        "\n",
        "1. Define an objective (metric) and identifying the [direction](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.StudyDirection.html#optuna.study.StudyDirection) to optimize.\n",
        "2. `[OPTIONAL]` Choose a [sampler](https://optuna.readthedocs.io/en/stable/reference/samplers.html) for determining parameters for subsequent trials. (default is a tree based sampler).\n",
        "3. `[OPTIONAL]` Choose a [pruner](https://optuna.readthedocs.io/en/stable/reference/pruners.html) to end unpromising trials early. \n",
        "4. Define the parameters to tune in each [trial](https://optuna.readthedocs.io/en/stable/reference/trial.html) and the [distribution](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna-trial-trial) of values to sample. \n",
        "\n",
        "> There are many more options (multiple objectives, storage options, etc.) to explore but this basic set up will allow us to optimize quite well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hsPDs3iXy1"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeGjHoore6Ca"
      },
      "source": [
        "# Specify arguments\n",
        "args = Namespace(\n",
        "    char_level=True,\n",
        "    filter_sizes=list(range(1, 11)),\n",
        "    batch_size=64,\n",
        "    embedding_dim=128, \n",
        "    num_filters=128,\n",
        "    hidden_dim=128, \n",
        "    dropout_p=0.5,\n",
        "    lr=2e-4,\n",
        "    num_epochs=200,\n",
        "    patience=10,\n",
        ")"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSxjDzajfxMF"
      },
      "source": [
        "We're going to modify our `Trainer` object to be able to prune unpromising trials based on the trial's validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu9OCdgxfxXx"
      },
      "source": [
        "# Trainer (modified for experiment tracking)\n",
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, \n",
        "                 optimizer=None, scheduler=None, trial=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.trial = trial\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "    \n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "\n",
        "            # Pruning based on the intermediate value\n",
        "            self.trial.report(val_loss, epoch)\n",
        "            if self.trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "                    \n",
        "        return best_model, best_val_loss"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3dGFhnehUbk"
      },
      "source": [
        "We'll also modify our `train_cnn` function to include information about the trial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm_xEptLhUqm"
      },
      "source": [
        "def train_cnn(args, df, trial=None):\n",
        "    \"\"\"Train a CNN using specific arguments.\"\"\"\n",
        "\n",
        "    # Set seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # Get data splits\n",
        "    preprocessed_df = df.copy()\n",
        "    preprocessed_df.text = preprocessed_df.text.apply(preprocess, lower=True)\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, label_encoder = get_data_splits(preprocessed_df)\n",
        "    X_test_raw = X_test\n",
        "    num_classes = len(label_encoder)\n",
        "\n",
        "    # Set device\n",
        "    cuda = True\n",
        "    device = torch.device('cuda' if (\n",
        "        torch.cuda.is_available() and cuda) else 'cpu')\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    if device.type == 'cuda':\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "    # Tokenize\n",
        "    tokenizer = Tokenizer(char_level=args.char_level)\n",
        "    tokenizer.fit_on_texts(texts=X_train)\n",
        "    vocab_size = len(tokenizer)\n",
        "\n",
        "    # Convert texts to sequences of indices\n",
        "    X_train = np.array(tokenizer.texts_to_sequences(X_train))\n",
        "    X_val = np.array(tokenizer.texts_to_sequences(X_val))\n",
        "    X_test = np.array(tokenizer.texts_to_sequences(X_test))\n",
        "\n",
        "    # Class weights\n",
        "    counts = np.bincount([label_encoder.class_to_index[class_] for class_ in all_tags])\n",
        "    class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CNNTextDataset(\n",
        "        X=X_train, y=y_train, max_filter_size=max(args.filter_sizes))\n",
        "    val_dataset = CNNTextDataset(\n",
        "        X=X_val, y=y_val, max_filter_size=max(args.filter_sizes))\n",
        "    test_dataset = CNNTextDataset(\n",
        "        X=X_test, y=y_test, max_filter_size=max(args.filter_sizes))\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = train_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    val_dataloader = val_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "    test_dataloader = test_dataset.create_dataloader(\n",
        "        batch_size=args.batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = CNN(\n",
        "        embedding_dim=args.embedding_dim, vocab_size=vocab_size,\n",
        "        num_filters=args.num_filters, filter_sizes=args.filter_sizes,\n",
        "        hidden_dim=args.hidden_dim, dropout_p=args.dropout_p,\n",
        "        num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss\n",
        "    class_weights_tensor = torch.Tensor(np.array(list(class_weights.values())))\n",
        "    loss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
        "\n",
        "    # Define optimizer & scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    # Trainer module\n",
        "    trainer = Trainer(\n",
        "        model=model, device=device, loss_fn=loss_fn, \n",
        "        optimizer=optimizer, scheduler=scheduler, trial=trial)\n",
        "\n",
        "    # Train\n",
        "    best_model, best_val_loss = trainer.train(\n",
        "        args.num_epochs, args.patience, train_dataloader, val_dataloader)\n",
        "\n",
        "    # Best threshold for f1\n",
        "    train_loss, y_true, y_prob = trainer.eval_step(dataloader=train_dataloader)\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true.ravel(), y_prob.ravel())\n",
        "    threshold = find_best_threshold(y_true.ravel(), y_prob.ravel())\n",
        "\n",
        "    # Determine predictions using threshold\n",
        "    test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "    y_pred = np.array([np.where(prob >= threshold, 1, 0) for prob in y_prob])\n",
        "\n",
        "    # Evaluate\n",
        "    performance = get_metrics(\n",
        "        y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "\n",
        "    return {\n",
        "        \"args\": args,\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"label_encoder\": label_encoder,\n",
        "        \"model\": best_model,\n",
        "        \"performance\": performance,\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"threshold\": threshold,\n",
        "    }"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncGdA34Ahod9"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzekaGZyeHXb"
      },
      "source": [
        "We need to define an `objective` function that will consume a trial and a set of arguments and produce the metric to optimize on (`f1` in our case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg33IjzSd27e"
      },
      "source": [
        "def objective(trial, args):\n",
        "    \"\"\"Objective function for optimization trials.\"\"\"\n",
        "\n",
        "    # Paramters (to tune)\n",
        "    args.embedding_dim = trial.suggest_int(\"embedding_dim\", 128, 512)\n",
        "    args.num_filters = trial.suggest_int(\"num_filters\", 128, 512)\n",
        "    args.hidden_dim = trial.suggest_int(\"hidden_dim\", 128, 512)\n",
        "    args.dropout_p = trial.suggest_uniform(\"dropout_p\", 0.3, 0.8)\n",
        "    args.lr = trial.suggest_loguniform(\"lr\", 5e-5, 5e-4)\n",
        "\n",
        "    # Train & evaluate\n",
        "    artifacts = train_cnn(args=args, df=df, trial=trial)\n",
        "\n",
        "    # Set additional attributes\n",
        "    trial.set_user_attr(\"precision\", artifacts[\"performance\"][\"overall\"][\"precision\"])\n",
        "    trial.set_user_attr(\"recall\", artifacts[\"performance\"][\"overall\"][\"recall\"])\n",
        "    trial.set_user_attr(\"f1\", artifacts[\"performance\"][\"overall\"][\"f1\"])\n",
        "    trial.set_user_attr(\"threshold\", artifacts[\"threshold\"])\n",
        "\n",
        "    return artifacts[\"performance\"][\"overall\"][\"f1\"]"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K42Yf3OEhp_V"
      },
      "source": [
        "### Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epa_kTIl9H7b"
      },
      "source": [
        "We're ready to kick off our study with our [MLFlowCallback](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.MLflowCallback.html) so we can track all of the different trials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC58iWVjjPN8"
      },
      "source": [
        "from numpyencoder import NumpyEncoder\n",
        "from optuna.integration.mlflow import MLflowCallback"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbPWc_c8hsA6"
      },
      "source": [
        "NUM_TRIALS = 50 # small sample for now"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQByQ8pihjIR",
        "outputId": "5f11eddf-e701-47b5-8c85-fe3aa0f979d5"
      },
      "source": [
        "# Optimize\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
        "study = optuna.create_study(study_name=\"optimization\", direction=\"maximize\", pruner=pruner)\n",
        "mlflow_callback = MLflowCallback(\n",
        "    tracking_uri=mlflow.get_tracking_uri(), metric_name=\"f1\")\n",
        "study.optimize(lambda trial: objective(trial, args),\n",
        "               n_trials=NUM_TRIALS,\n",
        "               callbacks=[mlflow_callback])"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:15:01,189]\u001b[0m A new study created in memory with name: optimization\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00645, val_loss: 0.00314, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00373, val_loss: 0.00249, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00293, val_loss: 0.00216, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00241, val_loss: 0.00191, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00206, val_loss: 0.00181, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00178, val_loss: 0.00167, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00156, val_loss: 0.00162, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00137, val_loss: 0.00157, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00114, val_loss: 0.00158, lr: 3.48E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00103, val_loss: 0.00152, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00088, val_loss: 0.00156, lr: 3.48E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00078, val_loss: 0.00156, lr: 3.48E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00068, val_loss: 0.00147, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00065, val_loss: 0.00144, lr: 3.48E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00056, val_loss: 0.00173, lr: 3.48E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00058, val_loss: 0.00190, lr: 3.48E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00056, val_loss: 0.00161, lr: 3.48E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00056, val_loss: 0.00144, lr: 3.48E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00053, val_loss: 0.00205, lr: 3.48E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00052, val_loss: 0.00171, lr: 3.48E-05, _patience: 4\n",
            "Epoch: 21 | train_loss: 0.00035, val_loss: 0.00184, lr: 3.48E-05, _patience: 3\n",
            "Epoch: 22 | train_loss: 0.00030, val_loss: 0.00170, lr: 3.48E-05, _patience: 2\n",
            "Epoch: 23 | train_loss: 0.00029, val_loss: 0.00175, lr: 3.48E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:16:25,449]\u001b[0m Trial 0 finished with value: 0.5999225606985846 and parameters: {'embedding_dim': 508, 'num_filters': 359, 'hidden_dim': 262, 'dropout_p': 0.6008497926241321, 'lr': 0.0003484755175747328}. Best is trial 0 with value: 0.5999225606985846.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO: 'optimization' does not exist. Creating a new experiment\n",
            "Epoch: 1 | train_loss: 0.00665, val_loss: 0.00322, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00366, val_loss: 0.00259, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00280, val_loss: 0.00223, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00227, val_loss: 0.00193, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00187, val_loss: 0.00174, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00160, val_loss: 0.00165, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00132, val_loss: 0.00155, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00110, val_loss: 0.00155, lr: 4.40E-04, _patience: 9\n",
            "Epoch: 9 | train_loss: 0.00091, val_loss: 0.00153, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00074, val_loss: 0.00157, lr: 4.40E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00062, val_loss: 0.00149, lr: 4.40E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00055, val_loss: 0.00163, lr: 4.40E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00046, val_loss: 0.00164, lr: 4.40E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00042, val_loss: 0.00164, lr: 4.40E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00035, val_loss: 0.00184, lr: 4.40E-04, _patience: 6\n",
            "Epoch: 16 | train_loss: 0.00034, val_loss: 0.00168, lr: 4.40E-04, _patience: 5\n",
            "Epoch: 17 | train_loss: 0.00029, val_loss: 0.00188, lr: 4.40E-05, _patience: 4\n",
            "Epoch: 18 | train_loss: 0.00026, val_loss: 0.00168, lr: 4.40E-05, _patience: 3\n",
            "Epoch: 19 | train_loss: 0.00021, val_loss: 0.00163, lr: 4.40E-05, _patience: 2\n",
            "Epoch: 20 | train_loss: 0.00018, val_loss: 0.00167, lr: 4.40E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:17:12,927]\u001b[0m Trial 1 finished with value: 0.6211826888657637 and parameters: {'embedding_dim': 274, 'num_filters': 406, 'hidden_dim': 432, 'dropout_p': 0.5222107567574638, 'lr': 0.0004402301841019062}. Best is trial 1 with value: 0.6211826888657637.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00517, val_loss: 0.00316, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00362, val_loss: 0.00274, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00315, val_loss: 0.00252, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00292, val_loss: 0.00243, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00278, val_loss: 0.00233, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00255, val_loss: 0.00222, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00242, val_loss: 0.00213, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00229, val_loss: 0.00205, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00214, val_loss: 0.00196, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00195, val_loss: 0.00188, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00185, val_loss: 0.00183, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00176, val_loss: 0.00178, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00166, val_loss: 0.00173, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00156, val_loss: 0.00170, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00147, val_loss: 0.00168, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00140, val_loss: 0.00163, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00133, val_loss: 0.00161, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00127, val_loss: 0.00159, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00120, val_loss: 0.00156, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00117, val_loss: 0.00154, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00108, val_loss: 0.00151, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00103, val_loss: 0.00154, lr: 9.11E-05, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00100, val_loss: 0.00151, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00092, val_loss: 0.00149, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00088, val_loss: 0.00152, lr: 9.11E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00085, val_loss: 0.00148, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00080, val_loss: 0.00147, lr: 9.11E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00076, val_loss: 0.00148, lr: 9.11E-05, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00074, val_loss: 0.00151, lr: 9.11E-05, _patience: 8\n",
            "Epoch: 30 | train_loss: 0.00070, val_loss: 0.00149, lr: 9.11E-05, _patience: 7\n",
            "Epoch: 31 | train_loss: 0.00066, val_loss: 0.00149, lr: 9.11E-05, _patience: 6\n",
            "Epoch: 32 | train_loss: 0.00064, val_loss: 0.00148, lr: 9.11E-05, _patience: 5\n",
            "Epoch: 33 | train_loss: 0.00060, val_loss: 0.00155, lr: 9.11E-06, _patience: 4\n",
            "Epoch: 34 | train_loss: 0.00058, val_loss: 0.00149, lr: 9.11E-06, _patience: 3\n",
            "Epoch: 35 | train_loss: 0.00056, val_loss: 0.00147, lr: 9.11E-06, _patience: 2\n",
            "Epoch: 36 | train_loss: 0.00054, val_loss: 0.00147, lr: 9.11E-06, _patience: 1\n",
            "Epoch: 37 | train_loss: 0.00054, val_loss: 0.00146, lr: 9.11E-06, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00054, val_loss: 0.00147, lr: 9.11E-06, _patience: 9\n",
            "Epoch: 39 | train_loss: 0.00053, val_loss: 0.00147, lr: 9.11E-06, _patience: 8\n",
            "Epoch: 40 | train_loss: 0.00054, val_loss: 0.00147, lr: 9.11E-06, _patience: 7\n",
            "Epoch: 41 | train_loss: 0.00052, val_loss: 0.00147, lr: 9.11E-06, _patience: 6\n",
            "Epoch: 42 | train_loss: 0.00052, val_loss: 0.00147, lr: 9.11E-06, _patience: 5\n",
            "Epoch: 43 | train_loss: 0.00054, val_loss: 0.00147, lr: 9.11E-07, _patience: 4\n",
            "Epoch: 44 | train_loss: 0.00052, val_loss: 0.00147, lr: 9.11E-07, _patience: 3\n",
            "Epoch: 45 | train_loss: 0.00052, val_loss: 0.00147, lr: 9.11E-07, _patience: 2\n",
            "Epoch: 46 | train_loss: 0.00050, val_loss: 0.00147, lr: 9.11E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:19:05,380]\u001b[0m Trial 2 finished with value: 0.6212529041207517 and parameters: {'embedding_dim': 505, 'num_filters': 255, 'hidden_dim': 164, 'dropout_p': 0.4141610937633518, 'lr': 9.113327516870463e-05}. Best is trial 2 with value: 0.6212529041207517.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00554, val_loss: 0.00352, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00384, val_loss: 0.00258, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00311, val_loss: 0.00250, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00276, val_loss: 0.00226, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00248, val_loss: 0.00206, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00221, val_loss: 0.00193, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00194, val_loss: 0.00181, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00175, val_loss: 0.00172, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00157, val_loss: 0.00166, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00143, val_loss: 0.00159, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00127, val_loss: 0.00158, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00123, val_loss: 0.00154, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00109, val_loss: 0.00151, lr: 2.66E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00099, val_loss: 0.00153, lr: 2.66E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00091, val_loss: 0.00153, lr: 2.66E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00084, val_loss: 0.00154, lr: 2.66E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00075, val_loss: 0.00152, lr: 2.66E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00068, val_loss: 0.00152, lr: 2.66E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00064, val_loss: 0.00156, lr: 2.66E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00057, val_loss: 0.00150, lr: 2.66E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00052, val_loss: 0.00149, lr: 2.66E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00048, val_loss: 0.00149, lr: 2.66E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00049, val_loss: 0.00148, lr: 2.66E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00048, val_loss: 0.00148, lr: 2.66E-05, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00045, val_loss: 0.00147, lr: 2.66E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00044, val_loss: 0.00151, lr: 2.66E-05, _patience: 9\n",
            "Epoch: 27 | train_loss: 0.00044, val_loss: 0.00148, lr: 2.66E-05, _patience: 8\n",
            "Epoch: 28 | train_loss: 0.00043, val_loss: 0.00148, lr: 2.66E-05, _patience: 7\n",
            "Epoch: 29 | train_loss: 0.00044, val_loss: 0.00150, lr: 2.66E-05, _patience: 6\n",
            "Epoch: 30 | train_loss: 0.00043, val_loss: 0.00147, lr: 2.66E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00042, val_loss: 0.00152, lr: 2.66E-06, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00042, val_loss: 0.00151, lr: 2.66E-06, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00041, val_loss: 0.00149, lr: 2.66E-06, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00042, val_loss: 0.00148, lr: 2.66E-06, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00040, val_loss: 0.00148, lr: 2.66E-06, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00041, val_loss: 0.00148, lr: 2.66E-06, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00040, val_loss: 0.00149, lr: 2.66E-07, _patience: 3\n",
            "Epoch: 38 | train_loss: 0.00040, val_loss: 0.00149, lr: 2.66E-07, _patience: 2\n",
            "Epoch: 39 | train_loss: 0.00040, val_loss: 0.00149, lr: 2.66E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:20:15,843]\u001b[0m Trial 3 finished with value: 0.6184279317255474 and parameters: {'embedding_dim': 239, 'num_filters': 360, 'hidden_dim': 305, 'dropout_p': 0.5966714510384632, 'lr': 0.0002657069276187612}. Best is trial 2 with value: 0.6212529041207517.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00524, val_loss: 0.00341, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00401, val_loss: 0.00263, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00340, val_loss: 0.00255, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00315, val_loss: 0.00244, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00283, val_loss: 0.00233, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00267, val_loss: 0.00221, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00247, val_loss: 0.00209, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00232, val_loss: 0.00200, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00214, val_loss: 0.00190, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00195, val_loss: 0.00181, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00184, val_loss: 0.00176, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00176, val_loss: 0.00170, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00167, val_loss: 0.00165, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00157, val_loss: 0.00162, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00145, val_loss: 0.00158, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00140, val_loss: 0.00156, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00133, val_loss: 0.00154, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00122, val_loss: 0.00157, lr: 1.89E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00118, val_loss: 0.00149, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00110, val_loss: 0.00153, lr: 1.89E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00106, val_loss: 0.00148, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00101, val_loss: 0.00149, lr: 1.89E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00094, val_loss: 0.00146, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00090, val_loss: 0.00152, lr: 1.89E-04, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00088, val_loss: 0.00147, lr: 1.89E-04, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00082, val_loss: 0.00148, lr: 1.89E-04, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00078, val_loss: 0.00146, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00073, val_loss: 0.00159, lr: 1.89E-04, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00070, val_loss: 0.00150, lr: 1.89E-04, _patience: 8\n",
            "Epoch: 30 | train_loss: 0.00068, val_loss: 0.00143, lr: 1.89E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00067, val_loss: 0.00149, lr: 1.89E-04, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00062, val_loss: 0.00148, lr: 1.89E-04, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00060, val_loss: 0.00154, lr: 1.89E-04, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00061, val_loss: 0.00154, lr: 1.89E-04, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00057, val_loss: 0.00158, lr: 1.89E-04, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00054, val_loss: 0.00177, lr: 1.89E-05, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00052, val_loss: 0.00151, lr: 1.89E-05, _patience: 3\n",
            "Epoch: 38 | train_loss: 0.00047, val_loss: 0.00156, lr: 1.89E-05, _patience: 2\n",
            "Epoch: 39 | train_loss: 0.00044, val_loss: 0.00155, lr: 1.89E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:21:05,500]\u001b[0m Trial 4 finished with value: 0.6173361123270803 and parameters: {'embedding_dim': 263, 'num_filters': 206, 'hidden_dim': 198, 'dropout_p': 0.6012381052071967, 'lr': 0.00018867466384032172}. Best is trial 2 with value: 0.6212529041207517.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00520, val_loss: 0.00378, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00382, val_loss: 0.00263, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00319, val_loss: 0.00251, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00292, val_loss: 0.00242, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00271, val_loss: 0.00229, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00254, val_loss: 0.00217, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00230, val_loss: 0.00209, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00216, val_loss: 0.00197, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00200, val_loss: 0.00190, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00187, val_loss: 0.00182, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00168, val_loss: 0.00177, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00163, val_loss: 0.00170, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00150, val_loss: 0.00164, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00144, val_loss: 0.00163, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00137, val_loss: 0.00159, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00127, val_loss: 0.00156, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00120, val_loss: 0.00154, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00112, val_loss: 0.00154, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00109, val_loss: 0.00151, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00097, val_loss: 0.00153, lr: 1.19E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00091, val_loss: 0.00152, lr: 1.19E-04, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00087, val_loss: 0.00152, lr: 1.19E-04, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00083, val_loss: 0.00153, lr: 1.19E-04, _patience: 6\n",
            "Epoch: 24 | train_loss: 0.00077, val_loss: 0.00152, lr: 1.19E-04, _patience: 5\n",
            "Epoch: 25 | train_loss: 0.00073, val_loss: 0.00153, lr: 1.19E-05, _patience: 4\n",
            "Epoch: 26 | train_loss: 0.00069, val_loss: 0.00150, lr: 1.19E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00065, val_loss: 0.00145, lr: 1.19E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00063, val_loss: 0.00147, lr: 1.19E-05, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00061, val_loss: 0.00146, lr: 1.19E-05, _patience: 8\n",
            "Epoch: 30 | train_loss: 0.00062, val_loss: 0.00146, lr: 1.19E-05, _patience: 7\n",
            "Epoch: 31 | train_loss: 0.00060, val_loss: 0.00147, lr: 1.19E-05, _patience: 6\n",
            "Epoch: 32 | train_loss: 0.00060, val_loss: 0.00147, lr: 1.19E-05, _patience: 5\n",
            "Epoch: 33 | train_loss: 0.00059, val_loss: 0.00146, lr: 1.19E-06, _patience: 4\n",
            "Epoch: 34 | train_loss: 0.00059, val_loss: 0.00146, lr: 1.19E-06, _patience: 3\n",
            "Epoch: 35 | train_loss: 0.00058, val_loss: 0.00146, lr: 1.19E-06, _patience: 2\n",
            "Epoch: 36 | train_loss: 0.00058, val_loss: 0.00146, lr: 1.19E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:22:37,292]\u001b[0m Trial 5 finished with value: 0.6283134076800848 and parameters: {'embedding_dim': 295, 'num_filters': 418, 'hidden_dim': 288, 'dropout_p': 0.5267673343669412, 'lr': 0.0001187681403568692}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00633, val_loss: 0.00355, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00427, val_loss: 0.00260, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00341, val_loss: 0.00251, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00305, val_loss: 0.00240, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00281, val_loss: 0.00221, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00251, val_loss: 0.00205, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00235, val_loss: 0.00191, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00217, val_loss: 0.00182, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00200, val_loss: 0.00173, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00183, val_loss: 0.00171, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00174, val_loss: 0.00161, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00163, val_loss: 0.00162, lr: 3.02E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00147, val_loss: 0.00156, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00136, val_loss: 0.00154, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00129, val_loss: 0.00155, lr: 3.02E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00122, val_loss: 0.00158, lr: 3.02E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00111, val_loss: 0.00155, lr: 3.02E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00108, val_loss: 0.00147, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00098, val_loss: 0.00147, lr: 3.02E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00093, val_loss: 0.00153, lr: 3.02E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00085, val_loss: 0.00143, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00082, val_loss: 0.00146, lr: 3.02E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00077, val_loss: 0.00168, lr: 3.02E-04, _patience: 8\n",
            "Epoch: 24 | train_loss: 0.00072, val_loss: 0.00154, lr: 3.02E-04, _patience: 7\n",
            "Epoch: 25 | train_loss: 0.00074, val_loss: 0.00148, lr: 3.02E-04, _patience: 6\n",
            "Epoch: 26 | train_loss: 0.00075, val_loss: 0.00140, lr: 3.02E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00072, val_loss: 0.00153, lr: 3.02E-04, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00076, val_loss: 0.00196, lr: 3.02E-04, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00081, val_loss: 0.00212, lr: 3.02E-04, _patience: 7\n",
            "Epoch: 30 | train_loss: 0.00082, val_loss: 0.00156, lr: 3.02E-04, _patience: 6\n",
            "Epoch: 31 | train_loss: 0.00071, val_loss: 0.00149, lr: 3.02E-04, _patience: 5\n",
            "Epoch: 32 | train_loss: 0.00063, val_loss: 0.00164, lr: 3.02E-05, _patience: 4\n",
            "Epoch: 33 | train_loss: 0.00049, val_loss: 0.00161, lr: 3.02E-05, _patience: 3\n",
            "Epoch: 34 | train_loss: 0.00047, val_loss: 0.00163, lr: 3.02E-05, _patience: 2\n",
            "Epoch: 35 | train_loss: 0.00044, val_loss: 0.00161, lr: 3.02E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:23:33,148]\u001b[0m Trial 6 finished with value: 0.6102614270169114 and parameters: {'embedding_dim': 246, 'num_filters': 276, 'hidden_dim': 295, 'dropout_p': 0.7443905983802349, 'lr': 0.00030174168197441456}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00592, val_loss: 0.00314, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00335, val_loss: 0.00256, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00251, val_loss: 0.00204, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00195, val_loss: 0.00179, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00154, val_loss: 0.00165, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00125, val_loss: 0.00156, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00099, val_loss: 0.00153, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00078, val_loss: 0.00151, lr: 3.53E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00063, val_loss: 0.00153, lr: 3.53E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00051, val_loss: 0.00164, lr: 3.53E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00044, val_loss: 0.00160, lr: 3.53E-04, _patience: 7\n",
            "Epoch: 12 | train_loss: 0.00038, val_loss: 0.00167, lr: 3.53E-04, _patience: 6\n",
            "Epoch: 13 | train_loss: 0.00032, val_loss: 0.00168, lr: 3.53E-04, _patience: 5\n",
            "Epoch: 14 | train_loss: 0.00030, val_loss: 0.00166, lr: 3.53E-05, _patience: 4\n",
            "Epoch: 15 | train_loss: 0.00023, val_loss: 0.00166, lr: 3.53E-05, _patience: 3\n",
            "Epoch: 16 | train_loss: 0.00019, val_loss: 0.00163, lr: 3.53E-05, _patience: 2\n",
            "Epoch: 17 | train_loss: 0.00018, val_loss: 0.00163, lr: 3.53E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:24:31,299]\u001b[0m Trial 7 finished with value: 0.6192697172853014 and parameters: {'embedding_dim': 348, 'num_filters': 491, 'hidden_dim': 469, 'dropout_p': 0.3237240109912777, 'lr': 0.0003531960047242533}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00607, val_loss: 0.00298, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00439, val_loss: 0.00284, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00385, val_loss: 0.00267, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00373, val_loss: 0.00263, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00356, val_loss: 0.00259, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00337, val_loss: 0.00257, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00331, val_loss: 0.00252, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00321, val_loss: 0.00250, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00309, val_loss: 0.00245, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00299, val_loss: 0.00241, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00290, val_loss: 0.00236, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00278, val_loss: 0.00233, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00274, val_loss: 0.00227, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00267, val_loss: 0.00222, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00253, val_loss: 0.00218, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00248, val_loss: 0.00214, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00238, val_loss: 0.00209, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00229, val_loss: 0.00205, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00221, val_loss: 0.00200, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00216, val_loss: 0.00196, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00213, val_loss: 0.00195, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00206, val_loss: 0.00190, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00201, val_loss: 0.00187, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00195, val_loss: 0.00182, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00191, val_loss: 0.00181, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00186, val_loss: 0.00179, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00178, val_loss: 0.00175, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00176, val_loss: 0.00174, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00172, val_loss: 0.00172, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00167, val_loss: 0.00168, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00160, val_loss: 0.00167, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00161, val_loss: 0.00167, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00153, val_loss: 0.00169, lr: 6.83E-05, _patience: 9\n",
            "Epoch: 34 | train_loss: 0.00152, val_loss: 0.00168, lr: 6.83E-05, _patience: 8\n",
            "Epoch: 35 | train_loss: 0.00149, val_loss: 0.00163, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00141, val_loss: 0.00162, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00139, val_loss: 0.00160, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00138, val_loss: 0.00158, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00129, val_loss: 0.00156, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00133, val_loss: 0.00159, lr: 6.83E-05, _patience: 9\n",
            "Epoch: 41 | train_loss: 0.00129, val_loss: 0.00154, lr: 6.83E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00126, val_loss: 0.00158, lr: 6.83E-05, _patience: 9\n",
            "Epoch: 43 | train_loss: 0.00120, val_loss: 0.00158, lr: 6.83E-05, _patience: 8\n",
            "Epoch: 44 | train_loss: 0.00118, val_loss: 0.00156, lr: 6.83E-05, _patience: 7\n",
            "Epoch: 45 | train_loss: 0.00112, val_loss: 0.00156, lr: 6.83E-05, _patience: 6\n",
            "Epoch: 46 | train_loss: 0.00111, val_loss: 0.00155, lr: 6.83E-05, _patience: 5\n",
            "Epoch: 47 | train_loss: 0.00112, val_loss: 0.00156, lr: 6.83E-06, _patience: 4\n",
            "Epoch: 48 | train_loss: 0.00107, val_loss: 0.00151, lr: 6.83E-06, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00104, val_loss: 0.00150, lr: 6.83E-06, _patience: 10\n",
            "Epoch: 50 | train_loss: 0.00101, val_loss: 0.00149, lr: 6.83E-06, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00098, val_loss: 0.00149, lr: 6.83E-06, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00097, val_loss: 0.00150, lr: 6.83E-06, _patience: 9\n",
            "Epoch: 53 | train_loss: 0.00097, val_loss: 0.00149, lr: 6.83E-06, _patience: 8\n",
            "Epoch: 54 | train_loss: 0.00097, val_loss: 0.00148, lr: 6.83E-06, _patience: 10\n",
            "Epoch: 55 | train_loss: 0.00097, val_loss: 0.00150, lr: 6.83E-06, _patience: 9\n",
            "Epoch: 56 | train_loss: 0.00098, val_loss: 0.00148, lr: 6.83E-06, _patience: 8\n",
            "Epoch: 57 | train_loss: 0.00098, val_loss: 0.00148, lr: 6.83E-06, _patience: 7\n",
            "Epoch: 58 | train_loss: 0.00095, val_loss: 0.00148, lr: 6.83E-06, _patience: 6\n",
            "Epoch: 59 | train_loss: 0.00095, val_loss: 0.00149, lr: 6.83E-06, _patience: 5\n",
            "Epoch: 60 | train_loss: 0.00095, val_loss: 0.00148, lr: 6.83E-07, _patience: 4\n",
            "Epoch: 61 | train_loss: 0.00094, val_loss: 0.00149, lr: 6.83E-07, _patience: 3\n",
            "Epoch: 62 | train_loss: 0.00097, val_loss: 0.00149, lr: 6.83E-07, _patience: 2\n",
            "Epoch: 63 | train_loss: 0.00094, val_loss: 0.00148, lr: 6.83E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:26:22,151]\u001b[0m Trial 8 finished with value: 0.6108763592775784 and parameters: {'embedding_dim': 253, 'num_filters': 328, 'hidden_dim': 408, 'dropout_p': 0.7777311705930168, 'lr': 6.832647984912969e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00516, val_loss: 0.00294, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00355, val_loss: 0.00255, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00295, val_loss: 0.00228, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00255, val_loss: 0.00204, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00217, val_loss: 0.00186, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00192, val_loss: 0.00172, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00167, val_loss: 0.00163, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00150, val_loss: 0.00159, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00133, val_loss: 0.00153, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00114, val_loss: 0.00150, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00104, val_loss: 0.00158, lr: 3.75E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00096, val_loss: 0.00146, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00084, val_loss: 0.00138, lr: 3.75E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00077, val_loss: 0.00164, lr: 3.75E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00072, val_loss: 0.00166, lr: 3.75E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00067, val_loss: 0.00145, lr: 3.75E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00057, val_loss: 0.00151, lr: 3.75E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00055, val_loss: 0.00178, lr: 3.75E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00053, val_loss: 0.00184, lr: 3.75E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00041, val_loss: 0.00159, lr: 3.75E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00036, val_loss: 0.00163, lr: 3.75E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00036, val_loss: 0.00163, lr: 3.75E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:26:57,107]\u001b[0m Trial 9 finished with value: 0.6234037691090378 and parameters: {'embedding_dim': 349, 'num_filters': 198, 'hidden_dim': 345, 'dropout_p': 0.6460873154642797, 'lr': 0.00037533799205750044}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00502, val_loss: 0.00357, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00376, val_loss: 0.00254, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00312, val_loss: 0.00239, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00277, val_loss: 0.00226, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00254, val_loss: 0.00215, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00229, val_loss: 0.00201, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00206, val_loss: 0.00191, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00191, val_loss: 0.00183, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00176, val_loss: 0.00177, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00162, val_loss: 0.00171, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00149, val_loss: 0.00167, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00138, val_loss: 0.00161, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00128, val_loss: 0.00162, lr: 1.16E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00122, val_loss: 0.00156, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00113, val_loss: 0.00153, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00103, val_loss: 0.00156, lr: 1.16E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00096, val_loss: 0.00158, lr: 1.16E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00089, val_loss: 0.00151, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00085, val_loss: 0.00153, lr: 1.16E-04, _patience: 9\n",
            "Epoch: 20 | train_loss: 0.00079, val_loss: 0.00161, lr: 1.16E-04, _patience: 8\n",
            "Epoch: 21 | train_loss: 0.00077, val_loss: 0.00153, lr: 1.16E-04, _patience: 7\n",
            "Epoch: 22 | train_loss: 0.00070, val_loss: 0.00154, lr: 1.16E-04, _patience: 6\n",
            "Epoch: 23 | train_loss: 0.00065, val_loss: 0.00157, lr: 1.16E-04, _patience: 5\n",
            "Epoch: 24 | train_loss: 0.00062, val_loss: 0.00150, lr: 1.16E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00057, val_loss: 0.00156, lr: 1.16E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00055, val_loss: 0.00157, lr: 1.16E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00053, val_loss: 0.00158, lr: 1.16E-04, _patience: 7\n",
            "Epoch: 28 | train_loss: 0.00049, val_loss: 0.00159, lr: 1.16E-04, _patience: 6\n",
            "Epoch: 29 | train_loss: 0.00046, val_loss: 0.00167, lr: 1.16E-04, _patience: 5\n",
            "Epoch: 30 | train_loss: 0.00043, val_loss: 0.00162, lr: 1.16E-05, _patience: 4\n",
            "Epoch: 31 | train_loss: 0.00041, val_loss: 0.00152, lr: 1.16E-05, _patience: 3\n",
            "Epoch: 32 | train_loss: 0.00037, val_loss: 0.00149, lr: 1.16E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00036, val_loss: 0.00153, lr: 1.16E-05, _patience: 9\n",
            "Epoch: 34 | train_loss: 0.00036, val_loss: 0.00150, lr: 1.16E-05, _patience: 8\n",
            "Epoch: 35 | train_loss: 0.00036, val_loss: 0.00152, lr: 1.16E-05, _patience: 7\n",
            "Epoch: 36 | train_loss: 0.00035, val_loss: 0.00149, lr: 1.16E-05, _patience: 6\n",
            "Epoch: 37 | train_loss: 0.00035, val_loss: 0.00150, lr: 1.16E-05, _patience: 5\n",
            "Epoch: 38 | train_loss: 0.00034, val_loss: 0.00152, lr: 1.16E-06, _patience: 4\n",
            "Epoch: 39 | train_loss: 0.00034, val_loss: 0.00152, lr: 1.16E-06, _patience: 3\n",
            "Epoch: 40 | train_loss: 0.00034, val_loss: 0.00152, lr: 1.16E-06, _patience: 2\n",
            "Epoch: 41 | train_loss: 0.00034, val_loss: 0.00152, lr: 1.16E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:29:31,756]\u001b[0m Trial 10 finished with value: 0.613589545192708 and parameters: {'embedding_dim': 422, 'num_filters': 472, 'hidden_dim': 209, 'dropout_p': 0.46726696861633454, 'lr': 0.00011630657200822141}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00547, val_loss: 0.00337, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00389, val_loss: 0.00280, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00344, val_loss: 0.00265, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00323, val_loss: 0.00263, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00307, val_loss: 0.00257, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00299, val_loss: 0.00254, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00286, val_loss: 0.00248, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00279, val_loss: 0.00241, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00267, val_loss: 0.00234, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00253, val_loss: 0.00228, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00246, val_loss: 0.00220, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00236, val_loss: 0.00211, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00223, val_loss: 0.00204, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00214, val_loss: 0.00197, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00204, val_loss: 0.00191, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00190, val_loss: 0.00185, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00186, val_loss: 0.00179, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00176, val_loss: 0.00176, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00175, val_loss: 0.00171, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00163, val_loss: 0.00168, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00159, val_loss: 0.00165, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00153, val_loss: 0.00162, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00148, val_loss: 0.00162, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00142, val_loss: 0.00159, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00137, val_loss: 0.00156, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00132, val_loss: 0.00155, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00126, val_loss: 0.00153, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00121, val_loss: 0.00151, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00115, val_loss: 0.00151, lr: 1.71E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00114, val_loss: 0.00150, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00104, val_loss: 0.00150, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00101, val_loss: 0.00150, lr: 1.71E-04, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00102, val_loss: 0.00145, lr: 1.71E-04, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00096, val_loss: 0.00148, lr: 1.71E-04, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00091, val_loss: 0.00150, lr: 1.71E-04, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00090, val_loss: 0.00147, lr: 1.71E-04, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00085, val_loss: 0.00151, lr: 1.71E-04, _patience: 6\n",
            "Epoch: 38 | train_loss: 0.00084, val_loss: 0.00148, lr: 1.71E-04, _patience: 5\n",
            "Epoch: 39 | train_loss: 0.00081, val_loss: 0.00145, lr: 1.71E-05, _patience: 4\n",
            "Epoch: 40 | train_loss: 0.00076, val_loss: 0.00148, lr: 1.71E-05, _patience: 3\n",
            "Epoch: 41 | train_loss: 0.00074, val_loss: 0.00148, lr: 1.71E-05, _patience: 2\n",
            "Epoch: 42 | train_loss: 0.00072, val_loss: 0.00147, lr: 1.71E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:29:58,099]\u001b[0m Trial 11 finished with value: 0.620223524598196 and parameters: {'embedding_dim': 137, 'num_filters': 143, 'hidden_dim': 368, 'dropout_p': 0.6886516681899693, 'lr': 0.00017079279039926913}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00523, val_loss: 0.00321, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00372, val_loss: 0.00276, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00329, val_loss: 0.00258, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00310, val_loss: 0.00250, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00289, val_loss: 0.00242, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00272, val_loss: 0.00232, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00257, val_loss: 0.00222, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00242, val_loss: 0.00212, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00228, val_loss: 0.00203, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00215, val_loss: 0.00195, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00202, val_loss: 0.00189, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00191, val_loss: 0.00182, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00181, val_loss: 0.00176, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00174, val_loss: 0.00172, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00164, val_loss: 0.00171, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00156, val_loss: 0.00165, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00145, val_loss: 0.00162, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00142, val_loss: 0.00159, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00131, val_loss: 0.00157, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00126, val_loss: 0.00154, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00122, val_loss: 0.00153, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00115, val_loss: 0.00152, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00110, val_loss: 0.00150, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00103, val_loss: 0.00154, lr: 1.27E-04, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00101, val_loss: 0.00149, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00094, val_loss: 0.00150, lr: 1.27E-04, _patience: 9\n",
            "Epoch: 27 | train_loss: 0.00091, val_loss: 0.00150, lr: 1.27E-04, _patience: 8\n",
            "Epoch: 28 | train_loss: 0.00087, val_loss: 0.00147, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00084, val_loss: 0.00150, lr: 1.27E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00079, val_loss: 0.00143, lr: 1.27E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00076, val_loss: 0.00146, lr: 1.27E-04, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00070, val_loss: 0.00151, lr: 1.27E-04, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00069, val_loss: 0.00152, lr: 1.27E-04, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00066, val_loss: 0.00147, lr: 1.27E-04, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00064, val_loss: 0.00155, lr: 1.27E-04, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00060, val_loss: 0.00152, lr: 1.27E-05, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00057, val_loss: 0.00146, lr: 1.27E-05, _patience: 3\n",
            "Epoch: 38 | train_loss: 0.00055, val_loss: 0.00148, lr: 1.27E-05, _patience: 2\n",
            "Epoch: 39 | train_loss: 0.00053, val_loss: 0.00147, lr: 1.27E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:30:52,960]\u001b[0m Trial 12 finished with value: 0.6106677178035941 and parameters: {'embedding_dim': 373, 'num_filters': 152, 'hidden_dim': 358, 'dropout_p': 0.6470041972947153, 'lr': 0.00012694440239720563}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00520, val_loss: 0.00317, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00381, val_loss: 0.00285, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00329, val_loss: 0.00257, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00314, val_loss: 0.00249, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00290, val_loss: 0.00241, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00280, val_loss: 0.00233, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00258, val_loss: 0.00226, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00251, val_loss: 0.00219, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00235, val_loss: 0.00211, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00221, val_loss: 0.00204, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00212, val_loss: 0.00198, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00200, val_loss: 0.00192, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00190, val_loss: 0.00187, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00186, val_loss: 0.00182, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00177, val_loss: 0.00177, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00169, val_loss: 0.00174, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00162, val_loss: 0.00171, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00156, val_loss: 0.00167, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00147, val_loss: 0.00164, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00140, val_loss: 0.00162, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00133, val_loss: 0.00160, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00127, val_loss: 0.00157, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00124, val_loss: 0.00155, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00115, val_loss: 0.00155, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00112, val_loss: 0.00154, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00111, val_loss: 0.00150, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00105, val_loss: 0.00150, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00099, val_loss: 0.00148, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00095, val_loss: 0.00145, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00090, val_loss: 0.00149, lr: 6.22E-05, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00088, val_loss: 0.00149, lr: 6.22E-05, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00084, val_loss: 0.00147, lr: 6.22E-05, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00081, val_loss: 0.00145, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00079, val_loss: 0.00144, lr: 6.22E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00074, val_loss: 0.00149, lr: 6.22E-05, _patience: 9\n",
            "Epoch: 36 | train_loss: 0.00072, val_loss: 0.00147, lr: 6.22E-05, _patience: 8\n",
            "Epoch: 37 | train_loss: 0.00069, val_loss: 0.00149, lr: 6.22E-05, _patience: 7\n",
            "Epoch: 38 | train_loss: 0.00067, val_loss: 0.00147, lr: 6.22E-05, _patience: 6\n",
            "Epoch: 39 | train_loss: 0.00066, val_loss: 0.00150, lr: 6.22E-05, _patience: 5\n",
            "Epoch: 40 | train_loss: 0.00061, val_loss: 0.00151, lr: 6.22E-06, _patience: 4\n",
            "Epoch: 41 | train_loss: 0.00060, val_loss: 0.00146, lr: 6.22E-06, _patience: 3\n",
            "Epoch: 42 | train_loss: 0.00058, val_loss: 0.00146, lr: 6.22E-06, _patience: 2\n",
            "Epoch: 43 | train_loss: 0.00057, val_loss: 0.00146, lr: 6.22E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:33:20,596]\u001b[0m Trial 13 finished with value: 0.6279574067236847 and parameters: {'embedding_dim': 414, 'num_filters': 428, 'hidden_dim': 247, 'dropout_p': 0.5211395212444181, 'lr': 6.222263432497006e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00482, val_loss: 0.00305, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00355, val_loss: 0.00276, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00312, val_loss: 0.00254, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00290, val_loss: 0.00245, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00279, val_loss: 0.00238, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00261, val_loss: 0.00230, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00247, val_loss: 0.00221, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00234, val_loss: 0.00213, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00219, val_loss: 0.00205, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00207, val_loss: 0.00198, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00198, val_loss: 0.00191, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00185, val_loss: 0.00186, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00174, val_loss: 0.00181, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00166, val_loss: 0.00177, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00158, val_loss: 0.00172, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00148, val_loss: 0.00169, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00146, val_loss: 0.00165, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00136, val_loss: 0.00163, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00130, val_loss: 0.00159, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00123, val_loss: 0.00158, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00118, val_loss: 0.00158, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00112, val_loss: 0.00155, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00107, val_loss: 0.00153, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00104, val_loss: 0.00151, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00099, val_loss: 0.00151, lr: 5.73E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00096, val_loss: 0.00152, lr: 5.73E-05, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00091, val_loss: 0.00149, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00086, val_loss: 0.00148, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00082, val_loss: 0.00147, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00078, val_loss: 0.00147, lr: 5.73E-05, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00076, val_loss: 0.00148, lr: 5.73E-05, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00072, val_loss: 0.00147, lr: 5.73E-05, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00069, val_loss: 0.00146, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00065, val_loss: 0.00147, lr: 5.73E-05, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00064, val_loss: 0.00148, lr: 5.73E-05, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00061, val_loss: 0.00146, lr: 5.73E-05, _patience: 7\n",
            "Epoch: 37 | train_loss: 0.00058, val_loss: 0.00145, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00057, val_loss: 0.00147, lr: 5.73E-05, _patience: 9\n",
            "Epoch: 39 | train_loss: 0.00055, val_loss: 0.00148, lr: 5.73E-05, _patience: 8\n",
            "Epoch: 40 | train_loss: 0.00053, val_loss: 0.00152, lr: 5.73E-05, _patience: 7\n",
            "Epoch: 41 | train_loss: 0.00050, val_loss: 0.00147, lr: 5.73E-05, _patience: 6\n",
            "Epoch: 42 | train_loss: 0.00049, val_loss: 0.00143, lr: 5.73E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00046, val_loss: 0.00148, lr: 5.73E-05, _patience: 9\n",
            "Epoch: 44 | train_loss: 0.00045, val_loss: 0.00148, lr: 5.73E-05, _patience: 8\n",
            "Epoch: 45 | train_loss: 0.00043, val_loss: 0.00149, lr: 5.73E-05, _patience: 7\n",
            "Epoch: 46 | train_loss: 0.00042, val_loss: 0.00151, lr: 5.73E-05, _patience: 6\n",
            "Epoch: 47 | train_loss: 0.00041, val_loss: 0.00147, lr: 5.73E-05, _patience: 5\n",
            "Epoch: 48 | train_loss: 0.00037, val_loss: 0.00156, lr: 5.73E-06, _patience: 4\n",
            "Epoch: 49 | train_loss: 0.00037, val_loss: 0.00149, lr: 5.73E-06, _patience: 3\n",
            "Epoch: 50 | train_loss: 0.00036, val_loss: 0.00146, lr: 5.73E-06, _patience: 2\n",
            "Epoch: 51 | train_loss: 0.00035, val_loss: 0.00147, lr: 5.73E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:36:21,628]\u001b[0m Trial 14 finished with value: 0.5976185219764525 and parameters: {'embedding_dim': 427, 'num_filters': 432, 'hidden_dim': 253, 'dropout_p': 0.4196029080594468, 'lr': 5.7348897206446935e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00638, val_loss: 0.00283, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00411, val_loss: 0.00279, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00395, val_loss: 0.00271, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00374, val_loss: 0.00266, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00354, val_loss: 0.00264, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00342, val_loss: 0.00260, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00332, val_loss: 0.00259, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00325, val_loss: 0.00255, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00323, val_loss: 0.00252, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00314, val_loss: 0.00250, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00306, val_loss: 0.00247, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00291, val_loss: 0.00244, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00291, val_loss: 0.00242, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00281, val_loss: 0.00237, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00278, val_loss: 0.00234, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00272, val_loss: 0.00231, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00261, val_loss: 0.00227, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00256, val_loss: 0.00224, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00250, val_loss: 0.00221, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00244, val_loss: 0.00219, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00238, val_loss: 0.00215, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00235, val_loss: 0.00212, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00228, val_loss: 0.00208, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00221, val_loss: 0.00206, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00216, val_loss: 0.00203, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00213, val_loss: 0.00200, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00206, val_loss: 0.00198, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00204, val_loss: 0.00195, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00197, val_loss: 0.00193, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00193, val_loss: 0.00190, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00187, val_loss: 0.00188, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00185, val_loss: 0.00186, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00180, val_loss: 0.00184, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00176, val_loss: 0.00181, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00170, val_loss: 0.00179, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00171, val_loss: 0.00180, lr: 5.00E-05, _patience: 9\n",
            "Epoch: 37 | train_loss: 0.00165, val_loss: 0.00177, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00161, val_loss: 0.00175, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00161, val_loss: 0.00173, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00158, val_loss: 0.00172, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00151, val_loss: 0.00172, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00149, val_loss: 0.00168, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00148, val_loss: 0.00168, lr: 5.00E-05, _patience: 9\n",
            "Epoch: 44 | train_loss: 0.00144, val_loss: 0.00167, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00145, val_loss: 0.00166, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00138, val_loss: 0.00165, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00137, val_loss: 0.00163, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 48 | train_loss: 0.00131, val_loss: 0.00162, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00129, val_loss: 0.00160, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 50 | train_loss: 0.00126, val_loss: 0.00161, lr: 5.00E-05, _patience: 9\n",
            "Epoch: 51 | train_loss: 0.00128, val_loss: 0.00162, lr: 5.00E-05, _patience: 8\n",
            "Epoch: 52 | train_loss: 0.00125, val_loss: 0.00160, lr: 5.00E-05, _patience: 7\n",
            "Epoch: 53 | train_loss: 0.00120, val_loss: 0.00159, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 54 | train_loss: 0.00118, val_loss: 0.00157, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 55 | train_loss: 0.00116, val_loss: 0.00157, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 56 | train_loss: 0.00116, val_loss: 0.00159, lr: 5.00E-05, _patience: 9\n",
            "Epoch: 57 | train_loss: 0.00112, val_loss: 0.00158, lr: 5.00E-05, _patience: 8\n",
            "Epoch: 58 | train_loss: 0.00110, val_loss: 0.00158, lr: 5.00E-05, _patience: 7\n",
            "Epoch: 59 | train_loss: 0.00108, val_loss: 0.00156, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 60 | train_loss: 0.00107, val_loss: 0.00157, lr: 5.00E-05, _patience: 9\n",
            "Epoch: 61 | train_loss: 0.00104, val_loss: 0.00153, lr: 5.00E-05, _patience: 10\n",
            "Epoch: 62 | train_loss: 0.00101, val_loss: 0.00154, lr: 5.00E-05, _patience: 9\n",
            "Epoch: 63 | train_loss: 0.00099, val_loss: 0.00155, lr: 5.00E-05, _patience: 8\n",
            "Epoch: 64 | train_loss: 0.00098, val_loss: 0.00157, lr: 5.00E-05, _patience: 7\n",
            "Epoch: 65 | train_loss: 0.00096, val_loss: 0.00156, lr: 5.00E-05, _patience: 6\n",
            "Epoch: 66 | train_loss: 0.00097, val_loss: 0.00156, lr: 5.00E-05, _patience: 5\n",
            "Epoch: 67 | train_loss: 0.00094, val_loss: 0.00155, lr: 5.00E-06, _patience: 4\n",
            "Epoch: 68 | train_loss: 0.00091, val_loss: 0.00152, lr: 5.00E-06, _patience: 10\n",
            "Epoch: 69 | train_loss: 0.00092, val_loss: 0.00152, lr: 5.00E-06, _patience: 9\n",
            "Epoch: 70 | train_loss: 0.00090, val_loss: 0.00151, lr: 5.00E-06, _patience: 10\n",
            "Epoch: 71 | train_loss: 0.00092, val_loss: 0.00151, lr: 5.00E-06, _patience: 10\n",
            "Epoch: 72 | train_loss: 0.00090, val_loss: 0.00151, lr: 5.00E-06, _patience: 9\n",
            "Epoch: 73 | train_loss: 0.00090, val_loss: 0.00151, lr: 5.00E-06, _patience: 8\n",
            "Epoch: 74 | train_loss: 0.00088, val_loss: 0.00152, lr: 5.00E-06, _patience: 7\n",
            "Epoch: 75 | train_loss: 0.00089, val_loss: 0.00152, lr: 5.00E-06, _patience: 6\n",
            "Epoch: 76 | train_loss: 0.00085, val_loss: 0.00151, lr: 5.00E-06, _patience: 5\n",
            "Epoch: 77 | train_loss: 0.00086, val_loss: 0.00152, lr: 5.00E-07, _patience: 4\n",
            "Epoch: 78 | train_loss: 0.00088, val_loss: 0.00152, lr: 5.00E-07, _patience: 3\n",
            "Epoch: 79 | train_loss: 0.00087, val_loss: 0.00152, lr: 5.00E-07, _patience: 2\n",
            "Epoch: 80 | train_loss: 0.00087, val_loss: 0.00152, lr: 5.00E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:38:35,416]\u001b[0m Trial 15 finished with value: 0.588630937742142 and parameters: {'embedding_dim': 160, 'num_filters': 429, 'hidden_dim': 134, 'dropout_p': 0.49506477351048933, 'lr': 5.002909569318933e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00457, val_loss: 0.00343, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00340, val_loss: 0.00255, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00281, val_loss: 0.00241, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00260, val_loss: 0.00229, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00240, val_loss: 0.00214, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00216, val_loss: 0.00203, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00198, val_loss: 0.00193, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00184, val_loss: 0.00186, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00167, val_loss: 0.00178, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00155, val_loss: 0.00173, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00144, val_loss: 0.00168, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00136, val_loss: 0.00163, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00126, val_loss: 0.00161, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00117, val_loss: 0.00158, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00106, val_loss: 0.00155, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00100, val_loss: 0.00153, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00096, val_loss: 0.00152, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00086, val_loss: 0.00149, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00079, val_loss: 0.00147, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00077, val_loss: 0.00148, lr: 8.44E-05, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00071, val_loss: 0.00148, lr: 8.44E-05, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00066, val_loss: 0.00148, lr: 8.44E-05, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00063, val_loss: 0.00145, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00058, val_loss: 0.00147, lr: 8.44E-05, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00056, val_loss: 0.00146, lr: 8.44E-05, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00052, val_loss: 0.00146, lr: 8.44E-05, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00049, val_loss: 0.00146, lr: 8.44E-05, _patience: 6\n",
            "Epoch: 28 | train_loss: 0.00047, val_loss: 0.00143, lr: 8.44E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00044, val_loss: 0.00143, lr: 8.44E-05, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00042, val_loss: 0.00149, lr: 8.44E-05, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00039, val_loss: 0.00149, lr: 8.44E-05, _patience: 7\n",
            "Epoch: 32 | train_loss: 0.00036, val_loss: 0.00146, lr: 8.44E-05, _patience: 6\n",
            "Epoch: 33 | train_loss: 0.00035, val_loss: 0.00148, lr: 8.44E-05, _patience: 5\n",
            "Epoch: 34 | train_loss: 0.00033, val_loss: 0.00154, lr: 8.44E-06, _patience: 4\n",
            "Epoch: 35 | train_loss: 0.00031, val_loss: 0.00150, lr: 8.44E-06, _patience: 3\n",
            "Epoch: 36 | train_loss: 0.00029, val_loss: 0.00150, lr: 8.44E-06, _patience: 2\n",
            "Epoch: 37 | train_loss: 0.00030, val_loss: 0.00151, lr: 8.44E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:41:08,219]\u001b[0m Trial 16 finished with value: 0.6216712178901085 and parameters: {'embedding_dim': 439, 'num_filters': 504, 'hidden_dim': 245, 'dropout_p': 0.33316417100503204, 'lr': 8.44088067552889e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00482, val_loss: 0.00318, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00356, val_loss: 0.00282, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00314, val_loss: 0.00263, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00302, val_loss: 0.00257, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00287, val_loss: 0.00252, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00279, val_loss: 0.00246, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00265, val_loss: 0.00240, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00258, val_loss: 0.00233, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00249, val_loss: 0.00226, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00233, val_loss: 0.00219, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00225, val_loss: 0.00213, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00216, val_loss: 0.00207, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00205, val_loss: 0.00200, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00198, val_loss: 0.00194, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00188, val_loss: 0.00191, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00182, val_loss: 0.00184, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00174, val_loss: 0.00180, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00163, val_loss: 0.00177, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00160, val_loss: 0.00173, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00153, val_loss: 0.00171, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00148, val_loss: 0.00168, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00143, val_loss: 0.00165, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00137, val_loss: 0.00163, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00131, val_loss: 0.00160, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00123, val_loss: 0.00159, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00120, val_loss: 0.00158, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00116, val_loss: 0.00157, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00111, val_loss: 0.00155, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00107, val_loss: 0.00156, lr: 7.25E-05, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00103, val_loss: 0.00153, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00099, val_loss: 0.00152, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00094, val_loss: 0.00150, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00092, val_loss: 0.00148, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00088, val_loss: 0.00148, lr: 7.25E-05, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00085, val_loss: 0.00149, lr: 7.25E-05, _patience: 8\n",
            "Epoch: 36 | train_loss: 0.00082, val_loss: 0.00148, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00079, val_loss: 0.00149, lr: 7.25E-05, _patience: 9\n",
            "Epoch: 38 | train_loss: 0.00076, val_loss: 0.00147, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00071, val_loss: 0.00149, lr: 7.25E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00069, val_loss: 0.00150, lr: 7.25E-05, _patience: 8\n",
            "Epoch: 41 | train_loss: 0.00067, val_loss: 0.00150, lr: 7.25E-05, _patience: 7\n",
            "Epoch: 42 | train_loss: 0.00066, val_loss: 0.00147, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00063, val_loss: 0.00147, lr: 7.25E-05, _patience: 10\n",
            "Epoch: 44 | train_loss: 0.00060, val_loss: 0.00148, lr: 7.25E-05, _patience: 9\n",
            "Epoch: 45 | train_loss: 0.00059, val_loss: 0.00152, lr: 7.25E-05, _patience: 8\n",
            "Epoch: 46 | train_loss: 0.00057, val_loss: 0.00150, lr: 7.25E-05, _patience: 7\n",
            "Epoch: 47 | train_loss: 0.00055, val_loss: 0.00151, lr: 7.25E-05, _patience: 6\n",
            "Epoch: 48 | train_loss: 0.00053, val_loss: 0.00149, lr: 7.25E-05, _patience: 5\n",
            "Epoch: 49 | train_loss: 0.00052, val_loss: 0.00149, lr: 7.25E-06, _patience: 4\n",
            "Epoch: 50 | train_loss: 0.00048, val_loss: 0.00146, lr: 7.25E-06, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00048, val_loss: 0.00145, lr: 7.25E-06, _patience: 10\n",
            "Epoch: 52 | train_loss: 0.00048, val_loss: 0.00145, lr: 7.25E-06, _patience: 10\n",
            "Epoch: 53 | train_loss: 0.00048, val_loss: 0.00144, lr: 7.25E-06, _patience: 10\n",
            "Epoch: 54 | train_loss: 0.00048, val_loss: 0.00145, lr: 7.25E-06, _patience: 9\n",
            "Epoch: 55 | train_loss: 0.00045, val_loss: 0.00146, lr: 7.25E-06, _patience: 8\n",
            "Epoch: 56 | train_loss: 0.00047, val_loss: 0.00144, lr: 7.25E-06, _patience: 10\n",
            "Epoch: 57 | train_loss: 0.00047, val_loss: 0.00145, lr: 7.25E-06, _patience: 9\n",
            "Epoch: 58 | train_loss: 0.00046, val_loss: 0.00145, lr: 7.25E-06, _patience: 8\n",
            "Epoch: 59 | train_loss: 0.00046, val_loss: 0.00145, lr: 7.25E-06, _patience: 7\n",
            "Epoch: 60 | train_loss: 0.00045, val_loss: 0.00146, lr: 7.25E-06, _patience: 6\n",
            "Epoch: 61 | train_loss: 0.00045, val_loss: 0.00144, lr: 7.25E-06, _patience: 10\n",
            "Epoch: 62 | train_loss: 0.00045, val_loss: 0.00146, lr: 7.25E-06, _patience: 9\n",
            "Epoch: 63 | train_loss: 0.00046, val_loss: 0.00145, lr: 7.25E-06, _patience: 8\n",
            "Epoch: 64 | train_loss: 0.00045, val_loss: 0.00145, lr: 7.25E-06, _patience: 7\n",
            "Epoch: 65 | train_loss: 0.00043, val_loss: 0.00146, lr: 7.25E-06, _patience: 6\n",
            "Epoch: 66 | train_loss: 0.00045, val_loss: 0.00146, lr: 7.25E-06, _patience: 5\n",
            "Epoch: 67 | train_loss: 0.00045, val_loss: 0.00146, lr: 7.25E-07, _patience: 4\n",
            "Epoch: 68 | train_loss: 0.00043, val_loss: 0.00146, lr: 7.25E-07, _patience: 3\n",
            "Epoch: 69 | train_loss: 0.00044, val_loss: 0.00146, lr: 7.25E-07, _patience: 2\n",
            "Epoch: 70 | train_loss: 0.00044, val_loss: 0.00146, lr: 7.25E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:43:03,070]\u001b[0m Trial 17 finished with value: 0.6256245453199515 and parameters: {'embedding_dim': 190, 'num_filters': 384, 'hidden_dim': 290, 'dropout_p': 0.43895128439506387, 'lr': 7.247600131882984e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00543, val_loss: 0.00349, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00413, val_loss: 0.00262, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00347, val_loss: 0.00251, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00313, val_loss: 0.00243, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00293, val_loss: 0.00232, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00273, val_loss: 0.00223, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00254, val_loss: 0.00212, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00234, val_loss: 0.00204, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00219, val_loss: 0.00198, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00208, val_loss: 0.00190, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00195, val_loss: 0.00184, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00179, val_loss: 0.00177, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00167, val_loss: 0.00171, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00164, val_loss: 0.00168, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00152, val_loss: 0.00166, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00143, val_loss: 0.00161, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00135, val_loss: 0.00158, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00126, val_loss: 0.00157, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00119, val_loss: 0.00155, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00113, val_loss: 0.00154, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00107, val_loss: 0.00152, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00103, val_loss: 0.00151, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00097, val_loss: 0.00151, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00092, val_loss: 0.00149, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00087, val_loss: 0.00153, lr: 1.19E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00084, val_loss: 0.00160, lr: 1.19E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00084, val_loss: 0.00148, lr: 1.19E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00076, val_loss: 0.00154, lr: 1.19E-04, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00072, val_loss: 0.00156, lr: 1.19E-04, _patience: 8\n",
            "Epoch: 30 | train_loss: 0.00069, val_loss: 0.00148, lr: 1.19E-04, _patience: 7\n",
            "Epoch: 31 | train_loss: 0.00065, val_loss: 0.00152, lr: 1.19E-04, _patience: 6\n",
            "Epoch: 32 | train_loss: 0.00063, val_loss: 0.00155, lr: 1.19E-04, _patience: 5\n",
            "Epoch: 33 | train_loss: 0.00060, val_loss: 0.00160, lr: 1.19E-05, _patience: 4\n",
            "Epoch: 34 | train_loss: 0.00058, val_loss: 0.00150, lr: 1.19E-05, _patience: 3\n",
            "Epoch: 35 | train_loss: 0.00054, val_loss: 0.00151, lr: 1.19E-05, _patience: 2\n",
            "Epoch: 36 | train_loss: 0.00050, val_loss: 0.00150, lr: 1.19E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:44:43,481]\u001b[0m Trial 18 finished with value: 0.6016148050439399 and parameters: {'embedding_dim': 307, 'num_filters': 449, 'hidden_dim': 212, 'dropout_p': 0.565978646576953, 'lr': 0.0001187049335068029}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00551, val_loss: 0.00346, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00385, val_loss: 0.00256, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00323, val_loss: 0.00236, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00283, val_loss: 0.00218, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00254, val_loss: 0.00204, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00222, val_loss: 0.00188, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00200, val_loss: 0.00180, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00184, val_loss: 0.00173, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00169, val_loss: 0.00165, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00152, val_loss: 0.00162, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00141, val_loss: 0.00165, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00128, val_loss: 0.00160, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00117, val_loss: 0.00158, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00109, val_loss: 0.00149, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00101, val_loss: 0.00149, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00094, val_loss: 0.00153, lr: 2.21E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00088, val_loss: 0.00151, lr: 2.21E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00078, val_loss: 0.00149, lr: 2.21E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00082, val_loss: 0.00144, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00072, val_loss: 0.00148, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00069, val_loss: 0.00164, lr: 2.21E-04, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00064, val_loss: 0.00167, lr: 2.21E-04, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00062, val_loss: 0.00153, lr: 2.21E-04, _patience: 6\n",
            "Epoch: 24 | train_loss: 0.00059, val_loss: 0.00142, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00059, val_loss: 0.00146, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00059, val_loss: 0.00181, lr: 2.21E-04, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00060, val_loss: 0.00205, lr: 2.21E-04, _patience: 7\n",
            "Epoch: 28 | train_loss: 0.00065, val_loss: 0.00178, lr: 2.21E-04, _patience: 6\n",
            "Epoch: 29 | train_loss: 0.00064, val_loss: 0.00140, lr: 2.21E-04, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00060, val_loss: 0.00182, lr: 2.21E-04, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00050, val_loss: 0.00186, lr: 2.21E-04, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00046, val_loss: 0.00158, lr: 2.21E-04, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00041, val_loss: 0.00194, lr: 2.21E-04, _patience: 6\n",
            "Epoch: 34 | train_loss: 0.00040, val_loss: 0.00158, lr: 2.21E-04, _patience: 5\n",
            "Epoch: 35 | train_loss: 0.00038, val_loss: 0.00162, lr: 2.21E-05, _patience: 4\n",
            "Epoch: 36 | train_loss: 0.00032, val_loss: 0.00172, lr: 2.21E-05, _patience: 3\n",
            "Epoch: 37 | train_loss: 0.00027, val_loss: 0.00166, lr: 2.21E-05, _patience: 2\n",
            "Epoch: 38 | train_loss: 0.00026, val_loss: 0.00166, lr: 2.21E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:46:22,484]\u001b[0m Trial 19 finished with value: 0.6022914908842414 and parameters: {'embedding_dim': 393, 'num_filters': 320, 'hidden_dim': 156, 'dropout_p': 0.5337138156050187, 'lr': 0.00022068839010259318}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00456, val_loss: 0.00313, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00329, val_loss: 0.00277, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00289, val_loss: 0.00255, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00273, val_loss: 0.00247, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00258, val_loss: 0.00240, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00249, val_loss: 0.00231, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00232, val_loss: 0.00223, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00219, val_loss: 0.00215, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00207, val_loss: 0.00207, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00193, val_loss: 0.00199, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00185, val_loss: 0.00193, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00175, val_loss: 0.00187, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00166, val_loss: 0.00182, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00157, val_loss: 0.00177, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00151, val_loss: 0.00173, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00142, val_loss: 0.00169, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00136, val_loss: 0.00167, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00130, val_loss: 0.00164, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00123, val_loss: 0.00163, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00118, val_loss: 0.00160, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00112, val_loss: 0.00157, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00109, val_loss: 0.00156, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00101, val_loss: 0.00154, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00098, val_loss: 0.00153, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00094, val_loss: 0.00151, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00089, val_loss: 0.00150, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00085, val_loss: 0.00149, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00080, val_loss: 0.00148, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00076, val_loss: 0.00147, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00075, val_loss: 0.00146, lr: 5.01E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00070, val_loss: 0.00147, lr: 5.01E-05, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00069, val_loss: 0.00147, lr: 5.01E-05, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00065, val_loss: 0.00149, lr: 5.01E-05, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00062, val_loss: 0.00148, lr: 5.01E-05, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00059, val_loss: 0.00146, lr: 5.01E-05, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00057, val_loss: 0.00146, lr: 5.01E-06, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00053, val_loss: 0.00145, lr: 5.01E-06, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00053, val_loss: 0.00146, lr: 5.01E-06, _patience: 9\n",
            "Epoch: 39 | train_loss: 0.00053, val_loss: 0.00146, lr: 5.01E-06, _patience: 8\n",
            "Epoch: 40 | train_loss: 0.00054, val_loss: 0.00145, lr: 5.01E-06, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00052, val_loss: 0.00145, lr: 5.01E-06, _patience: 9\n",
            "Epoch: 42 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.01E-06, _patience: 8\n",
            "Epoch: 43 | train_loss: 0.00052, val_loss: 0.00145, lr: 5.01E-06, _patience: 7\n",
            "Epoch: 44 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.01E-06, _patience: 6\n",
            "Epoch: 45 | train_loss: 0.00049, val_loss: 0.00146, lr: 5.01E-06, _patience: 5\n",
            "Epoch: 46 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.01E-06, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00051, val_loss: 0.00145, lr: 5.01E-06, _patience: 9\n",
            "Epoch: 48 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.01E-06, _patience: 8\n",
            "Epoch: 49 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.01E-06, _patience: 7\n",
            "Epoch: 50 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.01E-06, _patience: 6\n",
            "Epoch: 51 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.01E-06, _patience: 5\n",
            "Epoch: 52 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.01E-07, _patience: 4\n",
            "Epoch: 53 | train_loss: 0.00048, val_loss: 0.00145, lr: 5.01E-07, _patience: 3\n",
            "Epoch: 54 | train_loss: 0.00048, val_loss: 0.00145, lr: 5.01E-07, _patience: 2\n",
            "Epoch: 55 | train_loss: 0.00049, val_loss: 0.00145, lr: 5.01E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:49:41,142]\u001b[0m Trial 20 finished with value: 0.6133433874621202 and parameters: {'embedding_dim': 466, 'num_filters': 394, 'hidden_dim': 336, 'dropout_p': 0.3669751698791388, 'lr': 5.01324675612915e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00492, val_loss: 0.00339, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00367, val_loss: 0.00278, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00315, val_loss: 0.00260, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00299, val_loss: 0.00254, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00288, val_loss: 0.00247, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00269, val_loss: 0.00240, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00260, val_loss: 0.00232, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00246, val_loss: 0.00223, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00233, val_loss: 0.00216, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00218, val_loss: 0.00208, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00209, val_loss: 0.00201, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00198, val_loss: 0.00194, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00185, val_loss: 0.00189, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00180, val_loss: 0.00183, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00170, val_loss: 0.00179, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00161, val_loss: 0.00176, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00155, val_loss: 0.00170, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00144, val_loss: 0.00167, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00141, val_loss: 0.00164, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00133, val_loss: 0.00162, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00126, val_loss: 0.00160, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00123, val_loss: 0.00157, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00115, val_loss: 0.00157, lr: 9.09E-05, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00113, val_loss: 0.00153, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00109, val_loss: 0.00153, lr: 9.09E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00102, val_loss: 0.00154, lr: 9.09E-05, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00100, val_loss: 0.00151, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00092, val_loss: 0.00149, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00089, val_loss: 0.00148, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00085, val_loss: 0.00150, lr: 9.09E-05, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00081, val_loss: 0.00149, lr: 9.09E-05, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00080, val_loss: 0.00149, lr: 9.09E-05, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00075, val_loss: 0.00144, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00071, val_loss: 0.00143, lr: 9.09E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00068, val_loss: 0.00150, lr: 9.09E-05, _patience: 9\n",
            "Epoch: 36 | train_loss: 0.00065, val_loss: 0.00150, lr: 9.09E-05, _patience: 8\n",
            "Epoch: 37 | train_loss: 0.00063, val_loss: 0.00147, lr: 9.09E-05, _patience: 7\n",
            "Epoch: 38 | train_loss: 0.00060, val_loss: 0.00150, lr: 9.09E-05, _patience: 6\n",
            "Epoch: 39 | train_loss: 0.00057, val_loss: 0.00150, lr: 9.09E-05, _patience: 5\n",
            "Epoch: 40 | train_loss: 0.00054, val_loss: 0.00147, lr: 9.09E-06, _patience: 4\n",
            "Epoch: 41 | train_loss: 0.00054, val_loss: 0.00144, lr: 9.09E-06, _patience: 3\n",
            "Epoch: 42 | train_loss: 0.00050, val_loss: 0.00145, lr: 9.09E-06, _patience: 2\n",
            "Epoch: 43 | train_loss: 0.00049, val_loss: 0.00146, lr: 9.09E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:50:58,885]\u001b[0m Trial 21 finished with value: 0.6156978250604856 and parameters: {'embedding_dim': 198, 'num_filters': 386, 'hidden_dim': 281, 'dropout_p': 0.45112984549638313, 'lr': 9.093469111264484e-05}. Best is trial 5 with value: 0.6283134076800848.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00495, val_loss: 0.00300, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00348, val_loss: 0.00288, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00316, val_loss: 0.00264, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00303, val_loss: 0.00259, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00291, val_loss: 0.00254, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00283, val_loss: 0.00250, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00271, val_loss: 0.00244, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00262, val_loss: 0.00238, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00249, val_loss: 0.00233, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00244, val_loss: 0.00226, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00231, val_loss: 0.00221, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00223, val_loss: 0.00214, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00215, val_loss: 0.00208, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00206, val_loss: 0.00204, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00198, val_loss: 0.00198, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00191, val_loss: 0.00194, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00181, val_loss: 0.00189, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00176, val_loss: 0.00185, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00166, val_loss: 0.00182, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00161, val_loss: 0.00178, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00157, val_loss: 0.00175, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00152, val_loss: 0.00172, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00145, val_loss: 0.00169, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00139, val_loss: 0.00168, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00135, val_loss: 0.00167, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00130, val_loss: 0.00162, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00127, val_loss: 0.00162, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00122, val_loss: 0.00160, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00117, val_loss: 0.00159, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00113, val_loss: 0.00157, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00110, val_loss: 0.00157, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00106, val_loss: 0.00154, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00101, val_loss: 0.00152, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00098, val_loss: 0.00153, lr: 6.63E-05, _patience: 9\n",
            "Epoch: 35 | train_loss: 0.00094, val_loss: 0.00150, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00092, val_loss: 0.00151, lr: 6.63E-05, _patience: 9\n",
            "Epoch: 37 | train_loss: 0.00090, val_loss: 0.00152, lr: 6.63E-05, _patience: 8\n",
            "Epoch: 38 | train_loss: 0.00086, val_loss: 0.00149, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00083, val_loss: 0.00149, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00079, val_loss: 0.00149, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00078, val_loss: 0.00150, lr: 6.63E-05, _patience: 9\n",
            "Epoch: 42 | train_loss: 0.00075, val_loss: 0.00148, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00073, val_loss: 0.00146, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 44 | train_loss: 0.00071, val_loss: 0.00147, lr: 6.63E-05, _patience: 9\n",
            "Epoch: 45 | train_loss: 0.00068, val_loss: 0.00146, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00066, val_loss: 0.00146, lr: 6.63E-05, _patience: 9\n",
            "Epoch: 47 | train_loss: 0.00064, val_loss: 0.00149, lr: 6.63E-05, _patience: 8\n",
            "Epoch: 48 | train_loss: 0.00062, val_loss: 0.00146, lr: 6.63E-05, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00058, val_loss: 0.00148, lr: 6.63E-05, _patience: 9\n",
            "Epoch: 50 | train_loss: 0.00057, val_loss: 0.00147, lr: 6.63E-05, _patience: 8\n",
            "Epoch: 51 | train_loss: 0.00056, val_loss: 0.00150, lr: 6.63E-05, _patience: 7\n",
            "Epoch: 52 | train_loss: 0.00054, val_loss: 0.00151, lr: 6.63E-05, _patience: 6\n",
            "Epoch: 53 | train_loss: 0.00052, val_loss: 0.00152, lr: 6.63E-05, _patience: 5\n",
            "Epoch: 54 | train_loss: 0.00051, val_loss: 0.00151, lr: 6.63E-06, _patience: 4\n",
            "Epoch: 55 | train_loss: 0.00050, val_loss: 0.00145, lr: 6.63E-06, _patience: 10\n",
            "Epoch: 56 | train_loss: 0.00048, val_loss: 0.00146, lr: 6.63E-06, _patience: 9\n",
            "Epoch: 57 | train_loss: 0.00048, val_loss: 0.00147, lr: 6.63E-06, _patience: 8\n",
            "Epoch: 58 | train_loss: 0.00047, val_loss: 0.00147, lr: 6.63E-06, _patience: 7\n",
            "Epoch: 59 | train_loss: 0.00048, val_loss: 0.00146, lr: 6.63E-06, _patience: 6\n",
            "Epoch: 60 | train_loss: 0.00046, val_loss: 0.00146, lr: 6.63E-06, _patience: 5\n",
            "Epoch: 61 | train_loss: 0.00047, val_loss: 0.00146, lr: 6.63E-07, _patience: 4\n",
            "Epoch: 62 | train_loss: 0.00046, val_loss: 0.00146, lr: 6.63E-07, _patience: 3\n",
            "Epoch: 63 | train_loss: 0.00047, val_loss: 0.00146, lr: 6.63E-07, _patience: 2\n",
            "Epoch: 64 | train_loss: 0.00046, val_loss: 0.00146, lr: 6.63E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:52:45,358]\u001b[0m Trial 22 finished with value: 0.6295833361573554 and parameters: {'embedding_dim': 199, 'num_filters': 361, 'hidden_dim': 226, 'dropout_p': 0.38395133480652704, 'lr': 6.627650509930262e-05}. Best is trial 22 with value: 0.6295833361573554.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00478, val_loss: 0.00319, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00354, val_loss: 0.00281, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00311, val_loss: 0.00258, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00293, val_loss: 0.00250, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00279, val_loss: 0.00243, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00266, val_loss: 0.00234, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00250, val_loss: 0.00227, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00239, val_loss: 0.00219, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00228, val_loss: 0.00211, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00214, val_loss: 0.00205, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00201, val_loss: 0.00197, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00193, val_loss: 0.00191, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00185, val_loss: 0.00186, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00175, val_loss: 0.00180, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00165, val_loss: 0.00177, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00158, val_loss: 0.00173, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00152, val_loss: 0.00169, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00145, val_loss: 0.00168, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00138, val_loss: 0.00164, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00133, val_loss: 0.00162, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00129, val_loss: 0.00159, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00120, val_loss: 0.00158, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00114, val_loss: 0.00156, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00111, val_loss: 0.00153, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00106, val_loss: 0.00153, lr: 6.24E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00104, val_loss: 0.00151, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00098, val_loss: 0.00148, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00094, val_loss: 0.00150, lr: 6.24E-05, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00092, val_loss: 0.00148, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00086, val_loss: 0.00148, lr: 6.24E-05, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00080, val_loss: 0.00145, lr: 6.24E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00078, val_loss: 0.00147, lr: 6.24E-05, _patience: 9\n",
            "Epoch: 33 | train_loss: 0.00078, val_loss: 0.00148, lr: 6.24E-05, _patience: 8\n",
            "Epoch: 34 | train_loss: 0.00073, val_loss: 0.00149, lr: 6.24E-05, _patience: 7\n",
            "Epoch: 35 | train_loss: 0.00071, val_loss: 0.00146, lr: 6.24E-05, _patience: 6\n",
            "Epoch: 36 | train_loss: 0.00068, val_loss: 0.00146, lr: 6.24E-05, _patience: 5\n",
            "Epoch: 37 | train_loss: 0.00063, val_loss: 0.00147, lr: 6.24E-06, _patience: 4\n",
            "Epoch: 38 | train_loss: 0.00061, val_loss: 0.00145, lr: 6.24E-06, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00059, val_loss: 0.00142, lr: 6.24E-06, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00061, val_loss: 0.00143, lr: 6.24E-06, _patience: 9\n",
            "Epoch: 41 | train_loss: 0.00059, val_loss: 0.00144, lr: 6.24E-06, _patience: 8\n",
            "Epoch: 42 | train_loss: 0.00060, val_loss: 0.00143, lr: 6.24E-06, _patience: 7\n",
            "Epoch: 43 | train_loss: 0.00058, val_loss: 0.00143, lr: 6.24E-06, _patience: 6\n",
            "Epoch: 44 | train_loss: 0.00058, val_loss: 0.00144, lr: 6.24E-06, _patience: 5\n",
            "Epoch: 45 | train_loss: 0.00057, val_loss: 0.00144, lr: 6.24E-07, _patience: 4\n",
            "Epoch: 46 | train_loss: 0.00058, val_loss: 0.00144, lr: 6.24E-07, _patience: 3\n",
            "Epoch: 47 | train_loss: 0.00056, val_loss: 0.00144, lr: 6.24E-07, _patience: 2\n",
            "Epoch: 48 | train_loss: 0.00058, val_loss: 0.00144, lr: 6.24E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:55:00,815]\u001b[0m Trial 23 finished with value: 0.6326352768602452 and parameters: {'embedding_dim': 310, 'num_filters': 463, 'hidden_dim': 234, 'dropout_p': 0.3927827690742737, 'lr': 6.236665971406469e-05}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00467, val_loss: 0.00327, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00355, val_loss: 0.00274, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00303, val_loss: 0.00252, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00284, val_loss: 0.00243, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00268, val_loss: 0.00234, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00252, val_loss: 0.00225, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00233, val_loss: 0.00215, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00221, val_loss: 0.00207, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00203, val_loss: 0.00198, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00193, val_loss: 0.00191, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00184, val_loss: 0.00184, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00171, val_loss: 0.00180, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00161, val_loss: 0.00174, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00155, val_loss: 0.00172, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00146, val_loss: 0.00167, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00139, val_loss: 0.00166, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00129, val_loss: 0.00161, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00125, val_loss: 0.00159, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00120, val_loss: 0.00158, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00113, val_loss: 0.00155, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00105, val_loss: 0.00154, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00099, val_loss: 0.00151, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00093, val_loss: 0.00149, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00091, val_loss: 0.00149, lr: 7.80E-05, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00086, val_loss: 0.00148, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00082, val_loss: 0.00148, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00077, val_loss: 0.00149, lr: 7.80E-05, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00073, val_loss: 0.00147, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00069, val_loss: 0.00145, lr: 7.80E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00066, val_loss: 0.00147, lr: 7.80E-05, _patience: 9\n",
            "Epoch: 31 | train_loss: 0.00064, val_loss: 0.00150, lr: 7.80E-05, _patience: 8\n",
            "Epoch: 32 | train_loss: 0.00061, val_loss: 0.00150, lr: 7.80E-05, _patience: 7\n",
            "Epoch: 33 | train_loss: 0.00056, val_loss: 0.00151, lr: 7.80E-05, _patience: 6\n",
            "Epoch: 34 | train_loss: 0.00055, val_loss: 0.00151, lr: 7.80E-05, _patience: 5\n",
            "Epoch: 35 | train_loss: 0.00051, val_loss: 0.00147, lr: 7.80E-06, _patience: 4\n",
            "Epoch: 36 | train_loss: 0.00049, val_loss: 0.00144, lr: 7.80E-06, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00048, val_loss: 0.00142, lr: 7.80E-06, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00047, val_loss: 0.00144, lr: 7.80E-06, _patience: 9\n",
            "Epoch: 39 | train_loss: 0.00046, val_loss: 0.00144, lr: 7.80E-06, _patience: 8\n",
            "Epoch: 40 | train_loss: 0.00048, val_loss: 0.00143, lr: 7.80E-06, _patience: 7\n",
            "Epoch: 41 | train_loss: 0.00046, val_loss: 0.00144, lr: 7.80E-06, _patience: 6\n",
            "Epoch: 42 | train_loss: 0.00045, val_loss: 0.00144, lr: 7.80E-06, _patience: 5\n",
            "Epoch: 43 | train_loss: 0.00045, val_loss: 0.00144, lr: 7.80E-07, _patience: 4\n",
            "Epoch: 44 | train_loss: 0.00046, val_loss: 0.00144, lr: 7.80E-07, _patience: 3\n",
            "Epoch: 45 | train_loss: 0.00045, val_loss: 0.00144, lr: 7.80E-07, _patience: 2\n",
            "Epoch: 46 | train_loss: 0.00045, val_loss: 0.00144, lr: 7.80E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:57:12,633]\u001b[0m Trial 24 finished with value: 0.608032511726312 and parameters: {'embedding_dim': 305, 'num_filters': 473, 'hidden_dim': 218, 'dropout_p': 0.361930117375403, 'lr': 7.801541158662451e-05}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00480, val_loss: 0.00343, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00371, val_loss: 0.00264, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00316, val_loss: 0.00256, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00293, val_loss: 0.00246, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00273, val_loss: 0.00238, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00256, val_loss: 0.00228, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00237, val_loss: 0.00217, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00221, val_loss: 0.00206, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00209, val_loss: 0.00196, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00193, val_loss: 0.00189, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00181, val_loss: 0.00182, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00169, val_loss: 0.00177, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00162, val_loss: 0.00173, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00150, val_loss: 0.00168, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00144, val_loss: 0.00164, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00138, val_loss: 0.00162, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00129, val_loss: 0.00159, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00120, val_loss: 0.00156, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00114, val_loss: 0.00155, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00108, val_loss: 0.00154, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00103, val_loss: 0.00152, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00096, val_loss: 0.00152, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00090, val_loss: 0.00151, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00085, val_loss: 0.00149, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00081, val_loss: 0.00150, lr: 1.33E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00077, val_loss: 0.00146, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00072, val_loss: 0.00149, lr: 1.33E-04, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00069, val_loss: 0.00151, lr: 1.33E-04, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00069, val_loss: 0.00151, lr: 1.33E-04, _patience: 7\n",
            "Epoch: 30 | train_loss: 0.00064, val_loss: 0.00143, lr: 1.33E-04, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00061, val_loss: 0.00153, lr: 1.33E-04, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00057, val_loss: 0.00147, lr: 1.33E-04, _patience: 8\n",
            "Epoch: 33 | train_loss: 0.00056, val_loss: 0.00144, lr: 1.33E-04, _patience: 7\n",
            "Epoch: 34 | train_loss: 0.00054, val_loss: 0.00149, lr: 1.33E-04, _patience: 6\n",
            "Epoch: 35 | train_loss: 0.00050, val_loss: 0.00149, lr: 1.33E-04, _patience: 5\n",
            "Epoch: 36 | train_loss: 0.00048, val_loss: 0.00148, lr: 1.33E-05, _patience: 4\n",
            "Epoch: 37 | train_loss: 0.00045, val_loss: 0.00148, lr: 1.33E-05, _patience: 3\n",
            "Epoch: 38 | train_loss: 0.00041, val_loss: 0.00147, lr: 1.33E-05, _patience: 2\n",
            "Epoch: 39 | train_loss: 0.00041, val_loss: 0.00148, lr: 1.33E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:58:19,525]\u001b[0m Trial 25 finished with value: 0.6024737735659212 and parameters: {'embedding_dim': 207, 'num_filters': 355, 'hidden_dim': 166, 'dropout_p': 0.3867182991634074, 'lr': 0.00013272111786527294}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00488, val_loss: 0.00367, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00362, val_loss: 0.00262, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00308, val_loss: 0.00251, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00285, val_loss: 0.00242, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00260, val_loss: 0.00229, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00246, val_loss: 0.00218, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00226, val_loss: 0.00206, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00212, val_loss: 0.00196, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00197, val_loss: 0.00188, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00180, val_loss: 0.00180, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00169, val_loss: 0.00172, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00159, val_loss: 0.00168, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00149, val_loss: 0.00164, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00138, val_loss: 0.00161, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00130, val_loss: 0.00159, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00120, val_loss: 0.00154, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00113, val_loss: 0.00153, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00109, val_loss: 0.00151, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00099, val_loss: 0.00148, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00094, val_loss: 0.00148, lr: 1.09E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00090, val_loss: 0.00150, lr: 1.09E-04, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00089, val_loss: 0.00149, lr: 1.09E-04, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00079, val_loss: 0.00148, lr: 1.09E-04, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00074, val_loss: 0.00149, lr: 1.09E-04, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00072, val_loss: 0.00152, lr: 1.09E-04, _patience: 5\n",
            "Epoch: 26 | train_loss: 0.00066, val_loss: 0.00149, lr: 1.09E-05, _patience: 4\n",
            "Epoch: 27 | train_loss: 0.00063, val_loss: 0.00145, lr: 1.09E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00057, val_loss: 0.00141, lr: 1.09E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00056, val_loss: 0.00142, lr: 1.09E-05, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00056, val_loss: 0.00143, lr: 1.09E-05, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00055, val_loss: 0.00141, lr: 1.09E-05, _patience: 7\n",
            "Epoch: 32 | train_loss: 0.00054, val_loss: 0.00142, lr: 1.09E-05, _patience: 6\n",
            "Epoch: 33 | train_loss: 0.00054, val_loss: 0.00142, lr: 1.09E-05, _patience: 5\n",
            "Epoch: 34 | train_loss: 0.00053, val_loss: 0.00142, lr: 1.09E-06, _patience: 4\n",
            "Epoch: 35 | train_loss: 0.00052, val_loss: 0.00142, lr: 1.09E-06, _patience: 3\n",
            "Epoch: 36 | train_loss: 0.00052, val_loss: 0.00142, lr: 1.09E-06, _patience: 2\n",
            "Epoch: 37 | train_loss: 0.00052, val_loss: 0.00142, lr: 1.09E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 20:59:55,292]\u001b[0m Trial 26 finished with value: 0.6281324534171198 and parameters: {'embedding_dim': 286, 'num_filters': 456, 'hidden_dim': 322, 'dropout_p': 0.486589676160375, 'lr': 0.0001087827885519171}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00522, val_loss: 0.00280, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00328, val_loss: 0.00283, lr: 5.85E-05, _patience: 9\n",
            "Epoch: 3 | train_loss: 0.00311, val_loss: 0.00267, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00291, val_loss: 0.00261, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00288, val_loss: 0.00257, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00280, val_loss: 0.00254, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00274, val_loss: 0.00249, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00265, val_loss: 0.00245, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00258, val_loss: 0.00240, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00246, val_loss: 0.00235, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00240, val_loss: 0.00230, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00228, val_loss: 0.00224, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00224, val_loss: 0.00218, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00215, val_loss: 0.00213, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00206, val_loss: 0.00209, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00198, val_loss: 0.00203, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00193, val_loss: 0.00199, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00187, val_loss: 0.00194, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00177, val_loss: 0.00190, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00173, val_loss: 0.00187, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00165, val_loss: 0.00183, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00160, val_loss: 0.00179, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00155, val_loss: 0.00176, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00150, val_loss: 0.00174, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00144, val_loss: 0.00171, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00139, val_loss: 0.00168, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00135, val_loss: 0.00167, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00131, val_loss: 0.00165, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00125, val_loss: 0.00163, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00124, val_loss: 0.00161, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00118, val_loss: 0.00158, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00115, val_loss: 0.00158, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00111, val_loss: 0.00157, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 34 | train_loss: 0.00107, val_loss: 0.00156, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 35 | train_loss: 0.00104, val_loss: 0.00154, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 36 | train_loss: 0.00102, val_loss: 0.00153, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00099, val_loss: 0.00152, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 38 | train_loss: 0.00094, val_loss: 0.00151, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00090, val_loss: 0.00152, lr: 5.85E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00087, val_loss: 0.00150, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 41 | train_loss: 0.00085, val_loss: 0.00149, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 42 | train_loss: 0.00082, val_loss: 0.00149, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 43 | train_loss: 0.00082, val_loss: 0.00149, lr: 5.85E-05, _patience: 9\n",
            "Epoch: 44 | train_loss: 0.00077, val_loss: 0.00148, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00076, val_loss: 0.00148, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 46 | train_loss: 0.00073, val_loss: 0.00146, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 47 | train_loss: 0.00071, val_loss: 0.00146, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 48 | train_loss: 0.00067, val_loss: 0.00145, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 49 | train_loss: 0.00066, val_loss: 0.00145, lr: 5.85E-05, _patience: 9\n",
            "Epoch: 50 | train_loss: 0.00066, val_loss: 0.00144, lr: 5.85E-05, _patience: 10\n",
            "Epoch: 51 | train_loss: 0.00062, val_loss: 0.00145, lr: 5.85E-05, _patience: 9\n",
            "Epoch: 52 | train_loss: 0.00061, val_loss: 0.00146, lr: 5.85E-05, _patience: 8\n",
            "Epoch: 53 | train_loss: 0.00059, val_loss: 0.00145, lr: 5.85E-05, _patience: 7\n",
            "Epoch: 54 | train_loss: 0.00057, val_loss: 0.00146, lr: 5.85E-05, _patience: 6\n",
            "Epoch: 55 | train_loss: 0.00055, val_loss: 0.00148, lr: 5.85E-05, _patience: 5\n",
            "Epoch: 56 | train_loss: 0.00053, val_loss: 0.00146, lr: 5.85E-06, _patience: 4\n",
            "Epoch: 57 | train_loss: 0.00052, val_loss: 0.00146, lr: 5.85E-06, _patience: 3\n",
            "Epoch: 58 | train_loss: 0.00050, val_loss: 0.00145, lr: 5.85E-06, _patience: 2\n",
            "Epoch: 59 | train_loss: 0.00052, val_loss: 0.00145, lr: 5.85E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:01:23,479]\u001b[0m Trial 27 finished with value: 0.6176287191944866 and parameters: {'embedding_dim': 214, 'num_filters': 283, 'hidden_dim': 227, 'dropout_p': 0.3058323873898069, 'lr': 5.84690758029616e-05}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00477, val_loss: 0.00356, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00352, val_loss: 0.00260, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00293, val_loss: 0.00247, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00265, val_loss: 0.00237, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00244, val_loss: 0.00224, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00225, val_loss: 0.00214, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00204, val_loss: 0.00204, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00188, val_loss: 0.00194, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00173, val_loss: 0.00186, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00161, val_loss: 0.00179, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00148, val_loss: 0.00175, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00137, val_loss: 0.00170, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00130, val_loss: 0.00167, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00121, val_loss: 0.00163, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00113, val_loss: 0.00160, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00104, val_loss: 0.00155, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00097, val_loss: 0.00156, lr: 1.05E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00092, val_loss: 0.00153, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00086, val_loss: 0.00153, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00080, val_loss: 0.00153, lr: 1.05E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00074, val_loss: 0.00151, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00071, val_loss: 0.00151, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00066, val_loss: 0.00151, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00063, val_loss: 0.00149, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00059, val_loss: 0.00151, lr: 1.05E-04, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00057, val_loss: 0.00147, lr: 1.05E-04, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00054, val_loss: 0.00148, lr: 1.05E-04, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00049, val_loss: 0.00153, lr: 1.05E-04, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00047, val_loss: 0.00150, lr: 1.05E-04, _patience: 7\n",
            "Epoch: 30 | train_loss: 0.00045, val_loss: 0.00151, lr: 1.05E-04, _patience: 6\n",
            "Epoch: 31 | train_loss: 0.00042, val_loss: 0.00151, lr: 1.05E-04, _patience: 5\n",
            "Epoch: 32 | train_loss: 0.00041, val_loss: 0.00154, lr: 1.05E-05, _patience: 4\n",
            "Epoch: 33 | train_loss: 0.00037, val_loss: 0.00151, lr: 1.05E-05, _patience: 3\n",
            "Epoch: 34 | train_loss: 0.00034, val_loss: 0.00150, lr: 1.05E-05, _patience: 2\n",
            "Epoch: 35 | train_loss: 0.00034, val_loss: 0.00149, lr: 1.05E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:03:19,774]\u001b[0m Trial 28 finished with value: 0.6181858140623893 and parameters: {'embedding_dim': 334, 'num_filters': 511, 'hidden_dim': 187, 'dropout_p': 0.30137755761096685, 'lr': 0.00010461723250780904}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00466, val_loss: 0.00357, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00356, val_loss: 0.00266, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00304, val_loss: 0.00260, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00288, val_loss: 0.00252, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00270, val_loss: 0.00242, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00257, val_loss: 0.00231, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00233, val_loss: 0.00221, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00218, val_loss: 0.00211, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00202, val_loss: 0.00200, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00190, val_loss: 0.00192, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00176, val_loss: 0.00184, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00162, val_loss: 0.00176, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00152, val_loss: 0.00170, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00142, val_loss: 0.00165, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00132, val_loss: 0.00162, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00128, val_loss: 0.00157, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00117, val_loss: 0.00158, lr: 1.48E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00108, val_loss: 0.00153, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00101, val_loss: 0.00152, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00096, val_loss: 0.00155, lr: 1.48E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00090, val_loss: 0.00154, lr: 1.48E-04, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00085, val_loss: 0.00150, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00078, val_loss: 0.00151, lr: 1.48E-04, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00074, val_loss: 0.00154, lr: 1.48E-04, _patience: 8\n",
            "Epoch: 25 | train_loss: 0.00069, val_loss: 0.00156, lr: 1.48E-04, _patience: 7\n",
            "Epoch: 26 | train_loss: 0.00066, val_loss: 0.00151, lr: 1.48E-04, _patience: 6\n",
            "Epoch: 27 | train_loss: 0.00061, val_loss: 0.00149, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00059, val_loss: 0.00147, lr: 1.48E-04, _patience: 10\n",
            "Epoch: 29 | train_loss: 0.00055, val_loss: 0.00157, lr: 1.48E-04, _patience: 9\n",
            "Epoch: 30 | train_loss: 0.00054, val_loss: 0.00152, lr: 1.48E-04, _patience: 8\n",
            "Epoch: 31 | train_loss: 0.00049, val_loss: 0.00154, lr: 1.48E-04, _patience: 7\n",
            "Epoch: 32 | train_loss: 0.00047, val_loss: 0.00149, lr: 1.48E-04, _patience: 6\n",
            "Epoch: 33 | train_loss: 0.00043, val_loss: 0.00154, lr: 1.48E-04, _patience: 5\n",
            "Epoch: 34 | train_loss: 0.00041, val_loss: 0.00151, lr: 1.48E-05, _patience: 4\n",
            "Epoch: 35 | train_loss: 0.00038, val_loss: 0.00148, lr: 1.48E-05, _patience: 3\n",
            "Epoch: 36 | train_loss: 0.00035, val_loss: 0.00146, lr: 1.48E-05, _patience: 10\n",
            "Epoch: 37 | train_loss: 0.00035, val_loss: 0.00147, lr: 1.48E-05, _patience: 9\n",
            "Epoch: 38 | train_loss: 0.00035, val_loss: 0.00146, lr: 1.48E-05, _patience: 10\n",
            "Epoch: 39 | train_loss: 0.00034, val_loss: 0.00147, lr: 1.48E-05, _patience: 9\n",
            "Epoch: 40 | train_loss: 0.00034, val_loss: 0.00148, lr: 1.48E-05, _patience: 8\n",
            "Epoch: 41 | train_loss: 0.00035, val_loss: 0.00147, lr: 1.48E-05, _patience: 7\n",
            "Epoch: 42 | train_loss: 0.00034, val_loss: 0.00147, lr: 1.48E-05, _patience: 6\n",
            "Epoch: 43 | train_loss: 0.00033, val_loss: 0.00147, lr: 1.48E-05, _patience: 5\n",
            "Epoch: 44 | train_loss: 0.00033, val_loss: 0.00147, lr: 1.48E-06, _patience: 4\n",
            "Epoch: 45 | train_loss: 0.00033, val_loss: 0.00147, lr: 1.48E-06, _patience: 3\n",
            "Epoch: 46 | train_loss: 0.00033, val_loss: 0.00147, lr: 1.48E-06, _patience: 2\n",
            "Epoch: 47 | train_loss: 0.00033, val_loss: 0.00147, lr: 1.48E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:04:28,607]\u001b[0m Trial 29 finished with value: 0.6163783728069442 and parameters: {'embedding_dim': 159, 'num_filters': 362, 'hidden_dim': 272, 'dropout_p': 0.3789652951295809, 'lr': 0.0001483147710524721}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00529, val_loss: 0.00309, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00398, val_loss: 0.00274, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00338, val_loss: 0.00254, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00314, val_loss: 0.00246, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00291, val_loss: 0.00238, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00276, val_loss: 0.00230, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00256, val_loss: 0.00221, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00240, val_loss: 0.00214, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00232, val_loss: 0.00206, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00215, val_loss: 0.00200, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00203, val_loss: 0.00192, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00190, val_loss: 0.00188, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00183, val_loss: 0.00183, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00171, val_loss: 0.00178, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00164, val_loss: 0.00176, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00159, val_loss: 0.00171, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00150, val_loss: 0.00168, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00141, val_loss: 0.00165, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 19 | train_loss: 0.00135, val_loss: 0.00162, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00129, val_loss: 0.00160, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00121, val_loss: 0.00159, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00117, val_loss: 0.00156, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 23 | train_loss: 0.00114, val_loss: 0.00158, lr: 9.58E-05, _patience: 9\n",
            "Epoch: 24 | train_loss: 0.00109, val_loss: 0.00155, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00100, val_loss: 0.00154, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 26 | train_loss: 0.00096, val_loss: 0.00153, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 27 | train_loss: 0.00093, val_loss: 0.00154, lr: 9.58E-05, _patience: 9\n",
            "Epoch: 28 | train_loss: 0.00089, val_loss: 0.00154, lr: 9.58E-05, _patience: 8\n",
            "Epoch: 29 | train_loss: 0.00086, val_loss: 0.00152, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 30 | train_loss: 0.00080, val_loss: 0.00151, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 31 | train_loss: 0.00076, val_loss: 0.00151, lr: 9.58E-05, _patience: 9\n",
            "Epoch: 32 | train_loss: 0.00075, val_loss: 0.00149, lr: 9.58E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00071, val_loss: 0.00149, lr: 9.58E-05, _patience: 9\n",
            "Epoch: 34 | train_loss: 0.00069, val_loss: 0.00155, lr: 9.58E-05, _patience: 8\n",
            "Epoch: 35 | train_loss: 0.00065, val_loss: 0.00153, lr: 9.58E-05, _patience: 7\n",
            "Epoch: 36 | train_loss: 0.00061, val_loss: 0.00149, lr: 9.58E-05, _patience: 6\n",
            "Epoch: 37 | train_loss: 0.00061, val_loss: 0.00154, lr: 9.58E-05, _patience: 5\n",
            "Epoch: 38 | train_loss: 0.00058, val_loss: 0.00150, lr: 9.58E-06, _patience: 4\n",
            "Epoch: 39 | train_loss: 0.00056, val_loss: 0.00148, lr: 9.58E-06, _patience: 10\n",
            "Epoch: 40 | train_loss: 0.00054, val_loss: 0.00148, lr: 9.58E-06, _patience: 9\n",
            "Epoch: 41 | train_loss: 0.00053, val_loss: 0.00149, lr: 9.58E-06, _patience: 8\n",
            "Epoch: 42 | train_loss: 0.00053, val_loss: 0.00149, lr: 9.58E-06, _patience: 7\n",
            "Epoch: 43 | train_loss: 0.00052, val_loss: 0.00150, lr: 9.58E-06, _patience: 6\n",
            "Epoch: 44 | train_loss: 0.00052, val_loss: 0.00147, lr: 9.58E-06, _patience: 10\n",
            "Epoch: 45 | train_loss: 0.00050, val_loss: 0.00150, lr: 9.58E-06, _patience: 9\n",
            "Epoch: 46 | train_loss: 0.00053, val_loss: 0.00147, lr: 9.58E-06, _patience: 8\n",
            "Epoch: 47 | train_loss: 0.00050, val_loss: 0.00148, lr: 9.58E-06, _patience: 7\n",
            "Epoch: 48 | train_loss: 0.00051, val_loss: 0.00148, lr: 9.58E-06, _patience: 6\n",
            "Epoch: 49 | train_loss: 0.00049, val_loss: 0.00148, lr: 9.58E-06, _patience: 5\n",
            "Epoch: 50 | train_loss: 0.00050, val_loss: 0.00148, lr: 9.58E-07, _patience: 4\n",
            "Epoch: 51 | train_loss: 0.00049, val_loss: 0.00149, lr: 9.58E-07, _patience: 3\n",
            "Epoch: 52 | train_loss: 0.00050, val_loss: 0.00149, lr: 9.58E-07, _patience: 2\n",
            "Epoch: 53 | train_loss: 0.00050, val_loss: 0.00149, lr: 9.58E-07, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:06:37,930]\u001b[0m Trial 30 finished with value: 0.6053325926456903 and parameters: {'embedding_dim': 289, 'num_filters': 411, 'hidden_dim': 131, 'dropout_p': 0.4029785545873523, 'lr': 9.58248712475719e-05}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00479, val_loss: 0.00369, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00364, val_loss: 0.00259, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00305, val_loss: 0.00251, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00284, val_loss: 0.00244, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00265, val_loss: 0.00231, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00244, val_loss: 0.00220, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00229, val_loss: 0.00208, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00213, val_loss: 0.00200, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00196, val_loss: 0.00193, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00185, val_loss: 0.00183, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00170, val_loss: 0.00178, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00161, val_loss: 0.00172, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00149, val_loss: 0.00166, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00140, val_loss: 0.00163, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00131, val_loss: 0.00159, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00125, val_loss: 0.00156, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00115, val_loss: 0.00153, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00111, val_loss: 0.00155, lr: 1.03E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00105, val_loss: 0.00150, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00097, val_loss: 0.00151, lr: 1.03E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00094, val_loss: 0.00149, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00087, val_loss: 0.00149, lr: 1.03E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00085, val_loss: 0.00145, lr: 1.03E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00078, val_loss: 0.00147, lr: 1.03E-04, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00075, val_loss: 0.00145, lr: 1.03E-04, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00068, val_loss: 0.00147, lr: 1.03E-04, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00066, val_loss: 0.00146, lr: 1.03E-04, _patience: 6\n",
            "Epoch: 28 | train_loss: 0.00061, val_loss: 0.00146, lr: 1.03E-04, _patience: 5\n",
            "Epoch: 29 | train_loss: 0.00060, val_loss: 0.00150, lr: 1.03E-05, _patience: 4\n",
            "Epoch: 30 | train_loss: 0.00054, val_loss: 0.00145, lr: 1.03E-05, _patience: 3\n",
            "Epoch: 31 | train_loss: 0.00050, val_loss: 0.00143, lr: 1.03E-05, _patience: 10\n",
            "Epoch: 32 | train_loss: 0.00050, val_loss: 0.00142, lr: 1.03E-05, _patience: 10\n",
            "Epoch: 33 | train_loss: 0.00050, val_loss: 0.00143, lr: 1.03E-05, _patience: 9\n",
            "Epoch: 34 | train_loss: 0.00048, val_loss: 0.00143, lr: 1.03E-05, _patience: 8\n",
            "Epoch: 35 | train_loss: 0.00048, val_loss: 0.00143, lr: 1.03E-05, _patience: 7\n",
            "Epoch: 36 | train_loss: 0.00048, val_loss: 0.00144, lr: 1.03E-05, _patience: 6\n",
            "Epoch: 37 | train_loss: 0.00047, val_loss: 0.00144, lr: 1.03E-05, _patience: 5\n",
            "Epoch: 38 | train_loss: 0.00046, val_loss: 0.00144, lr: 1.03E-06, _patience: 4\n",
            "Epoch: 39 | train_loss: 0.00046, val_loss: 0.00144, lr: 1.03E-06, _patience: 3\n",
            "Epoch: 40 | train_loss: 0.00047, val_loss: 0.00144, lr: 1.03E-06, _patience: 2\n",
            "Epoch: 41 | train_loss: 0.00046, val_loss: 0.00144, lr: 1.03E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:08:27,426]\u001b[0m Trial 31 finished with value: 0.6198800477347535 and parameters: {'embedding_dim': 289, 'num_filters': 454, 'hidden_dim': 313, 'dropout_p': 0.4871262999352162, 'lr': 0.0001030303514829418}. Best is trial 23 with value: 0.6326352768602452.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00502, val_loss: 0.00371, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00366, val_loss: 0.00256, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00298, val_loss: 0.00244, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00272, val_loss: 0.00228, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00244, val_loss: 0.00211, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00219, val_loss: 0.00196, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00197, val_loss: 0.00187, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00174, val_loss: 0.00179, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00163, val_loss: 0.00171, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00146, val_loss: 0.00163, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00136, val_loss: 0.00160, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00125, val_loss: 0.00158, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00112, val_loss: 0.00155, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00103, val_loss: 0.00147, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00095, val_loss: 0.00150, lr: 1.43E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00086, val_loss: 0.00147, lr: 1.43E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00081, val_loss: 0.00146, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00076, val_loss: 0.00147, lr: 1.43E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00068, val_loss: 0.00146, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00064, val_loss: 0.00143, lr: 1.43E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00061, val_loss: 0.00145, lr: 1.43E-04, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00057, val_loss: 0.00146, lr: 1.43E-04, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00053, val_loss: 0.00147, lr: 1.43E-04, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00049, val_loss: 0.00151, lr: 1.43E-04, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00047, val_loss: 0.00152, lr: 1.43E-04, _patience: 5\n",
            "Epoch: 26 | train_loss: 0.00046, val_loss: 0.00154, lr: 1.43E-05, _patience: 4\n",
            "Epoch: 27 | train_loss: 0.00043, val_loss: 0.00150, lr: 1.43E-05, _patience: 3\n",
            "Epoch: 28 | train_loss: 0.00035, val_loss: 0.00151, lr: 1.43E-05, _patience: 2\n",
            "Epoch: 29 | train_loss: 0.00036, val_loss: 0.00150, lr: 1.43E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:09:54,151]\u001b[0m Trial 32 finished with value: 0.6383824161957408 and parameters: {'embedding_dim': 322, 'num_filters': 458, 'hidden_dim': 329, 'dropout_p': 0.4850596118064628, 'lr': 0.0001432421400352145}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00526, val_loss: 0.00355, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00356, val_loss: 0.00255, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00300, val_loss: 0.00243, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00272, val_loss: 0.00222, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00242, val_loss: 0.00206, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00216, val_loss: 0.00192, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00194, val_loss: 0.00183, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00172, val_loss: 0.00174, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00160, val_loss: 0.00165, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00142, val_loss: 0.00161, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00129, val_loss: 0.00157, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00117, val_loss: 0.00154, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00111, val_loss: 0.00146, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00097, val_loss: 0.00152, lr: 1.63E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00091, val_loss: 0.00145, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00083, val_loss: 0.00144, lr: 1.63E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00078, val_loss: 0.00153, lr: 1.63E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00070, val_loss: 0.00152, lr: 1.63E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00065, val_loss: 0.00154, lr: 1.63E-04, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00060, val_loss: 0.00151, lr: 1.63E-04, _patience: 6\n",
            "Epoch: 21 | train_loss: 0.00056, val_loss: 0.00155, lr: 1.63E-04, _patience: 5\n",
            "Epoch: 22 | train_loss: 0.00054, val_loss: 0.00152, lr: 1.63E-05, _patience: 4\n",
            "Epoch: 23 | train_loss: 0.00048, val_loss: 0.00149, lr: 1.63E-05, _patience: 3\n",
            "Epoch: 24 | train_loss: 0.00042, val_loss: 0.00149, lr: 1.63E-05, _patience: 2\n",
            "Epoch: 25 | train_loss: 0.00038, val_loss: 0.00149, lr: 1.63E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:11:14,038]\u001b[0m Trial 33 finished with value: 0.6381354672338425 and parameters: {'embedding_dim': 323, 'num_filters': 482, 'hidden_dim': 405, 'dropout_p': 0.5674191822253696, 'lr': 0.00016291923914375255}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00574, val_loss: 0.00363, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00386, val_loss: 0.00251, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00305, val_loss: 0.00231, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00259, val_loss: 0.00206, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00224, val_loss: 0.00187, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00198, val_loss: 0.00175, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00173, val_loss: 0.00166, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00154, val_loss: 0.00158, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00141, val_loss: 0.00156, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00126, val_loss: 0.00151, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00115, val_loss: 0.00149, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00099, val_loss: 0.00150, lr: 2.13E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00091, val_loss: 0.00146, lr: 2.13E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00083, val_loss: 0.00147, lr: 2.13E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00072, val_loss: 0.00158, lr: 2.13E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00068, val_loss: 0.00149, lr: 2.13E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00060, val_loss: 0.00148, lr: 2.13E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00054, val_loss: 0.00159, lr: 2.13E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00051, val_loss: 0.00147, lr: 2.13E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00045, val_loss: 0.00156, lr: 2.13E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00039, val_loss: 0.00146, lr: 2.13E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00037, val_loss: 0.00149, lr: 2.13E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:12:33,645]\u001b[0m Trial 34 finished with value: 0.6343387317471216 and parameters: {'embedding_dim': 371, 'num_filters': 486, 'hidden_dim': 379, 'dropout_p': 0.5926268762490299, 'lr': 0.00021337707475364417}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00578, val_loss: 0.00366, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00376, val_loss: 0.00255, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00300, val_loss: 0.00237, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00256, val_loss: 0.00215, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00225, val_loss: 0.00196, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00194, val_loss: 0.00182, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00173, val_loss: 0.00170, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00155, val_loss: 0.00164, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00136, val_loss: 0.00159, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00123, val_loss: 0.00152, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00110, val_loss: 0.00157, lr: 2.11E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00102, val_loss: 0.00147, lr: 2.11E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00088, val_loss: 0.00152, lr: 2.11E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00079, val_loss: 0.00153, lr: 2.11E-04, _patience: 8\n",
            "Epoch: 15 | train_loss: 0.00072, val_loss: 0.00155, lr: 2.11E-04, _patience: 7\n",
            "Epoch: 16 | train_loss: 0.00064, val_loss: 0.00156, lr: 2.11E-04, _patience: 6\n",
            "Epoch: 17 | train_loss: 0.00060, val_loss: 0.00170, lr: 2.11E-04, _patience: 5\n",
            "Epoch: 18 | train_loss: 0.00059, val_loss: 0.00165, lr: 2.11E-05, _patience: 4\n",
            "Epoch: 19 | train_loss: 0.00048, val_loss: 0.00153, lr: 2.11E-05, _patience: 3\n",
            "Epoch: 20 | train_loss: 0.00042, val_loss: 0.00150, lr: 2.11E-05, _patience: 2\n",
            "Epoch: 21 | train_loss: 0.00040, val_loss: 0.00150, lr: 2.11E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:13:50,748]\u001b[0m Trial 35 finished with value: 0.6152748303760257 and parameters: {'embedding_dim': 373, 'num_filters': 489, 'hidden_dim': 390, 'dropout_p': 0.5827438442139319, 'lr': 0.0002106251302862915}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00618, val_loss: 0.00369, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00392, val_loss: 0.00257, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00310, val_loss: 0.00237, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00268, val_loss: 0.00210, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00229, val_loss: 0.00194, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00198, val_loss: 0.00180, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00180, val_loss: 0.00170, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00158, val_loss: 0.00163, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00139, val_loss: 0.00155, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00126, val_loss: 0.00150, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00113, val_loss: 0.00151, lr: 2.36E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00099, val_loss: 0.00149, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00086, val_loss: 0.00152, lr: 2.36E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00079, val_loss: 0.00147, lr: 2.36E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00068, val_loss: 0.00149, lr: 2.36E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00062, val_loss: 0.00150, lr: 2.36E-04, _patience: 8\n",
            "Epoch: 17 | train_loss: 0.00055, val_loss: 0.00155, lr: 2.36E-04, _patience: 7\n",
            "Epoch: 18 | train_loss: 0.00052, val_loss: 0.00154, lr: 2.36E-04, _patience: 6\n",
            "Epoch: 19 | train_loss: 0.00048, val_loss: 0.00166, lr: 2.36E-04, _patience: 5\n",
            "Epoch: 20 | train_loss: 0.00046, val_loss: 0.00161, lr: 2.36E-05, _patience: 4\n",
            "Epoch: 21 | train_loss: 0.00038, val_loss: 0.00157, lr: 2.36E-05, _patience: 3\n",
            "Epoch: 22 | train_loss: 0.00033, val_loss: 0.00152, lr: 2.36E-05, _patience: 2\n",
            "Epoch: 23 | train_loss: 0.00032, val_loss: 0.00153, lr: 2.36E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:15:11,327]\u001b[0m Trial 36 finished with value: 0.605181386693785 and parameters: {'embedding_dim': 364, 'num_filters': 486, 'hidden_dim': 435, 'dropout_p': 0.6354300037378942, 'lr': 0.0002360360309857605}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00544, val_loss: 0.00374, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00365, val_loss: 0.00257, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00299, val_loss: 0.00246, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00270, val_loss: 0.00224, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00235, val_loss: 0.00207, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00206, val_loss: 0.00191, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00190, val_loss: 0.00182, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00167, val_loss: 0.00174, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00153, val_loss: 0.00168, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00141, val_loss: 0.00163, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00131, val_loss: 0.00157, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00118, val_loss: 0.00153, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00109, val_loss: 0.00150, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00097, val_loss: 0.00151, lr: 1.55E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00088, val_loss: 0.00150, lr: 1.55E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00080, val_loss: 0.00152, lr: 1.55E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00073, val_loss: 0.00155, lr: 1.55E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00068, val_loss: 0.00165, lr: 1.55E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00065, val_loss: 0.00158, lr: 1.55E-04, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00056, val_loss: 0.00152, lr: 1.55E-04, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00051, val_loss: 0.00158, lr: 1.55E-05, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00045, val_loss: 0.00151, lr: 1.55E-05, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00040, val_loss: 0.00147, lr: 1.55E-05, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00041, val_loss: 0.00147, lr: 1.55E-05, _patience: 10\n",
            "Epoch: 25 | train_loss: 0.00040, val_loss: 0.00148, lr: 1.55E-05, _patience: 9\n",
            "Epoch: 26 | train_loss: 0.00039, val_loss: 0.00147, lr: 1.55E-05, _patience: 8\n",
            "Epoch: 27 | train_loss: 0.00038, val_loss: 0.00146, lr: 1.55E-05, _patience: 10\n",
            "Epoch: 28 | train_loss: 0.00036, val_loss: 0.00147, lr: 1.55E-05, _patience: 9\n",
            "Epoch: 29 | train_loss: 0.00038, val_loss: 0.00147, lr: 1.55E-05, _patience: 8\n",
            "Epoch: 30 | train_loss: 0.00037, val_loss: 0.00146, lr: 1.55E-05, _patience: 7\n",
            "Epoch: 31 | train_loss: 0.00037, val_loss: 0.00147, lr: 1.55E-05, _patience: 6\n",
            "Epoch: 32 | train_loss: 0.00035, val_loss: 0.00146, lr: 1.55E-05, _patience: 5\n",
            "Epoch: 33 | train_loss: 0.00035, val_loss: 0.00147, lr: 1.55E-06, _patience: 4\n",
            "Epoch: 34 | train_loss: 0.00034, val_loss: 0.00147, lr: 1.55E-06, _patience: 3\n",
            "Epoch: 35 | train_loss: 0.00035, val_loss: 0.00147, lr: 1.55E-06, _patience: 2\n",
            "Epoch: 36 | train_loss: 0.00034, val_loss: 0.00147, lr: 1.55E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:17:12,570]\u001b[0m Trial 37 finished with value: 0.6270994175259204 and parameters: {'embedding_dim': 345, 'num_filters': 512, 'hidden_dim': 449, 'dropout_p': 0.5580624317452938, 'lr': 0.0001554641756818592}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00650, val_loss: 0.00347, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00382, val_loss: 0.00256, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00299, val_loss: 0.00231, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00250, val_loss: 0.00207, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00210, val_loss: 0.00188, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00182, val_loss: 0.00173, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00158, val_loss: 0.00162, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00137, val_loss: 0.00160, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00120, val_loss: 0.00159, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00103, val_loss: 0.00151, lr: 2.84E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00089, val_loss: 0.00152, lr: 2.84E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00076, val_loss: 0.00155, lr: 2.84E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00070, val_loss: 0.00154, lr: 2.84E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00061, val_loss: 0.00159, lr: 2.84E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00053, val_loss: 0.00157, lr: 2.84E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00051, val_loss: 0.00157, lr: 2.84E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00043, val_loss: 0.00155, lr: 2.84E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00036, val_loss: 0.00153, lr: 2.84E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00036, val_loss: 0.00151, lr: 2.84E-05, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00033, val_loss: 0.00152, lr: 2.84E-05, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00030, val_loss: 0.00152, lr: 2.84E-05, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00031, val_loss: 0.00152, lr: 2.84E-05, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00030, val_loss: 0.00154, lr: 2.84E-05, _patience: 6\n",
            "Epoch: 24 | train_loss: 0.00030, val_loss: 0.00152, lr: 2.84E-05, _patience: 5\n",
            "Epoch: 25 | train_loss: 0.00029, val_loss: 0.00152, lr: 2.84E-06, _patience: 4\n",
            "Epoch: 26 | train_loss: 0.00029, val_loss: 0.00152, lr: 2.84E-06, _patience: 3\n",
            "Epoch: 27 | train_loss: 0.00029, val_loss: 0.00152, lr: 2.84E-06, _patience: 2\n",
            "Epoch: 28 | train_loss: 0.00028, val_loss: 0.00153, lr: 2.84E-06, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:18:37,703]\u001b[0m Trial 38 finished with value: 0.6123523682809692 and parameters: {'embedding_dim': 323, 'num_filters': 468, 'hidden_dim': 505, 'dropout_p': 0.612024788157089, 'lr': 0.00028398817627934723}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00897, val_loss: 0.00307, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00394, val_loss: 0.00286, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00313, val_loss: 0.00232, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00259, val_loss: 0.00200, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00217, val_loss: 0.00176, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00182, val_loss: 0.00165, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00160, val_loss: 0.00158, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00139, val_loss: 0.00152, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00117, val_loss: 0.00149, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00098, val_loss: 0.00162, lr: 4.96E-04, _patience: 9\n",
            "Epoch: 11 | train_loss: 0.00085, val_loss: 0.00167, lr: 4.96E-04, _patience: 8\n",
            "Epoch: 12 | train_loss: 0.00074, val_loss: 0.00150, lr: 4.96E-04, _patience: 7\n",
            "Epoch: 13 | train_loss: 0.00065, val_loss: 0.00147, lr: 4.96E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00061, val_loss: 0.00174, lr: 4.96E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00062, val_loss: 0.00241, lr: 4.96E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00075, val_loss: 0.00152, lr: 4.96E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00051, val_loss: 0.00179, lr: 4.96E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00044, val_loss: 0.00171, lr: 4.96E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00038, val_loss: 0.00165, lr: 4.96E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00029, val_loss: 0.00185, lr: 4.96E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00026, val_loss: 0.00182, lr: 4.96E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00025, val_loss: 0.00178, lr: 4.96E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:20:01,271]\u001b[0m Trial 39 finished with value: 0.6376519589884427 and parameters: {'embedding_dim': 391, 'num_filters': 512, 'hidden_dim': 401, 'dropout_p': 0.6890441253911903, 'lr': 0.000496041357212239}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00850, val_loss: 0.00300, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00391, val_loss: 0.00268, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00310, val_loss: 0.00220, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00250, val_loss: 0.00194, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00216, val_loss: 0.00179, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00188, val_loss: 0.00166, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00165, val_loss: 0.00159, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00138, val_loss: 0.00151, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00119, val_loss: 0.00146, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00099, val_loss: 0.00143, lr: 4.54E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00088, val_loss: 0.00170, lr: 4.54E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00081, val_loss: 0.00184, lr: 4.54E-04, _patience: 8\n",
            "Epoch: 13 | train_loss: 0.00078, val_loss: 0.00143, lr: 4.54E-04, _patience: 7\n",
            "Epoch: 14 | train_loss: 0.00076, val_loss: 0.00163, lr: 4.54E-04, _patience: 6\n",
            "Epoch: 15 | train_loss: 0.00065, val_loss: 0.00186, lr: 4.54E-04, _patience: 5\n",
            "Epoch: 16 | train_loss: 0.00057, val_loss: 0.00153, lr: 4.54E-05, _patience: 4\n",
            "Epoch: 17 | train_loss: 0.00046, val_loss: 0.00180, lr: 4.54E-05, _patience: 3\n",
            "Epoch: 18 | train_loss: 0.00038, val_loss: 0.00165, lr: 4.54E-05, _patience: 2\n",
            "Epoch: 19 | train_loss: 0.00035, val_loss: 0.00166, lr: 4.54E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:21:25,990]\u001b[0m Trial 40 finished with value: 0.6220080717450269 and parameters: {'embedding_dim': 454, 'num_filters': 511, 'hidden_dim': 395, 'dropout_p': 0.7106028117711465, 'lr': 0.000454189664634792}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00596, val_loss: 0.00360, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00404, val_loss: 0.00256, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00323, val_loss: 0.00242, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00286, val_loss: 0.00224, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00250, val_loss: 0.00206, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00224, val_loss: 0.00194, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00207, val_loss: 0.00182, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00180, val_loss: 0.00174, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00166, val_loss: 0.00163, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00150, val_loss: 0.00158, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00133, val_loss: 0.00153, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00126, val_loss: 0.00156, lr: 1.95E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00113, val_loss: 0.00151, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00104, val_loss: 0.00151, lr: 1.95E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00095, val_loss: 0.00153, lr: 1.95E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00090, val_loss: 0.00151, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00083, val_loss: 0.00147, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 18 | train_loss: 0.00074, val_loss: 0.00156, lr: 1.95E-04, _patience: 9\n",
            "Epoch: 19 | train_loss: 0.00070, val_loss: 0.00146, lr: 1.95E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00066, val_loss: 0.00153, lr: 1.95E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00060, val_loss: 0.00157, lr: 1.95E-04, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00055, val_loss: 0.00155, lr: 1.95E-04, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00051, val_loss: 0.00157, lr: 1.95E-04, _patience: 6\n",
            "Epoch: 24 | train_loss: 0.00047, val_loss: 0.00164, lr: 1.95E-04, _patience: 5\n",
            "Epoch: 25 | train_loss: 0.00043, val_loss: 0.00155, lr: 1.95E-05, _patience: 4\n",
            "Epoch: 26 | train_loss: 0.00038, val_loss: 0.00165, lr: 1.95E-05, _patience: 3\n",
            "Epoch: 27 | train_loss: 0.00037, val_loss: 0.00153, lr: 1.95E-05, _patience: 2\n",
            "Epoch: 28 | train_loss: 0.00033, val_loss: 0.00159, lr: 1.95E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:23:13,170]\u001b[0m Trial 41 finished with value: 0.6314601910432183 and parameters: {'embedding_dim': 395, 'num_filters': 493, 'hidden_dim': 378, 'dropout_p': 0.6780432763892239, 'lr': 0.00019501840122838513}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00534, val_loss: 0.00350, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00367, val_loss: 0.00253, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00303, val_loss: 0.00242, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00272, val_loss: 0.00222, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00243, val_loss: 0.00205, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00220, val_loss: 0.00196, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00198, val_loss: 0.00181, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00175, val_loss: 0.00171, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00159, val_loss: 0.00167, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00150, val_loss: 0.00159, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00135, val_loss: 0.00157, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00125, val_loss: 0.00152, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00114, val_loss: 0.00150, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00100, val_loss: 0.00147, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00091, val_loss: 0.00148, lr: 1.78E-04, _patience: 9\n",
            "Epoch: 16 | train_loss: 0.00084, val_loss: 0.00143, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00076, val_loss: 0.00145, lr: 1.78E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00071, val_loss: 0.00146, lr: 1.78E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00065, val_loss: 0.00155, lr: 1.78E-04, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00063, val_loss: 0.00142, lr: 1.78E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00054, val_loss: 0.00146, lr: 1.78E-04, _patience: 9\n",
            "Epoch: 22 | train_loss: 0.00051, val_loss: 0.00152, lr: 1.78E-04, _patience: 8\n",
            "Epoch: 23 | train_loss: 0.00047, val_loss: 0.00155, lr: 1.78E-04, _patience: 7\n",
            "Epoch: 24 | train_loss: 0.00044, val_loss: 0.00155, lr: 1.78E-04, _patience: 6\n",
            "Epoch: 25 | train_loss: 0.00042, val_loss: 0.00155, lr: 1.78E-04, _patience: 5\n",
            "Epoch: 26 | train_loss: 0.00039, val_loss: 0.00151, lr: 1.78E-05, _patience: 4\n",
            "Epoch: 27 | train_loss: 0.00035, val_loss: 0.00154, lr: 1.78E-05, _patience: 3\n",
            "Epoch: 28 | train_loss: 0.00032, val_loss: 0.00150, lr: 1.78E-05, _patience: 2\n",
            "Epoch: 29 | train_loss: 0.00030, val_loss: 0.00152, lr: 1.78E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:24:37,535]\u001b[0m Trial 42 finished with value: 0.6184966130615616 and parameters: {'embedding_dim': 323, 'num_filters': 438, 'hidden_dim': 415, 'dropout_p': 0.6089382630939351, 'lr': 0.00017778532292201955}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00840, val_loss: 0.00339, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00406, val_loss: 0.00268, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00314, val_loss: 0.00229, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00260, val_loss: 0.00201, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00230, val_loss: 0.00184, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00196, val_loss: 0.00172, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00174, val_loss: 0.00161, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00154, val_loss: 0.00152, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00136, val_loss: 0.00152, lr: 4.03E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00118, val_loss: 0.00149, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00101, val_loss: 0.00147, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00090, val_loss: 0.00148, lr: 4.03E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00081, val_loss: 0.00149, lr: 4.03E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00073, val_loss: 0.00167, lr: 4.03E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00069, val_loss: 0.00145, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00062, val_loss: 0.00142, lr: 4.03E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00065, val_loss: 0.00169, lr: 4.03E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00065, val_loss: 0.00218, lr: 4.03E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00075, val_loss: 0.00157, lr: 4.03E-04, _patience: 7\n",
            "Epoch: 20 | train_loss: 0.00058, val_loss: 0.00151, lr: 4.03E-04, _patience: 6\n",
            "Epoch: 21 | train_loss: 0.00051, val_loss: 0.00179, lr: 4.03E-04, _patience: 5\n",
            "Epoch: 22 | train_loss: 0.00045, val_loss: 0.00156, lr: 4.03E-05, _patience: 4\n",
            "Epoch: 23 | train_loss: 0.00036, val_loss: 0.00181, lr: 4.03E-05, _patience: 3\n",
            "Epoch: 24 | train_loss: 0.00033, val_loss: 0.00173, lr: 4.03E-05, _patience: 2\n",
            "Epoch: 25 | train_loss: 0.00029, val_loss: 0.00175, lr: 4.03E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:26:10,427]\u001b[0m Trial 43 finished with value: 0.6240404272505599 and parameters: {'embedding_dim': 399, 'num_filters': 474, 'hidden_dim': 489, 'dropout_p': 0.763391865479536, 'lr': 0.0004029967590110221}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00504, val_loss: 0.00357, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00354, val_loss: 0.00262, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00303, val_loss: 0.00251, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00280, val_loss: 0.00236, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00258, val_loss: 0.00223, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00230, val_loss: 0.00209, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00211, val_loss: 0.00195, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00193, val_loss: 0.00185, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00178, val_loss: 0.00176, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00162, val_loss: 0.00169, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00146, val_loss: 0.00164, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00139, val_loss: 0.00160, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00127, val_loss: 0.00157, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00119, val_loss: 0.00156, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 15 | train_loss: 0.00110, val_loss: 0.00154, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00098, val_loss: 0.00153, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 17 | train_loss: 0.00091, val_loss: 0.00154, lr: 1.45E-04, _patience: 9\n",
            "Epoch: 18 | train_loss: 0.00087, val_loss: 0.00156, lr: 1.45E-04, _patience: 8\n",
            "Epoch: 19 | train_loss: 0.00084, val_loss: 0.00152, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00075, val_loss: 0.00147, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 21 | train_loss: 0.00070, val_loss: 0.00146, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 22 | train_loss: 0.00063, val_loss: 0.00154, lr: 1.45E-04, _patience: 9\n",
            "Epoch: 23 | train_loss: 0.00057, val_loss: 0.00144, lr: 1.45E-04, _patience: 10\n",
            "Epoch: 24 | train_loss: 0.00056, val_loss: 0.00152, lr: 1.45E-04, _patience: 9\n",
            "Epoch: 25 | train_loss: 0.00053, val_loss: 0.00148, lr: 1.45E-04, _patience: 8\n",
            "Epoch: 26 | train_loss: 0.00046, val_loss: 0.00151, lr: 1.45E-04, _patience: 7\n",
            "Epoch: 27 | train_loss: 0.00044, val_loss: 0.00154, lr: 1.45E-04, _patience: 6\n",
            "Epoch: 28 | train_loss: 0.00044, val_loss: 0.00155, lr: 1.45E-04, _patience: 5\n",
            "Epoch: 29 | train_loss: 0.00040, val_loss: 0.00156, lr: 1.45E-05, _patience: 4\n",
            "Epoch: 30 | train_loss: 0.00036, val_loss: 0.00150, lr: 1.45E-05, _patience: 3\n",
            "Epoch: 31 | train_loss: 0.00033, val_loss: 0.00147, lr: 1.45E-05, _patience: 2\n",
            "Epoch: 32 | train_loss: 0.00033, val_loss: 0.00150, lr: 1.45E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:27:29,424]\u001b[0m Trial 44 finished with value: 0.6029958119936436 and parameters: {'embedding_dim': 272, 'num_filters': 450, 'hidden_dim': 349, 'dropout_p': 0.5161272329666778, 'lr': 0.0001445766559276582}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00691, val_loss: 0.00410, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00437, val_loss: 0.00258, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00335, val_loss: 0.00242, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00287, val_loss: 0.00223, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00253, val_loss: 0.00198, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00224, val_loss: 0.00181, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00201, val_loss: 0.00174, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00184, val_loss: 0.00163, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00164, val_loss: 0.00158, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00147, val_loss: 0.00152, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00136, val_loss: 0.00156, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00130, val_loss: 0.00147, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00112, val_loss: 0.00146, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00099, val_loss: 0.00149, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00090, val_loss: 0.00144, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00080, val_loss: 0.00146, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00073, val_loss: 0.00149, lr: 2.40E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00066, val_loss: 0.00150, lr: 2.40E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00063, val_loss: 0.00143, lr: 2.40E-04, _patience: 10\n",
            "Epoch: 20 | train_loss: 0.00059, val_loss: 0.00149, lr: 2.40E-04, _patience: 9\n",
            "Epoch: 21 | train_loss: 0.00055, val_loss: 0.00156, lr: 2.40E-04, _patience: 8\n",
            "Epoch: 22 | train_loss: 0.00054, val_loss: 0.00162, lr: 2.40E-04, _patience: 7\n",
            "Epoch: 23 | train_loss: 0.00048, val_loss: 0.00165, lr: 2.40E-04, _patience: 6\n",
            "Epoch: 24 | train_loss: 0.00049, val_loss: 0.00160, lr: 2.40E-04, _patience: 5\n",
            "Epoch: 25 | train_loss: 0.00045, val_loss: 0.00162, lr: 2.40E-05, _patience: 4\n",
            "Epoch: 26 | train_loss: 0.00037, val_loss: 0.00161, lr: 2.40E-05, _patience: 3\n",
            "Epoch: 27 | train_loss: 0.00034, val_loss: 0.00160, lr: 2.40E-05, _patience: 2\n",
            "Epoch: 28 | train_loss: 0.00032, val_loss: 0.00156, lr: 2.40E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:29:09,405]\u001b[0m Trial 45 finished with value: 0.6276888355976069 and parameters: {'embedding_dim': 363, 'num_filters': 497, 'hidden_dim': 420, 'dropout_p': 0.7243934332587528, 'lr': 0.0002402307551301771}. Best is trial 32 with value: 0.6383824161957408.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00686, val_loss: 0.00363, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00400, val_loss: 0.00256, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00309, val_loss: 0.00233, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00259, val_loss: 0.00207, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00222, val_loss: 0.00190, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00194, val_loss: 0.00175, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00176, val_loss: 0.00166, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00155, val_loss: 0.00160, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00132, val_loss: 0.00157, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00119, val_loss: 0.00152, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00102, val_loss: 0.00146, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00090, val_loss: 0.00152, lr: 2.98E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00080, val_loss: 0.00145, lr: 2.98E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00068, val_loss: 0.00154, lr: 2.98E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00063, val_loss: 0.00150, lr: 2.98E-04, _patience: 8\n",
            "Epoch: 16 | train_loss: 0.00055, val_loss: 0.00155, lr: 2.98E-04, _patience: 7\n",
            "Epoch: 17 | train_loss: 0.00050, val_loss: 0.00156, lr: 2.98E-04, _patience: 6\n",
            "Epoch: 18 | train_loss: 0.00043, val_loss: 0.00158, lr: 2.98E-04, _patience: 5\n",
            "Epoch: 19 | train_loss: 0.00040, val_loss: 0.00156, lr: 2.98E-05, _patience: 4\n",
            "Epoch: 20 | train_loss: 0.00035, val_loss: 0.00166, lr: 2.98E-05, _patience: 3\n",
            "Epoch: 21 | train_loss: 0.00031, val_loss: 0.00158, lr: 2.98E-05, _patience: 2\n",
            "Epoch: 22 | train_loss: 0.00029, val_loss: 0.00159, lr: 2.98E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:30:20,638]\u001b[0m Trial 46 finished with value: 0.63900047716579 and parameters: {'embedding_dim': 335, 'num_filters': 477, 'hidden_dim': 458, 'dropout_p': 0.6707843486583486, 'lr': 0.00029782100137454434}. Best is trial 46 with value: 0.63900047716579.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00740, val_loss: 0.00374, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00410, val_loss: 0.00260, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00313, val_loss: 0.00233, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00260, val_loss: 0.00204, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00218, val_loss: 0.00184, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00193, val_loss: 0.00169, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00166, val_loss: 0.00163, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00146, val_loss: 0.00158, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00130, val_loss: 0.00153, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00110, val_loss: 0.00147, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00094, val_loss: 0.00148, lr: 3.32E-04, _patience: 9\n",
            "Epoch: 12 | train_loss: 0.00084, val_loss: 0.00147, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 13 | train_loss: 0.00073, val_loss: 0.00150, lr: 3.32E-04, _patience: 9\n",
            "Epoch: 14 | train_loss: 0.00063, val_loss: 0.00154, lr: 3.32E-04, _patience: 8\n",
            "Epoch: 15 | train_loss: 0.00057, val_loss: 0.00145, lr: 3.32E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00055, val_loss: 0.00169, lr: 3.32E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00051, val_loss: 0.00154, lr: 3.32E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00045, val_loss: 0.00152, lr: 3.32E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00038, val_loss: 0.00165, lr: 3.32E-04, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00036, val_loss: 0.00147, lr: 3.32E-04, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00034, val_loss: 0.00167, lr: 3.32E-05, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00029, val_loss: 0.00166, lr: 3.32E-05, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00025, val_loss: 0.00166, lr: 3.32E-05, _patience: 2\n",
            "Epoch: 24 | train_loss: 0.00022, val_loss: 0.00167, lr: 3.32E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:31:39,431]\u001b[0m Trial 47 finished with value: 0.629418507423591 and parameters: {'embedding_dim': 338, 'num_filters': 481, 'hidden_dim': 460, 'dropout_p': 0.6732750861661326, 'lr': 0.00033226717385043044}. Best is trial 46 with value: 0.63900047716579.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00671, val_loss: 0.00345, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00372, val_loss: 0.00257, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00288, val_loss: 0.00223, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00230, val_loss: 0.00193, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00196, val_loss: 0.00179, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00168, val_loss: 0.00168, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00143, val_loss: 0.00160, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00125, val_loss: 0.00151, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00102, val_loss: 0.00152, lr: 3.16E-04, _patience: 9\n",
            "Epoch: 10 | train_loss: 0.00089, val_loss: 0.00155, lr: 3.16E-04, _patience: 8\n",
            "Epoch: 11 | train_loss: 0.00079, val_loss: 0.00149, lr: 3.16E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00070, val_loss: 0.00152, lr: 3.16E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00058, val_loss: 0.00154, lr: 3.16E-04, _patience: 8\n",
            "Epoch: 14 | train_loss: 0.00051, val_loss: 0.00162, lr: 3.16E-04, _patience: 7\n",
            "Epoch: 15 | train_loss: 0.00042, val_loss: 0.00161, lr: 3.16E-04, _patience: 6\n",
            "Epoch: 16 | train_loss: 0.00037, val_loss: 0.00173, lr: 3.16E-04, _patience: 5\n",
            "Epoch: 17 | train_loss: 0.00035, val_loss: 0.00163, lr: 3.16E-05, _patience: 4\n",
            "Epoch: 18 | train_loss: 0.00031, val_loss: 0.00170, lr: 3.16E-05, _patience: 3\n",
            "Epoch: 19 | train_loss: 0.00027, val_loss: 0.00160, lr: 3.16E-05, _patience: 2\n",
            "Epoch: 20 | train_loss: 0.00024, val_loss: 0.00164, lr: 3.16E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:32:54,462]\u001b[0m Trial 48 finished with value: 0.634300450199267 and parameters: {'embedding_dim': 383, 'num_filters': 512, 'hidden_dim': 432, 'dropout_p': 0.5836919809831129, 'lr': 0.0003161256849611265}. Best is trial 46 with value: 0.63900047716579.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.00729, val_loss: 0.00378, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 2 | train_loss: 0.00441, val_loss: 0.00262, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 3 | train_loss: 0.00349, val_loss: 0.00240, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 4 | train_loss: 0.00299, val_loss: 0.00222, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 5 | train_loss: 0.00266, val_loss: 0.00205, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 6 | train_loss: 0.00242, val_loss: 0.00189, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 7 | train_loss: 0.00215, val_loss: 0.00174, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 8 | train_loss: 0.00197, val_loss: 0.00168, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 9 | train_loss: 0.00178, val_loss: 0.00165, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 10 | train_loss: 0.00165, val_loss: 0.00154, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 11 | train_loss: 0.00150, val_loss: 0.00151, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 12 | train_loss: 0.00136, val_loss: 0.00157, lr: 2.62E-04, _patience: 9\n",
            "Epoch: 13 | train_loss: 0.00120, val_loss: 0.00150, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 14 | train_loss: 0.00105, val_loss: 0.00156, lr: 2.62E-04, _patience: 9\n",
            "Epoch: 15 | train_loss: 0.00102, val_loss: 0.00143, lr: 2.62E-04, _patience: 10\n",
            "Epoch: 16 | train_loss: 0.00095, val_loss: 0.00155, lr: 2.62E-04, _patience: 9\n",
            "Epoch: 17 | train_loss: 0.00090, val_loss: 0.00160, lr: 2.62E-04, _patience: 8\n",
            "Epoch: 18 | train_loss: 0.00082, val_loss: 0.00144, lr: 2.62E-04, _patience: 7\n",
            "Epoch: 19 | train_loss: 0.00074, val_loss: 0.00150, lr: 2.62E-04, _patience: 6\n",
            "Epoch: 20 | train_loss: 0.00070, val_loss: 0.00155, lr: 2.62E-04, _patience: 5\n",
            "Epoch: 21 | train_loss: 0.00067, val_loss: 0.00161, lr: 2.62E-05, _patience: 4\n",
            "Epoch: 22 | train_loss: 0.00059, val_loss: 0.00157, lr: 2.62E-05, _patience: 3\n",
            "Epoch: 23 | train_loss: 0.00051, val_loss: 0.00159, lr: 2.62E-05, _patience: 2\n",
            "Epoch: 24 | train_loss: 0.00049, val_loss: 0.00158, lr: 2.62E-05, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 21:34:31,708]\u001b[0m Trial 49 finished with value: 0.6220047640997922 and parameters: {'embedding_dim': 485, 'num_filters': 420, 'hidden_dim': 477, 'dropout_p': 0.7984462152799114, 'lr': 0.0002619841505205434}. Best is trial 46 with value: 0.63900047716579.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfRGqQaGkfx8",
        "outputId": "be095549-cbe3-49d9-fc8f-6053fb2151a2"
      },
      "source": [
        "# MLFlow dashboard\n",
        "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: https://177f5e1c3edf.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NojJ-Z1X6IEQ"
      },
      "source": [
        "You can compare all (or a subset) of the trials in our experiment.\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/applied-ml/hyperparameter_optimization/compare.png\" width=\"1000\" alt=\"compare\">\n",
        "\n",
        "We can then view the results through various lens (contours, parallel coordinates, etc.)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/applied-ml/hyperparameter_optimization/contour.png\" width=\"1000\" alt=\"compare\">\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/images/applied-ml/hyperparameter_optimization/parallel_coordinates.png\" width=\"1000\" alt=\"compare\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "9HtwFRzEikt7",
        "outputId": "c63c2636-24b0-4443-e0b5-7dbeb1c5df24"
      },
      "source": [
        "# All trials\n",
        "trials_df = study.trials_dataframe()\n",
        "trials_df = trials_df.sort_values([\"value\"], ascending=False)  # sort by metric\n",
        "trials_df.head()"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_dropout_p</th>\n",
              "      <th>params_embedding_dim</th>\n",
              "      <th>params_hidden_dim</th>\n",
              "      <th>params_lr</th>\n",
              "      <th>params_num_filters</th>\n",
              "      <th>user_attrs_f1</th>\n",
              "      <th>user_attrs_precision</th>\n",
              "      <th>user_attrs_recall</th>\n",
              "      <th>user_attrs_threshold</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>2021-01-26 21:29:09.435991</td>\n",
              "      <td>2021-01-26 21:30:20.637867</td>\n",
              "      <td>0 days 00:01:11.201876</td>\n",
              "      <td>0.670784</td>\n",
              "      <td>335</td>\n",
              "      <td>458</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>477</td>\n",
              "      <td>0.639000</td>\n",
              "      <td>0.852947</td>\n",
              "      <td>0.540094</td>\n",
              "      <td>0.221352</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>0.638382</td>\n",
              "      <td>2021-01-26 21:08:27.456865</td>\n",
              "      <td>2021-01-26 21:09:54.151386</td>\n",
              "      <td>0 days 00:01:26.694521</td>\n",
              "      <td>0.485060</td>\n",
              "      <td>322</td>\n",
              "      <td>329</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>458</td>\n",
              "      <td>0.638382</td>\n",
              "      <td>0.860706</td>\n",
              "      <td>0.535624</td>\n",
              "      <td>0.285308</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>0.638135</td>\n",
              "      <td>2021-01-26 21:09:54.182560</td>\n",
              "      <td>2021-01-26 21:11:14.038009</td>\n",
              "      <td>0 days 00:01:19.855449</td>\n",
              "      <td>0.567419</td>\n",
              "      <td>323</td>\n",
              "      <td>405</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>482</td>\n",
              "      <td>0.638135</td>\n",
              "      <td>0.872309</td>\n",
              "      <td>0.537566</td>\n",
              "      <td>0.298093</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>0.637652</td>\n",
              "      <td>2021-01-26 21:18:37.735567</td>\n",
              "      <td>2021-01-26 21:20:01.271413</td>\n",
              "      <td>0 days 00:01:23.535846</td>\n",
              "      <td>0.689044</td>\n",
              "      <td>391</td>\n",
              "      <td>401</td>\n",
              "      <td>0.000496</td>\n",
              "      <td>512</td>\n",
              "      <td>0.637652</td>\n",
              "      <td>0.852757</td>\n",
              "      <td>0.536279</td>\n",
              "      <td>0.258009</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>0.634339</td>\n",
              "      <td>2021-01-26 21:11:14.068099</td>\n",
              "      <td>2021-01-26 21:12:33.645090</td>\n",
              "      <td>0 days 00:01:19.576991</td>\n",
              "      <td>0.592627</td>\n",
              "      <td>371</td>\n",
              "      <td>379</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>486</td>\n",
              "      <td>0.634339</td>\n",
              "      <td>0.863092</td>\n",
              "      <td>0.531822</td>\n",
              "      <td>0.263524</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number     value  ... user_attrs_threshold     state\n",
              "46      46  0.639000  ...             0.221352  COMPLETE\n",
              "32      32  0.638382  ...             0.285308  COMPLETE\n",
              "33      33  0.638135  ...             0.298093  COMPLETE\n",
              "39      39  0.637652  ...             0.258009  COMPLETE\n",
              "34      34  0.634339  ...             0.263524  COMPLETE\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mP99RFjiENR",
        "outputId": "8c4e541f-dbd3-41ef-b726-3ea5d88f6be4"
      },
      "source": [
        "# Best trial\n",
        "print (f\"Best value (f1): {study.best_trial.value}\")\n",
        "print (f\"Best hyperparameters: {study.best_trial.params}\")"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best value (f1): 0.63900047716579\n",
            "Best hyperparameters: {'embedding_dim': 335, 'num_filters': 477, 'hidden_dim': 458, 'dropout_p': 0.6707843486583486, 'lr': 0.00029782100137454434}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pggo1cnaix85"
      },
      "source": [
        "> Don't forget to save learned parameters (ex. decision threshold) during training which you'll need later for inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZIS8RtfiuDc",
        "outputId": "1e83aba6-b997-4748-b5f2-a91f43c4e63c"
      },
      "source": [
        "# Save best parameters\n",
        "params = {**args.__dict__, **study.best_trial.params}\n",
        "params[\"threshold\"] = study.best_trial.user_attrs[\"threshold\"]\n",
        "print (json.dumps(params, indent=2, cls=NumpyEncoder))"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"char_level\": true,\n",
            "  \"filter_sizes\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10\n",
            "  ],\n",
            "  \"batch_size\": 64,\n",
            "  \"embedding_dim\": 335,\n",
            "  \"num_filters\": 477,\n",
            "  \"hidden_dim\": 458,\n",
            "  \"dropout_p\": 0.6707843486583486,\n",
            "  \"lr\": 0.00029782100137454434,\n",
            "  \"num_epochs\": 200,\n",
            "  \"patience\": 10,\n",
            "  \"threshold\": 0.22135180234909058\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbxtdyENi78d"
      },
      "source": [
        "... and now we're finally ready to move from working in Jupyter notebooks to Python scripts. We'll be revisiting everything we did so far, but this time with proper software engineering prinicples such as object oriented programming (OOPs), styling, testing, etc."
      ]
    }
  ]
}